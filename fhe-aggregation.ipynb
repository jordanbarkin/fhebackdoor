{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure GPU (change if not M1 mac)\n",
    "mps = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "# Using CIFAR-10 again as in the programming assignments\n",
    "# Load training data\n",
    "transform_train = transforms.Compose([                                   \n",
    "    transforms.RandomCrop(32, padding=4),                                       \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "# Load testing data\n",
    "transform_test = transforms.Compose([                                           \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving And helpers\n",
    "\n",
    "def save_tracker(tracker, path):\n",
    "  np.savetxt(path, tracker, delimiter=',') \n",
    "\n",
    "def save_trackers(device, filename):\n",
    "  \"\"\"Save all trackers and current total_time to a file.\"\"\"\n",
    "  torch.save((device['train_loss_tracker'], device['train_acc_tracker'], device['test_loss_tracker'], device['test_acc_tracker'], total_time), filename)\n",
    "  print(\"Saved trackers to \" + filename)\n",
    "\n",
    "def moving_average(a, n=100):\n",
    "  '''Helper function used for visualization'''\n",
    "  ret = torch.cumsum(torch.Tensor(a), 0)\n",
    "  ret[n:] = ret[n:] - ret[:-n]\n",
    "  return ret[n - 1:] / n\n",
    "\n",
    "# Plotting helpers! \n",
    "def make_plot(trackers, num_epochs, title, y_axis_lab, should_average=False, legend=True, fix_ax=True):\n",
    "  avg_fn = moving_average if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  if fix_ax:\n",
    "    ax.set_ylim([0, 100])\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "\n",
    "  if legend:\n",
    "    _ = plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def make_plot_better(trackers, num_epochs, title, y_axis_lab, should_average=False, n = 100):\n",
    "  avg_fn = (lambda x : moving_average(x, n)) if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "  _ = plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "def iid_sampler(dataset, num_devices, data_pct):\n",
    "    '''\n",
    "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
    "    num_devices: integer number of devices to create subsets for\n",
    "    data_pct: percentalge of training samples to give each device\n",
    "              e.g., 0.1 represents 10%\n",
    "\n",
    "    return: a dictionary of the following format:\n",
    "      {\n",
    "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
    "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
    "        ...\n",
    "      }\n",
    "\n",
    "    iid (independent and identically distributed) means that the indexes\n",
    "    should be drawn independently in a uniformly random fashion.\n",
    "    '''\n",
    "    total_samples = len(dataset)\n",
    "    sampled = {}\n",
    "    number_samples = int((data_pct)*(total_samples)) \n",
    "\n",
    "    for i in range(num_devices):\n",
    "      sampled[i] = random.sample(range(total_samples), number_samples)\n",
    "        \n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net definitions\n",
    "\n",
    "# Same ConvNet as in Assignment 2 and 3\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
    "               padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
    "                  bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(3, 32),\n",
    "            conv_block(32, 32),\n",
    "            conv_block(32, 64, stride=2),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 128, stride=2),\n",
    "            conv_block(128, 128),\n",
    "            conv_block(128, 256),\n",
    "            conv_block(256, 256),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        B, C, _, _ = h.shape\n",
    "        h = h.view(B, C)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning helpers\n",
    "\n",
    "# The baseline `average' function. \n",
    "def average_weights(devices,*args, **kwargs):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "#     max_magnitude = 0\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "      w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "#             max_magnitude = max(max_magnitude, abs(torch.max(state_dicts[i][k].type(torch.float32))))\n",
    "            w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "def get_devices_for_round(devices, device_pct):  \n",
    "    return random.sample(devices, int(device_pct * len(devices)))\n",
    "\n",
    "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
    "                  milestones=None, batch_size=128):\n",
    "    if milestones == None:\n",
    "        milestones = [25, 50, 75]\n",
    "\n",
    "    device_net = copy.deepcopy(net)\n",
    "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                     milestones=milestones,\n",
    "                                                     gamma=0.1)\n",
    "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
    "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True)\n",
    "    return {\n",
    "        'net': device_net,\n",
    "        'id': device_id,\n",
    "        'dataloader': device_trainloader, \n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'train_loss_tracker': [],\n",
    "        'train_acc_tracker': [],\n",
    "        'test_loss_tracker': [],\n",
    "        'test_acc_tracker': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local device training and testing\n",
    "def train(epoch, device, criterion):\n",
    "    device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "        inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "        device['optimizer'].zero_grad()\n",
    "        outputs = device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        device['optimizer'].step()\n",
    "        train_loss += loss.item()\n",
    "        device['train_loss_tracker'].append(loss.item())\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        dev_id = device['id']\n",
    "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' + \n",
    "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "        sys.stdout.flush()\n",
    "    device['train_acc_tracker'].append(acc)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def test(epoch, device, criterion, testloader = testloader):\n",
    "    device['net'].eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "            outputs = device['net'](inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            device['test_loss_tracker'].append(loss.item())\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            loss = test_loss / (batch_idx + 1)\n",
    "            acc = 100.* correct / total\n",
    "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
    "    sys.stdout.flush()  \n",
    "    acc = 100.*correct/total\n",
    "    device['test_acc_tracker'].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function tests (the main experiment routine)\n",
    "\n",
    "# Given two different sets of aggregated weights, \n",
    "# gives a value representing the difference between them,\n",
    "# as a way to measure the direct cost of using our aggregated function\n",
    "def diff_aggregated_weights(strat, baseline):\n",
    "    result = 0 \n",
    "    for k in strat.keys():\n",
    "        result += torch.linalg.norm(strat[k] - baseline[k])\n",
    "    return result\n",
    "\n",
    "# A data type for experiment results\n",
    "BackdoorResult = namedtuple(\"BackdoorResult\", [\"scheme_loss\", \"test_accuracy\", \"backdoor_success\", \"devices\", \"avg_weight_history\"])\n",
    "\n",
    "# The main routine! \n",
    "def run_federated_test(agg_fn = average_weights,  # Pass in aggregation function, \n",
    "                                                  # Device list -> aggregated weights \n",
    "                       rounds = 10,               # Rounds of FL\n",
    "                       local_epochs = 4,          # Epochs per device                      \n",
    "                       num_devices = 50,          # Total # devices\n",
    "                       device_pct = 0.1,          # % of devices per round\n",
    "                       data_pct = 0.1,            # % of data each device gets\n",
    "                       net = ConvNet().to(mps),   # Net design; make sure on mps\n",
    "                       evil_round = None,         # If None, no attack; else attacker will mount attack on this round\n",
    "                       attacker_strategy = None,  # device --> void --- set up the local weights on the attacker\n",
    "                       evil_device_id = None,     # Which device attacks? \n",
    "                       evaluate_attack = None,    # Function devices --> <any> measuring how well the attack worked at the end\n",
    "                       output_filename = None, \n",
    "                       snapshot = True, \n",
    "                       resume_from_snap = None):   \n",
    "    def lighten_device(d):\n",
    "        return {\n",
    "            k: d[k] for k in ( 'id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker')\n",
    "        }                                   \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "    devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "    \n",
    "    scheme_loss = []\n",
    "#     max_magnitudes = []\n",
    "    avg_weight_history = []\n",
    "    _starting_round_num = 0\n",
    "    \n",
    "    if resume_from_snap: \n",
    "        print(\"Resuming from snapshot!\\n\")\n",
    "        # Load what we can\n",
    "        result = resume_from_snap\n",
    "        scheme_loss = result.scheme_loss\n",
    "        avg_weight_history = result.avg_weight_history\n",
    "        partial_devices = result.devices\n",
    "\n",
    "        # Fresh data and devices\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "        devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "\n",
    "        # Restore the devices with the info from the trackers\n",
    "        def restore_device(old_device, new_device):\n",
    "            for k in ('id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker'):\n",
    "                new_device[k] = old_device[k]\n",
    "            return new_device\n",
    "        \n",
    "        print(\"Restoring devices\\n\")\n",
    "        devices = [restore_device(partial_devices[i], devices[i]) for i in range(len(devices))]\n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(avg_weight_history[-1])\n",
    "        \n",
    "        _starting_round_num = len(result.test_accuracy)\n",
    "        print(\"Finished restoring\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "    ## IID Federated Learning\n",
    "    start_time = time.time()\n",
    "    for round_num in range(_starting_round_num, rounds):\n",
    "        round_start_time = time.time()\n",
    "        # Part 1.3: Implement getting devices for each round here\n",
    "        round_devices = get_devices_for_round(devices, device_pct)\n",
    "\n",
    "        print('Round: ', round_num)\n",
    "        # Train locally \n",
    "        for device in round_devices:\n",
    "            for local_epoch in range(local_epochs):\n",
    "                train(local_epoch, device, criterion)\n",
    "        \n",
    "        # One device becomes evil if required\n",
    "        if (evil_round and round_num == evil_round):\n",
    "            assert (evil_device_id is not None)\n",
    "            assert (attacker_strategy is not None)\n",
    "            print(\"Attacking!\\n\")\n",
    "            \n",
    "            attacker_strategy(devices[evil_device_id])\n",
    "            # Make sure evil guy gets averaged in \n",
    "            if evil_device_id not in round_devices:\n",
    "                round_devices.append(devices[evil_device_id])\n",
    "            print(\"Finished attacking\\n\")\n",
    "            \n",
    "        \n",
    "        # Weight averaging\n",
    "        w_baseline = average_weights(round_devices)\n",
    "        w_avg = agg_fn(round_devices, avg_weight_history[-1] if avg_weight_history != [] else None)\n",
    "#         max_magnitudes.append(max_magnitude)\n",
    "        \n",
    "        # Track the difference between the two; should be 0 if straight average\n",
    "        scheme_loss.append((float(diff_aggregated_weights(w_avg, w_baseline))))\n",
    "        \n",
    "        avg_weight_history.append(copy.deepcopy(w_avg))\n",
    "        \n",
    "        # Gradients         \n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(w_avg)\n",
    "            device['optimizer'].zero_grad()\n",
    "            device['optimizer'].step()\n",
    "            device['scheduler'].step()\n",
    "\n",
    "        # test accuracy after aggregation\n",
    "        # device 0 is the unique device with all of the \n",
    "        # test accuracies and losses in its tracker\n",
    "        test(round_num, devices[0], criterion)\n",
    "        \n",
    "        print(f\"\\nDiff: {scheme_loss[-1]}\\n\")\n",
    "        print(f\"Round time: {time.time() - start_time} \\n\")\n",
    "        if snapshot:\n",
    "            intermediate_result = BackdoorResult(\n",
    "                scheme_loss = scheme_loss, \n",
    "                test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "                backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "                devices = [lighten_device(d) for d in devices], \n",
    "                avg_weight_history = avg_weight_history\n",
    "            )\n",
    "\n",
    "\n",
    "            if output_filename is not None: \n",
    "                print(\"Writing snapshot\\n\")\n",
    "                with open(f\"snapshot_{output_filename}\", 'wb') as file: \n",
    "                    pickle.dump(intermediate_result, file)\n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    print('Total training time: {} seconds'.format(total_time))\n",
    "    \n",
    "    # Pack up everything we care about and the devices for good measure\n",
    "    result = BackdoorResult(\n",
    "        scheme_loss = scheme_loss, \n",
    "        test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "        backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "        devices = [lighten_device(d) for d in devices], \n",
    "        avg_weight_history = avg_weight_history\n",
    "    )\n",
    "\n",
    "    \n",
    "    if output_filename is not None: \n",
    "        with open(output_filename, 'wb') as file: \n",
    "            print(\"Writing file\\n\")\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Load output files back into memory\n",
    "def load_result(filename):\n",
    "    with open(filename, 'rb') as file: \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 5/Epoch 0) Train Loss: 2.025 | Train Acc: 23.580 | Test Loss: 2.479 | Test Acc: 22.110\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 17.671808004379272 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  1\n",
      "(Device 8/Epoch 0) Train Loss: 1.886 | Train Acc: 28.580 | Test Loss: 2.093 | Test Acc: 26.130\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 35.062156200408936 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 35.09929609298706 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "results = run_federated_test(local_epochs=1, num_devices = 10, rounds = 2, output_filename = \"testout.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also load it back\n",
    "# results = load_result(\"snapshot_testout.pickle\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A silly attack that just sends massive weights all of magnitude 10000\n",
    "def sample_attack(device):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    weights = device[\"net\"].state_dict().copy()\n",
    "    \n",
    "    for w in weights.keys():\n",
    "        weights[w] = torch.full(weights[w].size(), 10000)\n",
    "    \n",
    "    device['net'].load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function that squashes any weights with magnitude over 1000 (except on the first device but whatever)\n",
    "def super_smart_aggregation(devices):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights, excluding huge updates.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "        w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "            if (torch.max(state_dicts[i][k].type(torch.float32)) <= 1000): \n",
    "                w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 9/Epoch 0) Train Loss: 2.168 | Train Acc: 18.415"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/3893217655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Here, we carry out the attack but use the ordinary average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n\u001b[0m\u001b[1;32m      5\u001b[0m                                          \u001b[0mrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mlocal_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/3626052363.py\u001b[0m in \u001b[0;36mrun_federated_test\u001b[0;34m(agg_fn, rounds, local_epochs, num_devices, device_pct, data_pct, net, evil_round, attacker_strategy, evil_device_id, evaluate_attack, output_filename, snapshot, resume_from_snap)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mround_devices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlocal_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# One device becomes evil if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/275447899.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, device, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss_tracker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    198\u001b[0m          \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m          \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example of how this works\n",
    "\n",
    "# Here, we carry out the attack but use the ordinary average\n",
    "results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 3,              \n",
    "                                         local_epochs = 1,                             \n",
    "                                         num_devices = 10,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 1,        \n",
    "                                         attacker_strategy = sample_attack,  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline_trivial_attack.pickle\")  \n",
    "# Observe that it absolutely destroys our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 7/Epoch 0) Train Loss: 2.018 | Train Acc: 23.180 | Test Loss: 18.179 | Test Acc: 12.360\n",
      "\n",
      "Diff: 84.85118865966797\n",
      "\n",
      "Round:  1\n",
      "(Device 9/Epoch 0) Train Loss: 1.873 | Train Acc: 29.680Attacking!\n",
      "\n",
      " | Test Loss: 3.511 | Test Acc: 17.340\n",
      "\n",
      "Diff: 10114592.0\n",
      "\n",
      "Round:  2\n",
      "(Device 2/Epoch 0) Train Loss: 1.789 | Train Acc: 32.900 | Test Loss: 2.722 | Test Acc: 23.900\n",
      "\n",
      "Diff: 46.39040756225586\n",
      "\n",
      "Total training time: 56.98331904411316 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now we do it again but with the aggregation that rejects huge updates\n",
    "results_reject_huge = run_federated_test(agg_fn = super_smart_aggregation,                    \n",
    "                                         rounds = 3,              \n",
    "                                         local_epochs = 1,                             \n",
    "                                         num_devices = 10,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 1,        \n",
    "                                         attacker_strategy = sample_attack,  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None,\n",
    "                                         output_filename = \"simple_attack_and_defense.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 2/Epoch 3) Train Loss: 1.727 | Train Acc: 34.8200 | Test Loss: 2.821 | Test Acc: 10.200\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  1\n",
      "(Device 24/Epoch 3) Train Loss: 1.562 | Train Acc: 41.420 | Test Loss: 1.498 | Test Acc: 44.420\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  2\n",
      "(Device 21/Epoch 3) Train Loss: 1.314 | Train Acc: 50.700 | Test Loss: 1.242 | Test Acc: 54.680\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  3\n",
      "(Device 9/Epoch 3) Train Loss: 1.142 | Train Acc: 59.3200 | Test Loss: 1.086 | Test Acc: 60.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  4\n",
      "(Device 15/Epoch 3) Train Loss: 1.108 | Train Acc: 59.800 | Test Loss: 0.965 | Test Acc: 65.690\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  5\n",
      "(Device 1/Epoch 3) Train Loss: 1.012 | Train Acc: 63.1400 | Test Loss: 0.869 | Test Acc: 69.140\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  6\n",
      "(Device 28/Epoch 3) Train Loss: 0.883 | Train Acc: 68.640 | Test Loss: 0.815 | Test Acc: 71.450\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  7\n",
      "(Device 10/Epoch 3) Train Loss: 0.804 | Train Acc: 72.000 | Test Loss: 0.757 | Test Acc: 73.380\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  8\n",
      "(Device 41/Epoch 3) Train Loss: 0.766 | Train Acc: 73.160 | Test Loss: 0.683 | Test Acc: 76.610\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  9\n",
      "(Device 16/Epoch 3) Train Loss: 0.682 | Train Acc: 75.940 | Test Loss: 0.648 | Test Acc: 77.530\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  10\n",
      "(Device 24/Epoch 3) Train Loss: 0.643 | Train Acc: 77.680 | Test Loss: 0.602 | Test Acc: 79.700\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  11\n",
      "(Device 27/Epoch 3) Train Loss: 0.578 | Train Acc: 79.520 | Test Loss: 0.647 | Test Acc: 77.910\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  12\n",
      "(Device 27/Epoch 3) Train Loss: 0.583 | Train Acc: 79.420 | Test Loss: 0.595 | Test Acc: 79.950\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  13\n",
      "(Device 23/Epoch 3) Train Loss: 0.551 | Train Acc: 80.640 | Test Loss: 0.548 | Test Acc: 81.380\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  14\n",
      "(Device 24/Epoch 3) Train Loss: 0.537 | Train Acc: 81.080 | Test Loss: 0.521 | Test Acc: 82.400\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  15\n",
      "(Device 13/Epoch 3) Train Loss: 0.447 | Train Acc: 84.500 | Test Loss: 0.510 | Test Acc: 82.860\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  16\n",
      "(Device 41/Epoch 3) Train Loss: 0.539 | Train Acc: 80.840 | Test Loss: 0.504 | Test Acc: 83.430\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  17\n",
      "(Device 41/Epoch 3) Train Loss: 0.435 | Train Acc: 85.920 | Test Loss: 0.505 | Test Acc: 83.600\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  18\n",
      "(Device 36/Epoch 3) Train Loss: 0.414 | Train Acc: 85.340 | Test Loss: 0.469 | Test Acc: 84.710\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  19\n",
      "(Device 19/Epoch 3) Train Loss: 0.429 | Train Acc: 85.720 | Test Loss: 0.461 | Test Acc: 85.130\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  20\n",
      "(Device 15/Epoch 3) Train Loss: 0.356 | Train Acc: 87.620 | Test Loss: 0.449 | Test Acc: 85.460\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  21\n",
      "(Device 12/Epoch 3) Train Loss: 0.379 | Train Acc: 86.120 | Test Loss: 0.431 | Test Acc: 85.900\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  22\n",
      "(Device 28/Epoch 3) Train Loss: 0.382 | Train Acc: 87.000 | Test Loss: 0.442 | Test Acc: 85.790\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  23\n",
      "(Device 20/Epoch 3) Train Loss: 0.321 | Train Acc: 88.840 | Test Loss: 0.413 | Test Acc: 86.540\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  24\n",
      "(Device 15/Epoch 3) Train Loss: 0.270 | Train Acc: 90.920 | Test Loss: 0.419 | Test Acc: 86.480\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  25\n",
      "(Device 39/Epoch 3) Train Loss: 0.236 | Train Acc: 91.420 | Test Loss: 0.391 | Test Acc: 87.190\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  26\n",
      "(Device 36/Epoch 3) Train Loss: 0.245 | Train Acc: 92.040 | Test Loss: 0.390 | Test Acc: 87.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  27\n",
      "(Device 19/Epoch 3) Train Loss: 0.221 | Train Acc: 92.440 | Test Loss: 0.388 | Test Acc: 87.520\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  28\n",
      "(Device 19/Epoch 3) Train Loss: 0.235 | Train Acc: 92.680 | Test Loss: 0.386 | Test Acc: 87.520\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  29\n",
      "(Device 30/Epoch 3) Train Loss: 0.221 | Train Acc: 92.260 | Test Loss: 0.387 | Test Acc: 87.370\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  30\n",
      "(Device 26/Epoch 3) Train Loss: 0.221 | Train Acc: 92.580 | Test Loss: 0.386 | Test Acc: 87.480\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  31\n",
      "(Device 49/Epoch 3) Train Loss: 0.195 | Train Acc: 93.360 | Test Loss: 0.386 | Test Acc: 87.650\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  32\n",
      "(Device 34/Epoch 3) Train Loss: 0.216 | Train Acc: 93.480 | Test Loss: 0.389 | Test Acc: 87.620\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  33\n",
      "(Device 7/Epoch 3) Train Loss: 0.246 | Train Acc: 91.8800 | Test Loss: 0.384 | Test Acc: 87.560\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  34\n",
      "(Device 38/Epoch 3) Train Loss: 0.186 | Train Acc: 94.140 | Test Loss: 0.385 | Test Acc: 87.580\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  35\n",
      "(Device 44/Epoch 3) Train Loss: 0.189 | Train Acc: 93.860 | Test Loss: 0.387 | Test Acc: 87.700\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  36\n",
      "(Device 25/Epoch 3) Train Loss: 0.210 | Train Acc: 93.400 | Test Loss: 0.387 | Test Acc: 87.630\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  37\n",
      "(Device 38/Epoch 3) Train Loss: 0.184 | Train Acc: 94.600 | Test Loss: 0.389 | Test Acc: 87.620\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  38\n",
      "(Device 10/Epoch 3) Train Loss: 0.209 | Train Acc: 92.800 | Test Loss: 0.388 | Test Acc: 87.800\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  39\n",
      "(Device 47/Epoch 3) Train Loss: 0.180 | Train Acc: 93.820 | Test Loss: 0.388 | Test Acc: 87.760\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  40\n",
      "(Device 2/Epoch 3) Train Loss: 0.192 | Train Acc: 93.3200 | Test Loss: 0.390 | Test Acc: 87.920\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  41\n",
      "(Device 11/Epoch 3) Train Loss: 0.198 | Train Acc: 93.520 | Test Loss: 0.388 | Test Acc: 87.820\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  42\n",
      "(Device 11/Epoch 3) Train Loss: 0.218 | Train Acc: 93.460 | Test Loss: 0.391 | Test Acc: 87.870\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  43\n",
      "(Device 48/Epoch 3) Train Loss: 0.186 | Train Acc: 94.340 | Test Loss: 0.389 | Test Acc: 87.910\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  44\n",
      "(Device 28/Epoch 3) Train Loss: 0.175 | Train Acc: 93.680 | Test Loss: 0.390 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  45\n",
      "(Device 26/Epoch 3) Train Loss: 0.187 | Train Acc: 93.960 | Test Loss: 0.391 | Test Acc: 87.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  46\n",
      "(Device 29/Epoch 3) Train Loss: 0.171 | Train Acc: 93.880 | Test Loss: 0.388 | Test Acc: 88.110\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  47\n",
      "(Device 34/Epoch 3) Train Loss: 0.164 | Train Acc: 94.000 | Test Loss: 0.393 | Test Acc: 87.850\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  48\n",
      "(Device 40/Epoch 3) Train Loss: 0.191 | Train Acc: 94.680 | Test Loss: 0.393 | Test Acc: 87.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  49\n",
      "(Device 30/Epoch 3) Train Loss: 0.162 | Train Acc: 94.740 | Test Loss: 0.392 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  50\n",
      "(Device 48/Epoch 3) Train Loss: 0.177 | Train Acc: 93.800 | Test Loss: 0.391 | Test Acc: 88.090\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  51\n",
      "(Device 9/Epoch 3) Train Loss: 0.173 | Train Acc: 94.1000 | Test Loss: 0.390 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  52\n",
      "(Device 24/Epoch 3) Train Loss: 0.175 | Train Acc: 93.900 | Test Loss: 0.390 | Test Acc: 88.010\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  53\n",
      "(Device 49/Epoch 3) Train Loss: 0.174 | Train Acc: 94.080 | Test Loss: 0.390 | Test Acc: 87.940\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  54\n",
      "(Device 7/Epoch 3) Train Loss: 0.185 | Train Acc: 93.3800 | Test Loss: 0.389 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  55\n",
      "(Device 28/Epoch 3) Train Loss: 0.190 | Train Acc: 94.320 | Test Loss: 0.389 | Test Acc: 88.000\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  56\n",
      "(Device 37/Epoch 3) Train Loss: 0.165 | Train Acc: 94.220 | Test Loss: 0.388 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  57\n",
      "(Device 17/Epoch 3) Train Loss: 0.199 | Train Acc: 93.800 | Test Loss: 0.388 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  58\n",
      "(Device 37/Epoch 3) Train Loss: 0.170 | Train Acc: 94.200 | Test Loss: 0.387 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  59\n",
      "(Device 18/Epoch 3) Train Loss: 0.162 | Train Acc: 94.760 | Test Loss: 0.387 | Test Acc: 88.000\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  60\n",
      "(Device 7/Epoch 3) Train Loss: 0.184 | Train Acc: 93.3600 | Test Loss: 0.388 | Test Acc: 88.170\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  61\n",
      "(Device 40/Epoch 3) Train Loss: 0.170 | Train Acc: 94.060 | Test Loss: 0.387 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  62\n",
      "(Device 30/Epoch 3) Train Loss: 0.173 | Train Acc: 94.480 | Test Loss: 0.389 | Test Acc: 88.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  63\n",
      "(Device 18/Epoch 3) Train Loss: 0.164 | Train Acc: 94.420 | Test Loss: 0.388 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  64\n",
      "(Device 23/Epoch 3) Train Loss: 0.166 | Train Acc: 94.000 | Test Loss: 0.388 | Test Acc: 88.080\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  65\n",
      "(Device 46/Epoch 3) Train Loss: 0.162 | Train Acc: 94.620 | Test Loss: 0.388 | Test Acc: 87.990\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  66\n",
      "(Device 22/Epoch 3) Train Loss: 0.159 | Train Acc: 94.440 | Test Loss: 0.389 | Test Acc: 88.100\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  67\n",
      "(Device 27/Epoch 3) Train Loss: 0.180 | Train Acc: 95.020 | Test Loss: 0.387 | Test Acc: 88.110\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  68\n",
      "(Device 25/Epoch 3) Train Loss: 0.182 | Train Acc: 93.740 | Test Loss: 0.387 | Test Acc: 88.130\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Device 11/Epoch 3) Train Loss: 0.174 | Train Acc: 94.300 | Test Loss: 0.386 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  70\n",
      "(Device 0/Epoch 3) Train Loss: 0.190 | Train Acc: 94.0800 | Test Loss: 0.386 | Test Acc: 88.090\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  71\n",
      "(Device 31/Epoch 3) Train Loss: 0.166 | Train Acc: 94.200 | Test Loss: 0.386 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  72\n",
      "(Device 1/Epoch 1) Train Loss: 0.164 | Train Acc: 94.3820"
     ]
    }
   ],
   "source": [
    "# Here, we compute a real baseline over 100 epochs and typical averaging. Good starting point for future \n",
    "# tests; can resume from this snapshot.\n",
    "baseline = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 100,              \n",
    "                                         local_epochs = 4,                             \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_result(\"baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, now can get things like\n",
    "# baseline.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 27/Epoch 3) Train Loss: 0.324 | Train Acc: 88.320 | Test Loss: 0.409 | Test Acc: 86.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 664.8843719959259 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 667.9921019077301 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can resume from a snapshot:\n",
    "# NOTE : keep all the basic params (local epochs, num devices, net, etc) the same\n",
    "# when resuming from a snapshot \n",
    "baseline2 = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 101,              \n",
    "                                         local_epochs = 4,                             \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline2.pickle\", \n",
    "                                         resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline2_loaded = load_result(\"baseline2.pickle\")\n",
    "baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move on to a real defense. \n",
    "\n",
    "# We create factory functions that let us parametrize a double sigmoid using threshholds\n",
    "\n",
    "def torch_scaled_sigmoid_factory(a, c = 0.005, left = False):\n",
    "    \n",
    "    def f(x):\n",
    "        scaled = torch.sub(x, a)\n",
    "\n",
    "        divisor = c if left else -1*c\n",
    "\n",
    "        scaled = torch.div(scaled, divisor)\n",
    "\n",
    "        return torch.sigmoid(scaled)\n",
    "    return f\n",
    "\n",
    "def torch_double_sigmoid_factory(a,b,c = 0.005):\n",
    "    left = torch_scaled_sigmoid_factory(a, left = True)\n",
    "    right = torch_scaled_sigmoid_factory(b, left = False) \n",
    "    def f(x):\n",
    "        return (left(x)*right(x))\n",
    "    return f\n",
    "\n",
    "my_sigmoid = torch_double_sigmoid_factory(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it works\n",
    "# torch_double_sigmoid_factory(-2,2)(torch.Tensor([-5,-4,-3,-2,-1.5,-1.4,1.3,-1,0,1,1.5,1.6,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sigmoid defense,\n",
    "#     keys_to_range_mapping maps each layer name in the state dict to the sigmoid bounds for processing it\n",
    "#     All other layers just get identity function-ed\n",
    "watcher = {}\n",
    "def make_sigmoid_defense(keys_to_range_mapping, stickiness = 0):\n",
    "    \n",
    "    sigmoid_dict = defaultdict(lambda : (lambda x: 1))\n",
    "    \n",
    "    for k,(a,b) in keys_to_range_mapping.items():\n",
    "        sigmoid_dict[k] = torch_double_sigmoid_factory(a,b)\n",
    "    \n",
    "    def f(devices, previous_round_weights):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights preprocessed by sigmoid\n",
    "        '''\n",
    "        state_dicts = [device['net'].state_dict() for device in devices]\n",
    "        # initialize w_avg to tensors from device 0\n",
    "        w_avg = copy.deepcopy(state_dicts[0])\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "            x = w_avg[k].type(torch.float32)\n",
    "            prev_round_x = previous_round_weights[k].type(torch.float32) if  previous_round_weights is not None else x\n",
    "            print(\"Diff\\n\")\n",
    "            watcher[k] = (x - prev_round_x)\n",
    "            w_avg[k] = x*sig(x - prev_round_x)\n",
    "            for i in range(stickiness):\n",
    "                w_avg[k] += x*sig(x - prev_round_x)                \n",
    "\n",
    "        # for each model param\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "            # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "            prev_round_x = previous_round_weights[k].type(torch.float32)  if  previous_round_weights is not None else x\n",
    "            for i in range(1, len(devices)):\n",
    "                x = (state_dicts[i][k].type(torch.float32))\n",
    "                w_avg[k] += x*sig(x - prev_round_x)\n",
    "            # compute average\n",
    "            w_avg[k] /= float(len(devices) + stickiness)\n",
    "        return w_avg\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.0.0.weight',\n",
       " 'model.1.0.weight',\n",
       " 'model.2.0.weight',\n",
       " 'model.3.0.weight',\n",
       " 'model.4.0.weight',\n",
       " 'model.5.0.weight',\n",
       " 'model.6.0.weight',\n",
       " 'model.7.0.weight',\n",
       " 'model.8.0.weight']"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the actual layer weights that we care about\n",
    "[x for x in baseline.avg_weight_history[-1].keys() if '.0.weight' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up a potential sigmoid defense\n",
    "empirical_cutoffs = {\n",
    "    'model.0.0.weight' : (-2,2),\n",
    "    'model.1.0.weight' : (-2,2),\n",
    "    'model.2.0.weight' : (-.7,.7),\n",
    "    'model.3.0.weight' : (-.6,.6),\n",
    "    'model.4.0.weight' : (-0.7,0.7),\n",
    "    'model.5.0.weight' : (-0.5,0.5),\n",
    "    'model.6.0.weight' : (-0.3,0.3),\n",
    "    'model.7.0.weight' : (-0.2,0.2),\n",
    "    'model.8.0.weight' : (-0.2,0.2),\n",
    "}\n",
    "sigmoid_aggregation = make_sigmoid_defense(empirical_cutoffs, stickiness=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid_resumption = run_federated_test(agg_fn = sigmoid_accuracy,                    \n",
    "#                                          rounds = 110,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = None,\n",
    "#                                          snapshot = False,\n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make an attack\n",
    "# Makes an attack that puts noise in all of target layers. \n",
    "# Noise is uniform over a,b\n",
    "def noise_attack_factory(target_layers, a,b):\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        weights = device[\"net\"].state_dict().copy()\n",
    "\n",
    "        for w in weights.keys():\n",
    "            if w in target_layers:\n",
    "                weights[w] = (a - b) * torch.rand(weights[w].size()) + b\n",
    "\n",
    "        device['net'].load_state_dict(weights)\n",
    "    return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attack these layers with weights ranging from -4,4\n",
    "target_layers = ['model.0.0.weight',\n",
    " 'model.1.0.weight',\n",
    " 'model.2.0.weight',\n",
    " 'model.3.0.weight',\n",
    " 'model.4.0.weight',\n",
    " 'model.5.0.weight',\n",
    " 'model.6.0.weight',\n",
    " 'model.7.0.weight',\n",
    " 'model.8.0.weight']\n",
    "big_noise_attack = noise_attack_factory(target_layers,-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll resume from our baseline model\n",
    "baseline = load_result(\"baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 43/Epoch 3) Train Loss: 0.293 | Train Acc: 89.860 | Test Loss: 0.589 | Test Acc: 82.010\n",
      "\n",
      "Diff: 87.77852630615234\n",
      "\n",
      "Round time: 668.7943501472473 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 9/Epoch 3) Train Loss: 0.320 | Train Acc: 88.5200 | Test Loss: 0.493 | Test Acc: 84.380\n",
      "\n",
      "Diff: 70.42446899414062\n",
      "\n",
      "Round time: 1265.7698509693146 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 40/Epoch 3) Train Loss: 0.216 | Train Acc: 92.800 | Test Loss: 0.565 | Test Acc: 83.180\n",
      "\n",
      "Diff: 77.08517456054688\n",
      "\n",
      "Round time: 1843.9197390079498 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 43/Epoch 3) Train Loss: 0.384 | Train Acc: 86.640 | Test Loss: 0.663 | Test Acc: 79.490\n",
      "\n",
      "Diff: 66.0071029663086\n",
      "\n",
      "Round time: 2419.1470758914948 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 48/Epoch 3) Train Loss: 0.181 | Train Acc: 93.620 | Test Loss: 0.593 | Test Acc: 82.430\n",
      "\n",
      "Diff: 65.98039245605469\n",
      "\n",
      "Round time: 2990.5921189785004 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 4/Epoch 3) Train Loss: 0.351 | Train Acc: 88.2400 | Test Loss: 0.513 | Test Acc: 84.850\n",
      "\n",
      "Diff: 69.80987548828125\n",
      "\n",
      "Round time: 3561.174861907959 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 26/Epoch 3) Train Loss: 0.352 | Train Acc: 87.560 | Test Loss: 0.445 | Test Acc: 86.160\n",
      "\n",
      "Diff: 72.47367095947266\n",
      "\n",
      "Round time: 4138.866477012634 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 46/Epoch 3) Train Loss: 0.262 | Train Acc: 91.640 | Test Loss: 0.453 | Test Acc: 85.770\n",
      "\n",
      "Diff: 86.12258911132812\n",
      "\n",
      "Round time: 4723.356612920761 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 17/Epoch 3) Train Loss: 0.234 | Train Acc: 92.420 | Test Loss: 0.472 | Test Acc: 85.410\n",
      "\n",
      "Diff: 85.34950256347656\n",
      "\n",
      "Round time: 5298.934043884277 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 22/Epoch 3) Train Loss: 0.294 | Train Acc: 89.760 | Test Loss: 0.439 | Test Acc: 86.280\n",
      "\n",
      "Diff: 71.52302551269531\n",
      "\n",
      "Round time: 5924.683141946793 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 48/Epoch 3) Train Loss: 0.173 | Train Acc: 93.680Attacking!\n",
      "\n",
      " | Test Loss: 0.471 | Test Acc: 84.590\n",
      "\n",
      "Diff: 560.0950317382812\n",
      "\n",
      "Round time: 6654.875817060471 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 49/Epoch 3) Train Loss: 0.224 | Train Acc: 92.640 | Test Loss: 0.456 | Test Acc: 85.930\n",
      "\n",
      "Diff: 83.57064056396484\n",
      "\n",
      "Round time: 7395.187988042831 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 39/Epoch 3) Train Loss: 0.212 | Train Acc: 92.720 | Test Loss: 0.449 | Test Acc: 86.400\n",
      "\n",
      "Diff: 67.50779724121094\n",
      "\n",
      "Round time: 13916.307879924774 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 8/Epoch 3) Train Loss: 0.189 | Train Acc: 93.4000 | Test Loss: 0.450 | Test Acc: 86.550\n",
      "\n",
      "Diff: 60.869834899902344\n",
      "\n",
      "Round time: 14504.004343032837 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 30/Epoch 3) Train Loss: 0.239 | Train Acc: 91.340 | Test Loss: 0.474 | Test Acc: 85.770\n",
      "\n",
      "Diff: 82.01603698730469\n",
      "\n",
      "Round time: 15075.272027015686 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 19/Epoch 3) Train Loss: 0.249 | Train Acc: 91.320 | Test Loss: 0.473 | Test Acc: 85.680\n",
      "\n",
      "Diff: 76.22505950927734\n",
      "\n",
      "Round time: 15662.505131959915 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 24/Epoch 3) Train Loss: 0.196 | Train Acc: 93.300 | Test Loss: 0.423 | Test Acc: 87.220\n",
      "\n",
      "Diff: 67.48401641845703\n",
      "\n",
      "Round time: 16301.689856052399 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 43/Epoch 3) Train Loss: 0.199 | Train Acc: 92.960 | Test Loss: 0.489 | Test Acc: 84.760\n",
      "\n",
      "Diff: 93.21798706054688\n",
      "\n",
      "Round time: 17041.293228149414 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 18/Epoch 3) Train Loss: 0.189 | Train Acc: 92.960 | Test Loss: 0.471 | Test Acc: 86.080\n",
      "\n",
      "Diff: 68.53842163085938\n",
      "\n",
      "Round time: 19962.124579906464 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 29/Epoch 3) Train Loss: 0.241 | Train Acc: 91.660 | Test Loss: 0.479 | Test Acc: 86.490\n",
      "\n",
      "Diff: 95.97039031982422\n",
      "\n",
      "Round time: 20573.600088834763 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 9/Epoch 3) Train Loss: 0.239 | Train Acc: 91.9000 | Test Loss: 0.464 | Test Acc: 86.320\n",
      "\n",
      "Diff: 108.36822509765625\n",
      "\n",
      "Round time: 21168.965790987015 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 46/Epoch 3) Train Loss: 0.342 | Train Acc: 88.540 | Test Loss: 0.449 | Test Acc: 86.450\n",
      "\n",
      "Diff: 110.08718872070312\n",
      "\n",
      "Round time: 21768.884684085846 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 33/Epoch 3) Train Loss: 0.154 | Train Acc: 94.960 | Test Loss: 0.427 | Test Acc: 87.520\n",
      "\n",
      "Diff: 84.21282958984375\n",
      "\n",
      "Round time: 22361.200109004974 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 14/Epoch 3) Train Loss: 0.159 | Train Acc: 94.340 | Test Loss: 0.455 | Test Acc: 87.290\n",
      "\n",
      "Diff: 89.75833892822266\n",
      "\n",
      "Round time: 24335.490816116333 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 2/Epoch 3) Train Loss: 0.158 | Train Acc: 94.7000 | Test Loss: 0.490 | Test Acc: 86.200\n",
      "\n",
      "Diff: 85.81427764892578\n",
      "\n",
      "Round time: 24922.286353826523 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 16/Epoch 3) Train Loss: 0.191 | Train Acc: 94.200 | Test Loss: 0.390 | Test Acc: 88.490\n",
      "\n",
      "Diff: 20.6744384765625\n",
      "\n",
      "Round time: 26527.688716173172 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 13/Epoch 3) Train Loss: 0.153 | Train Acc: 95.120 | Test Loss: 0.377 | Test Acc: 88.880\n",
      "\n",
      "Diff: 20.290822982788086\n",
      "\n",
      "Round time: 32456.793838977814 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 42/Epoch 3) Train Loss: 0.161 | Train Acc: 94.800 | Test Loss: 0.372 | Test Acc: 88.670\n",
      "\n",
      "Diff: 18.645763397216797\n",
      "\n",
      "Round time: 40393.617008924484 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 27/Epoch 3) Train Loss: 0.145 | Train Acc: 95.000 | Test Loss: 0.374 | Test Acc: 88.830\n",
      "\n",
      "Diff: 18.296842575073242\n",
      "\n",
      "Round time: 40989.612004995346 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 1/Epoch 3) Train Loss: 0.140 | Train Acc: 94.98000 | Test Loss: 0.375 | Test Acc: 88.680\n",
      "\n",
      "Diff: 25.800113677978516\n",
      "\n",
      "Round time: 41589.1444401741 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 41592.47633099556 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sigmoid_against_noise_attack = run_federated_test(agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = big_noise_attack, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"sigmoid_against_noise_attack_1.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 13/Epoch 0) Train Loss: 0.334 | Train Acc: 88.200Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      "Diff\n",
      "\n",
      " | Test Loss: 1.250 | Test Acc: 72.800\n",
      "\n",
      "Diff: 34.20332717895508\n",
      "\n",
      "Round time: 34.021363258361816 \n",
      "\n",
      "Total training time: 34.021379232406616 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline = load_result(\"baseline.pickle\")\n",
    "determine_cutoffs = run_federated_test(agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 1,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.05,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = None, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = None, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = None,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = None,\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = False ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.0.0.weight': tensor([[[[-9.4310e-03, -6.7759e-03,  3.0469e-03],\n",
       "           [-1.7775e-02, -1.1662e-02,  1.3760e-03],\n",
       "           [-1.4200e-02, -1.4083e-02, -9.8117e-03]],\n",
       " \n",
       "          [[-6.7062e-03, -7.9544e-03, -1.8204e-03],\n",
       "           [-1.7414e-02, -1.4476e-02, -5.0078e-03],\n",
       "           [-8.6145e-03, -1.0224e-02, -6.3146e-03]],\n",
       " \n",
       "          [[-5.0432e-03, -4.2537e-03, -2.3357e-03],\n",
       "           [-1.1462e-02, -8.9888e-03, -8.9411e-03],\n",
       "           [-3.5206e-03, -6.3042e-03, -1.3175e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.8976e-03, -1.5522e-02, -1.1095e-02],\n",
       "           [-9.0138e-03, -1.3783e-02, -8.9821e-03],\n",
       "           [ 3.9757e-03,  1.1459e-03, -2.5883e-03]],\n",
       " \n",
       "          [[ 3.0415e-03, -1.8064e-03, -2.0479e-04],\n",
       "           [ 9.1547e-03,  6.0731e-03,  7.8201e-03],\n",
       "           [ 2.5521e-02,  2.4583e-02,  1.8199e-02]],\n",
       " \n",
       "          [[ 3.8094e-03, -7.5914e-04, -2.2959e-03],\n",
       "           [ 1.3139e-02,  9.9015e-03,  5.5838e-03],\n",
       "           [ 3.1718e-02,  3.0887e-02,  1.9483e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.9414e-02, -1.9807e-02, -1.2337e-02],\n",
       "           [-9.9552e-03, -1.5226e-02, -1.5918e-02],\n",
       "           [-8.6639e-03, -1.6390e-02, -2.0980e-02]],\n",
       " \n",
       "          [[-2.0568e-02, -2.1500e-02, -1.3814e-02],\n",
       "           [-1.0518e-02, -1.4131e-02, -1.3258e-02],\n",
       "           [-2.0754e-03, -9.2086e-03, -1.4582e-02]],\n",
       " \n",
       "          [[-1.2786e-02, -1.1674e-02, -2.3190e-03],\n",
       "           [-3.7982e-03, -2.0684e-03,  4.7606e-03],\n",
       "           [ 4.6745e-03,  3.3242e-03,  6.3651e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7627e-02,  2.4833e-02,  2.8034e-02],\n",
       "           [ 1.7108e-02,  3.0135e-02,  3.8243e-02],\n",
       "           [ 1.4850e-02,  2.6562e-02,  3.6882e-02]],\n",
       " \n",
       "          [[ 2.6601e-02,  3.4834e-02,  3.8450e-02],\n",
       "           [ 2.6684e-02,  4.0134e-02,  4.7611e-02],\n",
       "           [ 2.1756e-02,  3.4238e-02,  4.4157e-02]],\n",
       " \n",
       "          [[ 1.3867e-02,  2.0056e-02,  2.1858e-02],\n",
       "           [ 1.5510e-02,  2.5321e-02,  3.1643e-02],\n",
       "           [ 1.0815e-02,  1.9646e-02,  2.8703e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8977e-03,  4.7585e-03,  2.2510e-03],\n",
       "           [-5.4464e-03, -1.0274e-02, -9.2843e-03],\n",
       "           [-6.0101e-03, -1.3474e-02, -5.1022e-03]],\n",
       " \n",
       "          [[-7.2535e-03, -1.2255e-02, -1.8279e-02],\n",
       "           [-1.3617e-02, -1.8040e-02, -2.3109e-02],\n",
       "           [-9.8084e-03, -1.8985e-02, -1.1882e-02]],\n",
       " \n",
       "          [[ 3.8924e-03,  1.0087e-03, -4.1758e-03],\n",
       "           [ 1.4112e-03, -1.5211e-03, -1.0669e-02],\n",
       "           [ 1.3720e-02,  1.4744e-03, -1.1102e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4144e-03,  1.0221e-02,  1.1783e-02],\n",
       "           [ 9.7650e-04,  3.3557e-04,  3.7333e-03],\n",
       "           [-1.3046e-03, -5.8919e-03, -1.8445e-03]],\n",
       " \n",
       "          [[ 8.0681e-04,  8.4871e-03,  1.0191e-02],\n",
       "           [ 2.3001e-03,  3.7856e-03,  6.5075e-03],\n",
       "           [ 6.0080e-03,  1.7221e-03,  6.7756e-03]],\n",
       " \n",
       "          [[ 9.7348e-03,  1.6073e-02,  1.8668e-02],\n",
       "           [ 1.4198e-02,  1.5713e-02,  1.4499e-02],\n",
       "           [ 2.3766e-02,  1.8842e-02,  1.6399e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3016e-03,  6.6571e-03,  1.0744e-02],\n",
       "           [-1.1536e-03,  9.1159e-03,  1.5123e-02],\n",
       "           [-4.1023e-03,  4.6764e-03,  7.4151e-03]],\n",
       " \n",
       "          [[ 4.4232e-03,  1.2228e-02,  1.6378e-02],\n",
       "           [ 3.2091e-03,  1.3061e-02,  1.8934e-02],\n",
       "           [ 9.5454e-04,  9.3143e-03,  1.1801e-02]],\n",
       " \n",
       "          [[-2.7347e-03,  4.9080e-03,  9.3413e-03],\n",
       "           [-5.9757e-04,  7.5777e-03,  1.3539e-02],\n",
       "           [-2.5666e-03,  3.5155e-03,  5.6850e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4059e-03, -4.9073e-03, -1.0580e-02],\n",
       "           [-4.7145e-03, -1.0831e-02, -9.7063e-03],\n",
       "           [-1.0525e-02, -1.5923e-02, -1.1711e-02]],\n",
       " \n",
       "          [[ 6.3155e-03, -3.3818e-03, -9.9559e-03],\n",
       "           [-1.4817e-03, -7.9530e-03, -7.0983e-03],\n",
       "           [-2.2993e-03, -5.8680e-03, -7.0879e-04]],\n",
       " \n",
       "          [[ 2.4915e-03, -4.4891e-03, -1.1028e-02],\n",
       "           [ 3.1987e-04, -5.7684e-03, -9.5503e-03],\n",
       "           [-3.6332e-04, -4.8533e-03, -6.5551e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.5761e-02, -4.7987e-03,  2.2797e-02],\n",
       "           [ 2.0416e-03,  3.0051e-03,  2.4965e-02],\n",
       "           [-2.7422e-02,  1.2533e-02,  1.3610e-02]],\n",
       " \n",
       "          [[-9.3888e-03,  2.4065e-02,  4.6561e-02],\n",
       "           [ 2.4954e-02,  3.7172e-02,  4.5738e-02],\n",
       "           [ 1.7575e-02,  5.4236e-02,  4.5096e-02]],\n",
       " \n",
       "          [[ 1.2795e-02,  5.3624e-02,  6.1543e-02],\n",
       "           [ 4.5298e-02,  7.4419e-02,  6.7274e-02],\n",
       "           [ 3.8485e-02,  8.9098e-02,  6.5070e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.8135e-03,  1.6751e-02,  1.9566e-02],\n",
       "           [ 9.0821e-03,  1.0724e-02,  1.2420e-02],\n",
       "           [ 1.2797e-02,  9.1674e-03,  1.2034e-02]],\n",
       " \n",
       "          [[ 1.6779e-02,  2.7128e-02,  3.2998e-02],\n",
       "           [ 1.2074e-02,  1.8510e-02,  2.1987e-02],\n",
       "           [ 1.7523e-02,  1.8348e-02,  2.3162e-02]],\n",
       " \n",
       "          [[ 1.7442e-02,  2.6524e-02,  3.4860e-02],\n",
       "           [ 1.2654e-02,  1.8988e-02,  2.3886e-02],\n",
       "           [ 1.9019e-02,  2.1432e-02,  2.5438e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3091e-02,  2.5638e-02,  1.1555e-02],\n",
       "           [ 1.1954e-02,  3.0199e-03, -7.2825e-03],\n",
       "           [ 1.5633e-02,  6.0750e-03, -4.9505e-03]],\n",
       " \n",
       "          [[ 2.0608e-02,  1.6376e-02,  2.6909e-03],\n",
       "           [-2.9411e-03, -7.4598e-03, -1.4200e-02],\n",
       "           [-7.1378e-04, -5.8949e-03, -1.2109e-02]],\n",
       " \n",
       "          [[ 3.3163e-02,  3.2080e-02,  2.1518e-02],\n",
       "           [ 1.5652e-02,  1.4246e-02,  7.9834e-03],\n",
       "           [ 1.5073e-02,  1.0520e-02,  4.9918e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.6218e-02,  1.6560e-02,  2.2865e-02],\n",
       "           [ 2.2106e-02,  1.4437e-02,  1.6705e-02],\n",
       "           [ 2.5357e-02,  1.3471e-02,  1.4120e-02]],\n",
       " \n",
       "          [[ 3.7001e-02,  3.0128e-02,  3.0689e-02],\n",
       "           [ 3.0871e-02,  2.5435e-02,  2.4860e-02],\n",
       "           [ 2.0903e-02,  1.2615e-02,  1.2748e-02]],\n",
       " \n",
       "          [[ 1.7232e-02,  9.4857e-03,  2.9020e-03],\n",
       "           [ 1.6247e-02,  1.2577e-02,  6.2142e-03],\n",
       "           [ 1.2513e-02,  3.6024e-03,  1.5558e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.4084e-02, -3.1312e-02, -3.5323e-02],\n",
       "           [-2.2713e-02, -2.9859e-02, -3.6860e-02],\n",
       "           [-2.5104e-02, -2.2539e-02, -3.3360e-02]],\n",
       " \n",
       "          [[-4.5948e-03, -1.1844e-02, -2.0286e-02],\n",
       "           [ 5.2841e-03, -1.7823e-03, -1.1114e-02],\n",
       "           [ 3.7806e-03,  5.3520e-03, -7.2244e-03]],\n",
       " \n",
       "          [[ 1.3558e-02,  5.0786e-03, -1.3009e-02],\n",
       "           [ 2.0019e-02,  1.0728e-02, -5.7699e-03],\n",
       "           [ 1.9008e-02,  1.6834e-02,  2.5431e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6317e-03, -1.6067e-02, -2.4925e-02],\n",
       "           [ 2.7749e-03, -1.6423e-02, -3.0098e-02],\n",
       "           [ 2.9261e-02,  1.1536e-02, -9.7455e-03]],\n",
       " \n",
       "          [[ 3.5329e-03, -1.9274e-02, -3.4527e-02],\n",
       "           [-4.8749e-03, -3.0957e-02, -4.8778e-02],\n",
       "           [ 2.0411e-02, -5.5402e-03, -2.7689e-02]],\n",
       " \n",
       "          [[-1.0321e-02, -3.2059e-02, -4.7211e-02],\n",
       "           [-1.7822e-02, -4.2717e-02, -6.6305e-02],\n",
       "           [-5.2117e-03, -3.0065e-02, -5.6861e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3323e-02,  1.8732e-02,  1.1509e-02],\n",
       "           [ 9.5714e-03,  1.2109e-02,  4.5257e-03],\n",
       "           [ 1.5286e-02,  1.5075e-02,  7.4889e-03]],\n",
       " \n",
       "          [[ 6.5246e-03,  1.2159e-02,  4.1263e-03],\n",
       "           [ 2.3045e-03,  4.8146e-03, -3.1893e-03],\n",
       "           [ 8.3002e-03,  7.6306e-03, -2.7929e-05]],\n",
       " \n",
       "          [[-3.9052e-03,  2.8507e-03, -5.0100e-03],\n",
       "           [-7.5502e-03, -4.2118e-03, -1.1711e-02],\n",
       "           [-2.9098e-03, -3.5085e-03, -1.0556e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.8453e-03, -6.1743e-03, -8.1790e-03],\n",
       "           [-7.9658e-03, -1.4048e-03, -9.2912e-03],\n",
       "           [-7.0422e-03, -5.2652e-03, -1.5616e-02]],\n",
       " \n",
       "          [[ 1.0158e-02,  6.6068e-03,  1.7107e-03],\n",
       "           [ 8.3114e-03,  9.5963e-03,  2.2089e-03],\n",
       "           [ 1.1619e-02,  1.0345e-02,  1.0741e-03]],\n",
       " \n",
       "          [[ 2.4241e-02,  2.4687e-02,  1.7891e-02],\n",
       "           [ 2.9666e-02,  3.1889e-02,  2.0994e-02],\n",
       "           [ 3.3526e-02,  3.0607e-02,  1.8132e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.9086e-03,  6.7051e-03,  4.7263e-03],\n",
       "           [ 4.4544e-03,  9.5715e-03,  9.0020e-03],\n",
       "           [-9.7263e-03, -5.1264e-03, -5.9785e-03]],\n",
       " \n",
       "          [[-1.0319e-03,  2.2220e-03,  2.5702e-03],\n",
       "           [-1.6371e-03,  5.0202e-03,  7.2360e-03],\n",
       "           [-1.4067e-02, -8.9673e-03, -7.3647e-03]],\n",
       " \n",
       "          [[-1.1328e-02, -8.6856e-03, -6.1960e-03],\n",
       "           [-8.0609e-03, -3.6288e-03, -1.0122e-03],\n",
       "           [-1.8664e-02, -1.6210e-02, -1.6288e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3702e-02, -1.6200e-02, -1.8401e-02],\n",
       "           [-1.5437e-02, -1.3696e-02, -1.6990e-02],\n",
       "           [-2.2996e-02, -1.5476e-02, -1.9067e-02]],\n",
       " \n",
       "          [[-6.2781e-03, -9.5082e-03, -1.2210e-02],\n",
       "           [-3.1648e-03, -2.6841e-03, -6.1723e-03],\n",
       "           [-1.2711e-02, -7.9424e-03, -1.2330e-02]],\n",
       " \n",
       "          [[ 7.7629e-04, -5.3092e-03, -1.0553e-02],\n",
       "           [ 2.0878e-03, -8.9915e-04, -5.7676e-03],\n",
       "           [-4.7107e-03, -2.6818e-03, -6.7002e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.9592e-02,  2.4308e-02,  4.9510e-03],\n",
       "           [ 1.7472e-02,  5.9305e-03, -1.0421e-02],\n",
       "           [ 1.8647e-02,  8.7095e-03, -6.6255e-03]],\n",
       " \n",
       "          [[ 2.9498e-02,  1.6179e-02, -3.1216e-03],\n",
       "           [ 7.5047e-03, -2.7180e-03, -1.8145e-02],\n",
       "           [ 7.9581e-03, -1.9048e-03, -1.6342e-02]],\n",
       " \n",
       "          [[ 2.9361e-02,  2.1368e-02,  4.8147e-03],\n",
       "           [ 9.2373e-03,  4.9975e-03, -9.7510e-03],\n",
       "           [ 2.1272e-03, -3.1413e-03, -1.5722e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8868e-02, -3.2560e-02, -5.1307e-02],\n",
       "           [-1.5751e-02, -2.6894e-02, -4.1642e-02],\n",
       "           [ 1.1029e-02,  3.1188e-03, -7.1759e-03]],\n",
       " \n",
       "          [[ 1.3567e-02,  1.3760e-03, -1.8902e-02],\n",
       "           [ 2.5478e-02,  1.0360e-02, -8.5719e-03],\n",
       "           [ 5.2089e-02,  4.0675e-02,  2.9124e-02]],\n",
       " \n",
       "          [[ 2.9085e-03, -2.7095e-03, -1.6150e-02],\n",
       "           [ 2.0431e-02,  1.6892e-02, -3.0817e-03],\n",
       "           [ 3.6740e-02,  3.7215e-02,  2.1739e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.0138e-03,  6.0146e-04,  1.2466e-04],\n",
       "           [-4.8368e-03,  3.8361e-03,  1.6575e-03],\n",
       "           [-4.0903e-03,  5.3309e-03,  4.6740e-03]],\n",
       " \n",
       "          [[ 2.0696e-03,  2.7105e-03,  2.3970e-03],\n",
       "           [ 7.3493e-03,  9.7858e-03,  6.1598e-03],\n",
       "           [ 4.7354e-04,  4.5357e-03,  2.5678e-03]],\n",
       " \n",
       "          [[ 1.6841e-02,  8.3473e-03,  3.7305e-03],\n",
       "           [ 1.9293e-02,  1.2898e-02,  5.7595e-03],\n",
       "           [ 1.7043e-02,  1.3724e-02,  9.9166e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3645e-03,  5.4179e-03,  4.6433e-03],\n",
       "           [-4.4592e-03, -2.2966e-04, -1.4546e-03],\n",
       "           [-9.5363e-03, -6.7755e-03, -6.6753e-03]],\n",
       " \n",
       "          [[ 1.6348e-02,  1.5965e-02,  1.4513e-02],\n",
       "           [ 1.0999e-02,  1.2798e-02,  1.1042e-02],\n",
       "           [ 7.9488e-03,  8.6758e-03,  7.7911e-03]],\n",
       " \n",
       "          [[ 2.8378e-02,  2.6744e-02,  2.2903e-02],\n",
       "           [ 2.5854e-02,  2.5930e-02,  2.1851e-02],\n",
       "           [ 2.5333e-02,  2.4293e-02,  2.1201e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3742e-02,  5.4486e-02,  4.8460e-02],\n",
       "           [ 2.0121e-02,  1.6514e-02,  3.7616e-03],\n",
       "           [-4.6651e-03, -5.9353e-03, -1.5855e-02]],\n",
       " \n",
       "          [[ 4.8172e-02,  3.5868e-02,  2.7321e-02],\n",
       "           [-4.0898e-03, -1.1170e-02, -2.3948e-02],\n",
       "           [-2.4466e-02, -3.5073e-02, -4.4928e-02]],\n",
       " \n",
       "          [[ 1.1045e-01,  9.7978e-02,  8.6301e-02],\n",
       "           [ 6.0022e-02,  4.9308e-02,  3.2219e-02],\n",
       "           [ 4.4882e-02,  2.8999e-02,  1.1375e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.0611e-03, -4.1917e-03, -7.4806e-04],\n",
       "           [-9.9796e-03, -5.9177e-03, -2.3742e-03],\n",
       "           [-1.0024e-02, -5.1471e-03, -4.4030e-03]],\n",
       " \n",
       "          [[-6.6448e-03, -4.4837e-03, -1.3501e-03],\n",
       "           [-1.4137e-02, -1.0658e-02, -7.7536e-03],\n",
       "           [-1.2334e-02, -9.7415e-03, -9.2847e-03]],\n",
       " \n",
       "          [[-7.7206e-03, -4.3279e-03,  1.1294e-03],\n",
       "           [-1.5157e-02, -8.7848e-03, -4.5002e-03],\n",
       "           [-1.2357e-02, -6.6783e-03, -7.0171e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.8769e-02,  2.9437e-02,  2.6398e-02],\n",
       "           [ 3.1233e-03,  2.3110e-02,  9.6428e-04],\n",
       "           [ 2.1909e-02,  2.2511e-02,  3.3647e-02]],\n",
       " \n",
       "          [[-1.2185e-02,  3.3606e-02,  4.9849e-02],\n",
       "           [ 1.4579e-02,  2.1310e-02,  1.8503e-02],\n",
       "           [ 3.3253e-02,  4.2079e-02,  4.6450e-02]],\n",
       " \n",
       "          [[-8.2894e-03,  1.9056e-02,  5.3860e-02],\n",
       "           [ 2.3410e-02,  6.8685e-03,  3.3265e-02],\n",
       "           [ 2.7713e-02,  2.6817e-02,  4.7891e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8419e-02, -8.5101e-03, -3.0268e-03],\n",
       "           [-2.3766e-02, -1.1386e-02, -1.0159e-02],\n",
       "           [-1.3071e-02, -7.3608e-03, -1.3433e-02]],\n",
       " \n",
       "          [[-1.1899e-03,  4.1837e-03,  7.4434e-03],\n",
       "           [ 2.4666e-03,  9.5676e-03,  6.7341e-03],\n",
       "           [ 1.3270e-02,  1.5640e-02,  6.6930e-03]],\n",
       " \n",
       "          [[ 8.1810e-03,  8.7533e-03,  6.1483e-03],\n",
       "           [ 1.6482e-02,  1.7279e-02,  4.9556e-03],\n",
       "           [ 2.6594e-02,  2.3869e-02,  7.8598e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2900e-02,  2.2679e-02,  7.5954e-03],\n",
       "           [ 1.4132e-02,  7.6966e-03, -5.2495e-03],\n",
       "           [-5.4711e-04, -1.0273e-03, -4.3299e-03]],\n",
       " \n",
       "          [[ 2.2408e-02,  2.0455e-02,  1.3967e-02],\n",
       "           [ 1.1255e-02,  1.1044e-02,  1.7655e-03],\n",
       "           [-8.1749e-03, -3.6572e-03, -4.0077e-03]],\n",
       " \n",
       "          [[ 2.4394e-02,  1.8581e-02,  1.3874e-02],\n",
       "           [ 4.2353e-03,  2.1925e-03, -2.0251e-03],\n",
       "           [-1.2420e-02, -9.0449e-03, -4.9111e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.1330e-03, -7.2745e-03, -8.0769e-03],\n",
       "           [-7.8999e-03, -1.5042e-02, -1.8750e-02],\n",
       "           [-2.2688e-02, -2.6590e-02, -2.7619e-02]],\n",
       " \n",
       "          [[ 8.9104e-03,  4.2596e-03,  2.5619e-03],\n",
       "           [ 2.7947e-03, -2.5400e-03, -7.5966e-03],\n",
       "           [-7.8805e-03, -1.0031e-02, -1.5190e-02]],\n",
       " \n",
       "          [[ 2.0444e-02,  2.1313e-02,  2.3284e-02],\n",
       "           [ 1.2689e-02,  1.6189e-02,  1.9406e-02],\n",
       "           [ 3.1306e-03,  1.0654e-02,  1.4740e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3486e-03,  1.3131e-02,  1.1691e-02],\n",
       "           [-9.4635e-03, -1.3305e-02, -7.8270e-03],\n",
       "           [ 9.5630e-03,  9.5463e-04, -1.9023e-02]],\n",
       " \n",
       "          [[ 2.1438e-02,  4.0195e-02,  3.4836e-02],\n",
       "           [ 7.0478e-03,  1.2247e-02,  1.2002e-02],\n",
       "           [ 3.7986e-02,  3.3450e-02,  1.2248e-02]],\n",
       " \n",
       "          [[ 2.7238e-02,  5.3890e-02,  4.0694e-02],\n",
       "           [ 2.6702e-02,  4.0474e-02,  2.4115e-02],\n",
       "           [ 5.0875e-02,  5.2237e-02,  2.1182e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5852e-02, -2.7238e-02, -3.5584e-02],\n",
       "           [-2.8404e-02, -2.5150e-02, -3.6756e-02],\n",
       "           [-3.8276e-02, -3.2950e-02, -4.2925e-02]],\n",
       " \n",
       "          [[-5.7706e-04, -1.6987e-02, -2.3517e-02],\n",
       "           [-9.1772e-03, -1.3431e-02, -2.3066e-02],\n",
       "           [-2.5295e-02, -2.4550e-02, -3.5010e-02]],\n",
       " \n",
       "          [[-1.1752e-02, -2.3059e-02, -2.9382e-02],\n",
       "           [-1.2503e-02, -1.4826e-02, -2.2048e-02],\n",
       "           [-2.3312e-02, -2.3719e-02, -3.1106e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1362e-02, -1.1293e-02, -1.0476e-02],\n",
       "           [-9.0234e-03, -1.1604e-02, -1.5020e-02],\n",
       "           [-1.6231e-02, -1.9352e-02, -1.9791e-02]],\n",
       " \n",
       "          [[-9.5433e-03, -1.1550e-02, -9.7188e-03],\n",
       "           [-7.7989e-03, -1.1785e-02, -1.3076e-02],\n",
       "           [-1.6286e-02, -1.8967e-02, -1.8959e-02]],\n",
       " \n",
       "          [[ 5.9075e-03,  2.8030e-03,  2.7929e-03],\n",
       "           [ 7.6743e-03,  5.1941e-03,  6.3457e-03],\n",
       "           [ 1.3396e-03,  1.5137e-03,  6.2732e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.2675e-03, -8.2762e-03, -1.2600e-02],\n",
       "           [-2.9835e-04, -5.0042e-03, -1.1396e-02],\n",
       "           [-4.4780e-03, -7.3509e-03, -1.2696e-02]],\n",
       " \n",
       "          [[ 3.3361e-04, -5.4825e-03, -8.5032e-03],\n",
       "           [ 2.7627e-03, -2.0438e-03, -7.8143e-03],\n",
       "           [-4.7624e-03, -7.5408e-03, -1.2184e-02]],\n",
       " \n",
       "          [[ 6.4269e-03,  2.0773e-03, -3.8477e-03],\n",
       "           [ 7.5088e-03,  3.1764e-03, -4.4251e-03],\n",
       "           [-3.7946e-03, -6.1063e-03, -1.1107e-02]]]], device='mps:0'),\n",
       " 'model.0.1.weight': tensor([-0.0609, -0.0491,  0.0329, -0.0967, -0.0118,  0.0179, -0.0212, -0.0072,\n",
       "          0.0625,  0.0523, -0.0102, -0.0580, -0.0060, -0.0226, -0.0200, -0.0287,\n",
       "         -0.0254, -0.0225,  0.0176,  0.0292,  0.0359, -0.0064, -0.0259,  0.0275,\n",
       "         -0.0004, -0.0011, -0.0032,  0.0467,  0.0273, -0.0275, -0.0036,  0.0054],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.bias': tensor([ 0.0067,  0.0208, -0.0177, -0.0114,  0.0369,  0.0291, -0.0407,  0.0543,\n",
       "         -0.0370,  0.0259, -0.0461, -0.0136,  0.0412,  0.0394, -0.0017, -0.0404,\n",
       "         -0.0020,  0.0453,  0.0093,  0.0270,  0.0137, -0.0131, -0.0110,  0.0100,\n",
       "          0.0247, -0.0286,  0.0175,  0.0122, -0.0234,  0.0296, -0.0050,  0.0179],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_mean': tensor([ 0.0813, -0.0293,  0.0787, -0.1529,  0.1071, -0.0089, -0.0316,  0.0773,\n",
       "         -0.0842,  0.0022, -0.0386, -0.1034,  0.0660,  0.1633, -0.0583, -0.0788,\n",
       "          0.0630,  0.0562, -0.0340,  0.0265, -0.1071, -0.0791, -0.0542,  0.0747,\n",
       "         -0.0983, -0.0191, -0.0819,  0.0334, -0.0132,  0.1659,  0.0031,  0.1093],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_var': tensor([ 0.2810,  0.2454,  0.5046,  1.5267,  0.9684,  0.1016,  0.3382,  0.5751,\n",
       "         -0.2303, -0.0372, -1.4290,  0.2300,  0.1553,  1.1861,  0.1613,  0.7026,\n",
       "          0.4574, -0.0613, -1.0159,  0.2655,  0.9203,  0.8322,  0.2654,  0.1325,\n",
       "          0.5293,  0.3259,  0.7365,  0.8463, -0.0212,  0.0209,  0.2011,  1.0625],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.1.0.weight': tensor([[[[ 2.5200e-03,  4.9969e-03,  7.6354e-03],\n",
       "           [ 2.6879e-03,  4.7899e-03,  3.5814e-03],\n",
       "           [ 5.9695e-03,  9.5227e-03,  8.0898e-03]],\n",
       " \n",
       "          [[-6.6822e-04,  1.0536e-03,  2.4990e-03],\n",
       "           [ 1.8382e-03,  3.9865e-03,  1.4481e-03],\n",
       "           [ 1.1402e-03,  1.9530e-03, -3.5727e-03]],\n",
       " \n",
       "          [[-4.1274e-03, -4.6057e-03, -9.2558e-03],\n",
       "           [-6.3222e-03, -6.0006e-03, -1.0044e-02],\n",
       "           [-8.1867e-03, -7.7672e-03, -1.1726e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7909e-03, -9.5725e-03, -1.2838e-02],\n",
       "           [-8.5822e-04,  1.2804e-03, -2.3547e-03],\n",
       "           [ 6.1171e-04,  1.6237e-04, -2.3177e-03]],\n",
       " \n",
       "          [[-7.3179e-03, -6.7557e-03, -1.1115e-02],\n",
       "           [-5.2998e-03, -4.2612e-03, -6.7168e-03],\n",
       "           [-6.9124e-03, -5.0854e-03, -7.0385e-03]],\n",
       " \n",
       "          [[ 3.7576e-03,  1.1390e-03, -1.1721e-03],\n",
       "           [ 3.0300e-03,  1.0847e-03, -8.7085e-04],\n",
       "           [-2.0659e-03, -4.1888e-03, -6.6950e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2569e-02,  1.2116e-02,  1.1013e-02],\n",
       "           [ 1.5781e-02,  1.1196e-02,  1.0360e-02],\n",
       "           [ 1.9568e-02,  1.8538e-02,  1.6678e-02]],\n",
       " \n",
       "          [[ 1.0080e-02,  6.4496e-03, -5.1572e-03],\n",
       "           [ 1.2003e-02,  3.5136e-03, -3.9987e-03],\n",
       "           [ 1.1416e-02,  2.0297e-03,  3.8432e-04]],\n",
       " \n",
       "          [[-3.2266e-03, -7.3828e-03, -1.1801e-02],\n",
       "           [-2.7418e-03, -7.5969e-03, -6.8429e-03],\n",
       "           [ 4.7585e-03, -5.5694e-03, -1.0049e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.1832e-03, -4.0298e-03, -1.0361e-02],\n",
       "           [ 5.8816e-03,  4.2329e-03,  3.5031e-03],\n",
       "           [ 6.0951e-03,  7.6377e-03,  9.2239e-03]],\n",
       " \n",
       "          [[-1.1972e-02, -1.3060e-02, -1.5801e-02],\n",
       "           [-1.0977e-02, -1.0840e-02, -1.1023e-02],\n",
       "           [-9.1846e-03, -1.3357e-02, -1.5298e-02]],\n",
       " \n",
       "          [[-5.9644e-03, -9.6843e-03, -1.5296e-02],\n",
       "           [-3.6067e-03, -6.4546e-03, -8.8959e-03],\n",
       "           [-4.6216e-03, -9.7059e-03, -1.0140e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0652e-03,  9.3555e-04, -1.3000e-04],\n",
       "           [ 7.6228e-03,  3.7571e-03,  4.5518e-03],\n",
       "           [ 1.4604e-02,  1.3554e-02,  1.2585e-02]],\n",
       " \n",
       "          [[ 2.9307e-03,  4.0755e-03, -7.8104e-03],\n",
       "           [ 9.6704e-03,  3.6729e-03, -1.3697e-03],\n",
       "           [ 3.7947e-03, -1.6020e-03, -3.7565e-03]],\n",
       " \n",
       "          [[-9.4601e-03, -1.2300e-02, -1.0260e-02],\n",
       "           [-1.0446e-02, -9.6703e-03, -4.8960e-03],\n",
       "           [-1.1926e-02, -1.2257e-02, -1.7868e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.7436e-03,  5.8570e-03,  9.4202e-03],\n",
       "           [ 1.1287e-02,  1.1069e-02,  1.4895e-02],\n",
       "           [ 6.7725e-03,  6.9910e-03,  1.2593e-02]],\n",
       " \n",
       "          [[-6.8477e-03, -6.7741e-03, -5.9071e-03],\n",
       "           [-1.2978e-02, -1.0088e-02, -4.4393e-03],\n",
       "           [-9.3921e-03, -1.0197e-02, -2.9033e-03]],\n",
       " \n",
       "          [[-3.0053e-03, -5.0228e-03, -3.6624e-03],\n",
       "           [ 3.1261e-03, -2.1440e-03, -3.7968e-04],\n",
       "           [ 7.4912e-03,  9.8689e-04,  1.0705e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 5.9595e-03,  8.1846e-03,  1.0939e-02],\n",
       "           [ 3.3292e-03,  6.1129e-03,  1.3597e-02],\n",
       "           [ 3.0127e-04,  1.2067e-03,  5.3000e-03]],\n",
       " \n",
       "          [[ 6.2312e-03,  2.2619e-03,  8.9475e-03],\n",
       "           [ 3.7541e-03,  2.0137e-03,  8.5804e-03],\n",
       "           [-8.7334e-04, -5.9667e-04,  5.7188e-03]],\n",
       " \n",
       "          [[ 1.4050e-04,  6.2907e-03,  5.3319e-03],\n",
       "           [ 2.4940e-03,  6.8418e-03,  5.2028e-03],\n",
       "           [-2.1052e-04,  4.3324e-03,  7.0176e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.6415e-03,  3.1624e-03,  4.1088e-03],\n",
       "           [ 4.6173e-03,  4.9710e-03,  7.5964e-03],\n",
       "           [-2.9127e-03, -1.3721e-03, -2.2586e-03]],\n",
       " \n",
       "          [[ 9.5231e-04,  1.0585e-03,  2.3308e-04],\n",
       "           [ 2.2556e-03,  1.6868e-03,  1.8221e-03],\n",
       "           [-3.4081e-03, -3.3228e-03,  1.9063e-04]],\n",
       " \n",
       "          [[-6.4673e-04, -6.1836e-05,  2.2500e-03],\n",
       "           [-6.0664e-03, -4.0367e-03, -7.3966e-04],\n",
       "           [-1.3440e-02, -1.1377e-02, -7.3802e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.9185e-02, -2.0370e-02, -2.2675e-02],\n",
       "           [-9.5638e-03, -9.4360e-03, -1.4352e-02],\n",
       "           [-1.3988e-02, -1.4317e-02, -2.0357e-02]],\n",
       " \n",
       "          [[-1.0417e-02, -7.6343e-03, -7.0248e-03],\n",
       "           [-1.2956e-02, -1.0242e-02, -1.1115e-02],\n",
       "           [-1.3013e-02, -5.7864e-03, -6.9354e-03]],\n",
       " \n",
       "          [[-3.0609e-03, -2.5295e-03, -4.7975e-03],\n",
       "           [-3.5974e-03, -7.8710e-03, -6.9366e-03],\n",
       "           [-2.5538e-03, -5.7695e-03, -4.8880e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.8748e-03,  1.0828e-02,  3.4485e-03],\n",
       "           [-7.7088e-03, -3.9973e-03, -9.4141e-04],\n",
       "           [-1.7059e-02, -1.3655e-02, -5.5741e-03]],\n",
       " \n",
       "          [[ 4.4448e-03,  5.3658e-03,  3.4716e-03],\n",
       "           [-7.7005e-04, -2.3068e-03, -1.0096e-03],\n",
       "           [-5.5051e-03, -7.0246e-03, -5.0638e-03]],\n",
       " \n",
       "          [[-9.5144e-04, -2.8090e-04, -5.0231e-03],\n",
       "           [-1.0904e-02, -8.0537e-03, -8.1102e-03],\n",
       "           [-4.4208e-03, -2.9100e-03, -2.2383e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.0318e-03, -7.8083e-04, -6.7692e-03],\n",
       "           [ 3.3022e-03,  1.8979e-03, -1.5656e-03],\n",
       "           [ 1.0476e-03, -1.6375e-04, -4.9214e-03]],\n",
       " \n",
       "          [[ 1.3789e-02,  1.1030e-02,  1.9396e-03],\n",
       "           [ 9.7450e-03,  9.8353e-03,  6.8766e-04],\n",
       "           [ 8.0080e-03,  8.0017e-03, -6.2388e-04]],\n",
       " \n",
       "          [[-2.2170e-02, -1.9484e-02, -1.4444e-02],\n",
       "           [-1.9753e-02, -1.6136e-02, -8.2429e-03],\n",
       "           [-7.6618e-03, -6.1232e-03, -1.0266e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.8933e-03, -3.4554e-03, -7.2042e-03],\n",
       "           [-7.9227e-03, -5.9493e-03, -6.2456e-03],\n",
       "           [-9.0986e-03, -7.7098e-03, -6.0506e-03]],\n",
       " \n",
       "          [[-8.4920e-03, -3.7336e-03,  5.1472e-04],\n",
       "           [-3.7948e-03,  2.0914e-04,  3.8034e-03],\n",
       "           [ 1.9823e-03,  2.2661e-03,  3.8741e-03]],\n",
       " \n",
       "          [[ 3.5115e-03,  2.8064e-03,  6.1113e-04],\n",
       "           [-1.2731e-03, -2.5104e-03, -4.9992e-03],\n",
       "           [-1.6708e-03, -3.7841e-03, -6.2347e-03]]]], device='mps:0'),\n",
       " 'model.1.1.weight': tensor([-0.0493,  0.0148,  0.0245, -0.0203, -0.0193, -0.0186,  0.0181, -0.0234,\n",
       "          0.0072,  0.0086,  0.0318, -0.0168,  0.0283, -0.0370,  0.0034, -0.0237,\n",
       "         -0.1155, -0.0100,  0.0311,  0.0694, -0.0117, -0.0016, -0.0124, -0.0291,\n",
       "         -0.0325,  0.0054,  0.0209,  0.0420,  0.0065,  0.0139,  0.0231, -0.0714],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.bias': tensor([-0.0570, -0.0050,  0.0300, -0.0437, -0.0383, -0.0148,  0.0309, -0.0035,\n",
       "         -0.0873,  0.0127,  0.0364, -0.0025,  0.0585, -0.0072, -0.0196, -0.0217,\n",
       "         -0.0355, -0.0005,  0.0443, -0.0058, -0.0376,  0.0114,  0.0409, -0.0277,\n",
       "         -0.0617, -0.0691,  0.0392,  0.0611, -0.0257, -0.0066,  0.0287, -0.0881],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_mean': tensor([-0.4236, -0.1223, -0.3024, -0.2352,  0.0958,  0.0330, -0.1193, -0.5452,\n",
       "          0.2765,  0.2755, -0.1846,  0.2399, -0.0609, -0.3698, -0.3081, -0.0839,\n",
       "          0.1762, -0.0679, -0.0246, -0.2859, -0.1864, -0.2695, -0.3094, -0.3194,\n",
       "         -0.1110, -0.0336, -0.3329, -0.3204, -0.0564, -0.1211, -0.5051, -0.1050],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_var': tensor([-0.1474, -0.2996,  0.3699,  0.9230,  0.1659,  1.1516, -0.9567, -0.7459,\n",
       "         -4.0413,  0.7908, -0.5407,  0.2668,  0.7219,  0.2024,  0.1887, -0.2498,\n",
       "         -0.1047, -0.3503,  0.2760,  0.2572,  0.4942,  0.3118,  0.0179, -0.3218,\n",
       "         -1.3714, -8.8947,  0.6194, -0.2970, -0.7712, -3.0767, -0.2627,  1.3458],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.2.0.weight': tensor([[[[ 3.3358e-03, -1.5977e-03, -2.2774e-03],\n",
       "           [ 4.6922e-03, -4.3742e-03,  1.9932e-03],\n",
       "           [ 8.3557e-04, -4.9592e-03,  1.1314e-03]],\n",
       " \n",
       "          [[ 2.0948e-02,  1.0265e-02,  7.2582e-03],\n",
       "           [ 1.1749e-02,  6.8610e-03,  1.1623e-02],\n",
       "           [ 2.1901e-02,  7.6236e-03,  5.2128e-03]],\n",
       " \n",
       "          [[-1.0358e-02, -6.6292e-03,  3.8385e-05],\n",
       "           [ 1.8803e-03, -1.0678e-02, -2.7577e-03],\n",
       "           [-8.2586e-03, -8.1551e-04,  1.5665e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0954e-03,  2.3554e-03, -6.3487e-03],\n",
       "           [ 2.5444e-03,  5.7535e-03, -6.2516e-03],\n",
       "           [ 3.1337e-03,  1.8025e-02, -3.8466e-03]],\n",
       " \n",
       "          [[-7.2282e-03, -7.6339e-03, -4.2939e-03],\n",
       "           [ 6.8355e-03,  4.0850e-03,  3.4942e-03],\n",
       "           [ 1.7034e-02,  1.2713e-02,  8.3342e-03]],\n",
       " \n",
       "          [[ 3.1692e-03,  4.2574e-03,  5.9575e-03],\n",
       "           [ 1.2055e-02,  7.8527e-03,  1.1082e-02],\n",
       "           [ 1.7581e-02,  1.2371e-02,  1.4126e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.1969e-03, -3.3197e-03, -2.7577e-03],\n",
       "           [ 3.5921e-03,  5.4353e-03,  2.7968e-03],\n",
       "           [ 9.0631e-03,  8.4831e-03,  5.4640e-03]],\n",
       " \n",
       "          [[-3.3159e-03,  1.4270e-02,  4.7788e-03],\n",
       "           [ 1.5345e-02, -1.3321e-03, -1.3273e-03],\n",
       "           [-1.6172e-02, -1.5282e-03, -1.9268e-03]],\n",
       " \n",
       "          [[-6.2937e-03, -1.5886e-03, -3.9419e-03],\n",
       "           [-1.1935e-02, -7.1745e-03, -3.5772e-03],\n",
       "           [-1.2227e-02,  2.4765e-03, -6.1859e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.5657e-03,  7.9373e-04,  8.7081e-04],\n",
       "           [-3.7424e-04,  1.1685e-03, -1.2215e-03],\n",
       "           [-6.9618e-03,  3.1444e-03, -9.9672e-04]],\n",
       " \n",
       "          [[-2.8738e-05, -4.0801e-03,  9.0016e-04],\n",
       "           [-6.4497e-04,  1.7530e-03,  1.0435e-02],\n",
       "           [-1.2396e-04,  1.0821e-03,  6.1708e-03]],\n",
       " \n",
       "          [[-3.3251e-03,  1.1736e-03, -1.0134e-03],\n",
       "           [-7.9864e-03, -4.5019e-03, -8.4798e-03],\n",
       "           [-5.0244e-03,  3.1076e-04,  2.3254e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2823e-04, -5.2437e-04,  6.7632e-03],\n",
       "           [-2.7689e-04,  1.9618e-03,  7.6463e-04],\n",
       "           [-4.8714e-03, -2.3092e-03, -3.9048e-03]],\n",
       " \n",
       "          [[-3.7524e-03, -9.3239e-03, -7.4536e-03],\n",
       "           [ 6.4701e-03, -1.5710e-02, -1.4321e-02],\n",
       "           [-1.7829e-02, -1.4990e-02, -8.2498e-03]],\n",
       " \n",
       "          [[ 6.7038e-03,  2.5849e-03,  1.0322e-02],\n",
       "           [-7.6173e-03, -8.9366e-05, -4.1267e-03],\n",
       "           [ 9.9916e-03,  8.1374e-03,  6.8321e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7199e-03,  2.1069e-03, -1.7139e-02],\n",
       "           [-2.8554e-03, -3.1245e-03, -9.4666e-03],\n",
       "           [ 1.3391e-04, -3.0240e-03,  2.2426e-03]],\n",
       " \n",
       "          [[ 2.9424e-02,  2.9545e-02,  2.9482e-02],\n",
       "           [ 3.3052e-02,  3.3571e-02,  2.6653e-02],\n",
       "           [ 2.2904e-02,  1.3300e-02,  4.6669e-03]],\n",
       " \n",
       "          [[-1.0823e-02, -5.0131e-03, -7.0529e-04],\n",
       "           [-8.5711e-03, -8.6412e-03, -8.3424e-03],\n",
       "           [-4.9838e-03, -6.3767e-03, -5.6398e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-6.0222e-03, -9.8887e-03, -1.5835e-02],\n",
       "           [-6.0364e-04, -5.7673e-03, -2.8817e-03],\n",
       "           [ 1.8837e-03,  5.8584e-03,  1.1767e-02]],\n",
       " \n",
       "          [[ 6.2720e-04, -3.2781e-03,  2.4058e-02],\n",
       "           [ 1.1947e-02, -9.8853e-04,  1.0005e-03],\n",
       "           [-1.5760e-02, -1.0040e-02,  1.8193e-03]],\n",
       " \n",
       "          [[ 6.4517e-03,  4.7228e-03,  7.4024e-03],\n",
       "           [-3.1788e-03,  7.6358e-03,  5.1370e-03],\n",
       "           [ 7.5801e-03,  2.9740e-03, -1.6435e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3766e-02, -6.3229e-03, -3.7966e-03],\n",
       "           [-1.6311e-02, -5.8814e-03, -7.5012e-03],\n",
       "           [-2.0378e-02, -2.5570e-03, -1.1243e-02]],\n",
       " \n",
       "          [[ 5.0532e-03, -1.0645e-03, -5.1385e-03],\n",
       "           [ 2.4632e-03, -3.8590e-04, -1.9758e-03],\n",
       "           [ 9.1857e-03,  9.5311e-03,  1.1518e-02]],\n",
       " \n",
       "          [[ 6.2039e-03, -6.9888e-04,  3.4342e-03],\n",
       "           [-2.6861e-03, -5.9521e-03, -6.9581e-03],\n",
       "           [ 5.6483e-04, -6.3526e-03, -2.2750e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.6944e-03,  5.6978e-03, -3.0260e-03],\n",
       "           [-2.7072e-03, -8.1253e-04, -5.8536e-03],\n",
       "           [-2.6205e-03, -2.9867e-03,  2.2057e-03]],\n",
       " \n",
       "          [[-9.6850e-03, -9.8591e-03, -1.2619e-02],\n",
       "           [-9.3544e-03, -7.8351e-03, -6.1393e-03],\n",
       "           [ 3.9283e-03,  1.3802e-02,  3.8838e-03]],\n",
       " \n",
       "          [[ 8.6528e-03,  1.1355e-02,  1.5170e-02],\n",
       "           [ 8.2428e-03,  1.2357e-02,  7.8076e-03],\n",
       "           [-1.9337e-03,  1.7554e-03, -6.5707e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.2536e-03,  7.2810e-03,  9.8580e-03],\n",
       "           [-8.3056e-03, -7.8747e-04,  7.3418e-03],\n",
       "           [-7.4943e-03,  6.5732e-03,  6.1599e-03]],\n",
       " \n",
       "          [[ 1.0784e-03, -1.2331e-05, -5.0197e-03],\n",
       "           [-4.2800e-03, -5.3953e-03, -9.5972e-03],\n",
       "           [-4.3052e-03, -2.8856e-03,  2.0099e-03]],\n",
       " \n",
       "          [[-6.1018e-03, -7.5287e-03, -1.5596e-02],\n",
       "           [-5.8495e-03, -3.7883e-03, -9.8991e-03],\n",
       "           [-1.3665e-02, -5.3274e-03, -9.3394e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.3901e-03, -3.5602e-03, -1.1995e-03],\n",
       "           [ 4.2533e-03,  3.1142e-03,  6.5884e-03],\n",
       "           [-6.1365e-03, -1.2232e-02, -7.3953e-03]],\n",
       " \n",
       "          [[ 1.1064e-02,  2.4819e-02,  1.4557e-02],\n",
       "           [-7.1572e-03,  6.1056e-03,  3.5442e-03],\n",
       "           [ 2.3303e-02,  1.2268e-02,  6.5003e-03]],\n",
       " \n",
       "          [[ 1.1539e-02, -3.1709e-03,  6.2604e-03],\n",
       "           [ 1.4876e-02,  1.3429e-02,  1.9914e-02],\n",
       "           [ 7.7953e-03,  5.3013e-03,  1.9887e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.0096e-03,  9.4662e-03, -9.9338e-03],\n",
       "           [ 2.2746e-03,  1.4942e-02, -1.1300e-02],\n",
       "           [-7.8655e-03,  1.5041e-02, -1.3044e-02]],\n",
       " \n",
       "          [[-5.0997e-03, -3.2002e-03, -1.9040e-03],\n",
       "           [-6.0254e-03,  1.9832e-04,  7.7014e-04],\n",
       "           [ 4.0722e-03,  3.8728e-03,  2.9073e-03]],\n",
       " \n",
       "          [[ 2.0402e-02,  2.3728e-02,  2.5594e-02],\n",
       "           [ 1.0420e-02,  1.4480e-02,  1.6088e-02],\n",
       "           [ 6.5538e-03,  1.0954e-02,  1.9848e-02]]]], device='mps:0'),\n",
       " 'model.2.1.weight': tensor([ 0.0426,  0.0078,  0.0146, -0.0266, -0.0350, -0.0196,  0.0235, -0.0210,\n",
       "         -0.0035,  0.0160,  0.0035,  0.0025, -0.0454,  0.0529, -0.0756, -0.0127,\n",
       "         -0.0450, -0.0116, -0.0037,  0.0030, -0.0314, -0.0275, -0.0288, -0.0119,\n",
       "         -0.0218, -0.0550,  0.0190,  0.0114,  0.0474,  0.0230,  0.0222,  0.0532,\n",
       "          0.0079, -0.0109,  0.0039, -0.0491, -0.0251, -0.0321,  0.0428, -0.0026,\n",
       "         -0.0113, -0.0484, -0.0060,  0.0515, -0.0456,  0.0386, -0.0234, -0.0190,\n",
       "          0.0106,  0.0189,  0.0195, -0.0188,  0.0074, -0.0188, -0.0138, -0.0145,\n",
       "          0.0630, -0.0014,  0.0379,  0.0066,  0.0014, -0.0085,  0.0249, -0.0178],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.bias': tensor([ 0.0071, -0.0202,  0.0653,  0.0406, -0.0687, -0.0160,  0.0407, -0.0368,\n",
       "          0.0151,  0.0154,  0.0138, -0.0468, -0.0160,  0.0500, -0.0504, -0.0156,\n",
       "         -0.0398,  0.0119, -0.0256, -0.0265, -0.0107, -0.0259, -0.0369,  0.0137,\n",
       "         -0.0254, -0.0436,  0.0025, -0.0051,  0.0423,  0.0141,  0.0599,  0.0365,\n",
       "          0.0021, -0.0018, -0.0124, -0.0418,  0.0035, -0.0289,  0.0353, -0.0148,\n",
       "         -0.0043, -0.0267, -0.0203, -0.0253, -0.1125,  0.0621, -0.0424, -0.0262,\n",
       "         -0.0099, -0.0441, -0.0090, -0.0311, -0.0468, -0.0134, -0.0399, -0.0236,\n",
       "          0.0274,  0.0113,  0.0515,  0.0389,  0.0140,  0.0052, -0.0159, -0.0298],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_mean': tensor([ 0.2140,  0.0975, -0.0241, -0.0744, -0.1555, -0.0250, -0.0366,  0.0446,\n",
       "          0.0263, -0.1330,  0.1286,  0.0146, -0.0644, -0.1716,  0.1409, -0.1075,\n",
       "          0.0290,  0.1803, -0.2485, -0.2255, -0.2474,  0.0333,  0.1073, -0.1613,\n",
       "          0.1786, -0.2219,  0.1065,  0.1635, -0.0651, -0.0188,  0.0206,  0.0580,\n",
       "          0.3034,  0.1370, -0.0867, -0.0560, -0.0377,  0.1789, -0.1180, -0.0290,\n",
       "         -0.2028,  0.0915,  0.2005,  0.1190,  0.0222,  0.0656, -0.0016, -0.0942,\n",
       "          0.2103, -0.0874,  0.1940, -0.0745,  0.0851, -0.3041, -0.0825,  0.1119,\n",
       "          0.1513,  0.0245, -0.0256,  0.0319, -0.0185,  0.1375, -0.0102,  0.1293],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_var': tensor([-0.4715,  0.5929, -0.4339,  0.5654, -0.1380,  0.2572,  0.1679,  0.2061,\n",
       "          0.2047,  0.1249,  0.7378,  0.2322, -0.4595,  0.3220,  0.4550,  0.3694,\n",
       "         -0.2469,  0.1889, -0.0216,  0.6473,  0.3779,  0.0289,  0.0415,  0.5792,\n",
       "         -0.4005,  1.2180,  0.7216,  0.8520,  0.2553,  0.3662, -0.1013,  0.1310,\n",
       "          0.5430,  0.1856,  1.1557,  0.0858,  0.6518,  0.3079,  0.2410, -0.5870,\n",
       "          0.5770,  0.4991,  0.2795,  0.3619,  0.0676,  0.5238, -0.0429, -0.0335,\n",
       "          0.4255,  0.2851, -0.2757,  0.2823,  0.3885, -0.3277,  0.4326,  0.9883,\n",
       "         -0.4033,  0.0186,  0.3519,  0.2983,  0.1163,  0.2390, -0.4947, -0.2620],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.3.0.weight': tensor([[[[ 4.9826e-03, -9.0481e-03, -5.6392e-03],\n",
       "           [-6.7838e-03, -1.5491e-03,  5.9176e-03],\n",
       "           [ 4.0068e-03,  2.6900e-03, -6.1711e-03]],\n",
       " \n",
       "          [[-7.3918e-03,  3.4351e-03, -7.4734e-03],\n",
       "           [ 1.0698e-02, -8.0187e-03,  5.9524e-03],\n",
       "           [ 4.5172e-03,  6.7075e-03, -8.0327e-03]],\n",
       " \n",
       "          [[ 8.6537e-04,  1.7836e-03,  1.5258e-02],\n",
       "           [-1.5345e-02, -2.4349e-03,  5.8792e-03],\n",
       "           [ 5.5681e-03,  8.7045e-03,  1.5549e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0450e-03,  6.6013e-03,  3.6500e-03],\n",
       "           [-3.6385e-03,  9.9057e-03, -6.4178e-03],\n",
       "           [ 6.2930e-03,  8.8931e-03,  6.9411e-03]],\n",
       " \n",
       "          [[-8.8329e-03,  1.6260e-02, -1.1649e-02],\n",
       "           [ 4.8371e-03,  4.4178e-03, -1.1559e-02],\n",
       "           [-5.8572e-03, -8.3057e-03, -1.4319e-02]],\n",
       " \n",
       "          [[ 1.2658e-03,  1.3852e-02,  1.3109e-02],\n",
       "           [-8.0599e-03,  1.9596e-03, -1.1251e-02],\n",
       "           [-1.1878e-03, -6.9080e-03, -2.6498e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8656e-03,  1.0526e-02,  1.0633e-02],\n",
       "           [ 2.1709e-03,  2.8693e-04, -1.0204e-04],\n",
       "           [ 9.3330e-03,  1.5712e-03,  2.0978e-03]],\n",
       " \n",
       "          [[ 4.4691e-03,  1.6135e-03,  8.1540e-03],\n",
       "           [ 7.3635e-03,  4.9425e-03,  4.0509e-03],\n",
       "           [ 4.4445e-03, -1.7539e-03,  4.4861e-03]],\n",
       " \n",
       "          [[ 5.3051e-03,  6.9025e-03, -2.5581e-03],\n",
       "           [-6.3310e-04,  3.0138e-03,  9.5184e-04],\n",
       "           [-4.0868e-03, -3.3995e-03, -1.4531e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0619e-03,  1.2837e-03,  3.3470e-03],\n",
       "           [ 4.1837e-03,  6.3661e-03,  1.3581e-03],\n",
       "           [ 6.4320e-03, -9.9062e-04,  1.8365e-03]],\n",
       " \n",
       "          [[ 1.4188e-03, -7.8453e-03,  6.9582e-03],\n",
       "           [ 2.9040e-03, -2.9242e-04,  1.0820e-04],\n",
       "           [-3.1717e-03, -1.7504e-03,  6.1221e-03]],\n",
       " \n",
       "          [[ 4.2976e-03, -4.4346e-04, -1.0643e-02],\n",
       "           [ 1.3365e-03,  4.0065e-03, -2.4182e-03],\n",
       "           [ 1.1189e-02,  7.0418e-03,  1.3408e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8983e-02,  3.9694e-03, -2.8899e-03],\n",
       "           [ 9.6258e-03,  1.2554e-03,  8.9127e-03],\n",
       "           [ 1.4442e-02,  5.8843e-03,  1.2980e-02]],\n",
       " \n",
       "          [[ 1.1749e-03,  3.4402e-03,  2.2069e-03],\n",
       "           [ 5.0170e-03,  3.7081e-03,  4.5236e-04],\n",
       "           [ 4.3228e-03,  1.7018e-03,  6.2364e-03]],\n",
       " \n",
       "          [[-1.7491e-03, -1.0251e-02, -1.0214e-02],\n",
       "           [ 2.8154e-03, -7.0960e-03, -6.0495e-03],\n",
       "           [ 3.5228e-03, -2.0228e-03, -9.1791e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2195e-03,  9.0621e-03,  7.0227e-03],\n",
       "           [-2.1163e-03, -1.4900e-03, -1.1447e-02],\n",
       "           [-3.5567e-03,  4.9223e-03, -1.0581e-02]],\n",
       " \n",
       "          [[ 1.9321e-03,  8.0594e-03,  3.2410e-03],\n",
       "           [ 6.5344e-03, -6.7017e-03, -3.1213e-03],\n",
       "           [-2.9517e-03, -1.5560e-02,  5.2068e-03]],\n",
       " \n",
       "          [[-1.2957e-02, -7.6048e-03,  7.0233e-04],\n",
       "           [-1.6029e-02,  7.3096e-03,  3.2141e-03],\n",
       "           [-1.2672e-02, -9.5625e-04, -7.6644e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.2142e-03,  6.9317e-03,  5.3943e-03],\n",
       "           [-2.9726e-04,  1.8991e-02,  2.1028e-02],\n",
       "           [ 2.5357e-03,  1.1299e-02,  6.9075e-03]],\n",
       " \n",
       "          [[ 7.3977e-05,  4.5691e-03, -7.4261e-03],\n",
       "           [-5.6989e-03,  1.5481e-03,  1.3841e-04],\n",
       "           [ 1.2977e-02, -4.2620e-04,  6.2205e-03]],\n",
       " \n",
       "          [[-8.6637e-03, -7.4594e-03, -1.8593e-02],\n",
       "           [-9.6220e-03, -2.7928e-03, -1.1189e-02],\n",
       "           [-4.0564e-03, -1.5600e-03, -1.3004e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.9546e-04,  1.5353e-02, -7.2790e-04],\n",
       "           [-7.1058e-03,  1.1728e-02,  6.8470e-03],\n",
       "           [-8.7322e-04, -6.9375e-04,  1.4241e-02]],\n",
       " \n",
       "          [[ 5.0023e-03,  8.6045e-04,  3.7505e-03],\n",
       "           [ 1.9693e-02,  7.1298e-03, -2.5348e-03],\n",
       "           [ 1.0284e-02,  1.2086e-02, -4.6493e-03]],\n",
       " \n",
       "          [[-1.0669e-02, -9.4093e-04, -4.9378e-03],\n",
       "           [ 3.5518e-03,  1.5776e-03,  9.8021e-04],\n",
       "           [ 8.8787e-03,  5.0321e-03,  1.8586e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.0251e-04,  3.0527e-03, -1.2866e-02],\n",
       "           [-8.7172e-03,  1.5247e-03, -2.9254e-03],\n",
       "           [-5.5876e-03, -2.3123e-03, -6.3033e-03]],\n",
       " \n",
       "          [[ 3.0073e-03,  2.1975e-03, -4.1723e-03],\n",
       "           [ 5.9064e-03,  3.0045e-03, -4.7434e-03],\n",
       "           [ 6.0830e-03,  6.0422e-04, -2.7576e-03]],\n",
       " \n",
       "          [[-1.0434e-03,  1.3079e-03,  8.4693e-03],\n",
       "           [-8.1258e-03, -8.0167e-03, -3.2531e-03],\n",
       "           [-8.1927e-03, -1.5085e-02, -1.1414e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.3064e-03,  4.1975e-04, -8.1651e-03],\n",
       "           [-7.0150e-03,  2.6603e-03, -8.6636e-03],\n",
       "           [-7.3471e-03,  6.8312e-03, -6.4552e-03]],\n",
       " \n",
       "          [[ 6.0377e-03, -4.0648e-04, -2.3102e-03],\n",
       "           [ 5.6821e-03,  2.5453e-03,  7.3080e-04],\n",
       "           [-2.7642e-03,  6.9431e-03,  2.8514e-03]],\n",
       " \n",
       "          [[ 1.1442e-04,  1.2571e-02,  1.4010e-02],\n",
       "           [ 2.2422e-03,  9.1282e-03,  1.1590e-02],\n",
       "           [ 3.3981e-04,  5.6402e-03,  6.7581e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4987e-02,  1.4340e-03, -4.5295e-03],\n",
       "           [-4.1928e-03, -3.3672e-03, -4.9173e-03],\n",
       "           [-8.3889e-03, -9.3705e-03, -1.1141e-02]],\n",
       " \n",
       "          [[-1.2916e-03, -4.0337e-03, -7.9635e-03],\n",
       "           [-1.0422e-02, -5.0252e-03, -2.1793e-03],\n",
       "           [ 1.5885e-02,  1.4979e-03,  3.8738e-03]],\n",
       " \n",
       "          [[ 2.4321e-03,  2.7151e-03,  8.5161e-04],\n",
       "           [-2.3076e-03, -1.6956e-03,  9.9809e-04],\n",
       "           [-4.4622e-03, -1.6577e-03, -2.2520e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8140e-03, -3.8220e-03, -4.0806e-04],\n",
       "           [-3.0155e-03, -5.9120e-03,  6.0332e-03],\n",
       "           [-4.2151e-03,  1.1946e-02,  3.0382e-03]],\n",
       " \n",
       "          [[ 5.3831e-03, -7.8050e-03, -3.0170e-03],\n",
       "           [ 1.6806e-02,  2.0282e-03, -2.2357e-03],\n",
       "           [ 1.6480e-02,  9.2184e-03,  1.2488e-03]],\n",
       " \n",
       "          [[-2.2640e-02, -9.6782e-04, -8.7574e-04],\n",
       "           [-1.5427e-02,  5.4486e-05, -3.8981e-03],\n",
       "           [ 3.7637e-04, -1.9921e-03,  4.8008e-03]]]], device='mps:0'),\n",
       " 'model.3.1.weight': tensor([-0.0248, -0.0060, -0.0018,  0.0296, -0.0047,  0.0388, -0.0250,  0.0039,\n",
       "         -0.0071,  0.0227, -0.0652,  0.0399,  0.0299, -0.0291,  0.0227, -0.0193,\n",
       "          0.0170,  0.0235,  0.0370,  0.0449, -0.0026, -0.0537, -0.0372, -0.0090,\n",
       "         -0.0358, -0.0244, -0.0203, -0.0127, -0.0472, -0.0123,  0.0669,  0.0490,\n",
       "          0.0231, -0.0068, -0.0176, -0.0181,  0.0066,  0.0021,  0.0713,  0.0121,\n",
       "          0.0147,  0.0238,  0.0014, -0.0239,  0.0121, -0.0376,  0.0153,  0.0035,\n",
       "          0.0060, -0.0141,  0.0391, -0.0303,  0.0392,  0.0223,  0.0084,  0.0164,\n",
       "         -0.0091, -0.0019,  0.0121, -0.0390,  0.0142, -0.0266,  0.0160, -0.0449],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.bias': tensor([-0.0415, -0.0288, -0.0160, -0.0265,  0.0070,  0.0325, -0.0136,  0.0051,\n",
       "          0.0076,  0.0188, -0.0524, -0.0192, -0.0027, -0.0321,  0.0382,  0.0169,\n",
       "          0.0088,  0.0051,  0.0494,  0.0635, -0.0085, -0.0244, -0.0348,  0.0109,\n",
       "         -0.0301,  0.0036, -0.0173, -0.0069, -0.0414,  0.0003,  0.0164,  0.0050,\n",
       "          0.0114,  0.0151, -0.0103,  0.0209,  0.0125, -0.0142,  0.0310,  0.0017,\n",
       "         -0.0137, -0.0058,  0.0070, -0.0029,  0.0374, -0.0187,  0.0143,  0.0147,\n",
       "          0.0128, -0.0083,  0.0288, -0.0365,  0.0372,  0.0302, -0.0011,  0.0158,\n",
       "         -0.0294, -0.0083,  0.0237, -0.0405,  0.0229, -0.0277,  0.0207, -0.0143],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_mean': tensor([ 0.1319,  0.2707, -0.1081,  0.0435, -0.0703,  0.0104,  0.1204, -0.0914,\n",
       "         -0.0748,  0.0384, -0.2947, -0.1094,  0.0346, -0.1987,  0.0338,  0.0204,\n",
       "          0.0685,  0.0396,  0.1102, -0.1766,  0.0146,  0.1039, -0.0151, -0.0553,\n",
       "         -0.0057, -0.0476,  0.0221,  0.0312, -0.1879,  0.0445,  0.0969,  0.0429,\n",
       "          0.0682,  0.0774, -0.0258, -0.0571,  0.0524,  0.0817, -0.0185, -0.1953,\n",
       "          0.0643, -0.1481, -0.1674,  0.0945,  0.1030,  0.1061,  0.1516,  0.1655,\n",
       "          0.2344, -0.1409, -0.1182, -0.1360, -0.1012,  0.0249, -0.1240,  0.0766,\n",
       "          0.1007, -0.0857,  0.0379, -0.0571,  0.1282,  0.0142,  0.2257, -0.0298],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_var': tensor([ 0.3219, -0.4409,  0.4636, -0.1853,  0.4742, -0.0661,  0.0439,  0.5691,\n",
       "          0.2829,  0.0503,  0.4853, -0.4068,  0.0280, -0.5041, -0.0186,  0.2541,\n",
       "         -0.1126,  0.1447,  0.8568,  0.1178,  0.1036, -0.0999,  0.9257, -0.0034,\n",
       "          0.1596,  0.0934,  0.3126,  0.1751,  0.0012,  0.1846, -0.0681,  0.0962,\n",
       "         -0.1432,  0.2033, -0.3666, -0.0572,  0.2189,  0.6869, -0.3310,  0.2112,\n",
       "          0.1494,  0.0289,  0.6808,  0.1678,  0.2397, -0.0585,  0.0897,  0.0964,\n",
       "         -0.0858,  0.1028,  0.1808,  0.2323, -0.2036,  0.5438, -0.0180,  0.5175,\n",
       "          0.1627,  0.1726,  0.3148, -0.1410,  0.2319,  0.3322, -0.0262, -0.3670],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.4.0.weight': tensor([[[[-5.4366e-04,  8.2138e-03, -3.1323e-03],\n",
       "           [-2.0293e-03,  3.8964e-03, -4.7715e-03],\n",
       "           [ 5.2717e-03,  6.5219e-03,  1.1815e-02]],\n",
       " \n",
       "          [[ 6.8812e-03,  1.0667e-03,  6.0485e-03],\n",
       "           [ 8.5238e-03,  2.6981e-03,  1.1627e-02],\n",
       "           [ 6.1024e-03,  5.0087e-03,  1.6695e-02]],\n",
       " \n",
       "          [[ 6.2146e-03,  6.0606e-03,  1.7481e-03],\n",
       "           [ 5.9143e-03,  2.2395e-03,  5.6924e-04],\n",
       "           [ 4.3939e-03, -3.6442e-04,  4.2657e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4191e-03, -2.0324e-03, -8.4530e-03],\n",
       "           [-1.0877e-03, -3.4024e-03, -1.7631e-03],\n",
       "           [-4.4991e-04,  1.3639e-03, -4.9482e-04]],\n",
       " \n",
       "          [[ 2.2094e-03,  1.1953e-03,  2.8360e-03],\n",
       "           [ 2.7955e-03,  1.0293e-03,  4.8131e-03],\n",
       "           [ 7.4137e-03,  7.2989e-03,  6.6943e-03]],\n",
       " \n",
       "          [[ 2.0734e-03,  8.7373e-03,  9.4675e-03],\n",
       "           [ 7.3762e-03,  1.1455e-02,  1.2200e-02],\n",
       "           [ 1.1089e-03,  2.8603e-03,  6.3257e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.4899e-03, -5.3057e-03,  8.4131e-03],\n",
       "           [-1.6698e-02, -5.2570e-03,  8.8096e-03],\n",
       "           [-1.5749e-03,  1.6358e-02,  2.2699e-02]],\n",
       " \n",
       "          [[ 4.1224e-03,  6.7711e-03,  8.7328e-03],\n",
       "           [ 7.3404e-03,  2.5802e-03, -3.6643e-03],\n",
       "           [ 1.1256e-02,  2.1263e-03,  1.9954e-03]],\n",
       " \n",
       "          [[-9.2126e-04, -6.0700e-03, -3.7637e-03],\n",
       "           [-5.6626e-04, -5.1200e-03, -1.0831e-02],\n",
       "           [ 3.6368e-03,  1.7811e-03, -8.2605e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2789e-03,  1.6647e-03,  9.8011e-04],\n",
       "           [-1.0088e-02, -8.8414e-03, -7.2553e-03],\n",
       "           [-2.3393e-03, -1.1287e-03,  2.3383e-03]],\n",
       " \n",
       "          [[-8.2796e-03, -8.2317e-03, -5.5559e-03],\n",
       "           [-5.9247e-03, -3.7459e-03, -2.5446e-03],\n",
       "           [-3.3101e-03, -3.7494e-03, -2.5444e-03]],\n",
       " \n",
       "          [[-1.3907e-03, -7.7846e-03, -1.8271e-02],\n",
       "           [ 4.2737e-03, -3.8444e-03, -3.5880e-03],\n",
       "           [ 5.8979e-03,  1.4177e-02,  8.2913e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5585e-02,  4.3734e-03, -1.6077e-03],\n",
       "           [ 7.5149e-04, -7.7672e-03, -1.4673e-02],\n",
       "           [-1.2543e-03, -1.3057e-02, -2.2499e-02]],\n",
       " \n",
       "          [[ 6.9634e-03,  1.0109e-02,  1.0026e-02],\n",
       "           [-9.3718e-04, -7.3598e-04, -1.7731e-03],\n",
       "           [ 9.5480e-04,  1.5824e-03,  3.9066e-03]],\n",
       " \n",
       "          [[-5.9962e-03, -4.5222e-03,  2.2235e-03],\n",
       "           [-2.8509e-03,  7.0135e-04,  5.0799e-03],\n",
       "           [ 1.1738e-03,  3.8555e-03,  7.4527e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.6677e-03, -1.1567e-02,  5.7705e-03],\n",
       "           [-6.5697e-03, -2.0887e-02, -6.0914e-03],\n",
       "           [-6.3169e-03, -1.2510e-02,  1.7087e-03]],\n",
       " \n",
       "          [[ 6.5919e-04,  4.7257e-03,  4.4965e-03],\n",
       "           [-1.8291e-03, -3.2341e-03,  3.2083e-03],\n",
       "           [-2.5865e-03, -2.5214e-03,  1.4819e-03]],\n",
       " \n",
       "          [[-3.3699e-04, -7.1987e-04,  5.1203e-03],\n",
       "           [ 4.2492e-03, -3.0630e-03,  1.3230e-04],\n",
       "           [ 1.5954e-02,  1.4038e-02,  2.0732e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-7.7035e-03,  1.7530e-03,  5.3890e-03],\n",
       "           [-8.1956e-03,  2.0922e-03,  5.6499e-03],\n",
       "           [-1.6687e-02, -3.2996e-03, -4.5359e-03]],\n",
       " \n",
       "          [[-3.9014e-03, -4.8077e-03, -1.0891e-02],\n",
       "           [ 7.0819e-04, -5.6962e-03, -6.8437e-03],\n",
       "           [ 7.0215e-05,  1.0434e-03,  3.3060e-03]],\n",
       " \n",
       "          [[ 9.0560e-04,  1.3365e-03,  1.5076e-03],\n",
       "           [ 2.9075e-03,  5.9113e-03,  7.4042e-03],\n",
       "           [-2.8161e-03, -3.1394e-03, -1.3505e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.6212e-03, -1.9423e-04,  2.5728e-04],\n",
       "           [-2.5337e-03,  3.6893e-03,  6.2259e-03],\n",
       "           [-5.8342e-03, -8.6927e-03, -4.3902e-03]],\n",
       " \n",
       "          [[ 1.9582e-03,  8.5292e-03,  5.4706e-03],\n",
       "           [ 4.7376e-03,  8.8644e-03,  5.3076e-03],\n",
       "           [ 5.9742e-03,  6.5519e-03,  2.1712e-03]],\n",
       " \n",
       "          [[ 7.3985e-03, -8.0435e-03, -1.1836e-02],\n",
       "           [ 2.1606e-02,  1.0305e-02, -5.6907e-03],\n",
       "           [ 5.4141e-03,  8.0938e-03,  8.3643e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1630e-02,  2.0720e-02,  9.4336e-03],\n",
       "           [ 4.0050e-03,  2.3912e-03, -7.9407e-03],\n",
       "           [ 7.5593e-04, -1.7388e-02, -3.0582e-02]],\n",
       " \n",
       "          [[ 2.1778e-03,  7.4421e-03,  9.3021e-03],\n",
       "           [-1.6090e-02, -5.9524e-03,  4.9846e-03],\n",
       "           [-1.5986e-02, -1.5653e-02, -9.8996e-03]],\n",
       " \n",
       "          [[ 1.9631e-03,  9.5623e-03,  2.0183e-02],\n",
       "           [-6.4058e-03, -1.3642e-03,  9.7715e-03],\n",
       "           [ 9.2748e-03,  1.2392e-02,  1.4513e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7115e-02,  9.0735e-04, -1.1567e-02],\n",
       "           [-1.6195e-02, -6.5966e-03, -1.2098e-02],\n",
       "           [-1.9516e-03, -1.1055e-03, -6.1511e-03]],\n",
       " \n",
       "          [[-2.6517e-03,  1.0072e-02,  1.7503e-02],\n",
       "           [-8.0577e-03,  8.9244e-03,  1.2101e-02],\n",
       "           [-5.5798e-03,  8.0791e-03,  1.1009e-02]],\n",
       " \n",
       "          [[ 1.3508e-03,  1.2011e-02,  1.3719e-02],\n",
       "           [-4.9820e-03, -1.3109e-02, -7.7090e-03],\n",
       "           [ 2.3558e-03, -1.0467e-02, -1.1883e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0307e-02, -2.9855e-03, -2.0927e-03],\n",
       "           [ 3.5450e-03,  8.2804e-03, -9.9740e-03],\n",
       "           [ 2.0650e-02,  1.7920e-02,  1.3669e-02]],\n",
       " \n",
       "          [[-6.4724e-03, -1.1481e-02, -1.5557e-02],\n",
       "           [-1.1980e-02, -1.3505e-02, -1.9116e-02],\n",
       "           [-2.8326e-04, -2.5092e-03, -9.0657e-03]],\n",
       " \n",
       "          [[ 8.5923e-03,  6.8987e-03,  3.8130e-03],\n",
       "           [ 2.9038e-03,  3.9832e-03,  2.4776e-03],\n",
       "           [ 1.1594e-02,  9.4120e-03,  5.9620e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0632e-02, -2.8246e-03,  6.9429e-03],\n",
       "           [-1.5995e-02, -6.0140e-03,  6.2041e-03],\n",
       "           [-1.9346e-02, -7.8578e-03,  7.1864e-04]],\n",
       " \n",
       "          [[-1.2233e-02, -1.5159e-02, -7.3857e-03],\n",
       "           [-1.1818e-02, -1.0715e-02, -6.3451e-03],\n",
       "           [-4.7593e-03, -3.2848e-03, -1.8770e-03]],\n",
       " \n",
       "          [[ 2.9862e-03, -2.9970e-03, -1.2150e-02],\n",
       "           [ 4.7639e-03,  9.8164e-03,  5.6548e-03],\n",
       "           [ 5.9816e-03,  1.0735e-02,  6.0726e-03]]]], device='mps:0'),\n",
       " 'model.4.1.weight': tensor([ 0.0437,  0.0264,  0.0571, -0.0040, -0.0158,  0.0177, -0.0303, -0.0227,\n",
       "         -0.0236, -0.0222, -0.0296,  0.0038, -0.0105, -0.0122,  0.0399,  0.0254,\n",
       "          0.0020,  0.0222, -0.0072,  0.0048, -0.0052,  0.0141, -0.0134, -0.0932,\n",
       "          0.0111,  0.0009, -0.0060, -0.0153,  0.0396,  0.0150,  0.0612, -0.0229,\n",
       "          0.0502,  0.0676,  0.0247,  0.0566, -0.0128, -0.0219,  0.0172,  0.0453,\n",
       "          0.0051, -0.0078, -0.0299, -0.0095, -0.0185,  0.0065,  0.0244, -0.0344,\n",
       "         -0.0374,  0.0125, -0.0065, -0.0350, -0.0292, -0.0044, -0.0208,  0.0432,\n",
       "         -0.0451,  0.0317,  0.0241, -0.0197, -0.0110,  0.0065,  0.0878,  0.0027],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.bias': tensor([ 0.0153,  0.0221,  0.0417,  0.0196,  0.0113,  0.0251, -0.0013, -0.0328,\n",
       "         -0.0264, -0.0168,  0.0006,  0.0100,  0.0031, -0.0188,  0.0445, -0.0126,\n",
       "         -0.0018,  0.0130, -0.0032, -0.0190, -0.0128,  0.0282, -0.0020,  0.0051,\n",
       "          0.0190,  0.0079,  0.0020,  0.0336,  0.0058,  0.0201,  0.0349, -0.0198,\n",
       "          0.0249,  0.0260,  0.0119,  0.0876, -0.0090, -0.0034, -0.0162,  0.0280,\n",
       "         -0.0179, -0.0042, -0.0024, -0.0253,  0.0044,  0.0105,  0.0300, -0.0110,\n",
       "         -0.0168,  0.0151, -0.0301, -0.0197, -0.0488,  0.0194, -0.0067,  0.0697,\n",
       "         -0.0536,  0.0074,  0.0059, -0.0106, -0.0091,  0.0201,  0.0636,  0.0143],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_mean': tensor([-0.0235,  0.0890, -0.1168, -0.0650, -0.1158, -0.1082, -0.0814, -0.2448,\n",
       "          0.0586, -0.0250, -0.1095, -0.0697, -0.0375, -0.1073, -0.2537, -0.1275,\n",
       "          0.1428, -0.0162, -0.1409,  0.0471, -0.1590, -0.1058, -0.0676,  0.1245,\n",
       "          0.0224, -0.2491, -0.1917, -0.1392, -0.0794, -0.0615,  0.1151, -0.0128,\n",
       "          0.0426,  0.0393,  0.1242, -0.4306,  0.1259, -0.0818,  0.0425,  0.1963,\n",
       "          0.0792,  0.0187, -0.2558, -0.1395, -0.3659, -0.1540,  0.4013, -0.2134,\n",
       "          0.1887, -0.0841, -0.0307,  0.0155, -0.0523, -0.1746, -0.1190, -0.2061,\n",
       "         -0.2771, -0.0655,  0.0833, -0.1036, -0.0323, -0.0186,  0.0686, -0.0657],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_var': tensor([ 0.0815,  0.3425, -0.1003,  0.3776,  0.0948,  0.1806, -0.0563,  0.2762,\n",
       "          0.0569,  0.1422,  0.5485,  0.2258,  0.2769, -0.3022,  0.0037,  0.3508,\n",
       "          0.2822,  0.1304,  0.2415,  0.2008,  0.0800,  0.4226, -0.1524, -0.0036,\n",
       "          0.2678,  0.0769, -0.0839, -0.0869,  0.0926, -0.1212,  0.1753,  0.7389,\n",
       "          0.1171,  0.3442,  0.5249,  0.3939,  0.3624,  0.1873,  0.2221, -0.2705,\n",
       "          0.1458,  0.2154,  0.3207, -0.0671,  0.0202,  0.1836,  0.2144,  0.1957,\n",
       "          1.1224,  0.1115,  0.2403,  0.4128, -0.0495,  0.1955,  0.0555, -0.2771,\n",
       "          0.6356, -0.1181,  0.4063,  0.1567,  0.3817,  0.3323,  0.6373,  0.0563],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.5.0.weight': tensor([[[[-1.3576e-03, -5.0554e-03, -6.0772e-04],\n",
       "           [-3.1712e-03, -1.0249e-02, -6.2147e-03],\n",
       "           [-3.8982e-03, -1.7731e-02, -2.0006e-03]],\n",
       " \n",
       "          [[-3.0076e-03,  8.2977e-03,  1.4363e-02],\n",
       "           [ 5.6676e-03,  2.1771e-02,  1.0986e-02],\n",
       "           [ 8.5485e-03,  1.1575e-02,  1.0350e-02]],\n",
       " \n",
       "          [[-6.0596e-03,  3.7109e-04,  1.4457e-03],\n",
       "           [ 7.4677e-04, -5.2068e-03, -3.9226e-03],\n",
       "           [ 2.8886e-03, -6.1304e-04,  3.5346e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.1844e-03, -7.1022e-04, -3.3923e-03],\n",
       "           [-4.6760e-03,  5.1007e-05,  6.4520e-04],\n",
       "           [ 7.5895e-04,  5.3291e-03,  5.8232e-03]],\n",
       " \n",
       "          [[-4.4513e-03,  3.8133e-03,  4.1642e-03],\n",
       "           [ 1.0371e-03,  5.6607e-03,  3.5498e-03],\n",
       "           [-8.2975e-03, -3.4430e-03, -1.5722e-03]],\n",
       " \n",
       "          [[ 6.8502e-03,  3.2719e-03,  8.1820e-03],\n",
       "           [ 4.7204e-03,  6.7113e-03,  2.7637e-03],\n",
       "           [ 4.4394e-03,  4.4650e-03,  3.9377e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.9169e-03,  1.1688e-02,  6.0305e-05],\n",
       "           [ 7.3457e-03,  7.3229e-04, -1.6854e-03],\n",
       "           [-6.0369e-03, -4.1462e-03, -1.2537e-02]],\n",
       " \n",
       "          [[-8.5006e-03, -2.8860e-03,  4.3771e-03],\n",
       "           [-2.1184e-03,  2.6872e-03,  5.2178e-03],\n",
       "           [-2.8684e-03, -6.5307e-03, -6.6801e-03]],\n",
       " \n",
       "          [[-1.5449e-02, -1.2775e-02, -6.8589e-03],\n",
       "           [-1.6438e-02, -1.1093e-02, -1.2479e-02],\n",
       "           [-1.5360e-03, -6.7744e-03, -6.2554e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3395e-03, -1.1387e-02, -1.2842e-02],\n",
       "           [-6.2682e-03, -2.1417e-02, -1.3034e-02],\n",
       "           [-1.4543e-02, -1.6537e-02, -1.2625e-02]],\n",
       " \n",
       "          [[ 1.7406e-03,  1.2545e-02, -4.7929e-03],\n",
       "           [ 3.6960e-03,  9.4965e-03, -3.7678e-03],\n",
       "           [-1.7741e-03,  4.6726e-03,  3.1669e-03]],\n",
       " \n",
       "          [[ 5.4693e-03,  1.2207e-03,  3.8944e-03],\n",
       "           [ 3.7746e-03, -9.6900e-05,  4.0972e-03],\n",
       "           [ 9.1776e-03,  6.5677e-03,  7.1622e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.9022e-03, -1.1979e-02, -3.6004e-03],\n",
       "           [ 2.9990e-03, -3.0795e-03, -6.1170e-04],\n",
       "           [ 2.6341e-03, -5.3557e-03, -1.2865e-02]],\n",
       " \n",
       "          [[ 3.4712e-03, -8.1092e-03, -3.9924e-03],\n",
       "           [-4.4124e-03, -5.7006e-03, -6.5054e-03],\n",
       "           [-5.9573e-03,  1.1660e-03, -1.3166e-03]],\n",
       " \n",
       "          [[-1.3752e-03,  1.3636e-03, -4.3022e-03],\n",
       "           [ 1.0944e-03,  1.6326e-03, -3.2393e-03],\n",
       "           [-6.4795e-03, -2.8923e-03,  1.0843e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.3958e-03, -1.6673e-04,  1.4183e-03],\n",
       "           [-3.3560e-03, -3.4438e-03,  1.1804e-02],\n",
       "           [-4.5683e-03, -6.4795e-03,  8.5663e-03]],\n",
       " \n",
       "          [[-5.9868e-03,  7.2834e-03,  1.1660e-03],\n",
       "           [ 2.8266e-03,  1.8176e-02,  1.0733e-02],\n",
       "           [ 7.3415e-03,  2.1603e-03,  7.3948e-03]],\n",
       " \n",
       "          [[-6.7208e-03, -3.4283e-03,  9.5200e-04],\n",
       "           [ 2.0033e-03, -4.3179e-03, -9.1438e-04],\n",
       "           [-2.3581e-03, -1.2073e-03,  4.9944e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.2854e-03,  9.3736e-03,  4.5181e-03],\n",
       "           [ 3.8276e-03,  1.1293e-02,  2.2043e-03],\n",
       "           [-8.1962e-03, -1.4681e-03, -3.5871e-05]],\n",
       " \n",
       "          [[-6.1085e-03, -8.5735e-03,  3.9512e-03],\n",
       "           [-6.9577e-03, -8.1523e-04,  1.1318e-02],\n",
       "           [-2.6326e-03,  3.5791e-03, -2.5647e-03]],\n",
       " \n",
       "          [[-4.9683e-03,  2.3979e-03,  1.1232e-03],\n",
       "           [-1.4525e-02, -1.3531e-02, -1.1279e-02],\n",
       "           [-6.1564e-03, -7.0740e-03, -4.2432e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.2781e-03, -7.0618e-03, -1.1704e-02],\n",
       "           [-3.7341e-03, -1.3537e-02, -1.6055e-02],\n",
       "           [-5.9020e-03, -1.3964e-02, -1.3775e-02]],\n",
       " \n",
       "          [[-1.1225e-02, -7.0945e-03, -9.0991e-03],\n",
       "           [-1.2161e-02, -1.4522e-02, -1.6612e-02],\n",
       "           [ 1.0807e-03, -5.5292e-03,  4.2024e-03]],\n",
       " \n",
       "          [[ 5.7550e-03,  5.7534e-03,  1.0008e-02],\n",
       "           [ 1.2984e-02,  1.3183e-02,  9.3539e-03],\n",
       "           [ 2.9971e-03, -7.5478e-04, -2.8241e-05]]],\n",
       " \n",
       " \n",
       "         [[[ 4.0956e-03,  1.9040e-03,  6.2961e-04],\n",
       "           [-4.5821e-04, -1.3891e-03,  2.3189e-04],\n",
       "           [-6.7394e-04, -2.8689e-03, -7.3090e-03]],\n",
       " \n",
       "          [[-5.2482e-04, -1.5215e-03, -4.2811e-03],\n",
       "           [ 3.4478e-03, -6.3183e-03, -6.9929e-03],\n",
       "           [ 3.4794e-05, -1.2327e-02, -1.0089e-02]],\n",
       " \n",
       "          [[-2.0218e-03, -3.4129e-03, -3.8124e-03],\n",
       "           [-9.8649e-03, -2.7620e-03, -5.4081e-03],\n",
       "           [-2.9656e-03, -1.4607e-04,  1.0724e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0207e-03,  1.5807e-03,  7.4668e-03],\n",
       "           [ 1.8675e-03, -6.7441e-04,  7.0004e-03],\n",
       "           [ 5.7279e-03, -3.9755e-03,  3.7853e-03]],\n",
       " \n",
       "          [[ 4.3562e-03,  1.4035e-03, -3.6728e-03],\n",
       "           [-1.9922e-03,  3.0931e-03, -4.8592e-04],\n",
       "           [-4.7026e-03, -2.3222e-04, -2.2747e-03]],\n",
       " \n",
       "          [[ 8.3997e-04, -2.2547e-03, -3.1534e-03],\n",
       "           [ 8.0391e-04, -1.5348e-03, -2.1693e-03],\n",
       "           [ 2.3109e-03,  3.0168e-03,  4.6638e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8223e-03,  8.6255e-03,  8.4306e-03],\n",
       "           [ 6.5464e-03,  5.8566e-03,  6.8162e-04],\n",
       "           [-1.5785e-03, -7.7375e-04, -9.4473e-03]],\n",
       " \n",
       "          [[ 1.1597e-02, -9.1483e-04, -4.7388e-03],\n",
       "           [ 1.2891e-02, -3.7761e-03,  3.2947e-03],\n",
       "           [ 3.7214e-03, -2.1547e-03,  3.7580e-03]],\n",
       " \n",
       "          [[-1.2473e-03, -1.4469e-03, -1.7626e-03],\n",
       "           [-9.3240e-05,  3.5323e-03,  9.7716e-04],\n",
       "           [-2.6859e-03, -4.9577e-03, -3.3462e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0657e-03,  8.5140e-03,  1.0126e-03],\n",
       "           [ 6.5766e-03,  6.9124e-03,  2.5829e-03],\n",
       "           [ 2.2272e-03,  1.4326e-03,  2.2567e-03]],\n",
       " \n",
       "          [[-8.1449e-03, -3.7677e-04, -2.1203e-03],\n",
       "           [-1.1198e-02, -4.4819e-03, -1.9681e-03],\n",
       "           [-4.6384e-03,  3.8915e-03,  2.9564e-03]],\n",
       " \n",
       "          [[-2.4027e-03, -9.3972e-03, -6.5498e-03],\n",
       "           [-2.3548e-04, -3.0301e-03, -2.2803e-03],\n",
       "           [-1.1193e-03,  9.1503e-04,  2.1777e-03]]]], device='mps:0'),\n",
       " 'model.5.1.weight': tensor([ 0.0182,  0.0092,  0.0065,  0.0127,  0.0456,  0.0232,  0.0009, -0.0095,\n",
       "         -0.0518, -0.0048,  0.0116,  0.0088,  0.0330,  0.0074,  0.0178,  0.0211,\n",
       "         -0.0165,  0.0245, -0.0075, -0.0340,  0.0179,  0.0235, -0.0523, -0.0053,\n",
       "         -0.0187, -0.0149, -0.0144,  0.0052,  0.0338, -0.0105, -0.0081, -0.0343,\n",
       "          0.0008,  0.0383,  0.0257,  0.0321,  0.0076,  0.0241, -0.0179,  0.0160,\n",
       "         -0.0114,  0.0062,  0.0310,  0.0105,  0.0192,  0.0091,  0.0012, -0.0062,\n",
       "         -0.0339, -0.0167,  0.0049, -0.0643, -0.0232, -0.0133, -0.0278, -0.0216,\n",
       "         -0.0506,  0.0104,  0.0242, -0.0166,  0.0494, -0.0418,  0.0075,  0.0088,\n",
       "          0.0028,  0.0468, -0.0106,  0.0213, -0.0110,  0.0406,  0.0114,  0.0057,\n",
       "         -0.0072,  0.0313,  0.0378,  0.0193,  0.0266,  0.0101,  0.0070,  0.0079,\n",
       "          0.0350, -0.0084, -0.0121,  0.0155, -0.0074, -0.0064, -0.0214,  0.0238,\n",
       "         -0.0463, -0.0229, -0.0487,  0.0203,  0.0011, -0.0595, -0.0572,  0.0464,\n",
       "          0.0142, -0.0036,  0.0141, -0.0008,  0.0031, -0.0329,  0.0147, -0.0284,\n",
       "         -0.0067, -0.0100, -0.0142,  0.0083,  0.0217,  0.0050,  0.0050,  0.0011,\n",
       "          0.0240, -0.0191, -0.0137, -0.0235, -0.0085, -0.0043, -0.0110, -0.0113,\n",
       "          0.0025, -0.0075,  0.0616, -0.0025, -0.0070, -0.0333,  0.0010, -0.0274],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.bias': tensor([ 3.6864e-02, -5.2853e-03,  8.3351e-03,  1.9025e-03,  2.7929e-02,\n",
       "         -1.5692e-03, -1.3566e-03, -5.5720e-03, -3.7509e-02,  1.9331e-03,\n",
       "          7.9545e-03,  9.0599e-03,  3.4660e-05, -1.3421e-03,  5.7296e-03,\n",
       "         -6.2264e-03, -3.6915e-02,  7.7527e-03,  2.3207e-02, -2.2164e-02,\n",
       "          1.4653e-02, -1.4569e-02, -2.6418e-02,  7.7331e-03, -1.5108e-02,\n",
       "         -9.0893e-03, -1.6116e-03,  1.0662e-02,  1.8742e-02, -9.7895e-03,\n",
       "          4.9084e-03, -2.4800e-02, -3.9521e-02,  1.7230e-02,  1.3347e-02,\n",
       "          2.0713e-02,  1.5456e-02,  1.8565e-02, -2.5364e-02,  1.1530e-02,\n",
       "         -2.2778e-02, -2.4475e-02,  4.6317e-02,  3.7790e-03,  7.9167e-03,\n",
       "          7.7714e-04,  5.7407e-03, -9.1790e-03, -9.5951e-03, -1.4538e-02,\n",
       "         -5.2309e-03, -7.1778e-02, -3.8057e-02,  6.5109e-03, -1.2252e-02,\n",
       "         -2.5099e-02, -4.0542e-02, -7.1723e-03,  2.5297e-02, -2.4445e-02,\n",
       "          3.0571e-02, -3.2524e-02,  4.3340e-03, -9.4705e-03,  5.6923e-03,\n",
       "          3.0787e-03, -1.7130e-02, -3.9437e-03,  2.4605e-02,  2.7523e-02,\n",
       "          3.6093e-03, -7.0995e-04, -1.5063e-02,  2.0693e-02,  1.5348e-02,\n",
       "          7.0482e-03,  8.1182e-03,  1.9892e-02,  5.6972e-03, -9.0244e-03,\n",
       "          2.2028e-02, -1.2679e-02, -2.2872e-02,  1.9744e-02,  6.2950e-03,\n",
       "         -8.7817e-03, -4.0558e-03,  1.3698e-02, -2.6976e-02, -2.7746e-02,\n",
       "         -4.5429e-02,  5.3183e-03, -8.1593e-03, -2.2966e-02, -1.9835e-02,\n",
       "          3.5966e-02,  4.0371e-03, -2.8270e-03, -2.1122e-03, -1.7579e-02,\n",
       "          1.0553e-02, -2.2266e-02,  1.9671e-02,  1.1104e-02, -1.8715e-02,\n",
       "          5.3031e-03, -1.4854e-02, -7.1751e-03,  7.6924e-03, -7.7404e-03,\n",
       "          1.5309e-02, -2.8798e-03,  8.0121e-03, -6.3360e-03, -5.0917e-03,\n",
       "         -1.4627e-02, -1.3488e-02, -9.5865e-03, -1.5979e-02, -4.0388e-02,\n",
       "         -4.3088e-03, -1.6506e-02,  2.0095e-02,  3.0428e-04, -4.3422e-04,\n",
       "         -1.6318e-02,  3.0567e-03, -4.1157e-02], device='mps:0'),\n",
       " 'model.5.1.running_mean': tensor([ 7.7916e-02,  6.0894e-02, -1.1549e-01,  2.4818e-01,  4.8869e-02,\n",
       "          5.0907e-02,  1.2290e-01, -1.8011e-02,  5.5243e-02, -1.5887e-01,\n",
       "          3.0439e-02, -3.6996e-03,  5.5066e-02,  4.4235e-02,  6.2149e-02,\n",
       "         -1.5011e-01, -7.4450e-02, -7.5818e-02, -4.6138e-02, -7.0938e-02,\n",
       "         -6.5878e-02,  1.2535e-01, -1.2636e-01,  5.4585e-02,  1.4108e-03,\n",
       "          1.1182e-01,  9.6716e-02, -8.2085e-02,  4.7522e-02, -7.4445e-02,\n",
       "          7.9997e-02, -4.6057e-02,  1.4368e-01, -3.6114e-02, -5.1370e-02,\n",
       "          1.2207e-01,  1.0595e-01,  4.2438e-02,  4.8134e-03,  6.6936e-02,\n",
       "          6.4878e-03, -1.4950e-01,  1.6534e-01,  5.9343e-03,  1.5499e-02,\n",
       "         -4.9253e-02, -4.1885e-02, -4.7000e-02, -4.1101e-02,  3.1759e-02,\n",
       "          2.3881e-02, -1.0221e-01,  7.4813e-04, -1.2848e-01, -1.0283e-01,\n",
       "          7.8125e-02, -9.2602e-02,  1.1595e-01,  8.1983e-02, -6.8145e-02,\n",
       "          9.0188e-02, -2.1967e-02, -8.1197e-02,  2.5817e-03,  5.7645e-02,\n",
       "         -1.1973e-01, -1.1848e-01, -1.2246e-02,  1.1738e-02,  1.2689e-01,\n",
       "         -1.7829e-02, -9.8495e-02, -1.6484e-01,  1.2102e-01,  1.7837e-01,\n",
       "         -6.4998e-02,  1.2495e-01,  1.6414e-01,  1.2934e-01,  1.8954e-01,\n",
       "          1.0260e-02,  6.5948e-02,  4.7405e-02,  7.0883e-02, -1.1985e-01,\n",
       "         -2.4036e-03, -1.9840e-01,  1.4843e-01, -1.1871e-01,  1.2433e-01,\n",
       "          1.0878e-01,  3.4402e-02,  5.9968e-02,  1.4430e-02, -5.8400e-02,\n",
       "         -5.4959e-03, -7.6403e-02, -6.1590e-02,  2.8938e-03, -3.0973e-02,\n",
       "         -1.0170e-01, -1.4121e-01,  3.7705e-02, -1.1796e-01,  1.1435e-01,\n",
       "         -3.5430e-02,  1.7262e-02, -1.6099e-03,  1.4971e-01, -9.2876e-02,\n",
       "         -1.8456e-02, -1.4151e-01,  2.1100e-04,  5.9666e-02, -9.5647e-02,\n",
       "          4.2416e-02, -2.7990e-02,  1.7154e-01,  8.4691e-02,  1.1588e-01,\n",
       "          8.2857e-02,  8.7308e-02,  5.9512e-02, -5.9012e-02, -3.5544e-02,\n",
       "         -3.0975e-01, -4.2242e-02,  2.5923e-02], device='mps:0'),\n",
       " 'model.5.1.running_var': tensor([ 0.2115,  0.3403, -0.0463,  0.1534,  0.2472,  0.0723,  0.1632,  0.2370,\n",
       "          0.0983, -0.0688,  0.2038,  0.1623,  0.0674,  0.2069,  0.0144,  0.3651,\n",
       "          0.0239,  0.1004,  0.0612,  0.1207,  0.0401, -0.0969,  0.0322,  0.1513,\n",
       "          0.2205, -0.0049, -0.0939,  0.1443,  0.1378,  0.1176,  0.0151, -0.0880,\n",
       "          0.1998, -0.1143, -0.0611,  0.1731,  0.0084,  0.1127,  0.0234,  0.0459,\n",
       "          0.1915, -0.0592,  0.3270,  0.2091,  0.2248,  0.0105,  0.2122,  0.0797,\n",
       "          0.0062,  0.0571,  0.0081,  0.2809,  0.1360,  0.3072,  0.1306,  0.1241,\n",
       "          0.2568,  0.0096,  0.2356,  0.2362,  0.2199, -0.0818,  0.0942,  0.2415,\n",
       "         -0.0393,  0.0716,  0.1095,  0.1689,  0.0644,  0.1211,  0.0685,  0.1111,\n",
       "          0.1893, -0.1039,  0.3912,  0.1807,  0.0104,  0.0470,  0.1578, -0.0758,\n",
       "         -0.0438, -0.0908,  0.0771,  0.0600,  0.3515, -0.0179, -0.0354,  0.1319,\n",
       "         -0.0850,  0.0745,  0.1665,  0.1022, -0.0526,  0.0366,  0.0208,  0.1176,\n",
       "          0.1549,  0.2569,  0.1684,  0.2120,  0.0518,  0.3050,  0.3108,  0.2070,\n",
       "          0.1468,  0.3369, -0.0834,  0.0641,  0.0342,  0.2261, -0.0164,  0.0225,\n",
       "         -0.2155,  0.1497,  0.0687,  0.0050,  0.1415,  0.0680, -0.0537, -0.1317,\n",
       "         -0.0527,  0.2133, -0.0398,  0.1743, -0.0286,  0.1859,  0.1123,  0.0953],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.6.0.weight': tensor([[[[ 1.3071e-04, -8.3420e-04,  2.7519e-03],\n",
       "           [-5.0059e-03, -5.0105e-04,  3.7691e-04],\n",
       "           [-4.1772e-03,  1.5525e-03,  7.3677e-04]],\n",
       " \n",
       "          [[ 4.8309e-03,  2.4301e-04,  2.2649e-03],\n",
       "           [ 2.3899e-03, -3.5950e-03, -3.8654e-04],\n",
       "           [-3.8148e-03, -2.4047e-03, -6.7456e-03]],\n",
       " \n",
       "          [[ 1.1801e-02,  9.6137e-03,  5.0352e-03],\n",
       "           [ 1.7471e-02,  7.5466e-03,  2.0555e-03],\n",
       "           [ 1.9464e-02,  1.8352e-03,  5.3173e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0588e-02,  3.5197e-03, -3.6164e-04],\n",
       "           [ 5.7178e-03, -8.6636e-03, -9.9473e-03],\n",
       "           [ 4.0018e-03,  6.3593e-03,  5.2831e-03]],\n",
       " \n",
       "          [[ 1.3818e-03,  5.2816e-03,  6.6115e-03],\n",
       "           [-3.8222e-03, -2.7086e-03, -2.7691e-04],\n",
       "           [-4.5063e-03, -1.6946e-03, -7.8629e-03]],\n",
       " \n",
       "          [[ 4.4776e-03, -2.9290e-03, -7.4693e-03],\n",
       "           [-4.9684e-03, -5.5952e-03, -3.2085e-03],\n",
       "           [-1.8952e-02, -1.1485e-02, -8.4496e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 8.7175e-03,  7.4017e-03,  1.1259e-02],\n",
       "           [-2.0112e-04,  7.7636e-03,  9.4757e-03],\n",
       "           [ 1.8476e-02,  9.9177e-03,  4.9130e-03]],\n",
       " \n",
       "          [[-3.2731e-04, -1.3023e-03,  5.0363e-03],\n",
       "           [-6.6298e-03, -5.6470e-03,  7.1063e-04],\n",
       "           [ 6.7283e-03,  7.0223e-03,  3.2773e-03]],\n",
       " \n",
       "          [[-4.6412e-03,  1.3160e-02,  2.5170e-02],\n",
       "           [ 3.3684e-03,  1.3348e-02,  2.9761e-02],\n",
       "           [ 5.6772e-03,  8.4063e-03,  7.2301e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0680e-04,  1.3669e-03,  5.7116e-03],\n",
       "           [-6.0497e-03, -7.8742e-03, -7.4860e-03],\n",
       "           [-9.2280e-03, -9.5451e-03, -9.5957e-03]],\n",
       " \n",
       "          [[ 4.1725e-03, -2.9591e-03,  3.6508e-03],\n",
       "           [ 7.9609e-03,  1.1777e-02,  1.2574e-02],\n",
       "           [-1.4665e-03,  6.0045e-03,  8.6456e-03]],\n",
       " \n",
       "          [[ 4.2829e-03,  6.9809e-03,  3.3218e-03],\n",
       "           [ 6.9872e-03,  2.7766e-03,  6.0032e-03],\n",
       "           [-2.8412e-04, -1.8718e-03, -2.7152e-05]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1635e-03, -2.6378e-03, -5.7682e-03],\n",
       "           [ 6.7215e-03,  2.3702e-03, -1.1404e-03],\n",
       "           [ 5.6517e-03,  4.8717e-03,  1.9173e-03]],\n",
       " \n",
       "          [[ 5.2406e-03,  2.4070e-04, -6.0615e-04],\n",
       "           [ 5.6720e-03,  6.8970e-03,  5.2383e-03],\n",
       "           [ 3.7951e-03,  3.9678e-03,  6.5244e-03]],\n",
       " \n",
       "          [[ 2.0578e-03,  3.4715e-04,  2.3942e-03],\n",
       "           [-4.3271e-03,  1.3291e-04,  3.2989e-03],\n",
       "           [-6.1903e-03,  3.3228e-03,  6.0347e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8113e-03, -7.1381e-03, -4.4908e-03],\n",
       "           [-6.2412e-04, -6.9677e-04, -7.2239e-03],\n",
       "           [ 5.4343e-03,  6.2272e-03,  7.2483e-04]],\n",
       " \n",
       "          [[-1.7669e-03, -1.1508e-03, -2.9769e-03],\n",
       "           [-7.5915e-03, -2.1074e-03, -6.9185e-04],\n",
       "           [-9.8641e-03, -9.1083e-03, -1.5793e-03]],\n",
       " \n",
       "          [[ 2.5735e-03, -1.7119e-03, -3.2889e-03],\n",
       "           [-4.4964e-03, -7.5780e-03, -5.0982e-03],\n",
       "           [-1.3017e-02, -9.2235e-03, -2.3061e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.9603e-03,  7.6505e-03,  8.1853e-03],\n",
       "           [-7.5409e-03,  1.4072e-02, -1.8232e-05],\n",
       "           [ 3.4841e-03,  1.4134e-02, -3.2083e-03]],\n",
       " \n",
       "          [[ 5.2799e-05, -7.5899e-04,  6.0133e-04],\n",
       "           [-1.2173e-03, -1.9764e-03,  5.4880e-03],\n",
       "           [ 6.2444e-03, -1.8553e-03,  1.6158e-03]],\n",
       " \n",
       "          [[-2.1231e-03, -1.5506e-03, -8.1180e-03],\n",
       "           [-1.0315e-02,  2.1179e-03, -4.9908e-03],\n",
       "           [-1.4892e-02, -7.1474e-03, -1.0305e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0903e-03, -1.9860e-03, -5.4517e-03],\n",
       "           [ 9.0153e-03, -8.0686e-03, -1.7720e-03],\n",
       "           [ 3.2407e-03, -2.9961e-03,  4.5671e-03]],\n",
       " \n",
       "          [[ 5.1286e-03,  1.5657e-03,  3.4360e-03],\n",
       "           [-2.1009e-03,  1.9623e-03,  5.3630e-03],\n",
       "           [-1.6642e-03,  2.4997e-03,  1.6314e-03]],\n",
       " \n",
       "          [[ 3.1037e-03,  1.6359e-03, -6.2217e-03],\n",
       "           [ 1.1253e-03,  9.8863e-04, -1.2686e-03],\n",
       "           [-1.2000e-03,  2.6653e-03, -2.0712e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3984e-02,  7.0614e-03,  8.5258e-03],\n",
       "           [ 9.7816e-03, -2.0075e-03, -9.8999e-03],\n",
       "           [ 1.0799e-02,  1.1317e-02,  1.0288e-03]],\n",
       " \n",
       "          [[-1.6736e-03, -3.5030e-04, -2.0032e-03],\n",
       "           [ 2.4073e-03,  4.2016e-04,  1.7613e-03],\n",
       "           [ 8.8198e-03,  2.1385e-03, -3.3931e-04]],\n",
       " \n",
       "          [[-1.6432e-02, -8.4488e-03, -7.2635e-03],\n",
       "           [-1.4892e-02, -9.4809e-03, -3.9988e-03],\n",
       "           [-3.4802e-03, -4.9492e-03,  2.1920e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.4760e-03, -6.9575e-03, -3.4218e-04],\n",
       "           [-5.3337e-03,  1.3419e-02,  1.3833e-02],\n",
       "           [ 1.4047e-02,  2.7491e-03,  5.7668e-03]],\n",
       " \n",
       "          [[-1.1248e-03, -5.7738e-03, -2.9962e-03],\n",
       "           [ 2.4716e-03, -9.4326e-03, -8.0704e-03],\n",
       "           [ 2.1817e-03, -2.8931e-03, -7.0935e-03]],\n",
       " \n",
       "          [[-2.1612e-03,  1.0901e-04, -3.2147e-03],\n",
       "           [ 8.5674e-04, -1.0803e-02, -7.4146e-03],\n",
       "           [ 6.0898e-03, -5.2569e-03, -1.3220e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.1409e-03, -9.8115e-03, -6.5792e-03],\n",
       "           [ 8.8220e-03,  1.8119e-03, -5.6575e-04],\n",
       "           [ 5.4309e-03,  1.8115e-03, -1.0438e-02]],\n",
       " \n",
       "          [[-4.2065e-03, -2.3282e-03, -5.1664e-03],\n",
       "           [-7.7414e-03, -7.8428e-04,  5.4668e-04],\n",
       "           [-3.0250e-03, -4.4081e-03, -8.1251e-04]],\n",
       " \n",
       "          [[ 1.1481e-02,  1.6215e-02,  2.0489e-02],\n",
       "           [ 1.3467e-02,  3.1448e-02,  3.4977e-02],\n",
       "           [-4.6600e-03,  3.8300e-03,  2.0071e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1216e-02, -6.1035e-03, -6.4660e-03],\n",
       "           [-1.0299e-02, -1.1143e-02, -1.5746e-02],\n",
       "           [-6.5158e-03, -1.7121e-03,  1.4655e-04]],\n",
       " \n",
       "          [[ 3.4629e-03,  4.1537e-03,  3.3596e-03],\n",
       "           [-4.0203e-03, -4.7075e-04,  6.0632e-03],\n",
       "           [-2.5957e-03, -3.5838e-03,  3.5211e-03]],\n",
       " \n",
       "          [[ 6.0216e-03,  6.8414e-03,  4.0750e-03],\n",
       "           [-7.1723e-03, -3.5747e-03, -1.8690e-03],\n",
       "           [-7.0710e-03, -1.3561e-02, -3.5530e-03]]]], device='mps:0'),\n",
       " 'model.6.1.weight': tensor([ 0.0749,  0.0107, -0.0454, -0.0127, -0.0536, -0.0338,  0.0172, -0.0101,\n",
       "         -0.0075,  0.0121,  0.0586,  0.0323,  0.0363,  0.0110,  0.0411, -0.0328,\n",
       "         -0.0331, -0.0061, -0.0143,  0.0336,  0.0024, -0.0434,  0.0147,  0.0368,\n",
       "          0.0117,  0.0327, -0.0280, -0.0037,  0.0455,  0.0146, -0.0249, -0.0215,\n",
       "         -0.0492,  0.0107, -0.0264,  0.0309, -0.0108,  0.0251, -0.0033,  0.0337,\n",
       "         -0.0405,  0.0061, -0.0115, -0.0548, -0.0548,  0.0061,  0.0077, -0.0141,\n",
       "         -0.0169,  0.0159, -0.0232, -0.0392,  0.0377, -0.0181,  0.0427, -0.0026,\n",
       "         -0.0196, -0.0027,  0.0189, -0.0022,  0.0114, -0.0413, -0.0001,  0.0137,\n",
       "         -0.0536, -0.0309,  0.0046,  0.0196, -0.0068, -0.0008,  0.0182, -0.0326,\n",
       "          0.0155,  0.0285,  0.0349,  0.0378,  0.0508,  0.0244,  0.0196,  0.0268,\n",
       "          0.0341, -0.0156,  0.0314,  0.0504, -0.0483, -0.0271,  0.0209,  0.0203,\n",
       "         -0.0712, -0.0103, -0.0121, -0.0274,  0.0090,  0.0084,  0.0377, -0.0247,\n",
       "         -0.0153, -0.0284, -0.0127,  0.0958,  0.0591,  0.0430, -0.0148,  0.0102,\n",
       "         -0.0243, -0.0066, -0.0723, -0.0060, -0.0222, -0.0148,  0.0023,  0.0053,\n",
       "         -0.0064, -0.0048,  0.0152,  0.0030, -0.0430,  0.0334, -0.0577, -0.0110,\n",
       "         -0.0204,  0.0035, -0.0193, -0.0062,  0.0066, -0.0145, -0.0086, -0.0022],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.bias': tensor([ 0.0485, -0.0102, -0.0135, -0.0086, -0.0381, -0.0205,  0.0104,  0.0189,\n",
       "         -0.0121, -0.0038,  0.0211,  0.0183,  0.0120, -0.0108,  0.0139, -0.0213,\n",
       "         -0.0275, -0.0019, -0.0170,  0.0397,  0.0051, -0.0220, -0.0024,  0.0028,\n",
       "          0.0106,  0.0236, -0.0207, -0.0080,  0.0416, -0.0112, -0.0274, -0.0283,\n",
       "         -0.0334, -0.0148, -0.0256,  0.0034, -0.0085,  0.0024, -0.0133,  0.0280,\n",
       "         -0.0282,  0.0018, -0.0035, -0.0285, -0.0406,  0.0105, -0.0133, -0.0014,\n",
       "         -0.0118,  0.0093, -0.0191, -0.0519,  0.0222, -0.0106,  0.0075, -0.0065,\n",
       "         -0.0123,  0.0201,  0.0041, -0.0040,  0.0068, -0.0137,  0.0004, -0.0034,\n",
       "         -0.0242, -0.0320, -0.0179,  0.0147, -0.0094, -0.0063,  0.0139, -0.0167,\n",
       "          0.0039,  0.0212,  0.0024,  0.0280,  0.0286,  0.0084,  0.0063,  0.0035,\n",
       "          0.0116, -0.0109, -0.0137,  0.0449, -0.0375, -0.0203,  0.0077,  0.0267,\n",
       "         -0.0438, -0.0091, -0.0289, -0.0056, -0.0040,  0.0068,  0.0148, -0.0127,\n",
       "         -0.0243, -0.0296, -0.0099,  0.0462,  0.0230,  0.0259, -0.0173, -0.0174,\n",
       "         -0.0042, -0.0209, -0.0403, -0.0054, -0.0283, -0.0175, -0.0057,  0.0121,\n",
       "         -0.0104, -0.0035,  0.0208, -0.0096, -0.0444, -0.0029, -0.0494, -0.0014,\n",
       "         -0.0307, -0.0287, -0.0341, -0.0067, -0.0071, -0.0138,  0.0113, -0.0205],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.running_mean': tensor([ 4.0775e-01,  3.6565e-01,  7.0715e-02, -3.8217e-02, -2.0926e-01,\n",
       "         -3.4874e-01, -5.7410e-02, -2.0018e-02,  4.5776e-05,  1.2545e-01,\n",
       "          5.5051e-02,  1.4735e-01, -7.0158e-03, -4.5565e-02,  6.1781e-01,\n",
       "          1.1757e-01, -3.2534e-01, -2.1180e-01, -4.4862e-02, -1.0404e-01,\n",
       "         -7.0423e-02, -3.8209e-02, -2.3393e-01,  5.4976e-01,  5.9028e-02,\n",
       "         -4.8257e-02,  1.2555e-03,  8.3138e-02,  2.0848e-01,  2.1181e-01,\n",
       "          2.3012e-01,  1.7227e-01, -2.3465e-02, -1.5088e-01,  7.0272e-02,\n",
       "          2.5600e-01, -1.1491e-01,  1.5889e-01, -1.1964e-01, -2.0707e-02,\n",
       "         -2.3607e-02, -2.4769e-01, -3.2298e-02, -5.1103e-02, -1.9076e-01,\n",
       "         -3.0832e-02,  3.2090e-01, -1.7061e-01,  1.7259e-01,  1.8071e-01,\n",
       "         -1.5639e-01, -5.3894e-02,  2.4118e-01,  3.9100e-01, -4.9806e-02,\n",
       "         -1.1537e-01,  9.0838e-03,  2.9238e-03, -7.5868e-02,  1.8657e-01,\n",
       "          3.2502e-02,  8.2923e-02,  2.6505e-01,  9.9540e-02, -6.4914e-01,\n",
       "         -7.5485e-02,  4.8967e-02,  6.4885e-02, -6.7689e-02,  1.0961e-01,\n",
       "          3.2838e-02, -3.8011e-01,  2.3890e-01, -2.8920e-01,  2.1448e-01,\n",
       "          2.4188e-01,  4.4968e-02,  1.6390e-01,  1.0382e-01,  7.4917e-02,\n",
       "          2.6933e-01,  2.4581e-01, -5.5546e-01, -7.6547e-02,  9.7852e-02,\n",
       "         -3.5204e-01,  8.8855e-03,  1.6319e-01, -2.6196e-01,  1.1740e-01,\n",
       "         -2.5600e-01,  1.4697e-01,  5.5000e-02, -1.9334e-01, -1.6323e-01,\n",
       "          4.2741e-02, -1.0113e-01, -1.7530e-02,  3.6765e-02,  4.4286e-01,\n",
       "          1.2853e-01,  2.2949e-02, -1.0744e-01,  1.4811e-01,  4.8700e-02,\n",
       "         -3.3912e-01, -1.1815e-01,  2.7387e-01,  2.0213e-02, -2.7048e-01,\n",
       "          1.8166e-01,  7.4559e-02,  9.5798e-02,  1.3143e-01,  1.7736e-01,\n",
       "         -2.0074e-01, -7.7164e-02,  2.0018e-01, -5.2231e-01,  1.4989e-01,\n",
       "         -2.8056e-01, -2.1627e-01, -1.0542e-01, -1.4632e-01,  6.3541e-03,\n",
       "          3.8067e-02,  3.6427e-01, -9.9205e-02], device='mps:0'),\n",
       " 'model.6.1.running_var': tensor([ 0.4318,  0.0257,  0.4285,  0.3674,  0.1404,  0.0936,  0.2344,  0.4419,\n",
       "          0.0417, -0.1975,  0.3023,  0.0327,  0.4439, -0.0687,  0.3297,  0.2987,\n",
       "          0.4202,  0.1442,  0.3022,  0.0444,  0.0301,  0.4122,  0.3759, -0.0746,\n",
       "          0.1219,  0.2268,  0.0526, -0.0854,  0.1017, -0.0351,  0.1011,  0.2399,\n",
       "          0.2148,  0.3559,  0.3552,  0.1056,  0.0514, -0.1128,  0.2829,  0.3496,\n",
       "          0.0704,  0.3496,  0.1128,  0.2377,  0.2954, -0.0010,  0.3143,  0.2001,\n",
       "          0.0123, -0.3128,  0.1816,  0.0959,  0.2775,  0.1452, -0.1999,  0.3606,\n",
       "         -0.0085,  0.0136, -0.0200,  0.1754,  0.3309, -0.0239,  0.2109,  0.0145,\n",
       "          0.0863,  0.2073,  0.3250,  0.3108,  0.0937, -0.1517,  0.0485,  0.2622,\n",
       "          0.2106,  0.2967,  0.0617,  0.0696, -0.0203,  0.0047, -0.0267,  0.2837,\n",
       "          0.2358,  0.0612,  0.3469,  0.1324,  0.1534,  0.3414, -0.1232,  0.0344,\n",
       "          0.1602, -0.0082, -0.0046,  0.0782, -0.0590,  0.2944,  0.1315,  0.1639,\n",
       "         -0.0208,  0.0241,  0.1858,  0.2163,  0.0210, -0.3128,  0.2167,  0.2149,\n",
       "          0.0960,  0.3537, -0.1582,  0.1021,  0.1859, -0.0988, -0.1915,  0.0793,\n",
       "          0.1676,  0.0416,  0.0390,  0.1257,  0.3840,  0.2572,  0.3216,  0.1064,\n",
       "          0.1344,  0.1689,  0.2848, -0.0745, -0.2154,  0.1880,  0.3082,  0.2977],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.7.0.weight': tensor([[[[ 2.0517e-03,  6.2334e-03,  6.1817e-03],\n",
       "           [ 8.8101e-04,  3.9758e-03,  2.3903e-03],\n",
       "           [-2.6057e-03, -1.8735e-03, -1.3249e-03]],\n",
       " \n",
       "          [[-3.8049e-03, -7.9315e-03, -7.7281e-03],\n",
       "           [ 1.7235e-03, -8.2732e-04, -1.8267e-03],\n",
       "           [-1.4006e-03, -2.9209e-03, -3.3566e-03]],\n",
       " \n",
       "          [[ 6.7115e-04,  2.0139e-03,  1.6210e-03],\n",
       "           [ 1.8421e-03,  1.5969e-03,  1.7253e-03],\n",
       "           [ 2.5406e-03, -7.6881e-04, -6.0456e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0357e-03,  9.4351e-04,  2.2469e-03],\n",
       "           [-1.9503e-03, -3.3493e-03,  9.2529e-04],\n",
       "           [-1.8532e-03, -3.2571e-03,  5.6979e-04]],\n",
       " \n",
       "          [[-5.8863e-04,  9.6448e-05, -6.2571e-04],\n",
       "           [ 4.9668e-03,  3.0550e-03, -8.1595e-04],\n",
       "           [ 4.3146e-03,  2.5875e-03,  1.0734e-03]],\n",
       " \n",
       "          [[ 5.8763e-03,  6.7789e-03,  5.3061e-03],\n",
       "           [ 1.3170e-03,  1.5828e-03,  1.6041e-03],\n",
       "           [ 2.2008e-03, -4.6824e-04, -7.6468e-04]]],\n",
       " \n",
       " \n",
       "         [[[-3.3013e-03, -2.9695e-03, -4.8749e-04],\n",
       "           [-2.8518e-03, -5.5628e-04, -1.0022e-04],\n",
       "           [ 2.7214e-03,  4.2079e-03,  3.4405e-03]],\n",
       " \n",
       "          [[ 1.4861e-03,  6.4128e-04, -3.2528e-04],\n",
       "           [-3.3090e-04,  3.0589e-03, -6.0342e-04],\n",
       "           [ 2.2960e-03,  5.7082e-03,  4.7179e-03]],\n",
       " \n",
       "          [[ 3.0858e-03,  1.7860e-03,  9.1179e-04],\n",
       "           [-1.1371e-04, -1.1476e-04, -3.3080e-05],\n",
       "           [-1.7638e-03, -2.3521e-04,  1.2956e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7597e-05,  7.0792e-04,  4.3287e-03],\n",
       "           [-4.2399e-03, -4.6480e-03,  2.6342e-04],\n",
       "           [-2.1896e-03, -5.4366e-03, -1.6472e-03]],\n",
       " \n",
       "          [[ 1.4177e-03,  4.0003e-03,  7.2125e-03],\n",
       "           [ 4.0778e-03,  6.3569e-03,  4.4102e-03],\n",
       "           [ 1.1977e-03,  1.5139e-03,  1.8052e-03]],\n",
       " \n",
       "          [[ 1.9175e-04, -2.5381e-03, -1.3535e-03],\n",
       "           [-5.0462e-03, -6.4214e-03, -4.6157e-03],\n",
       "           [-8.3368e-03, -8.6313e-03, -7.8882e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1979e-03,  2.5365e-03,  6.4927e-03],\n",
       "           [-6.0639e-03,  7.8006e-04,  1.0093e-02],\n",
       "           [-9.5285e-03, -3.2773e-03,  4.6850e-03]],\n",
       " \n",
       "          [[-3.7322e-03, -4.6615e-03, -3.0010e-03],\n",
       "           [-2.8917e-03, -1.6872e-03,  3.2566e-04],\n",
       "           [ 1.2589e-03,  2.7461e-03,  4.0369e-03]],\n",
       " \n",
       "          [[ 2.7707e-03,  3.6473e-03,  2.9769e-03],\n",
       "           [ 3.3579e-04,  2.8721e-03,  4.3871e-03],\n",
       "           [-2.3934e-03,  2.2317e-03,  4.0505e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4473e-03,  5.4112e-03,  9.8907e-03],\n",
       "           [-6.9979e-04,  4.7423e-03,  1.2974e-02],\n",
       "           [-4.2422e-03, -8.2389e-04,  9.2937e-03]],\n",
       " \n",
       "          [[-4.6577e-03, -7.2509e-03, -1.1860e-03],\n",
       "           [-5.6639e-03, -5.1932e-03, -5.0337e-03],\n",
       "           [-2.7726e-03, -7.8620e-04, -3.2809e-03]],\n",
       " \n",
       "          [[ 5.1064e-03,  5.6184e-03,  2.0396e-03],\n",
       "           [ 5.8045e-03,  2.7727e-03,  1.8455e-04],\n",
       "           [ 2.9482e-03,  1.0386e-03, -3.4929e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.5364e-03,  3.4322e-03,  8.5285e-04],\n",
       "           [ 2.5221e-03,  8.2131e-03,  7.0117e-03],\n",
       "           [ 1.3172e-03,  5.0226e-03,  6.3715e-03]],\n",
       " \n",
       "          [[-1.1621e-03,  2.4127e-03,  5.7933e-03],\n",
       "           [-2.1721e-03, -7.2049e-04,  1.6963e-03],\n",
       "           [-5.9237e-03, -4.4604e-03, -3.8483e-03]],\n",
       " \n",
       "          [[ 1.9700e-03,  4.3975e-03,  4.2839e-03],\n",
       "           [ 3.5023e-03,  5.2855e-03,  6.0703e-03],\n",
       "           [ 5.9597e-03,  7.3261e-03,  8.4118e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4643e-03, -2.8993e-03, -3.5025e-03],\n",
       "           [-1.2233e-03,  1.9946e-04,  6.4261e-03],\n",
       "           [ 8.7179e-04,  1.6797e-03,  1.0265e-02]],\n",
       " \n",
       "          [[ 1.4581e-03,  1.0123e-03,  3.8785e-04],\n",
       "           [ 2.4447e-03,  3.1031e-03,  4.4312e-03],\n",
       "           [ 4.1535e-03,  5.5489e-03,  4.8246e-03]],\n",
       " \n",
       "          [[ 6.4126e-04, -3.9622e-05,  1.3498e-03],\n",
       "           [-4.6531e-03,  1.3612e-03, -8.8678e-04],\n",
       "           [-8.7683e-03, -3.3554e-03, -7.4451e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0237e-03,  3.3631e-03,  3.6602e-04],\n",
       "           [-2.3637e-03,  1.0927e-03,  1.7803e-03],\n",
       "           [-2.7856e-03, -1.0822e-03, -8.1450e-04]],\n",
       " \n",
       "          [[-1.4756e-03, -2.3105e-03, -1.9275e-04],\n",
       "           [ 5.0105e-07, -1.0276e-03, -2.1561e-03],\n",
       "           [ 2.1364e-03,  2.8472e-03,  1.6264e-03]],\n",
       " \n",
       "          [[-9.5171e-04, -1.2036e-03, -1.0611e-03],\n",
       "           [ 3.8115e-04,  5.9136e-04,  1.4889e-04],\n",
       "           [ 2.9628e-04,  1.6490e-03,  1.2008e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8188e-05,  5.2266e-03,  6.2848e-03],\n",
       "           [-6.2217e-04,  2.9119e-03,  4.9431e-03],\n",
       "           [ 4.9753e-03,  2.8818e-03,  6.3979e-03]],\n",
       " \n",
       "          [[-2.4784e-03, -9.8208e-04, -7.0310e-04],\n",
       "           [-3.2900e-03, -4.5560e-03, -3.7802e-03],\n",
       "           [ 3.1355e-03,  9.2456e-04, -2.2160e-03]],\n",
       " \n",
       "          [[ 2.1681e-03,  2.2919e-03,  8.1043e-04],\n",
       "           [ 4.9940e-03,  6.0274e-03, -7.9509e-04],\n",
       "           [ 3.4490e-03,  6.2072e-03,  3.6299e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.9193e-03,  3.7278e-03,  4.4395e-03],\n",
       "           [ 1.7038e-03,  2.3888e-03,  3.9227e-03],\n",
       "           [ 2.7619e-03,  3.0468e-03,  4.7566e-03]],\n",
       " \n",
       "          [[-7.3673e-03, -9.2118e-03, -7.7539e-03],\n",
       "           [-5.7497e-03, -5.7562e-03, -2.7590e-03],\n",
       "           [-2.3307e-03,  1.1184e-04,  2.1159e-03]],\n",
       " \n",
       "          [[ 1.3650e-03,  3.3322e-03,  1.5204e-03],\n",
       "           [ 2.0019e-03,  4.4938e-03,  2.2653e-03],\n",
       "           [ 1.5398e-03,  2.0443e-03,  1.4217e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0564e-04, -9.3416e-04,  5.2884e-04],\n",
       "           [-1.6868e-03, -2.4106e-04,  2.5715e-04],\n",
       "           [-6.6623e-04,  2.3624e-03,  1.1503e-03]],\n",
       " \n",
       "          [[ 2.5028e-03, -7.0855e-04, -3.3105e-03],\n",
       "           [-1.2545e-04, -7.0709e-04, -2.7345e-03],\n",
       "           [ 4.4332e-04,  3.0481e-04,  7.4930e-04]],\n",
       " \n",
       "          [[ 1.6831e-03,  2.6950e-04, -1.8566e-03],\n",
       "           [-9.6814e-04, -4.7298e-03, -7.0419e-03],\n",
       "           [-6.6508e-05, -5.6737e-03, -9.4894e-03]]]], device='mps:0'),\n",
       " 'model.7.1.weight': tensor([-0.0023,  0.0052, -0.0105, -0.0076,  0.0005,  0.0007,  0.0014,  0.0156,\n",
       "         -0.0011, -0.0018, -0.0075,  0.0111,  0.0066, -0.0191, -0.0065, -0.0004,\n",
       "         -0.0105, -0.0004, -0.0081,  0.0033, -0.0051,  0.0122, -0.0012, -0.0040,\n",
       "          0.0082, -0.0155, -0.0016, -0.0026,  0.0078, -0.0073,  0.0246,  0.0103,\n",
       "          0.0014,  0.0064,  0.0065,  0.0007, -0.0031,  0.0107, -0.0086,  0.0054,\n",
       "         -0.0066, -0.0009,  0.0001,  0.0073, -0.0073, -0.0033, -0.0041,  0.0177,\n",
       "          0.0029,  0.0078,  0.0072,  0.0011, -0.0059,  0.0044,  0.0039,  0.0040,\n",
       "          0.0070, -0.0053,  0.0081,  0.0103,  0.0059,  0.0012, -0.0002, -0.0017,\n",
       "         -0.0029, -0.0069,  0.0021, -0.0052, -0.0017,  0.0165, -0.0078,  0.0134,\n",
       "         -0.0129,  0.0100, -0.0060,  0.0073,  0.0089, -0.0069, -0.0088,  0.0032,\n",
       "         -0.0160, -0.0097, -0.0019, -0.0019,  0.0118,  0.0063,  0.0009,  0.0135,\n",
       "          0.0012,  0.0003, -0.0029,  0.0075, -0.0006,  0.0149,  0.0032, -0.0129,\n",
       "          0.0071,  0.0011,  0.0167,  0.0046,  0.0102, -0.0026,  0.0023,  0.0089,\n",
       "         -0.0088, -0.0015, -0.0075, -0.0118, -0.0030,  0.0042, -0.0056, -0.0230,\n",
       "          0.0130, -0.0078,  0.0139, -0.0024, -0.0051,  0.0165, -0.0060, -0.0035,\n",
       "          0.0267, -0.0061, -0.0036, -0.0131, -0.0061,  0.0027,  0.0177,  0.0031,\n",
       "         -0.0024, -0.0048,  0.0035,  0.0074, -0.0179, -0.0062, -0.0112,  0.0091,\n",
       "          0.0055,  0.0153,  0.0180,  0.0100,  0.0007, -0.0116, -0.0134, -0.0349,\n",
       "          0.0015, -0.0056,  0.0063, -0.0102,  0.0014,  0.0022,  0.0142, -0.0043,\n",
       "         -0.0056, -0.0191, -0.0073,  0.0030, -0.0071, -0.0185,  0.0043, -0.0035,\n",
       "         -0.0034,  0.0093,  0.0112,  0.0096, -0.0111, -0.0066,  0.0061,  0.0008,\n",
       "         -0.0026,  0.0010,  0.0052, -0.0074,  0.0149, -0.0021,  0.0208, -0.0076,\n",
       "         -0.0113, -0.0175,  0.0067,  0.0154,  0.0067, -0.0011, -0.0160, -0.0115,\n",
       "         -0.0039, -0.0063,  0.0193, -0.0057,  0.0023,  0.0118,  0.0085, -0.0112,\n",
       "          0.0030,  0.0064,  0.0085, -0.0074,  0.0008, -0.0052,  0.0023, -0.0142,\n",
       "          0.0021, -0.0229, -0.0173, -0.0023,  0.0158,  0.0070, -0.0020,  0.0082,\n",
       "         -0.0117, -0.0043, -0.0039,  0.0141, -0.0224, -0.0073, -0.0118,  0.0092,\n",
       "          0.0050, -0.0032, -0.0080,  0.0094,  0.0015, -0.0118, -0.0046,  0.0107,\n",
       "          0.0205,  0.0032, -0.0069, -0.0006, -0.0004, -0.0007,  0.0104, -0.0043,\n",
       "          0.0006,  0.0036, -0.0170,  0.0037, -0.0009, -0.0135, -0.0060,  0.0107,\n",
       "          0.0040, -0.0027, -0.0087, -0.0065,  0.0115, -0.0188, -0.0266,  0.0044,\n",
       "          0.0011,  0.0198, -0.0008,  0.0011, -0.0016, -0.0046, -0.0118,  0.0131],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.bias': tensor([-4.5565e-03,  4.7289e-03, -3.6447e-03,  2.0715e-04, -5.0656e-03,\n",
       "         -3.1018e-03,  6.0310e-04,  7.9931e-03, -2.4715e-03, -3.0658e-03,\n",
       "         -3.2584e-03,  5.9539e-03, -1.3502e-03, -1.8057e-02, -6.3726e-03,\n",
       "          6.8097e-04, -2.0397e-04,  1.2742e-03, -8.7223e-03,  3.7523e-04,\n",
       "         -8.3646e-03,  8.7659e-03,  6.7918e-03, -6.3662e-03,  6.1445e-03,\n",
       "         -1.3393e-02,  2.5458e-03, -5.1503e-03, -1.0376e-03, -1.0977e-02,\n",
       "         -1.3685e-03,  6.8332e-03,  3.5739e-04, -3.8469e-03,  2.5738e-03,\n",
       "         -3.1061e-03, -4.0488e-03,  7.1965e-03, -5.3161e-04,  8.6524e-03,\n",
       "         -1.0123e-03, -5.2310e-03, -1.8362e-03,  6.0408e-03, -6.8454e-03,\n",
       "         -7.0953e-03, -3.0891e-03,  9.9596e-04, -5.5119e-04,  5.5030e-03,\n",
       "          1.1418e-02,  2.3152e-03, -1.3828e-02,  4.0906e-03,  1.2442e-03,\n",
       "          3.7924e-03,  7.4065e-03, -5.7501e-03,  7.9478e-03, -1.0778e-03,\n",
       "         -2.6481e-03, -4.1661e-03, -3.2738e-03, -6.4284e-03,  2.0916e-03,\n",
       "         -1.6258e-02,  5.0572e-03, -9.1019e-03, -4.8046e-03,  8.0586e-03,\n",
       "          1.5994e-03,  1.9920e-03,  8.1807e-06,  4.0066e-03, -6.0474e-03,\n",
       "          2.6236e-03,  1.0083e-02, -1.0068e-02, -5.1233e-03, -6.6950e-03,\n",
       "         -3.8418e-03, -9.6992e-03, -4.1421e-03, -1.0314e-03,  1.0838e-02,\n",
       "         -6.4204e-03, -2.8218e-04,  6.5524e-03, -6.0133e-03,  9.5695e-04,\n",
       "         -7.1173e-03, -1.6291e-03, -4.2416e-03, -3.9190e-03,  2.8521e-03,\n",
       "         -6.8512e-03,  4.6960e-03, -4.1883e-03,  1.3551e-02,  1.1760e-04,\n",
       "          8.0980e-03, -8.7813e-05,  5.4335e-04,  4.7504e-03, -3.8087e-03,\n",
       "         -3.6404e-04, -7.4137e-03, -1.0998e-02, -3.7262e-03,  4.4520e-03,\n",
       "         -2.7591e-03, -1.5311e-02,  8.6341e-03,  2.5073e-04, -1.2658e-03,\n",
       "          1.7631e-03, -1.0163e-02,  1.0807e-02,  1.4880e-04, -5.4533e-03,\n",
       "          5.5416e-03, -3.2033e-03, -6.0060e-03, -8.1240e-03, -3.3737e-03,\n",
       "          3.4252e-04,  3.2949e-03, -5.8619e-03,  8.0231e-04, -1.3618e-02,\n",
       "          3.9566e-03,  9.5317e-03, -1.7240e-02, -9.6886e-03, -7.5062e-03,\n",
       "          1.1710e-02,  2.7347e-03,  1.8008e-03,  8.3226e-03,  1.7554e-03,\n",
       "          2.2309e-03, -1.0771e-03, -1.1368e-02, -3.1175e-02,  2.2874e-03,\n",
       "         -5.6357e-03, -6.4757e-03, -6.3653e-03, -5.1141e-04, -2.2259e-03,\n",
       "          1.9779e-03, -9.7266e-03,  1.2562e-03, -2.3044e-02,  6.0949e-04,\n",
       "         -2.3656e-03, -1.1436e-02, -1.1132e-02, -4.5262e-03, -1.4372e-03,\n",
       "         -2.6797e-03,  2.5620e-03,  7.8155e-03, -1.5132e-03, -4.6074e-03,\n",
       "         -5.0445e-03,  1.9106e-03,  2.6067e-03,  1.8874e-03, -7.2910e-03,\n",
       "          7.2243e-03, -6.3456e-03,  1.3670e-02,  6.4695e-03,  1.4289e-02,\n",
       "         -5.9657e-03, -1.3399e-02, -1.5856e-02,  1.5663e-03,  5.9080e-03,\n",
       "          1.5552e-03,  6.2490e-03, -1.9931e-02, -7.8980e-03, -7.2941e-03,\n",
       "         -1.0491e-02,  3.4988e-03, -1.4228e-02, -4.0471e-03,  4.6208e-03,\n",
       "         -2.9241e-03, -6.4159e-03,  5.3625e-03,  7.2872e-03,  6.4268e-03,\n",
       "         -1.0137e-02,  2.4958e-03, -1.4912e-02, -6.4938e-04, -5.9331e-03,\n",
       "          8.7079e-03, -1.1128e-02, -3.2630e-03, -8.7999e-04,  8.1410e-03,\n",
       "          1.5807e-03,  3.8120e-03,  1.1610e-03, -8.8160e-03, -6.0358e-03,\n",
       "         -3.0124e-03, -1.2868e-03, -1.0864e-02, -9.4283e-03, -2.1874e-02,\n",
       "          1.2089e-02,  3.3202e-03, -1.4795e-02, -6.8872e-03,  6.2302e-03,\n",
       "         -1.4962e-04, -7.5111e-03, -3.2837e-03,  1.0223e-02,  2.9658e-03,\n",
       "          1.0076e-02, -2.0868e-03, -3.8309e-03, -6.5590e-03, -4.5099e-03,\n",
       "          1.0844e-03, -5.2356e-03,  4.1233e-03, -7.6887e-03, -7.0789e-03,\n",
       "         -4.7408e-04, -4.3668e-03, -1.6331e-02, -1.5983e-02,  9.7346e-04,\n",
       "         -8.0358e-03, -5.2041e-03, -2.5228e-03, -8.4471e-03,  8.9741e-03,\n",
       "         -7.6938e-03, -2.4961e-02, -4.0291e-03, -4.5770e-03, -1.3439e-03,\n",
       "         -7.5173e-04, -1.7836e-03, -4.0254e-03, -8.8186e-03, -1.4457e-02,\n",
       "         -7.4933e-04], device='mps:0'),\n",
       " 'model.7.1.running_mean': tensor([ 0.0354,  0.0395, -0.0824,  0.0932, -0.0943,  0.0874,  0.0045,  0.1031,\n",
       "         -0.0546, -0.0184, -0.0391,  0.0558,  0.1633, -0.0530, -0.0942,  0.0417,\n",
       "         -0.1443, -0.1178,  0.0487,  0.0899,  0.1369,  0.0834, -0.0100,  0.1302,\n",
       "          0.0701, -0.1322, -0.0062, -0.0043,  0.1277, -0.0908,  0.0591,  0.0686,\n",
       "          0.0570,  0.0093,  0.0419,  0.0812,  0.0288,  0.0950,  0.0284,  0.0159,\n",
       "         -0.1173,  0.0849, -0.0473,  0.0209, -0.0510,  0.0779, -0.1104, -0.0306,\n",
       "         -0.0125, -0.0717,  0.0167, -0.0087, -0.1108,  0.0057, -0.0637,  0.0876,\n",
       "          0.0982,  0.0107,  0.0776,  0.0878,  0.1244,  0.1762, -0.0343,  0.0375,\n",
       "          0.1013, -0.0396,  0.0481, -0.0271, -0.0061,  0.0054, -0.0080, -0.0282,\n",
       "          0.0787,  0.0381, -0.0911,  0.0018,  0.0710, -0.0887,  0.0534,  0.0335,\n",
       "         -0.1339, -0.1165,  0.0406,  0.0213,  0.0383,  0.0175,  0.0425,  0.0882,\n",
       "          0.0401, -0.0224,  0.1740,  0.0145,  0.1256, -0.0331,  0.0290, -0.0999,\n",
       "          0.1042, -0.0474,  0.0179,  0.0256,  0.1560,  0.0216, -0.0105,  0.0328,\n",
       "          0.0687,  0.1175,  0.0073, -0.0982, -0.0251,  0.0524, -0.1268,  0.0852,\n",
       "          0.0358, -0.0695,  0.0574, -0.0341, -0.0357,  0.0283, -0.0657, -0.0869,\n",
       "          0.0733, -0.0129, -0.0509, -0.0142, -0.0534,  0.0024,  0.0686,  0.0453,\n",
       "          0.0056,  0.0128,  0.1047, -0.0399, -0.0564,  0.0037, -0.1528, -0.1488,\n",
       "          0.0763, -0.0279,  0.0898,  0.1764,  0.0214, -0.0909, -0.0783, -0.0699,\n",
       "         -0.0929, -0.0293,  0.2117,  0.1192,  0.1214,  0.1962, -0.0520, -0.0874,\n",
       "         -0.0551, -0.0816,  0.0962,  0.0754, -0.0766, -0.0969,  0.0819,  0.0564,\n",
       "         -0.1126,  0.0852,  0.0570,  0.0080, -0.0920,  0.0143,  0.1251,  0.0736,\n",
       "         -0.0376,  0.0394, -0.0744,  0.1261,  0.0064, -0.0466,  0.0613, -0.0366,\n",
       "          0.0878, -0.0559,  0.0577, -0.0715, -0.0132,  0.0613,  0.0549,  0.1219,\n",
       "         -0.0361,  0.0222,  0.2053,  0.0725, -0.0039,  0.0304,  0.0625, -0.1129,\n",
       "         -0.0797,  0.0024,  0.0852, -0.0888,  0.1461,  0.0234,  0.0318,  0.0339,\n",
       "          0.0557,  0.0309, -0.0328,  0.1334,  0.0899,  0.0703,  0.0377, -0.0020,\n",
       "          0.0304,  0.0030,  0.0617,  0.0508, -0.0262, -0.0754,  0.1739, -0.0351,\n",
       "         -0.0077,  0.0078,  0.0654,  0.1204,  0.1324, -0.0252, -0.0519,  0.0089,\n",
       "         -0.0527,  0.0873, -0.0927,  0.0995,  0.0190, -0.0965,  0.1836, -0.1142,\n",
       "          0.0587,  0.0967, -0.0476,  0.0280,  0.1096,  0.1197, -0.0776,  0.1576,\n",
       "         -0.0176,  0.0076,  0.0024,  0.0533,  0.0635, -0.1028, -0.1091,  0.1363,\n",
       "          0.1192,  0.0054,  0.0499,  0.0334,  0.1286, -0.1429, -0.0185,  0.0938],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.running_var': tensor([ 6.9679e-02,  1.8804e-03,  8.1287e-02,  9.1219e-04, -8.7469e-03,\n",
       "         -3.0077e-02, -2.4744e-02,  2.2271e-03,  7.1813e-02,  7.4637e-02,\n",
       "          1.5299e-01,  1.0981e-01, -4.4526e-02, -3.0663e-02,  1.1247e-01,\n",
       "          5.9056e-02,  3.0621e-02, -8.6014e-03,  7.6832e-02,  5.9607e-02,\n",
       "          5.5855e-02,  5.2065e-02,  6.3415e-02,  6.4637e-03, -9.8621e-03,\n",
       "          4.8471e-02,  7.4555e-02,  1.1981e-01,  4.1129e-02,  3.0962e-02,\n",
       "          1.7243e-01,  4.9841e-02, -2.6636e-02,  4.7323e-02,  6.1849e-02,\n",
       "         -3.4259e-02,  7.8832e-02,  1.4018e-01,  1.3308e-01,  2.0947e-02,\n",
       "          7.1194e-03, -1.1263e-02,  4.6119e-02, -4.8663e-02,  3.1726e-02,\n",
       "          4.6435e-02,  6.8187e-02,  1.3966e-01,  3.6591e-02,  4.8578e-02,\n",
       "         -3.6682e-03,  7.4817e-02,  1.1394e-01,  8.9680e-03,  7.4471e-02,\n",
       "          6.2386e-02, -3.7449e-02,  3.5168e-02,  1.4092e-01,  1.6924e-02,\n",
       "          6.4598e-02,  7.6232e-02,  1.0271e-02, -8.4220e-03,  5.8437e-02,\n",
       "          7.0997e-02,  1.1700e-02,  5.1161e-02,  1.7607e-02,  8.5831e-02,\n",
       "          1.3278e-01,  6.9547e-02,  8.3653e-02,  2.3560e-02,  3.6889e-02,\n",
       "          2.6925e-03,  1.0528e-02,  6.2937e-02, -1.6055e-02, -4.7661e-03,\n",
       "          3.3525e-02,  5.7503e-02,  1.3304e-01,  9.1781e-02,  9.1315e-02,\n",
       "          4.4895e-02,  3.3722e-02,  5.0625e-02,  3.3136e-02,  6.3097e-02,\n",
       "          1.2166e-01,  2.9471e-02,  1.0233e-01,  9.0502e-02,  8.2697e-02,\n",
       "         -1.3157e-02,  3.2477e-02,  4.3450e-02,  3.4996e-02,  9.7184e-03,\n",
       "          2.3829e-03,  1.8125e-02, -2.1299e-02, -2.5373e-02,  1.1014e-02,\n",
       "          2.5512e-01,  1.4337e-01,  6.6719e-02,  6.7655e-02,  4.0246e-02,\n",
       "          5.0195e-02,  1.7582e-01,  7.7681e-02, -2.9949e-02,  2.8936e-02,\n",
       "          3.0862e-02,  8.7791e-02,  4.3081e-02, -5.8252e-03,  6.0953e-02,\n",
       "          1.1809e-01,  8.4821e-02,  1.5468e-02,  6.5310e-02,  1.7886e-02,\n",
       "         -1.7538e-02,  8.6004e-02,  2.5028e-02, -1.7064e-02,  1.7202e-04,\n",
       "          1.1705e-01,  1.7753e-03,  1.9464e-03,  2.8358e-02,  5.8363e-02,\n",
       "          5.6578e-02, -1.4057e-02,  3.9833e-02,  1.2633e-01,  9.6825e-02,\n",
       "          8.8968e-02,  1.7573e-01,  2.1674e-02,  1.5386e-01,  1.0206e-02,\n",
       "         -1.2032e-02,  5.7442e-02,  1.8822e-01,  1.0513e-01,  4.3114e-02,\n",
       "         -3.0255e-02, -3.4614e-02,  3.2559e-02,  1.2674e-01,  1.0344e-01,\n",
       "         -1.5105e-02,  1.0751e-01,  5.8931e-02,  1.4985e-02,  4.6113e-02,\n",
       "          1.1136e-01,  4.6662e-02,  7.4924e-02, -2.3192e-02, -3.5102e-03,\n",
       "          1.3062e-01, -2.0452e-02, -3.4316e-03,  8.2640e-02,  2.2205e-01,\n",
       "          4.3334e-02, -3.7827e-03,  1.4568e-01,  7.0052e-03,  4.3619e-02,\n",
       "          1.0654e-02,  5.3169e-02,  1.0177e-01,  4.8500e-02,  1.3695e-01,\n",
       "          3.9601e-02,  3.4895e-02,  2.2457e-02,  4.4832e-02,  3.8743e-02,\n",
       "          8.4398e-02,  5.7232e-04, -1.1322e-02, -1.5766e-02, -1.1055e-02,\n",
       "         -3.3162e-02,  7.5921e-02,  1.3255e-01,  1.4679e-01,  6.6896e-02,\n",
       "          2.3296e-02,  1.5025e-01,  3.6828e-02,  5.4549e-02,  5.0382e-02,\n",
       "          7.5294e-02,  4.7960e-02,  7.4526e-02, -4.7406e-02,  1.1297e-02,\n",
       "         -3.2072e-02,  7.4780e-02,  8.8335e-02, -4.4751e-02,  9.8052e-02,\n",
       "          2.9194e-02,  7.0517e-02,  1.2775e-01,  1.4779e-01,  9.2201e-02,\n",
       "          9.3487e-02, -1.8389e-02,  8.4669e-02,  5.0331e-02,  7.6869e-03,\n",
       "         -3.6781e-02,  4.4068e-02,  3.8490e-02,  6.6633e-02,  3.0181e-03,\n",
       "          1.3051e-01,  1.8888e-01,  9.4604e-02,  3.7280e-03,  8.9169e-02,\n",
       "          3.8487e-02,  3.5241e-02, -3.7157e-02,  9.0762e-03,  5.0697e-02,\n",
       "          1.0937e-03,  5.4233e-02,  4.0716e-02, -4.6120e-02,  8.7126e-02,\n",
       "         -2.2258e-02,  6.1884e-02,  4.6615e-02,  3.0538e-02,  2.2038e-02,\n",
       "          1.5614e-01,  1.6655e-01, -1.5412e-02,  4.3932e-02,  1.0146e-01,\n",
       "          4.2755e-02,  2.1295e-02,  6.3833e-02,  4.1134e-02,  1.4524e-02,\n",
       "          8.2085e-03], device='mps:0'),\n",
       " 'model.7.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.8.0.weight': tensor([[[[ 1.0740e-03,  1.6858e-03,  1.4910e-03],\n",
       "           [ 5.0294e-04,  6.6265e-04,  2.9766e-04],\n",
       "           [ 1.1491e-03,  1.3240e-03,  7.1226e-04]],\n",
       " \n",
       "          [[ 1.8466e-03,  1.5779e-03,  1.8594e-03],\n",
       "           [ 6.3967e-04,  4.5447e-05,  1.7523e-04],\n",
       "           [-6.8116e-04, -1.3399e-03, -6.3176e-04]],\n",
       " \n",
       "          [[ 2.8072e-03,  2.8124e-03,  2.4662e-03],\n",
       "           [ 1.8736e-03,  1.0619e-03,  8.1767e-04],\n",
       "           [ 5.1177e-04,  3.1295e-04,  2.1499e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5308e-03, -1.6524e-03, -1.9575e-03],\n",
       "           [-1.5929e-03, -2.4144e-03, -2.9436e-03],\n",
       "           [ 1.0405e-03,  2.3044e-04, -8.1054e-04]],\n",
       " \n",
       "          [[ 1.7641e-03,  1.5366e-03,  8.3419e-04],\n",
       "           [ 1.1004e-03,  6.6200e-04,  2.2354e-04],\n",
       "           [ 8.8269e-04,  2.3944e-04, -5.7464e-04]],\n",
       " \n",
       "          [[ 8.0814e-04,  4.5913e-04,  7.3533e-05],\n",
       "           [ 1.5271e-03,  1.5949e-03,  1.1902e-03],\n",
       "           [ 2.8126e-03,  2.9130e-03,  2.1995e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.8928e-04,  4.8015e-04, -1.6781e-04],\n",
       "           [ 1.1629e-04,  2.6199e-04, -2.5813e-04],\n",
       "           [-1.7059e-03, -1.3768e-03, -1.2667e-03]],\n",
       " \n",
       "          [[ 8.4055e-05,  5.9532e-04, -1.0288e-03],\n",
       "           [-1.4511e-04,  8.3495e-04, -4.8429e-04],\n",
       "           [-8.2982e-04, -1.7627e-04, -7.3789e-04]],\n",
       " \n",
       "          [[-2.5967e-03, -1.8049e-03, -1.4581e-03],\n",
       "           [-9.1513e-04, -6.3578e-05,  3.0416e-04],\n",
       "           [-4.3979e-04, -4.8312e-04,  2.1514e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8921e-04, -1.3678e-03, -2.4479e-03],\n",
       "           [-7.5156e-04, -2.1713e-03, -4.3266e-03],\n",
       "           [-1.1464e-03, -2.8330e-03, -5.2886e-03]],\n",
       " \n",
       "          [[-1.5629e-03, -6.2977e-04, -1.7747e-03],\n",
       "           [-7.0471e-04, -8.1779e-06, -1.4088e-03],\n",
       "           [-8.0628e-04, -2.8300e-04, -1.1736e-03]],\n",
       " \n",
       "          [[-1.3232e-03, -1.1060e-03, -1.0230e-03],\n",
       "           [-7.9600e-04, -5.3122e-04, -6.2549e-04],\n",
       "           [-6.7995e-04, -5.1007e-04, -4.6249e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.8751e-03, -1.7473e-03, -5.0876e-04],\n",
       "           [ 9.9098e-04,  1.0576e-03,  1.6449e-03],\n",
       "           [ 2.3856e-03,  1.6450e-03,  1.1930e-03]],\n",
       " \n",
       "          [[ 1.8742e-03,  4.1429e-04,  5.0437e-04],\n",
       "           [ 2.1272e-03,  1.1366e-03,  1.0783e-03],\n",
       "           [ 4.3610e-03,  2.5250e-03,  1.6300e-03]],\n",
       " \n",
       "          [[ 6.7172e-04,  9.2898e-04, -7.6273e-05],\n",
       "           [ 1.5695e-03,  5.1936e-04, -1.2724e-03],\n",
       "           [ 2.1023e-03,  1.4770e-03, -4.8208e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7299e-03,  6.8409e-04, -4.6816e-04],\n",
       "           [ 2.5781e-03,  1.6854e-03, -5.6364e-05],\n",
       "           [ 3.3384e-03,  2.2927e-03,  5.0925e-04]],\n",
       " \n",
       "          [[ 1.4354e-03,  1.7080e-03,  2.3786e-03],\n",
       "           [-6.2257e-04, -6.1539e-04,  6.1545e-05],\n",
       "           [ 1.5217e-03,  4.1332e-04,  2.5486e-04]],\n",
       " \n",
       "          [[ 6.6634e-04, -1.3553e-04, -2.7100e-04],\n",
       "           [-5.7749e-04, -3.6241e-04,  1.7777e-04],\n",
       "           [-2.6590e-03, -2.0132e-03, -7.6975e-04]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 6.9207e-04,  1.3844e-03,  1.6512e-03],\n",
       "           [-3.6369e-04, -3.8760e-04, -1.8046e-04],\n",
       "           [ 6.0085e-04,  3.7323e-04,  5.8043e-04]],\n",
       " \n",
       "          [[-5.6764e-04, -1.7006e-03, -7.8897e-04],\n",
       "           [ 2.6392e-05, -1.0761e-03, -7.0848e-04],\n",
       "           [ 1.4524e-03,  5.9987e-04,  6.5863e-04]],\n",
       " \n",
       "          [[ 6.2452e-05,  3.0468e-04, -1.2966e-04],\n",
       "           [ 7.1246e-04,  9.7631e-04,  8.4396e-04],\n",
       "           [ 7.5110e-04,  1.0440e-03,  2.6135e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3627e-03, -3.7913e-03, -3.7461e-03],\n",
       "           [-2.0672e-03, -3.4771e-03, -2.6902e-03],\n",
       "           [-9.7428e-04, -1.9125e-03, -7.2911e-04]],\n",
       " \n",
       "          [[ 1.8678e-03,  1.4885e-03,  1.9562e-03],\n",
       "           [ 1.7413e-03,  1.1754e-03,  1.6167e-03],\n",
       "           [ 2.5944e-03,  2.1911e-03,  1.6582e-03]],\n",
       " \n",
       "          [[-7.5730e-05, -2.5194e-05,  3.8111e-04],\n",
       "           [ 1.0511e-04,  3.3979e-04,  6.7720e-04],\n",
       "           [ 4.5638e-04,  8.2275e-04,  1.3615e-03]]],\n",
       " \n",
       " \n",
       "         [[[-6.9047e-04, -7.1952e-04, -3.2166e-04],\n",
       "           [ 1.9615e-04,  6.5921e-04,  8.6715e-04],\n",
       "           [ 1.4030e-03,  1.4063e-03,  1.2401e-03]],\n",
       " \n",
       "          [[-7.1654e-04, -7.8938e-04,  6.0007e-04],\n",
       "           [-1.2828e-04, -1.0060e-04,  8.3679e-04],\n",
       "           [-3.9494e-04, -1.7759e-04,  1.1670e-04]],\n",
       " \n",
       "          [[ 3.0613e-04,  8.4658e-04,  1.1004e-03],\n",
       "           [ 2.3674e-03,  2.5060e-03,  2.0883e-03],\n",
       "           [ 2.3742e-03,  3.4570e-03,  2.8427e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8385e-04, -1.2079e-03, -1.2604e-03],\n",
       "           [ 1.1429e-05,  2.9085e-04,  3.2148e-04],\n",
       "           [-6.2072e-04,  1.1726e-04,  4.3239e-04]],\n",
       " \n",
       "          [[ 6.9818e-04, -5.8202e-05, -2.4990e-05],\n",
       "           [ 2.0687e-04, -2.8985e-05,  3.6061e-05],\n",
       "           [ 5.1825e-04,  7.4383e-04,  4.2630e-04]],\n",
       " \n",
       "          [[ 3.6542e-04, -1.1407e-04, -4.3032e-04],\n",
       "           [-2.6138e-04, -6.2434e-04, -1.0195e-03],\n",
       "           [-2.6136e-04, -8.0968e-04, -1.2565e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.0453e-04, -3.5994e-04, -9.5835e-04],\n",
       "           [-2.0753e-03, -2.1046e-03, -2.1842e-03],\n",
       "           [-1.5014e-04, -5.8247e-04, -9.3550e-04]],\n",
       " \n",
       "          [[ 1.8967e-04,  1.6918e-04, -4.5165e-04],\n",
       "           [-6.5346e-04, -6.5700e-04, -7.8118e-04],\n",
       "           [-1.1144e-03, -1.1100e-03, -5.8004e-04]],\n",
       " \n",
       "          [[ 2.7039e-04,  3.1316e-04,  1.8469e-04],\n",
       "           [-4.8291e-04, -3.2484e-04, -9.3454e-05],\n",
       "           [-5.3997e-04, -2.3873e-04, -2.2707e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.9677e-05,  1.1066e-04,  2.1105e-04],\n",
       "           [-4.2585e-04, -7.3775e-04, -6.4492e-04],\n",
       "           [ 2.6788e-04, -7.2606e-04, -4.6665e-04]],\n",
       " \n",
       "          [[ 6.1540e-04,  5.9804e-04,  3.7607e-04],\n",
       "           [-9.2825e-04, -6.9669e-04, -6.4305e-04],\n",
       "           [-6.3884e-04, -1.0624e-04, -5.8294e-04]],\n",
       " \n",
       "          [[ 1.3975e-03,  1.0989e-03,  6.7647e-04],\n",
       "           [ 1.8117e-04,  8.1220e-05,  3.2222e-04],\n",
       "           [ 1.1803e-05,  1.1838e-04,  1.1939e-04]]]], device='mps:0'),\n",
       " 'model.8.1.weight': tensor([-0.0092, -0.0051, -0.0070, -0.0181, -0.0073, -0.0134,  0.0101, -0.0220,\n",
       "         -0.0172, -0.0073, -0.0058, -0.0025, -0.0104, -0.0147, -0.0037, -0.0099,\n",
       "         -0.0225, -0.0155, -0.0068, -0.0027, -0.0005, -0.0188, -0.0086, -0.0009,\n",
       "          0.0037,  0.0044, -0.0040, -0.0041, -0.0022,  0.0017, -0.0140, -0.0106,\n",
       "         -0.0251, -0.0084, -0.0303, -0.0328, -0.0106, -0.0007, -0.0099, -0.0151,\n",
       "         -0.0014, -0.0151, -0.0195, -0.0012,  0.0051, -0.0132, -0.0103, -0.0123,\n",
       "          0.0003, -0.0078, -0.0076, -0.0351, -0.0159, -0.0103, -0.0353, -0.0036,\n",
       "         -0.0074, -0.0120, -0.0042, -0.0197, -0.0314, -0.0403,  0.0004, -0.0077,\n",
       "         -0.0114, -0.0387, -0.0133, -0.0033, -0.0004, -0.0098, -0.0074, -0.0147,\n",
       "          0.0037, -0.0026,  0.0018, -0.0044, -0.0198, -0.0218, -0.0237, -0.0022,\n",
       "         -0.0020, -0.0122,  0.0090, -0.0018, -0.0037,  0.0024, -0.0048, -0.0005,\n",
       "         -0.0038, -0.0039, -0.0004, -0.0246, -0.0121, -0.0113, -0.0137, -0.0171,\n",
       "          0.0008, -0.0070, -0.0126, -0.0066, -0.0010, -0.0110, -0.0123,  0.0027,\n",
       "         -0.0058, -0.0161, -0.0082, -0.0014, -0.0193, -0.0265, -0.0196, -0.0054,\n",
       "         -0.0252, -0.0058, -0.0109, -0.0159, -0.0054, -0.0059,  0.0029, -0.0285,\n",
       "         -0.0133, -0.0342,  0.0092, -0.0277, -0.0115, -0.0200, -0.0054,  0.0025,\n",
       "          0.0096, -0.0109, -0.0097, -0.0090,  0.0060, -0.0026, -0.0221,  0.0008,\n",
       "         -0.0062, -0.0093, -0.0096, -0.0143, -0.0026,  0.0020, -0.0160, -0.0048,\n",
       "         -0.0061, -0.0151,  0.0055,  0.0036, -0.0198, -0.0049,  0.0091,  0.0038,\n",
       "         -0.0518, -0.0129, -0.0109, -0.0217, -0.0002, -0.0172, -0.0091, -0.0244,\n",
       "         -0.0005, -0.0035,  0.0095, -0.0081, -0.0322, -0.0120, -0.0186, -0.0081,\n",
       "         -0.0158, -0.0056, -0.0147, -0.0009, -0.0033, -0.0212, -0.0006, -0.0112,\n",
       "         -0.0002, -0.0040, -0.0128, -0.0029,  0.0064, -0.0249,  0.0149, -0.0002,\n",
       "         -0.0135, -0.0087, -0.0012, -0.0108, -0.0010, -0.0085, -0.0310, -0.0203,\n",
       "         -0.0250, -0.0159, -0.0069, -0.0268, -0.0032, -0.0027, -0.0116, -0.0036,\n",
       "         -0.0321, -0.0036, -0.0265, -0.0257, -0.0135, -0.0140, -0.0011, -0.0016,\n",
       "          0.0016, -0.0009, -0.0181,  0.0124, -0.0184, -0.0088, -0.0172, -0.0232,\n",
       "         -0.0023, -0.0316, -0.0469,  0.0018,  0.0024, -0.0021,  0.0002, -0.0066,\n",
       "         -0.0011, -0.0013, -0.0326, -0.0037, -0.0051, -0.0074, -0.0170,  0.0055,\n",
       "          0.0113,  0.0065, -0.0122, -0.0104,  0.0037, -0.0112, -0.0223, -0.0071,\n",
       "         -0.0100, -0.0058, -0.0376, -0.0169, -0.0516, -0.0177,  0.0086, -0.0126,\n",
       "         -0.0344, -0.0108,  0.0172, -0.0212, -0.0137,  0.0111,  0.0004, -0.0168],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.bias': tensor([-3.6895e-03, -5.6908e-03, -3.7153e-03, -4.9520e-03, -6.2257e-03,\n",
       "         -7.1844e-03,  7.1700e-03, -1.2713e-02, -1.3508e-02, -7.7962e-03,\n",
       "         -6.8431e-03, -2.6956e-03, -5.7505e-03, -8.9524e-03, -1.4069e-03,\n",
       "         -1.0099e-02, -1.2502e-02, -1.2454e-02, -8.4443e-03,  5.8082e-04,\n",
       "         -2.4657e-03, -1.1119e-02, -5.7276e-03, -3.6200e-03,  2.6721e-03,\n",
       "          3.0894e-03, -4.0139e-03, -3.0636e-03,  2.0701e-04,  1.6941e-03,\n",
       "         -1.4061e-02, -5.9117e-03, -1.8893e-02, -6.4950e-03, -2.1538e-02,\n",
       "         -2.0199e-02, -7.3891e-03, -6.1280e-04, -8.5773e-03, -1.2391e-02,\n",
       "         -1.9501e-03, -1.3669e-02, -2.3200e-02, -2.0710e-03,  6.6145e-03,\n",
       "         -8.7254e-03, -4.0935e-03, -9.8706e-03, -2.4519e-03, -8.9251e-03,\n",
       "         -4.5675e-03, -1.9976e-02, -1.2660e-02, -7.3099e-03, -2.9534e-02,\n",
       "         -3.0900e-03, -5.5124e-03, -6.8988e-03, -4.8643e-03, -1.4786e-02,\n",
       "         -2.0884e-02, -2.1494e-02, -3.5252e-03, -6.6519e-03, -6.7269e-03,\n",
       "         -3.1206e-02, -4.7044e-03, -7.9360e-03, -9.6866e-04, -9.2224e-03,\n",
       "         -6.9297e-03, -1.0228e-02,  1.4381e-03, -2.6647e-03, -1.9923e-03,\n",
       "         -3.7019e-03, -1.4146e-02, -1.1911e-02, -1.6186e-02, -2.5444e-03,\n",
       "         -1.7804e-04, -8.7999e-03,  7.4193e-03, -7.3627e-04,  8.7678e-05,\n",
       "          9.7245e-04, -6.0849e-03, -1.6516e-03, -2.9898e-03, -9.1425e-03,\n",
       "         -6.2822e-03, -1.3983e-02, -8.6046e-03, -6.3068e-03, -8.6698e-03,\n",
       "         -7.1728e-03,  3.8117e-04, -5.0375e-03, -1.7682e-02, -5.2779e-03,\n",
       "         -4.1417e-03, -7.5221e-03, -1.5570e-02,  1.0000e-03, -3.7514e-03,\n",
       "         -1.2025e-02, -2.9358e-03, -3.2806e-03, -1.7719e-02, -1.6060e-02,\n",
       "         -9.8853e-03, -3.7461e-03, -1.4341e-02, -4.6618e-03, -6.6973e-03,\n",
       "         -1.4417e-02, -4.8943e-03, -8.3233e-03,  4.3401e-03, -1.3725e-02,\n",
       "         -1.1194e-02, -2.0550e-02,  7.3744e-03, -1.8915e-02, -7.3262e-03,\n",
       "         -1.5327e-02, -4.3011e-03,  1.8086e-03,  2.6743e-03, -9.5802e-03,\n",
       "         -6.8349e-03, -8.4091e-03,  1.3785e-03,  1.3604e-03, -1.4078e-02,\n",
       "          1.3323e-03, -1.4511e-03, -9.8497e-03, -1.0267e-02, -9.8406e-03,\n",
       "         -3.4138e-03,  1.0101e-03, -1.0180e-02, -5.7570e-03, -7.2241e-03,\n",
       "         -6.1425e-03,  4.9399e-03, -1.0051e-03, -1.1580e-02, -4.2059e-03,\n",
       "          3.5122e-03,  3.2555e-03, -3.5542e-02, -9.7385e-03, -9.5773e-03,\n",
       "         -1.5675e-02, -1.3904e-03, -1.2772e-02, -6.8340e-03, -1.3214e-02,\n",
       "         -1.6366e-03, -4.9503e-03,  4.1249e-03, -4.8337e-03, -2.0885e-02,\n",
       "         -9.9270e-03, -1.0480e-02, -6.8137e-03, -1.6598e-02, -6.0768e-03,\n",
       "         -1.1983e-02, -2.6523e-03, -8.2765e-03, -1.0370e-02, -4.9677e-04,\n",
       "         -1.0225e-02, -3.8370e-03, -3.7636e-03, -1.1654e-02, -6.2794e-03,\n",
       "         -3.9201e-03, -1.6082e-02,  1.0026e-02, -6.5103e-04, -1.2685e-02,\n",
       "         -3.5874e-03,  2.7749e-04, -1.0828e-02, -2.0106e-03, -9.0509e-03,\n",
       "         -1.3965e-02, -1.2117e-02, -1.8486e-02, -9.2219e-03, -2.8093e-03,\n",
       "         -1.7091e-02, -6.1598e-03, -5.4437e-03, -6.9797e-03, -3.1442e-03,\n",
       "         -1.6675e-02, -2.5655e-03, -1.9915e-02, -1.5532e-02, -9.4615e-03,\n",
       "         -1.2357e-02, -4.5616e-03, -2.2272e-03, -2.5168e-03, -5.6157e-03,\n",
       "         -1.8717e-02,  8.0668e-03, -1.0333e-02, -7.0215e-03, -1.4615e-02,\n",
       "         -1.3957e-02, -2.2743e-03, -1.8005e-02, -3.5020e-02,  1.3311e-03,\n",
       "          1.6763e-03,  3.1629e-04, -4.3799e-03, -5.9512e-03, -1.7168e-03,\n",
       "         -4.7117e-04, -1.2035e-02, -1.6885e-03, -1.1097e-03, -8.6320e-03,\n",
       "         -1.2943e-02,  4.8208e-03,  5.1787e-03,  6.2421e-03, -1.1864e-02,\n",
       "         -7.1515e-03,  3.0125e-03, -6.0245e-03, -1.8354e-02, -4.4365e-03,\n",
       "         -8.2314e-03,  1.2086e-03, -2.6164e-02, -7.5684e-03, -2.9539e-02,\n",
       "         -7.5375e-03,  6.1095e-03, -8.3638e-03, -2.6865e-02, -1.2278e-02,\n",
       "          1.5709e-02, -2.2941e-02, -1.2776e-02,  9.2249e-03, -2.6318e-03,\n",
       "         -1.2965e-02], device='mps:0'),\n",
       " 'model.8.1.running_mean': tensor([ 7.6701e-02, -9.9057e-04, -1.0439e-01, -1.0405e-01, -1.5292e-02,\n",
       "          1.6566e-02, -1.6968e-02,  6.8607e-02, -5.6338e-02,  7.3334e-02,\n",
       "          1.3299e-01,  1.7797e-02,  3.3937e-02,  6.0625e-03, -7.2538e-02,\n",
       "         -1.0179e-01,  6.9920e-02, -1.2436e-01, -2.6889e-02, -1.9480e-01,\n",
       "          1.1848e-02,  4.9438e-02,  4.5552e-02,  6.1082e-02,  1.0779e-02,\n",
       "         -2.0955e-02,  8.3009e-02,  9.7089e-02, -5.0629e-02, -5.7997e-03,\n",
       "          5.9691e-03,  5.9561e-02,  7.5626e-04, -3.0608e-02,  5.0774e-03,\n",
       "          1.1817e-01, -6.4884e-03,  1.0030e-01,  7.4885e-02,  8.2999e-02,\n",
       "          5.8127e-02, -1.1321e-01,  1.0962e-01,  5.9943e-03, -6.4405e-03,\n",
       "          1.0523e-01, -5.7532e-02, -6.7834e-02,  3.1678e-02,  3.7399e-02,\n",
       "          4.5598e-02,  1.9541e-01, -4.9726e-02, -4.9794e-02,  2.0769e-02,\n",
       "          2.0011e-03,  1.8736e-02, -2.3771e-01,  7.7313e-02,  2.4288e-02,\n",
       "          1.0642e-01,  1.9782e-01,  2.4733e-02,  6.6080e-02, -9.2621e-02,\n",
       "          1.0158e-01, -8.2522e-02, -1.3905e-02, -9.2971e-02, -7.6430e-02,\n",
       "         -4.6933e-03,  2.0071e-02,  9.2639e-03, -5.3044e-02, -3.8543e-02,\n",
       "         -3.7435e-02,  5.4345e-02, -2.5384e-02,  1.5586e-01, -3.8873e-02,\n",
       "         -3.8922e-02, -3.0344e-02, -3.4743e-02, -1.8795e-01, -1.1780e-01,\n",
       "          4.8716e-02,  9.9519e-02, -1.4206e-02, -1.0050e-02,  7.4868e-02,\n",
       "          1.3507e-02,  2.9880e-02, -7.8687e-02, -7.4365e-02, -9.4557e-03,\n",
       "          1.1530e-01, -1.3660e-01,  6.9452e-02,  1.1057e-01, -7.0446e-02,\n",
       "         -5.2519e-02,  3.1063e-03,  3.8007e-02,  2.7432e-02,  1.0011e-01,\n",
       "          8.2992e-02, -9.8469e-02,  4.1961e-02,  2.3865e-01, -5.0417e-02,\n",
       "          6.0641e-02, -4.5187e-02,  2.5510e-02, -1.2120e-02,  1.1541e-01,\n",
       "         -4.3686e-02,  1.8310e-02,  6.0400e-02,  1.1465e-02,  2.5820e-02,\n",
       "          2.8423e-02,  7.8647e-02,  4.1036e-02,  9.2251e-02, -5.7998e-02,\n",
       "         -1.0517e-01, -8.2294e-03,  2.3248e-02,  3.4752e-02, -6.4384e-03,\n",
       "         -9.6139e-02, -3.6764e-02, -3.5540e-02, -8.8725e-02,  1.2447e-01,\n",
       "          6.0409e-03, -2.6430e-02, -2.5128e-02,  7.6849e-02,  4.7350e-02,\n",
       "          3.7168e-02, -9.0870e-02, -5.2358e-02, -3.3613e-02,  1.5404e-01,\n",
       "         -3.1397e-02, -1.1037e-02,  7.9607e-02, -1.6944e-01,  5.8348e-02,\n",
       "         -3.0730e-02, -8.2936e-02, -6.2696e-02, -3.3786e-03, -6.8326e-02,\n",
       "          8.1821e-02,  3.7548e-02, -6.9476e-02,  3.1679e-03,  1.6222e-02,\n",
       "          1.2729e-01,  3.6812e-02, -1.2955e-01,  9.7027e-03,  1.3227e-01,\n",
       "          3.4658e-02, -2.4448e-03,  8.4803e-02,  6.4157e-02, -2.6283e-02,\n",
       "          3.5485e-02,  1.4420e-02,  2.9898e-02,  3.4962e-02,  4.8269e-02,\n",
       "         -1.0408e-01, -1.1936e-01,  1.2722e-03, -2.2003e-03,  2.2802e-02,\n",
       "         -5.5695e-02, -2.6247e-03,  5.7331e-02,  2.4239e-02,  8.2256e-02,\n",
       "          1.7133e-02, -3.3455e-02,  8.0913e-05,  3.6822e-02,  1.0852e-01,\n",
       "         -1.3835e-02,  8.9349e-02, -9.6949e-03,  1.2451e-01, -2.3070e-02,\n",
       "          7.1175e-02,  1.0585e-01,  4.2959e-02,  3.7559e-02,  8.8584e-03,\n",
       "          7.5155e-02, -1.3459e-01, -4.1046e-02, -2.8470e-02,  5.4816e-02,\n",
       "         -4.0851e-03,  2.8649e-02,  2.6676e-02,  2.5798e-02, -1.1118e-02,\n",
       "         -1.7022e-02, -3.7547e-02,  7.1098e-02,  1.1556e-01,  7.4787e-02,\n",
       "          8.4056e-02, -6.9991e-02,  4.0966e-03,  3.1801e-01,  6.7956e-02,\n",
       "         -1.6856e-02, -4.8278e-02,  1.2742e-02, -1.7395e-02, -1.9939e-02,\n",
       "         -1.8740e-02,  1.5561e-01,  3.8063e-04, -9.1446e-02,  1.3286e-01,\n",
       "          8.6665e-02,  9.9438e-02,  2.5207e-03,  6.6566e-02,  1.1960e-02,\n",
       "          1.3640e-01,  1.0193e-01, -8.3188e-03,  5.1746e-02, -5.6325e-02,\n",
       "         -1.4747e-02,  1.6923e-03,  1.2410e-03, -2.3278e-02,  2.7331e-01,\n",
       "          5.6152e-02,  1.0354e-03, -3.5265e-02, -1.5118e-01,  3.2969e-02,\n",
       "          4.4969e-02, -1.0062e-02, -1.5154e-02,  1.3810e-02, -3.6751e-02,\n",
       "          7.6552e-02], device='mps:0'),\n",
       " 'model.8.1.running_var': tensor([ 0.3939,  0.1592,  0.1613,  0.4959,  0.0290,  0.1566,  0.6811,  0.3738,\n",
       "          0.0350,  0.0018,  0.2694,  0.2825, -0.0131,  0.0273,  0.1462,  0.0754,\n",
       "          0.6141,  0.1154,  0.3660,  0.2358,  0.5272,  0.1845,  0.0768,  1.0490,\n",
       "          0.2747,  0.3258,  0.9945,  0.3883,  0.2041,  0.4575,  0.4282,  0.1309,\n",
       "          0.2635,  0.2318,  0.2153,  0.3493,  0.4514,  0.7338,  0.2359,  0.5072,\n",
       "          0.0055,  0.1302,  0.5215,  0.3971,  0.4877,  0.1884,  0.1081,  0.0600,\n",
       "         -0.0543,  0.5068,  0.1557,  0.5990,  0.1937,  0.0718,  0.3220,  0.2668,\n",
       "          0.2280,  0.4078, -0.0122,  0.5213,  0.3781,  0.4661,  0.5500,  0.2678,\n",
       "          0.4195,  0.2488,  0.3029,  0.2254,  0.0817,  0.3277,  0.3297, -0.0033,\n",
       "          0.3466,  0.2251,  0.3522,  0.2576,  0.0692,  0.2784,  0.7033,  0.2435,\n",
       "          0.0367,  0.2430,  0.3725,  0.5102,  0.2589,  0.4620,  0.8706,  0.3026,\n",
       "          0.1425,  0.0123,  1.1327,  0.4688,  0.2077,  0.1423,  0.2068,  0.2731,\n",
       "          0.2664,  0.0142,  0.2420,  0.2490,  0.1847,  0.2095,  0.4238,  0.8320,\n",
       "          0.3584,  0.2590,  0.5273,  1.0409,  1.0314,  0.1985,  0.1313,  0.3115,\n",
       "          0.4519,  0.0545,  0.1812,  0.2038,  0.2172,  0.7352,  0.7176,  0.1014,\n",
       "          0.1645,  0.5856,  0.6765,  0.3915,  0.3522,  0.0084,  0.0541,  0.0976,\n",
       "          0.5055,  0.2803,  0.3767,  0.2077,  0.2797,  0.0236,  0.1054,  1.0469,\n",
       "          0.3677,  0.0353,  0.0278,  0.2142,  0.6687,  0.2246,  0.2528,  0.1707,\n",
       "          0.0588,  0.4805,  0.5544,  1.3976,  0.2741, -0.0281,  0.8427,  0.2311,\n",
       "          0.3330,  0.1098,  0.1821, -0.0168,  0.2308,  0.1218,  0.1803,  0.2201,\n",
       "          0.6308,  0.6403, -0.0079,  0.6257,  0.1086,  0.4566,  0.2871,  0.3388,\n",
       "         -0.0506,  0.3596,  0.1295,  0.0159,  0.4090,  0.4009,  0.2941,  0.0529,\n",
       "          0.2082, -0.0606,  0.3285,  0.6692,  0.2460,  0.0627,  0.6653,  0.1889,\n",
       "          0.9104,  0.1399,  0.4074,  0.2030,  0.5621,  0.2502,  0.0789,  0.2684,\n",
       "          0.1727,  0.3077,  0.5337,  0.1529,  0.5531,  0.4498,  0.4993,  0.0254,\n",
       "          0.4850,  0.2307,  0.1597,  0.0263,  0.0533,  0.0067,  0.4577,  0.1453,\n",
       "          0.2822,  0.2541,  0.0907, -0.1458,  0.1804,  0.1370,  0.0708, -0.0098,\n",
       "          0.1668,  0.4292,  1.0367,  0.3787,  0.1204, -0.0442,  1.1254,  0.0668,\n",
       "          0.2704,  0.6946,  0.7974,  0.0414,  0.3940,  0.0647,  0.3644,  0.9933,\n",
       "          0.0109,  1.4298,  0.0125,  0.4376,  0.5151,  0.6040,  0.2857,  0.0798,\n",
       "          0.1375,  0.7317,  0.4642,  0.7129,  0.5187,  0.3926,  0.4909,  0.1096,\n",
       "          0.4096,  0.0558,  1.1526,  0.2396,  0.1629,  0.6498,  0.1356,  0.2897],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'classifier.weight': tensor([[-3.5655e-03, -1.9065e-03, -4.1060e-03,  ...,  7.0214e-05,\n",
       "          -1.4665e-03, -5.2476e-03],\n",
       "         [ 1.4721e-03, -1.4277e-03,  1.2915e-03,  ..., -3.0310e-03,\n",
       "           9.2912e-04,  1.6359e-03],\n",
       "         [ 3.4789e-03,  5.5311e-03,  1.1220e-02,  ..., -5.5215e-03,\n",
       "          -2.4371e-03,  6.1973e-03],\n",
       "         ...,\n",
       "         [-3.1053e-04, -9.9510e-05,  1.9950e-03,  ..., -5.4586e-04,\n",
       "           4.8032e-03,  2.6822e-03],\n",
       "         [-1.2812e-02, -4.3093e-03,  3.9149e-03,  ..., -2.7399e-04,\n",
       "          -2.8274e-03, -2.7776e-03],\n",
       "         [ 9.2979e-03,  8.3807e-03,  5.4074e-03,  ...,  1.2728e-02,\n",
       "           4.4645e-03,  4.6760e-03]], device='mps:0'),\n",
       " 'classifier.bias': tensor([-0.0242, -0.0082,  0.0214, -0.0063, -0.0270, -0.0114,  0.0199, -0.0020,\n",
       "          0.0026,  0.0351], device='mps:0')}"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sigmoid_on_cutoff(a,c=0.005, left = False):\n",
    "#     def f(x):\n",
    "#         if(not left and x > (a + 2)):\n",
    "#             return 0\n",
    "#         if(left and x < (a - 2)):\n",
    "#             return 0\n",
    "#         exponent = (-(x-a))/(c if left else -1*c)\n",
    "#         return 1/(1 + (math.e**(exponent)))\n",
    "#     return f \n",
    "\n",
    "# def make_double_sigmoid(a,b):\n",
    "#     left = make_sigmoid_on_cutoff(a, left = True)\n",
    "#     right = make_sigmoid_on_cutoff(b, left = False)\n",
    "#     def f(x):\n",
    "#         return left(x)*right(x)\n",
    "#     return f\n",
    "# baseline2.devices[0]['net']\n",
    "\n",
    "def make_test_device(trainset):\n",
    "    data_idxs = iid_sampler(trainset, 1, .1)\n",
    "    return create_device(ConvNet().to(mps), 0, trainset, data_idxs[0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_noise_attack(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device['net'].state_dict()['model.0.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [x[1] for x in trainset if x[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def swap_classes_dataset(s, a, b):\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if s[i][1] == a:\n",
    "            s[i] = s[i][0],b\n",
    "        if s[i][1] == b:\n",
    "            s[i] = s[i][0],a \n",
    "    \n",
    "    return s\n",
    "\n",
    "# Make switch classes attack\n",
    "def switch_classes_attack(a,b, train_epochs):\n",
    "    transform_train = transforms.Compose([                                   \n",
    "        transforms.RandomCrop(32, padding=4),                                       \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    evil_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "    evil_trainset = swap_classes_dataset(evil_trainset, a,b)\n",
    "    print(\"swapping\\n\")\n",
    "    \n",
    "    # Load testing data\n",
    "    transform_test = transforms.Compose([                                           \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    evil_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transform_test)\n",
    "    \n",
    "    evil_testset = swap_classes_dataset(evil_testset, a,b)\n",
    "    \n",
    "    evil_testloader = torch.utils.data.DataLoader(evil_testset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    attack_idx = iid_sampler(evil_trainset, 1, 1)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    evil_device_trainset = DatasetSplit(evil_trainset, attack_idx)\n",
    "    evil_device_trainloader = torch.utils.data.DataLoader(evil_device_trainset,\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        device['dataloader'] = evil_device_trainloader\n",
    "\n",
    "        for local_epoch in range(train_epochs):\n",
    "            train(local_epoch, device, criterion)\n",
    "        \n",
    "        print(\"Confirm the attack worked. (This should be high)\")  \n",
    "        test(0, device, criterion,testloader =  evil_testloader)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    return attack\n",
    "\n",
    "sca = switch_classes_attack(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Now let's make an instance of this attack that performs 25 epochs of training on the evil device with the misclassified data.\n",
    "# Specifically, we switch cars and airplanes\n",
    "sca2 = switch_classes_attack(0,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 30/Epoch 3) Train Loss: 0.448 | Train Acc: 84.700 | Test Loss: 0.389 | Test Acc: 87.390\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 218.5696198940277 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 3/Epoch 3) Train Loss: 0.327 | Train Acc: 88.8800 | Test Loss: 0.382 | Test Acc: 87.490\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 425.6108150482178 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 14/Epoch 3) Train Loss: 0.222 | Train Acc: 92.600 | Test Loss: 0.408 | Test Acc: 86.950\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 632.2491769790649 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 25/Epoch 3) Train Loss: 0.335 | Train Acc: 88.440 | Test Loss: 0.419 | Test Acc: 86.930\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 830.303952217102 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 40/Epoch 3) Train Loss: 0.231 | Train Acc: 93.040 | Test Loss: 0.383 | Test Acc: 87.780\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1036.1185810565948 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 42/Epoch 3) Train Loss: 0.255 | Train Acc: 91.180 | Test Loss: 0.392 | Test Acc: 87.840\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1244.9114549160004 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 38/Epoch 3) Train Loss: 0.280 | Train Acc: 90.120 | Test Loss: 0.390 | Test Acc: 87.540\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1455.037827014923 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 48/Epoch 3) Train Loss: 0.292 | Train Acc: 89.680 | Test Loss: 0.370 | Test Acc: 88.290\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1667.519868850708 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 42/Epoch 3) Train Loss: 0.345 | Train Acc: 87.840 | Test Loss: 0.369 | Test Acc: 88.460\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1876.9336681365967 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 18/Epoch 3) Train Loss: 0.186 | Train Acc: 93.520 | Test Loss: 0.377 | Test Acc: 88.280\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2105.277766227722 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 14/Epoch 3) Train Loss: 0.225 | Train Acc: 92.440Attacking!\n",
      "\n",
      "(Device 2/Epoch 24) Train Loss: 0.013 | Train Acc: 99.5780Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.855 | Test Acc: 85.830\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.376 | Test Acc: 88.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3514.256497144699 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 49/Epoch 3) Train Loss: 0.228 | Train Acc: 92.280 | Test Loss: 0.363 | Test Acc: 88.500\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3872.9786880016327 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 19/Epoch 3) Train Loss: 0.176 | Train Acc: 94.480 | Test Loss: 0.369 | Test Acc: 88.470\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4388.051183223724 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 12/Epoch 3) Train Loss: 0.181 | Train Acc: 93.920 | Test Loss: 0.368 | Test Acc: 88.760\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4672.941226005554 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 38/Epoch 3) Train Loss: 0.166 | Train Acc: 94.120 | Test Loss: 0.368 | Test Acc: 88.920\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4955.253675937653 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 34/Epoch 3) Train Loss: 0.158 | Train Acc: 94.380 | Test Loss: 0.365 | Test Acc: 89.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5454.384433269501 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 42/Epoch 3) Train Loss: 0.237 | Train Acc: 93.120 | Test Loss: 0.349 | Test Acc: 89.640\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5803.5099267959595 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 40/Epoch 3) Train Loss: 0.209 | Train Acc: 92.960 | Test Loss: 0.355 | Test Acc: 88.940\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6158.822886943817 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 12/Epoch 3) Train Loss: 0.298 | Train Acc: 90.6200 | Test Loss: 0.376 | Test Acc: 89.040\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6527.806505918503 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 46/Epoch 3) Train Loss: 0.197 | Train Acc: 93.1000 | Test Loss: 0.364 | Test Acc: 89.170\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6739.291934967041 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 13/Epoch 3) Train Loss: 0.243 | Train Acc: 91.7600 | Test Loss: 0.358 | Test Acc: 89.550\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6952.29815196991 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 15/Epoch 3) Train Loss: 0.188 | Train Acc: 93.9600 | Test Loss: 0.350 | Test Acc: 89.550\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7167.842609167099 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 7/Epoch 3) Train Loss: 0.195 | Train Acc: 94.0000 | Test Loss: 0.347 | Test Acc: 89.590\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7389.792389154434 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 34/Epoch 3) Train Loss: 0.107 | Train Acc: 96.5800 | Test Loss: 0.354 | Test Acc: 89.690\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7609.542908191681 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 0/Epoch 3) Train Loss: 0.172 | Train Acc: 94.1200 | Test Loss: 0.381 | Test Acc: 89.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7972.639851093292 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 37/Epoch 3) Train Loss: 0.071 | Train Acc: 97.7000 | Test Loss: 0.347 | Test Acc: 90.250\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8186.583430051804 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 49/Epoch 3) Train Loss: 0.076 | Train Acc: 97.6600 | Test Loss: 0.347 | Test Acc: 90.240\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8406.754409074783 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 13/Epoch 3) Train Loss: 0.071 | Train Acc: 98.1800 | Test Loss: 0.349 | Test Acc: 90.220\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8638.34443116188 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 26/Epoch 3) Train Loss: 0.067 | Train Acc: 97.8200 | Test Loss: 0.350 | Test Acc: 90.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8878.929777145386 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 24/Epoch 3) Train Loss: 0.071 | Train Acc: 98.1400 | Test Loss: 0.352 | Test Acc: 90.350\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 9122.999819993973 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 9140.565530061722 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_no_defense = run_federated_test(                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca2, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_no_defense.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_classes_no_defense = load_result(\"switch_classes_no_defense.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.2,\n",
       " 44.42,\n",
       " 54.68,\n",
       " 60.89,\n",
       " 65.69,\n",
       " 69.14,\n",
       " 71.45,\n",
       " 73.38,\n",
       " 76.61,\n",
       " 77.53,\n",
       " 79.7,\n",
       " 77.91,\n",
       " 79.95,\n",
       " 81.38,\n",
       " 82.4,\n",
       " 82.86,\n",
       " 83.43,\n",
       " 83.6,\n",
       " 84.71,\n",
       " 85.13,\n",
       " 85.46,\n",
       " 85.9,\n",
       " 85.79,\n",
       " 86.54,\n",
       " 86.48,\n",
       " 87.19,\n",
       " 87.33,\n",
       " 87.52,\n",
       " 87.52,\n",
       " 87.37,\n",
       " 87.48,\n",
       " 87.65,\n",
       " 87.62,\n",
       " 87.56,\n",
       " 87.58,\n",
       " 87.7,\n",
       " 87.63,\n",
       " 87.62,\n",
       " 87.8,\n",
       " 87.76,\n",
       " 87.92,\n",
       " 87.82,\n",
       " 87.87,\n",
       " 87.91,\n",
       " 87.96,\n",
       " 87.89,\n",
       " 88.11,\n",
       " 87.85,\n",
       " 87.89,\n",
       " 88.12,\n",
       " 88.09,\n",
       " 87.96,\n",
       " 88.01,\n",
       " 87.94,\n",
       " 88.05,\n",
       " 88.0,\n",
       " 87.96,\n",
       " 88.07,\n",
       " 88.05,\n",
       " 88.0,\n",
       " 88.17,\n",
       " 88.07,\n",
       " 88.23,\n",
       " 88.07,\n",
       " 88.08,\n",
       " 87.99,\n",
       " 88.1,\n",
       " 88.11,\n",
       " 88.13,\n",
       " 88.12,\n",
       " 88.09,\n",
       " 88.12,\n",
       " 88.08,\n",
       " 88.12,\n",
       " 88.13,\n",
       " 88.11,\n",
       " 88.06,\n",
       " 88.12,\n",
       " 88.07,\n",
       " 88.15,\n",
       " 88.1,\n",
       " 88.06,\n",
       " 88.16,\n",
       " 88.12,\n",
       " 88.14,\n",
       " 88.14,\n",
       " 88.18,\n",
       " 88.12,\n",
       " 88.11,\n",
       " 88.09,\n",
       " 88.07,\n",
       " 88.08,\n",
       " 88.16,\n",
       " 88.09,\n",
       " 88.23,\n",
       " 88.22,\n",
       " 88.13,\n",
       " 88.04,\n",
       " 88.13,\n",
       " 88.05,\n",
       " 87.39,\n",
       " 87.49,\n",
       " 86.95,\n",
       " 86.93,\n",
       " 87.78,\n",
       " 87.84,\n",
       " 87.54,\n",
       " 88.29,\n",
       " 88.46,\n",
       " 88.28,\n",
       " 88.34,\n",
       " 88.5,\n",
       " 88.47,\n",
       " 88.76,\n",
       " 88.92,\n",
       " 89.23,\n",
       " 89.64,\n",
       " 88.94,\n",
       " 89.04,\n",
       " 89.17,\n",
       " 89.55,\n",
       " 89.55,\n",
       " 89.59,\n",
       " 89.69,\n",
       " 89.05,\n",
       " 90.25,\n",
       " 90.24,\n",
       " 90.22,\n",
       " 90.33,\n",
       " 90.35]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_classes_no_defense.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_device = make_test_device(trainset)\n",
    "test_device['net'].load_state_dict(switch_classes_no_defense.avg_weight_history[112])\n",
    "# def test(epoch, device, criterion, testloader = testloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.368 | Test Acc: 88.560\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_test_set(s, labels):\n",
    "    s = list(s)\n",
    "    s = [s for s in s if s[1] in labels]\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def make_testloader_subset(labels):\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "    \n",
    "    restricted_test_set = limit_test_set(testset, labels)\n",
    "    print(len(restricted_test_set))\n",
    "#     restricted_test_set = swap_classes_dataset(restricted_test_set, 0, 1)\n",
    "    \n",
    "    restricted_testloader = torch.utils.data.DataLoader(restricted_test_set, batch_size=128, shuffle=False)\n",
    "    return restricted_testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "checker_test_set = make_testloader_subset([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.392 | Test Acc: 89.400\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), checker_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs187",
   "language": "python",
   "name": "cs187"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
