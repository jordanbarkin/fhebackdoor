{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dca87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6fcba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure GPU (change if not M1 mac)\n",
    "mps = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "827a7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "# Using CIFAR-10 again as in the programming assignments\n",
    "# Load training data\n",
    "transform_train = transforms.Compose([                                   \n",
    "    transforms.RandomCrop(32, padding=4),                                       \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "# Load testing data\n",
    "transform_test = transforms.Compose([                                           \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5f2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving And helpers\n",
    "\n",
    "def save_tracker(tracker, path):\n",
    "  np.savetxt(path, tracker, delimiter=',') \n",
    "\n",
    "def save_trackers(device, filename):\n",
    "  \"\"\"Save all trackers and current total_time to a file.\"\"\"\n",
    "  torch.save((device['train_loss_tracker'], device['train_acc_tracker'], device['test_loss_tracker'], device['test_acc_tracker'], total_time), filename)\n",
    "  print(\"Saved trackers to \" + filename)\n",
    "\n",
    "def moving_average(a, n=100):\n",
    "  '''Helper function used for visualization'''\n",
    "  ret = torch.cumsum(torch.Tensor(a), 0)\n",
    "  ret[n:] = ret[n:] - ret[:-n]\n",
    "  return ret[n - 1:] / n\n",
    "\n",
    "# Plotting helpers! \n",
    "def make_plot(trackers, num_epochs, title, y_axis_lab, should_average=False, legend=True, fix_ax=True):\n",
    "  avg_fn = moving_average if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  if fix_ax:\n",
    "    ax.set_ylim([0, 100])\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "\n",
    "  if legend:\n",
    "    _ = plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def make_plot_better(trackers, num_epochs, title, y_axis_lab, should_average=False, n = 100):\n",
    "  avg_fn = (lambda x : moving_average(x, n)) if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "  _ = plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ed703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "def iid_sampler(dataset, num_devices, data_pct):\n",
    "    '''\n",
    "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
    "    num_devices: integer number of devices to create subsets for\n",
    "    data_pct: percentalge of training samples to give each device\n",
    "              e.g., 0.1 represents 10%\n",
    "\n",
    "    return: a dictionary of the following format:\n",
    "      {\n",
    "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
    "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
    "        ...\n",
    "      }\n",
    "\n",
    "    iid (independent and identically distributed) means that the indexes\n",
    "    should be drawn independently in a uniformly random fashion.\n",
    "    '''\n",
    "    total_samples = len(dataset)\n",
    "    sampled = {}\n",
    "    number_samples = int((data_pct)*(total_samples)) \n",
    "\n",
    "    for i in range(num_devices):\n",
    "      sampled[i] = random.sample(range(total_samples), number_samples)\n",
    "        \n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea60c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a718639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net definitions\n",
    "\n",
    "# Same ConvNet as in Assignment 2 and 3\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
    "               padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
    "                  bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(3, 32),\n",
    "            conv_block(32, 32),\n",
    "            conv_block(32, 64, stride=2),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 128, stride=2),\n",
    "            conv_block(128, 128),\n",
    "            conv_block(128, 256),\n",
    "            conv_block(256, 256),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        B, C, _, _ = h.shape\n",
    "        h = h.view(B, C)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning helpers\n",
    "\n",
    "# The baseline `average' function. \n",
    "def average_weights(devices,*args, **kwargs):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "#     max_magnitude = 0\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "      w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "#             max_magnitude = max(max_magnitude, abs(torch.max(state_dicts[i][k].type(torch.float32))))\n",
    "            w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "def get_devices_for_round(devices, device_pct):  \n",
    "    return random.sample(devices, int(device_pct * len(devices)))\n",
    "\n",
    "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
    "                  milestones=None, batch_size=128):\n",
    "    if milestones == None:\n",
    "        milestones = [25, 50, 75]\n",
    "\n",
    "    device_net = copy.deepcopy(net)\n",
    "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                     milestones=milestones,\n",
    "                                                     gamma=0.1)\n",
    "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
    "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True)\n",
    "    return {\n",
    "        'net': device_net,\n",
    "        'id': device_id,\n",
    "        'dataloader': device_trainloader, \n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'train_loss_tracker': [],\n",
    "        'train_acc_tracker': [],\n",
    "        'test_loss_tracker': [],\n",
    "        'test_acc_tracker': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584da899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local device training and testing\n",
    "def train(epoch, device, criterion):\n",
    "    device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "        inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "        device['optimizer'].zero_grad()\n",
    "        outputs = device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        device['optimizer'].step()\n",
    "        train_loss += loss.item()\n",
    "        device['train_loss_tracker'].append(loss.item())\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        dev_id = device['id']\n",
    "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' + \n",
    "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "        sys.stdout.flush()\n",
    "    device['train_acc_tracker'].append(acc)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def test(epoch, device, criterion, testloader = testloader):\n",
    "    device['net'].eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "            outputs = device['net'](inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            device['test_loss_tracker'].append(loss.item())\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            loss = test_loss / (batch_idx + 1)\n",
    "            acc = 100.* correct / total\n",
    "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
    "    sys.stdout.flush()  \n",
    "    acc = 100.*correct/total\n",
    "    device['test_acc_tracker'].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce49187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function tests (the main experiment routine)\n",
    "\n",
    "# Given two different sets of aggregated weights, \n",
    "# gives a value representing the difference between them,\n",
    "# as a way to measure the direct cost of using our aggregated function\n",
    "def diff_aggregated_weights(strat, baseline):\n",
    "    result = 0 \n",
    "    for k in strat.keys():\n",
    "        result += torch.linalg.norm(strat[k] - baseline[k])\n",
    "    return result\n",
    "\n",
    "# A data type for experiment results\n",
    "BackdoorResult = namedtuple(\"BackdoorResult\", [\"scheme_loss\", \"test_accuracy\", \"backdoor_success\", \"devices\", \"avg_weight_history\"])\n",
    "\n",
    "# The main routine! \n",
    "def run_federated_test(agg_fn = average_weights,  # Pass in aggregation function, \n",
    "                                                  # Device list -> aggregated weights \n",
    "                       rounds = 10,               # Rounds of FL\n",
    "                       local_epochs = 4,          # Epochs per device                      \n",
    "                       num_devices = 50,          # Total # devices\n",
    "                       device_pct = 0.1,          # % of devices per round\n",
    "                       data_pct = 0.1,            # % of data each device gets\n",
    "                       net = ConvNet().to(mps),   # Net design; make sure on mps\n",
    "                       evil_round = None,         # If None, no attack; else attacker will mount attack on this round\n",
    "                       attacker_strategy = None,  # device --> void --- set up the local weights on the attacker\n",
    "                       evil_device_id = None,     # Which device attacks? \n",
    "                       evaluate_attack = None,    # Function devices --> <any> measuring how well the attack worked at the end\n",
    "                       output_filename = None, \n",
    "                       snapshot = True, \n",
    "                       resume_from_snap = None):   \n",
    "    def lighten_device(d):\n",
    "        return {\n",
    "            k: d[k] for k in ( 'id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker')\n",
    "        }                                   \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "    devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "    \n",
    "    scheme_loss = []\n",
    "#     max_magnitudes = []\n",
    "    avg_weight_history = []\n",
    "    _starting_round_num = 0\n",
    "    \n",
    "    if resume_from_snap: \n",
    "        print(\"Resuming from snapshot!\\n\")\n",
    "        # Load what we can\n",
    "        result = resume_from_snap\n",
    "        scheme_loss = result.scheme_loss\n",
    "        avg_weight_history = result.avg_weight_history\n",
    "        partial_devices = result.devices\n",
    "\n",
    "        # Fresh data and devices\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "        devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "\n",
    "        # Restore the devices with the info from the trackers\n",
    "        def restore_device(old_device, new_device):\n",
    "            for k in ('id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker'):\n",
    "                new_device[k] = old_device[k]\n",
    "            return new_device\n",
    "        \n",
    "        print(\"Restoring devices\\n\")\n",
    "        devices = [restore_device(partial_devices[i], devices[i]) for i in range(len(devices))]\n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(avg_weight_history[-1])\n",
    "        \n",
    "        _starting_round_num = len(result.test_accuracy)\n",
    "        print(\"Finished restoring\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "    ## IID Federated Learning\n",
    "    start_time = time.time()\n",
    "    for round_num in range(_starting_round_num, rounds):\n",
    "        round_start_time = time.time()\n",
    "        # Part 1.3: Implement getting devices for each round here\n",
    "        round_devices = get_devices_for_round(devices, device_pct)\n",
    "\n",
    "        print('Round: ', round_num)\n",
    "        # Train locally \n",
    "        for device in round_devices:\n",
    "            for local_epoch in range(local_epochs):\n",
    "                train(local_epoch, device, criterion)\n",
    "        \n",
    "        # One device becomes evil if required\n",
    "        if (evil_round and round_num == evil_round):\n",
    "            assert (evil_device_id is not None)\n",
    "            assert (attacker_strategy is not None)\n",
    "            print(\"Attacking!\\n\")\n",
    "            \n",
    "            attacker_strategy(devices[evil_device_id])\n",
    "            # Make sure evil guy gets averaged in \n",
    "            if evil_device_id not in round_devices:\n",
    "                round_devices.append(devices[evil_device_id])\n",
    "            print(\"Finished attacking\\n\")\n",
    "            \n",
    "        \n",
    "        # Weight averaging\n",
    "        w_baseline = average_weights(round_devices)\n",
    "        w_avg = agg_fn(round_devices, (avg_weight_history[-1] if avg_weight_history != [] else None))\n",
    "#         max_magnitudes.append(max_magnitude)\n",
    "        \n",
    "        # Track the difference between the two; should be 0 if straight average\n",
    "        scheme_loss.append((float(diff_aggregated_weights(w_avg, w_baseline))))\n",
    "        \n",
    "        avg_weight_history.append(copy.deepcopy(w_avg))\n",
    "        \n",
    "        # Gradients         \n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(w_avg)\n",
    "            device['optimizer'].zero_grad()\n",
    "            device['optimizer'].step()\n",
    "            device['scheduler'].step()\n",
    "\n",
    "        # test accuracy after aggregation\n",
    "        # device 0 is the unique device with all of the \n",
    "        # test accuracies and losses in its tracker\n",
    "        test(round_num, devices[0], criterion)\n",
    "        \n",
    "        print(f\"\\nDiff: {scheme_loss[-1]}\\n\")\n",
    "        print(f\"Round time: {time.time() - start_time} \\n\")\n",
    "        if snapshot:\n",
    "            intermediate_result = BackdoorResult(\n",
    "                scheme_loss = scheme_loss, \n",
    "                test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "                backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "                devices = [lighten_device(d) for d in devices], \n",
    "                avg_weight_history = avg_weight_history\n",
    "            )\n",
    "\n",
    "\n",
    "            if output_filename is not None: \n",
    "                print(\"Writing snapshot\\n\")\n",
    "                with open(f\"snapshot_{output_filename}\", 'wb') as file: \n",
    "                    pickle.dump(intermediate_result, file)\n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    print('Total training time: {} seconds'.format(total_time))\n",
    "    \n",
    "    # Pack up everything we care about and the devices for good measure\n",
    "    result = BackdoorResult(\n",
    "        scheme_loss = scheme_loss, \n",
    "        test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "        backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "        devices = [lighten_device(d) for d in devices], \n",
    "        avg_weight_history = avg_weight_history\n",
    "    )\n",
    "\n",
    "    \n",
    "    if output_filename is not None: \n",
    "        with open(output_filename, 'wb') as file: \n",
    "            print(\"Writing file\\n\")\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Load output files back into memory\n",
    "def load_result(filename):\n",
    "    with open(filename, 'rb') as file: \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20f631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be4169e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 9/Epoch 0) Train Loss: 2.198 | Train Acc: 17.746"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_federated_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_devices\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrounds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtestout.pickle\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [10], line 87\u001b[0m, in \u001b[0;36mrun_federated_test\u001b[0;34m(agg_fn, rounds, local_epochs, num_devices, device_pct, data_pct, net, evil_round, attacker_strategy, evil_device_id, evaluate_attack, output_filename, snapshot, resume_from_snap)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m round_devices:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m local_epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(local_epochs):\n\u001b[0;32m---> 87\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# One device becomes evil if required\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (evil_round \u001b[38;5;129;01mand\u001b[39;00m round_num \u001b[38;5;241m==\u001b[39m evil_round):\n",
      "Cell \u001b[0;32mIn [8], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, device, criterion)\u001b[0m\n\u001b[1;32m      6\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(mps), targets\u001b[38;5;241m.\u001b[39mto(mps)\n\u001b[1;32m      7\u001b[0m device[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdevice\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [6], line 32\u001b[0m, in \u001b[0;36mConvNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 32\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     B, C, _, _ \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     34\u001b[0m     h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mview(B, C)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:148\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m--> 148\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_batches_tracked\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmomentum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# use cumulative moving average\u001b[39;00m\n\u001b[1;32m    150\u001b[0m             exponential_average_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_batches_tracked)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "results = run_federated_test(local_epochs=1, num_devices = 10, rounds = 2, output_filename = \"testout.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf2e74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also load it back\n",
    "# results = load_result(\"snapshot_testout.pickle\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad48138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A silly attack that just sends massive weights all of magnitude 10000\n",
    "def sample_attack(device):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    weights = device[\"net\"].state_dict().copy()\n",
    "    \n",
    "    for w in weights.keys():\n",
    "        weights[w] = torch.full(weights[w].size(), 10000)\n",
    "    \n",
    "    device['net'].load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b08537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function that squashes any weights with magnitude over 1000 (except on the first device but whatever)\n",
    "def super_smart_aggregation(devices):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights, excluding huge updates.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "        w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "            if (torch.max(state_dicts[i][k].type(torch.float32)) <= 1000): \n",
    "                w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a4507b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 9/Epoch 0) Train Loss: 2.168 | Train Acc: 18.415"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/3893217655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Here, we carry out the attack but use the ordinary average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n\u001b[0m\u001b[1;32m      5\u001b[0m                                          \u001b[0mrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mlocal_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/3626052363.py\u001b[0m in \u001b[0;36mrun_federated_test\u001b[0;34m(agg_fn, rounds, local_epochs, num_devices, device_pct, data_pct, net, evil_round, attacker_strategy, evil_device_id, evaluate_attack, output_filename, snapshot, resume_from_snap)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mround_devices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlocal_epoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# One device becomes evil if required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/mk/ydf2207j325_0l9ph1swkbzc0000gq/T/ipykernel_26277/275447899.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, device, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss_tracker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    144\u001b[0m                         \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             sgd(params_with_grad,\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    198\u001b[0m          \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m          \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/cs187/lib/python3.8/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example of how this works\n",
    "\n",
    "# Here, we carry out the attack but use the ordinary average\n",
    "results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 3,              \n",
    "                                         local_epochs = 1,                             \n",
    "                                         num_devices = 10,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 1,        \n",
    "                                         attacker_strategy = sample_attack,  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline_trivial_attack.pickle\")  \n",
    "# Observe that it absolutely destroys our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e703e878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 7/Epoch 0) Train Loss: 2.018 | Train Acc: 23.180 | Test Loss: 18.179 | Test Acc: 12.360\n",
      "\n",
      "Diff: 84.85118865966797\n",
      "\n",
      "Round:  1\n",
      "(Device 9/Epoch 0) Train Loss: 1.873 | Train Acc: 29.680Attacking!\n",
      "\n",
      " | Test Loss: 3.511 | Test Acc: 17.340\n",
      "\n",
      "Diff: 10114592.0\n",
      "\n",
      "Round:  2\n",
      "(Device 2/Epoch 0) Train Loss: 1.789 | Train Acc: 32.900 | Test Loss: 2.722 | Test Acc: 23.900\n",
      "\n",
      "Diff: 46.39040756225586\n",
      "\n",
      "Total training time: 56.98331904411316 seconds\n"
     ]
    }
   ],
   "source": [
    "# Now we do it again but with the aggregation that rejects huge updates\n",
    "results_reject_huge = run_federated_test(agg_fn = super_smart_aggregation,                    \n",
    "                                         rounds = 3,              \n",
    "                                         local_epochs = 1,                             \n",
    "                                         num_devices = 10,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 1,        \n",
    "                                         attacker_strategy = sample_attack,  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None,\n",
    "                                         output_filename = \"simple_attack_and_defense.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcc5580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  0\n",
      "(Device 2/Epoch 3) Train Loss: 1.727 | Train Acc: 34.8200 | Test Loss: 2.821 | Test Acc: 10.200\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  1\n",
      "(Device 24/Epoch 3) Train Loss: 1.562 | Train Acc: 41.420 | Test Loss: 1.498 | Test Acc: 44.420\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  2\n",
      "(Device 21/Epoch 3) Train Loss: 1.314 | Train Acc: 50.700 | Test Loss: 1.242 | Test Acc: 54.680\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  3\n",
      "(Device 9/Epoch 3) Train Loss: 1.142 | Train Acc: 59.3200 | Test Loss: 1.086 | Test Acc: 60.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  4\n",
      "(Device 15/Epoch 3) Train Loss: 1.108 | Train Acc: 59.800 | Test Loss: 0.965 | Test Acc: 65.690\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  5\n",
      "(Device 1/Epoch 3) Train Loss: 1.012 | Train Acc: 63.1400 | Test Loss: 0.869 | Test Acc: 69.140\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  6\n",
      "(Device 28/Epoch 3) Train Loss: 0.883 | Train Acc: 68.640 | Test Loss: 0.815 | Test Acc: 71.450\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  7\n",
      "(Device 10/Epoch 3) Train Loss: 0.804 | Train Acc: 72.000 | Test Loss: 0.757 | Test Acc: 73.380\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  8\n",
      "(Device 41/Epoch 3) Train Loss: 0.766 | Train Acc: 73.160 | Test Loss: 0.683 | Test Acc: 76.610\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  9\n",
      "(Device 16/Epoch 3) Train Loss: 0.682 | Train Acc: 75.940 | Test Loss: 0.648 | Test Acc: 77.530\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  10\n",
      "(Device 24/Epoch 3) Train Loss: 0.643 | Train Acc: 77.680 | Test Loss: 0.602 | Test Acc: 79.700\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  11\n",
      "(Device 27/Epoch 3) Train Loss: 0.578 | Train Acc: 79.520 | Test Loss: 0.647 | Test Acc: 77.910\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  12\n",
      "(Device 27/Epoch 3) Train Loss: 0.583 | Train Acc: 79.420 | Test Loss: 0.595 | Test Acc: 79.950\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  13\n",
      "(Device 23/Epoch 3) Train Loss: 0.551 | Train Acc: 80.640 | Test Loss: 0.548 | Test Acc: 81.380\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  14\n",
      "(Device 24/Epoch 3) Train Loss: 0.537 | Train Acc: 81.080 | Test Loss: 0.521 | Test Acc: 82.400\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  15\n",
      "(Device 13/Epoch 3) Train Loss: 0.447 | Train Acc: 84.500 | Test Loss: 0.510 | Test Acc: 82.860\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  16\n",
      "(Device 41/Epoch 3) Train Loss: 0.539 | Train Acc: 80.840 | Test Loss: 0.504 | Test Acc: 83.430\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  17\n",
      "(Device 41/Epoch 3) Train Loss: 0.435 | Train Acc: 85.920 | Test Loss: 0.505 | Test Acc: 83.600\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  18\n",
      "(Device 36/Epoch 3) Train Loss: 0.414 | Train Acc: 85.340 | Test Loss: 0.469 | Test Acc: 84.710\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  19\n",
      "(Device 19/Epoch 3) Train Loss: 0.429 | Train Acc: 85.720 | Test Loss: 0.461 | Test Acc: 85.130\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  20\n",
      "(Device 15/Epoch 3) Train Loss: 0.356 | Train Acc: 87.620 | Test Loss: 0.449 | Test Acc: 85.460\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  21\n",
      "(Device 12/Epoch 3) Train Loss: 0.379 | Train Acc: 86.120 | Test Loss: 0.431 | Test Acc: 85.900\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  22\n",
      "(Device 28/Epoch 3) Train Loss: 0.382 | Train Acc: 87.000 | Test Loss: 0.442 | Test Acc: 85.790\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  23\n",
      "(Device 20/Epoch 3) Train Loss: 0.321 | Train Acc: 88.840 | Test Loss: 0.413 | Test Acc: 86.540\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  24\n",
      "(Device 15/Epoch 3) Train Loss: 0.270 | Train Acc: 90.920 | Test Loss: 0.419 | Test Acc: 86.480\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  25\n",
      "(Device 39/Epoch 3) Train Loss: 0.236 | Train Acc: 91.420 | Test Loss: 0.391 | Test Acc: 87.190\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  26\n",
      "(Device 36/Epoch 3) Train Loss: 0.245 | Train Acc: 92.040 | Test Loss: 0.390 | Test Acc: 87.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  27\n",
      "(Device 19/Epoch 3) Train Loss: 0.221 | Train Acc: 92.440 | Test Loss: 0.388 | Test Acc: 87.520\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  28\n",
      "(Device 19/Epoch 3) Train Loss: 0.235 | Train Acc: 92.680 | Test Loss: 0.386 | Test Acc: 87.520\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  29\n",
      "(Device 30/Epoch 3) Train Loss: 0.221 | Train Acc: 92.260 | Test Loss: 0.387 | Test Acc: 87.370\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  30\n",
      "(Device 26/Epoch 3) Train Loss: 0.221 | Train Acc: 92.580 | Test Loss: 0.386 | Test Acc: 87.480\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  31\n",
      "(Device 49/Epoch 3) Train Loss: 0.195 | Train Acc: 93.360 | Test Loss: 0.386 | Test Acc: 87.650\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  32\n",
      "(Device 34/Epoch 3) Train Loss: 0.216 | Train Acc: 93.480 | Test Loss: 0.389 | Test Acc: 87.620\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  33\n",
      "(Device 7/Epoch 3) Train Loss: 0.246 | Train Acc: 91.8800 | Test Loss: 0.384 | Test Acc: 87.560\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  34\n",
      "(Device 38/Epoch 3) Train Loss: 0.186 | Train Acc: 94.140 | Test Loss: 0.385 | Test Acc: 87.580\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  35\n",
      "(Device 44/Epoch 3) Train Loss: 0.189 | Train Acc: 93.860 | Test Loss: 0.387 | Test Acc: 87.700\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  36\n",
      "(Device 25/Epoch 3) Train Loss: 0.210 | Train Acc: 93.400 | Test Loss: 0.387 | Test Acc: 87.630\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  37\n",
      "(Device 38/Epoch 3) Train Loss: 0.184 | Train Acc: 94.600 | Test Loss: 0.389 | Test Acc: 87.620\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  38\n",
      "(Device 10/Epoch 3) Train Loss: 0.209 | Train Acc: 92.800 | Test Loss: 0.388 | Test Acc: 87.800\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  39\n",
      "(Device 47/Epoch 3) Train Loss: 0.180 | Train Acc: 93.820 | Test Loss: 0.388 | Test Acc: 87.760\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  40\n",
      "(Device 2/Epoch 3) Train Loss: 0.192 | Train Acc: 93.3200 | Test Loss: 0.390 | Test Acc: 87.920\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  41\n",
      "(Device 11/Epoch 3) Train Loss: 0.198 | Train Acc: 93.520 | Test Loss: 0.388 | Test Acc: 87.820\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  42\n",
      "(Device 11/Epoch 3) Train Loss: 0.218 | Train Acc: 93.460 | Test Loss: 0.391 | Test Acc: 87.870\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  43\n",
      "(Device 48/Epoch 3) Train Loss: 0.186 | Train Acc: 94.340 | Test Loss: 0.389 | Test Acc: 87.910\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  44\n",
      "(Device 28/Epoch 3) Train Loss: 0.175 | Train Acc: 93.680 | Test Loss: 0.390 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  45\n",
      "(Device 26/Epoch 3) Train Loss: 0.187 | Train Acc: 93.960 | Test Loss: 0.391 | Test Acc: 87.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  46\n",
      "(Device 29/Epoch 3) Train Loss: 0.171 | Train Acc: 93.880 | Test Loss: 0.388 | Test Acc: 88.110\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  47\n",
      "(Device 34/Epoch 3) Train Loss: 0.164 | Train Acc: 94.000 | Test Loss: 0.393 | Test Acc: 87.850\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  48\n",
      "(Device 40/Epoch 3) Train Loss: 0.191 | Train Acc: 94.680 | Test Loss: 0.393 | Test Acc: 87.890\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  49\n",
      "(Device 30/Epoch 3) Train Loss: 0.162 | Train Acc: 94.740 | Test Loss: 0.392 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  50\n",
      "(Device 48/Epoch 3) Train Loss: 0.177 | Train Acc: 93.800 | Test Loss: 0.391 | Test Acc: 88.090\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  51\n",
      "(Device 9/Epoch 3) Train Loss: 0.173 | Train Acc: 94.1000 | Test Loss: 0.390 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  52\n",
      "(Device 24/Epoch 3) Train Loss: 0.175 | Train Acc: 93.900 | Test Loss: 0.390 | Test Acc: 88.010\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  53\n",
      "(Device 49/Epoch 3) Train Loss: 0.174 | Train Acc: 94.080 | Test Loss: 0.390 | Test Acc: 87.940\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  54\n",
      "(Device 7/Epoch 3) Train Loss: 0.185 | Train Acc: 93.3800 | Test Loss: 0.389 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  55\n",
      "(Device 28/Epoch 3) Train Loss: 0.190 | Train Acc: 94.320 | Test Loss: 0.389 | Test Acc: 88.000\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  56\n",
      "(Device 37/Epoch 3) Train Loss: 0.165 | Train Acc: 94.220 | Test Loss: 0.388 | Test Acc: 87.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  57\n",
      "(Device 17/Epoch 3) Train Loss: 0.199 | Train Acc: 93.800 | Test Loss: 0.388 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  58\n",
      "(Device 37/Epoch 3) Train Loss: 0.170 | Train Acc: 94.200 | Test Loss: 0.387 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  59\n",
      "(Device 18/Epoch 3) Train Loss: 0.162 | Train Acc: 94.760 | Test Loss: 0.387 | Test Acc: 88.000\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  60\n",
      "(Device 7/Epoch 3) Train Loss: 0.184 | Train Acc: 93.3600 | Test Loss: 0.388 | Test Acc: 88.170\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  61\n",
      "(Device 40/Epoch 3) Train Loss: 0.170 | Train Acc: 94.060 | Test Loss: 0.387 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  62\n",
      "(Device 30/Epoch 3) Train Loss: 0.173 | Train Acc: 94.480 | Test Loss: 0.389 | Test Acc: 88.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  63\n",
      "(Device 18/Epoch 3) Train Loss: 0.164 | Train Acc: 94.420 | Test Loss: 0.388 | Test Acc: 88.070\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  64\n",
      "(Device 23/Epoch 3) Train Loss: 0.166 | Train Acc: 94.000 | Test Loss: 0.388 | Test Acc: 88.080\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  65\n",
      "(Device 46/Epoch 3) Train Loss: 0.162 | Train Acc: 94.620 | Test Loss: 0.388 | Test Acc: 87.990\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  66\n",
      "(Device 22/Epoch 3) Train Loss: 0.159 | Train Acc: 94.440 | Test Loss: 0.389 | Test Acc: 88.100\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  67\n",
      "(Device 27/Epoch 3) Train Loss: 0.180 | Train Acc: 95.020 | Test Loss: 0.387 | Test Acc: 88.110\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  68\n",
      "(Device 25/Epoch 3) Train Loss: 0.182 | Train Acc: 93.740 | Test Loss: 0.387 | Test Acc: 88.130\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Device 11/Epoch 3) Train Loss: 0.174 | Train Acc: 94.300 | Test Loss: 0.386 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  70\n",
      "(Device 0/Epoch 3) Train Loss: 0.190 | Train Acc: 94.0800 | Test Loss: 0.386 | Test Acc: 88.090\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  71\n",
      "(Device 31/Epoch 3) Train Loss: 0.166 | Train Acc: 94.200 | Test Loss: 0.386 | Test Acc: 88.120\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round:  72\n",
      "(Device 1/Epoch 1) Train Loss: 0.164 | Train Acc: 94.3820"
     ]
    }
   ],
   "source": [
    "# Here, we compute a real baseline over 100 epochs and typical averaging. Good starting point for future \n",
    "# tests; can resume from this snapshot.\n",
    "baseline = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 100,              \n",
    "                                         local_epochs = 4,                             \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4835de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_result(\"baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "d7c03e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, now can get things like\n",
    "# baseline.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94b08e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 27/Epoch 3) Train Loss: 0.324 | Train Acc: 88.320 | Test Loss: 0.409 | Test Acc: 86.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 664.8843719959259 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 667.9921019077301 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can resume from a snapshot:\n",
    "# NOTE : keep all the basic params (local epochs, num devices, net, etc) the same\n",
    "# when resuming from a snapshot \n",
    "baseline2 = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "                                         rounds = 101,              \n",
    "                                         local_epochs = 4,                             \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evaluate_attack = None, \n",
    "                                         output_filename = \"baseline2.pickle\", \n",
    "                                         resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0d140864",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline2_loaded = load_result(\"baseline2.pickle\")\n",
    "baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7864d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move on to a real defense. \n",
    "\n",
    "# We create factory functions that let us parametrize a double sigmoid using threshholds\n",
    "\n",
    "def torch_scaled_sigmoid_factory(a, c = 0.005, left = False):\n",
    "    \n",
    "    def f(x):\n",
    "        scaled = torch.sub(x, a)\n",
    "\n",
    "        divisor = c if left else -1*c\n",
    "\n",
    "        scaled = torch.div(scaled, divisor)\n",
    "\n",
    "        return torch.sigmoid(scaled)\n",
    "    return f\n",
    "\n",
    "def torch_double_sigmoid_factory(a,b,c = 0.005):\n",
    "    left = torch_scaled_sigmoid_factory(a, left = True)\n",
    "    right = torch_scaled_sigmoid_factory(b, left = False) \n",
    "    def f(x):\n",
    "        return (left(x)*right(x))\n",
    "    return f\n",
    "\n",
    "my_sigmoid = torch_double_sigmoid_factory(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a035df7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000, 1.0000, 0.5000, 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_double_sigmoid_factory(-1,6)(torch.tensor(list(range(-5,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6fd6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it works\n",
    "# torch_double_sigmoid_factory(-2,2)(torch.Tensor([-5,-4,-3,-2,-1.5,-1.4,1.3,-1,0,1,1.5,1.6,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54a43171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sigmoid defense,\n",
    "#     keys_to_range_mapping maps each layer name in the state dict to the sigmoid bounds for processing it\n",
    "#     All other layers just get identity function-ed\n",
    "watcher = {}\n",
    "def make_sigmoid_defense(keys_to_range_mapping, stickiness = 0):\n",
    "    \n",
    "    sigmoid_dict = defaultdict(lambda : (lambda x: 1))\n",
    "    \n",
    "    for k,(a,b) in keys_to_range_mapping.items():\n",
    "        sigmoid_dict[k] = torch_double_sigmoid_factory(a,b)\n",
    "    \n",
    "    def f(devices, previous_round_weights):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights preprocessed by sigmoid\n",
    "        '''\n",
    "        state_dicts = [device['net'].state_dict() for device in devices]\n",
    "        # initialize w_avg to tensors from device 0\n",
    "        w_avg = copy.deepcopy(state_dicts[0])\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "#             prev_round_x = previous_round_weights[k].type(torch.float32) if  previous_round_weights is not None else x\n",
    "            w_avg[k] = w_avg[k].type(torch.float32)\n",
    "#             for i in range(stickiness):\n",
    "#                 w_avg[k] += x              \n",
    "\n",
    "        # for each model param\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "            # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "            for i in range(1, len(devices)):\n",
    "                new_weight = (state_dicts[i][k].type(torch.float32))\n",
    "                prev_round_x = previous_round_weights[k].type(torch.float32)  if (previous_round_weights is not None) else new_weight\n",
    "#                 if i == 1:\n",
    "#                     watcher[k] = (new_weight - prev_round_x)\n",
    "#                 print((())))\n",
    "#                 print((len(new_weight)))\n",
    "\n",
    "\n",
    "                w_avg[k] += new_weight*(sig(torch.sub(new_weight, prev_round_x)))\n",
    "            # compute average\n",
    "            w_avg[k] /= float(len(devices) + stickiness)\n",
    "        return w_avg\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2da666cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.0.0.weight',\n",
       " 'model.1.0.weight',\n",
       " 'model.2.0.weight',\n",
       " 'model.3.0.weight',\n",
       " 'model.4.0.weight',\n",
       " 'model.5.0.weight',\n",
       " 'model.6.0.weight',\n",
       " 'model.7.0.weight',\n",
       " 'model.8.0.weight']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the actual layer weights that we care about\n",
    "[x for x in baseline.avg_weight_history[-1].keys() if '.0.weight' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "286d9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up a potential sigmoid defense\n",
    "# empirical_cutoffs = {\n",
    "#     'model.0.0.weight' : (-2,2),\n",
    "#     'model.1.0.weight' : (-2,2),\n",
    "#     'model.2.0.weight' : (-.7,.7),\n",
    "#     'model.3.0.weight' : (-.6,.6),\n",
    "#     'model.4.0.weight' : (-0.7,0.7),\n",
    "#     'model.5.0.weight' : (-0.5,0.5),\n",
    "#     'model.6.0.weight' : (-0.3,0.3),\n",
    "#     'model.7.0.weight' : (-0.2,0.2),\n",
    "#     'model.8.0.weight' : (-0.2,0.2),\n",
    "# }\n",
    "empirical_cutoffs = {\n",
    "    'model.0.0.weight' : (-0.3,0.3),\n",
    "    'model.1.0.weight' : (-0.3,0.3),\n",
    "    'model.2.0.weight' : (-0.3,0.3),\n",
    "    'model.3.0.weight' : (-0.3,0.3),\n",
    "    'model.4.0.weight' : (-0.3,0.3),\n",
    "    'model.5.0.weight' : (-0.3,0.3),\n",
    "    'model.6.0.weight' : (-0.3,0.3),\n",
    "    'model.7.0.weight' : (-0.1,0.1),\n",
    "    'model.8.0.weight' : (-0.1,0.1),\n",
    "}\n",
    "sigmoid_aggregation = make_sigmoid_defense(empirical_cutoffs, stickiness=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d064241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid_resumption = run_federated_test(agg_fn = sigmoid_accuracy,                    \n",
    "#                                          rounds = 110,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = None,\n",
    "#                                          snapshot = False,\n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f8ed2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make an attack\n",
    "# Makes an attack that puts noise in all of target layers. \n",
    "# Noise is uniform over a,b\n",
    "def noise_attack_factory(target_layers, a,b):\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        weights = device[\"net\"].state_dict().copy()\n",
    "\n",
    "        for w in weights.keys():\n",
    "            if w in target_layers:\n",
    "                weights[w] = (a - b) * torch.rand(weights[w].size()) + b\n",
    "\n",
    "        device['net'].load_state_dict(weights)\n",
    "    return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a127ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attack these layers with weights ranging from -4,4\n",
    "target_layers = ['model.0.0.weight',\n",
    " 'model.1.0.weight',\n",
    " 'model.2.0.weight',\n",
    " 'model.3.0.weight',\n",
    " 'model.4.0.weight',\n",
    " 'model.5.0.weight',\n",
    " 'model.6.0.weight',\n",
    " 'model.7.0.weight',\n",
    " 'model.8.0.weight']\n",
    "big_noise_attack = noise_attack_factory(target_layers,-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "774e5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll resume from our baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e049559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "Attacking!\n",
      "\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.524 | Test Acc: 82.980\n",
      "\n",
      "Diff: 411.29498291015625\n",
      "\n",
      "Round time: 4.861669063568115 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 7.348390102386475 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = load_result(\"baseline.pickle\")\n",
    "sigmoid_against_noise_attack = run_federated_test(agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 0,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 100, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = big_noise_attack, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"sigmoid_against_noise_attack_3_scratch.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3188c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      " | Test Loss: 0.387 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4.258912086486816 \n",
      "\n",
      "Total training time: 4.2589240074157715 seconds\n"
     ]
    }
   ],
   "source": [
    "baseline = load_result(\"baseline.pickle\")\n",
    "determine_cutoffs = run_federated_test( agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 0,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.05,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = None, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = None, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = None,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = None,\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = False ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "439a7f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.0.0.weight': tensor([[[[-9.4310e-03, -6.7759e-03,  3.0469e-03],\n",
       "           [-1.7775e-02, -1.1662e-02,  1.3760e-03],\n",
       "           [-1.4200e-02, -1.4083e-02, -9.8117e-03]],\n",
       " \n",
       "          [[-6.7062e-03, -7.9544e-03, -1.8204e-03],\n",
       "           [-1.7414e-02, -1.4476e-02, -5.0078e-03],\n",
       "           [-8.6145e-03, -1.0224e-02, -6.3146e-03]],\n",
       " \n",
       "          [[-5.0432e-03, -4.2537e-03, -2.3357e-03],\n",
       "           [-1.1462e-02, -8.9888e-03, -8.9411e-03],\n",
       "           [-3.5206e-03, -6.3042e-03, -1.3175e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.8976e-03, -1.5522e-02, -1.1095e-02],\n",
       "           [-9.0138e-03, -1.3783e-02, -8.9821e-03],\n",
       "           [ 3.9757e-03,  1.1459e-03, -2.5883e-03]],\n",
       " \n",
       "          [[ 3.0415e-03, -1.8064e-03, -2.0479e-04],\n",
       "           [ 9.1547e-03,  6.0731e-03,  7.8201e-03],\n",
       "           [ 2.5521e-02,  2.4583e-02,  1.8199e-02]],\n",
       " \n",
       "          [[ 3.8094e-03, -7.5914e-04, -2.2959e-03],\n",
       "           [ 1.3139e-02,  9.9015e-03,  5.5838e-03],\n",
       "           [ 3.1718e-02,  3.0887e-02,  1.9483e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.9414e-02, -1.9807e-02, -1.2337e-02],\n",
       "           [-9.9552e-03, -1.5226e-02, -1.5918e-02],\n",
       "           [-8.6639e-03, -1.6390e-02, -2.0980e-02]],\n",
       " \n",
       "          [[-2.0568e-02, -2.1500e-02, -1.3814e-02],\n",
       "           [-1.0518e-02, -1.4131e-02, -1.3258e-02],\n",
       "           [-2.0754e-03, -9.2086e-03, -1.4582e-02]],\n",
       " \n",
       "          [[-1.2786e-02, -1.1674e-02, -2.3190e-03],\n",
       "           [-3.7982e-03, -2.0684e-03,  4.7606e-03],\n",
       "           [ 4.6745e-03,  3.3242e-03,  6.3651e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.7627e-02,  2.4833e-02,  2.8034e-02],\n",
       "           [ 1.7108e-02,  3.0135e-02,  3.8243e-02],\n",
       "           [ 1.4850e-02,  2.6562e-02,  3.6882e-02]],\n",
       " \n",
       "          [[ 2.6601e-02,  3.4834e-02,  3.8450e-02],\n",
       "           [ 2.6684e-02,  4.0134e-02,  4.7611e-02],\n",
       "           [ 2.1756e-02,  3.4238e-02,  4.4157e-02]],\n",
       " \n",
       "          [[ 1.3867e-02,  2.0056e-02,  2.1858e-02],\n",
       "           [ 1.5510e-02,  2.5321e-02,  3.1643e-02],\n",
       "           [ 1.0815e-02,  1.9646e-02,  2.8703e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.8977e-03,  4.7585e-03,  2.2510e-03],\n",
       "           [-5.4464e-03, -1.0274e-02, -9.2843e-03],\n",
       "           [-6.0101e-03, -1.3474e-02, -5.1022e-03]],\n",
       " \n",
       "          [[-7.2535e-03, -1.2255e-02, -1.8279e-02],\n",
       "           [-1.3617e-02, -1.8040e-02, -2.3109e-02],\n",
       "           [-9.8084e-03, -1.8985e-02, -1.1882e-02]],\n",
       " \n",
       "          [[ 3.8924e-03,  1.0087e-03, -4.1758e-03],\n",
       "           [ 1.4112e-03, -1.5211e-03, -1.0669e-02],\n",
       "           [ 1.3720e-02,  1.4744e-03, -1.1102e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4144e-03,  1.0221e-02,  1.1783e-02],\n",
       "           [ 9.7650e-04,  3.3557e-04,  3.7333e-03],\n",
       "           [-1.3046e-03, -5.8919e-03, -1.8445e-03]],\n",
       " \n",
       "          [[ 8.0681e-04,  8.4871e-03,  1.0191e-02],\n",
       "           [ 2.3001e-03,  3.7856e-03,  6.5075e-03],\n",
       "           [ 6.0080e-03,  1.7221e-03,  6.7756e-03]],\n",
       " \n",
       "          [[ 9.7348e-03,  1.6073e-02,  1.8668e-02],\n",
       "           [ 1.4198e-02,  1.5713e-02,  1.4499e-02],\n",
       "           [ 2.3766e-02,  1.8842e-02,  1.6399e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3016e-03,  6.6571e-03,  1.0744e-02],\n",
       "           [-1.1536e-03,  9.1159e-03,  1.5123e-02],\n",
       "           [-4.1023e-03,  4.6764e-03,  7.4151e-03]],\n",
       " \n",
       "          [[ 4.4232e-03,  1.2228e-02,  1.6378e-02],\n",
       "           [ 3.2091e-03,  1.3061e-02,  1.8934e-02],\n",
       "           [ 9.5454e-04,  9.3143e-03,  1.1801e-02]],\n",
       " \n",
       "          [[-2.7347e-03,  4.9080e-03,  9.3413e-03],\n",
       "           [-5.9757e-04,  7.5777e-03,  1.3539e-02],\n",
       "           [-2.5666e-03,  3.5155e-03,  5.6850e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.4059e-03, -4.9073e-03, -1.0580e-02],\n",
       "           [-4.7145e-03, -1.0831e-02, -9.7063e-03],\n",
       "           [-1.0525e-02, -1.5923e-02, -1.1711e-02]],\n",
       " \n",
       "          [[ 6.3155e-03, -3.3818e-03, -9.9559e-03],\n",
       "           [-1.4817e-03, -7.9530e-03, -7.0983e-03],\n",
       "           [-2.2993e-03, -5.8680e-03, -7.0879e-04]],\n",
       " \n",
       "          [[ 2.4915e-03, -4.4891e-03, -1.1028e-02],\n",
       "           [ 3.1987e-04, -5.7684e-03, -9.5503e-03],\n",
       "           [-3.6332e-04, -4.8533e-03, -6.5551e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.5761e-02, -4.7987e-03,  2.2797e-02],\n",
       "           [ 2.0416e-03,  3.0051e-03,  2.4965e-02],\n",
       "           [-2.7422e-02,  1.2533e-02,  1.3610e-02]],\n",
       " \n",
       "          [[-9.3888e-03,  2.4065e-02,  4.6561e-02],\n",
       "           [ 2.4954e-02,  3.7172e-02,  4.5738e-02],\n",
       "           [ 1.7575e-02,  5.4236e-02,  4.5096e-02]],\n",
       " \n",
       "          [[ 1.2795e-02,  5.3624e-02,  6.1543e-02],\n",
       "           [ 4.5298e-02,  7.4419e-02,  6.7274e-02],\n",
       "           [ 3.8485e-02,  8.9098e-02,  6.5070e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.8135e-03,  1.6751e-02,  1.9566e-02],\n",
       "           [ 9.0821e-03,  1.0724e-02,  1.2420e-02],\n",
       "           [ 1.2797e-02,  9.1674e-03,  1.2034e-02]],\n",
       " \n",
       "          [[ 1.6779e-02,  2.7128e-02,  3.2998e-02],\n",
       "           [ 1.2074e-02,  1.8510e-02,  2.1987e-02],\n",
       "           [ 1.7523e-02,  1.8348e-02,  2.3162e-02]],\n",
       " \n",
       "          [[ 1.7442e-02,  2.6524e-02,  3.4860e-02],\n",
       "           [ 1.2654e-02,  1.8988e-02,  2.3886e-02],\n",
       "           [ 1.9019e-02,  2.1432e-02,  2.5438e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3091e-02,  2.5638e-02,  1.1555e-02],\n",
       "           [ 1.1954e-02,  3.0199e-03, -7.2825e-03],\n",
       "           [ 1.5633e-02,  6.0750e-03, -4.9505e-03]],\n",
       " \n",
       "          [[ 2.0608e-02,  1.6376e-02,  2.6909e-03],\n",
       "           [-2.9411e-03, -7.4598e-03, -1.4200e-02],\n",
       "           [-7.1378e-04, -5.8949e-03, -1.2109e-02]],\n",
       " \n",
       "          [[ 3.3163e-02,  3.2080e-02,  2.1518e-02],\n",
       "           [ 1.5652e-02,  1.4246e-02,  7.9834e-03],\n",
       "           [ 1.5073e-02,  1.0520e-02,  4.9918e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.6218e-02,  1.6560e-02,  2.2865e-02],\n",
       "           [ 2.2106e-02,  1.4437e-02,  1.6705e-02],\n",
       "           [ 2.5357e-02,  1.3471e-02,  1.4120e-02]],\n",
       " \n",
       "          [[ 3.7001e-02,  3.0128e-02,  3.0689e-02],\n",
       "           [ 3.0871e-02,  2.5435e-02,  2.4860e-02],\n",
       "           [ 2.0903e-02,  1.2615e-02,  1.2748e-02]],\n",
       " \n",
       "          [[ 1.7232e-02,  9.4857e-03,  2.9020e-03],\n",
       "           [ 1.6247e-02,  1.2577e-02,  6.2142e-03],\n",
       "           [ 1.2513e-02,  3.6024e-03,  1.5558e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.4084e-02, -3.1312e-02, -3.5323e-02],\n",
       "           [-2.2713e-02, -2.9859e-02, -3.6860e-02],\n",
       "           [-2.5104e-02, -2.2539e-02, -3.3360e-02]],\n",
       " \n",
       "          [[-4.5948e-03, -1.1844e-02, -2.0286e-02],\n",
       "           [ 5.2841e-03, -1.7823e-03, -1.1114e-02],\n",
       "           [ 3.7806e-03,  5.3520e-03, -7.2244e-03]],\n",
       " \n",
       "          [[ 1.3558e-02,  5.0786e-03, -1.3009e-02],\n",
       "           [ 2.0019e-02,  1.0728e-02, -5.7699e-03],\n",
       "           [ 1.9008e-02,  1.6834e-02,  2.5431e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6317e-03, -1.6067e-02, -2.4925e-02],\n",
       "           [ 2.7749e-03, -1.6423e-02, -3.0098e-02],\n",
       "           [ 2.9261e-02,  1.1536e-02, -9.7455e-03]],\n",
       " \n",
       "          [[ 3.5329e-03, -1.9274e-02, -3.4527e-02],\n",
       "           [-4.8749e-03, -3.0957e-02, -4.8778e-02],\n",
       "           [ 2.0411e-02, -5.5402e-03, -2.7689e-02]],\n",
       " \n",
       "          [[-1.0321e-02, -3.2059e-02, -4.7211e-02],\n",
       "           [-1.7822e-02, -4.2717e-02, -6.6305e-02],\n",
       "           [-5.2117e-03, -3.0065e-02, -5.6861e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3323e-02,  1.8732e-02,  1.1509e-02],\n",
       "           [ 9.5714e-03,  1.2109e-02,  4.5257e-03],\n",
       "           [ 1.5286e-02,  1.5075e-02,  7.4889e-03]],\n",
       " \n",
       "          [[ 6.5246e-03,  1.2159e-02,  4.1263e-03],\n",
       "           [ 2.3045e-03,  4.8146e-03, -3.1893e-03],\n",
       "           [ 8.3002e-03,  7.6306e-03, -2.7929e-05]],\n",
       " \n",
       "          [[-3.9052e-03,  2.8507e-03, -5.0100e-03],\n",
       "           [-7.5502e-03, -4.2118e-03, -1.1711e-02],\n",
       "           [-2.9098e-03, -3.5085e-03, -1.0556e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.8453e-03, -6.1743e-03, -8.1790e-03],\n",
       "           [-7.9658e-03, -1.4048e-03, -9.2912e-03],\n",
       "           [-7.0422e-03, -5.2652e-03, -1.5616e-02]],\n",
       " \n",
       "          [[ 1.0158e-02,  6.6068e-03,  1.7107e-03],\n",
       "           [ 8.3114e-03,  9.5963e-03,  2.2089e-03],\n",
       "           [ 1.1619e-02,  1.0345e-02,  1.0741e-03]],\n",
       " \n",
       "          [[ 2.4241e-02,  2.4687e-02,  1.7891e-02],\n",
       "           [ 2.9666e-02,  3.1889e-02,  2.0994e-02],\n",
       "           [ 3.3526e-02,  3.0607e-02,  1.8132e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.9086e-03,  6.7051e-03,  4.7263e-03],\n",
       "           [ 4.4544e-03,  9.5715e-03,  9.0020e-03],\n",
       "           [-9.7263e-03, -5.1264e-03, -5.9785e-03]],\n",
       " \n",
       "          [[-1.0319e-03,  2.2220e-03,  2.5702e-03],\n",
       "           [-1.6371e-03,  5.0202e-03,  7.2360e-03],\n",
       "           [-1.4067e-02, -8.9673e-03, -7.3647e-03]],\n",
       " \n",
       "          [[-1.1328e-02, -8.6856e-03, -6.1960e-03],\n",
       "           [-8.0609e-03, -3.6288e-03, -1.0122e-03],\n",
       "           [-1.8664e-02, -1.6210e-02, -1.6288e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3702e-02, -1.6200e-02, -1.8401e-02],\n",
       "           [-1.5437e-02, -1.3696e-02, -1.6990e-02],\n",
       "           [-2.2996e-02, -1.5476e-02, -1.9067e-02]],\n",
       " \n",
       "          [[-6.2781e-03, -9.5082e-03, -1.2210e-02],\n",
       "           [-3.1648e-03, -2.6841e-03, -6.1723e-03],\n",
       "           [-1.2711e-02, -7.9424e-03, -1.2330e-02]],\n",
       " \n",
       "          [[ 7.7629e-04, -5.3092e-03, -1.0553e-02],\n",
       "           [ 2.0878e-03, -8.9915e-04, -5.7676e-03],\n",
       "           [-4.7107e-03, -2.6818e-03, -6.7002e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.9592e-02,  2.4308e-02,  4.9510e-03],\n",
       "           [ 1.7472e-02,  5.9305e-03, -1.0421e-02],\n",
       "           [ 1.8647e-02,  8.7095e-03, -6.6255e-03]],\n",
       " \n",
       "          [[ 2.9498e-02,  1.6179e-02, -3.1216e-03],\n",
       "           [ 7.5047e-03, -2.7180e-03, -1.8145e-02],\n",
       "           [ 7.9581e-03, -1.9048e-03, -1.6342e-02]],\n",
       " \n",
       "          [[ 2.9361e-02,  2.1368e-02,  4.8147e-03],\n",
       "           [ 9.2373e-03,  4.9975e-03, -9.7510e-03],\n",
       "           [ 2.1272e-03, -3.1413e-03, -1.5722e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8868e-02, -3.2560e-02, -5.1307e-02],\n",
       "           [-1.5751e-02, -2.6894e-02, -4.1642e-02],\n",
       "           [ 1.1029e-02,  3.1188e-03, -7.1759e-03]],\n",
       " \n",
       "          [[ 1.3567e-02,  1.3760e-03, -1.8902e-02],\n",
       "           [ 2.5478e-02,  1.0360e-02, -8.5719e-03],\n",
       "           [ 5.2089e-02,  4.0675e-02,  2.9124e-02]],\n",
       " \n",
       "          [[ 2.9085e-03, -2.7095e-03, -1.6150e-02],\n",
       "           [ 2.0431e-02,  1.6892e-02, -3.0817e-03],\n",
       "           [ 3.6740e-02,  3.7215e-02,  2.1739e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.0138e-03,  6.0146e-04,  1.2466e-04],\n",
       "           [-4.8368e-03,  3.8361e-03,  1.6575e-03],\n",
       "           [-4.0903e-03,  5.3309e-03,  4.6740e-03]],\n",
       " \n",
       "          [[ 2.0696e-03,  2.7105e-03,  2.3970e-03],\n",
       "           [ 7.3493e-03,  9.7858e-03,  6.1598e-03],\n",
       "           [ 4.7354e-04,  4.5357e-03,  2.5678e-03]],\n",
       " \n",
       "          [[ 1.6841e-02,  8.3473e-03,  3.7305e-03],\n",
       "           [ 1.9293e-02,  1.2898e-02,  5.7595e-03],\n",
       "           [ 1.7043e-02,  1.3724e-02,  9.9166e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3645e-03,  5.4179e-03,  4.6433e-03],\n",
       "           [-4.4592e-03, -2.2966e-04, -1.4546e-03],\n",
       "           [-9.5363e-03, -6.7755e-03, -6.6753e-03]],\n",
       " \n",
       "          [[ 1.6348e-02,  1.5965e-02,  1.4513e-02],\n",
       "           [ 1.0999e-02,  1.2798e-02,  1.1042e-02],\n",
       "           [ 7.9488e-03,  8.6758e-03,  7.7911e-03]],\n",
       " \n",
       "          [[ 2.8378e-02,  2.6744e-02,  2.2903e-02],\n",
       "           [ 2.5854e-02,  2.5930e-02,  2.1851e-02],\n",
       "           [ 2.5333e-02,  2.4293e-02,  2.1201e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3742e-02,  5.4486e-02,  4.8460e-02],\n",
       "           [ 2.0121e-02,  1.6514e-02,  3.7616e-03],\n",
       "           [-4.6651e-03, -5.9353e-03, -1.5855e-02]],\n",
       " \n",
       "          [[ 4.8172e-02,  3.5868e-02,  2.7321e-02],\n",
       "           [-4.0898e-03, -1.1170e-02, -2.3948e-02],\n",
       "           [-2.4466e-02, -3.5073e-02, -4.4928e-02]],\n",
       " \n",
       "          [[ 1.1045e-01,  9.7978e-02,  8.6301e-02],\n",
       "           [ 6.0022e-02,  4.9308e-02,  3.2219e-02],\n",
       "           [ 4.4882e-02,  2.8999e-02,  1.1375e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.0611e-03, -4.1917e-03, -7.4806e-04],\n",
       "           [-9.9796e-03, -5.9177e-03, -2.3742e-03],\n",
       "           [-1.0024e-02, -5.1471e-03, -4.4030e-03]],\n",
       " \n",
       "          [[-6.6448e-03, -4.4837e-03, -1.3501e-03],\n",
       "           [-1.4137e-02, -1.0658e-02, -7.7536e-03],\n",
       "           [-1.2334e-02, -9.7415e-03, -9.2847e-03]],\n",
       " \n",
       "          [[-7.7206e-03, -4.3279e-03,  1.1294e-03],\n",
       "           [-1.5157e-02, -8.7848e-03, -4.5002e-03],\n",
       "           [-1.2357e-02, -6.6783e-03, -7.0171e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.8769e-02,  2.9437e-02,  2.6398e-02],\n",
       "           [ 3.1233e-03,  2.3110e-02,  9.6428e-04],\n",
       "           [ 2.1909e-02,  2.2511e-02,  3.3647e-02]],\n",
       " \n",
       "          [[-1.2185e-02,  3.3606e-02,  4.9849e-02],\n",
       "           [ 1.4579e-02,  2.1310e-02,  1.8503e-02],\n",
       "           [ 3.3253e-02,  4.2079e-02,  4.6450e-02]],\n",
       " \n",
       "          [[-8.2894e-03,  1.9056e-02,  5.3860e-02],\n",
       "           [ 2.3410e-02,  6.8685e-03,  3.3265e-02],\n",
       "           [ 2.7713e-02,  2.6817e-02,  4.7891e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.8419e-02, -8.5101e-03, -3.0268e-03],\n",
       "           [-2.3766e-02, -1.1386e-02, -1.0159e-02],\n",
       "           [-1.3071e-02, -7.3608e-03, -1.3433e-02]],\n",
       " \n",
       "          [[-1.1899e-03,  4.1837e-03,  7.4434e-03],\n",
       "           [ 2.4666e-03,  9.5676e-03,  6.7341e-03],\n",
       "           [ 1.3270e-02,  1.5640e-02,  6.6930e-03]],\n",
       " \n",
       "          [[ 8.1810e-03,  8.7533e-03,  6.1483e-03],\n",
       "           [ 1.6482e-02,  1.7279e-02,  4.9556e-03],\n",
       "           [ 2.6594e-02,  2.3869e-02,  7.8598e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2900e-02,  2.2679e-02,  7.5954e-03],\n",
       "           [ 1.4132e-02,  7.6966e-03, -5.2495e-03],\n",
       "           [-5.4711e-04, -1.0273e-03, -4.3299e-03]],\n",
       " \n",
       "          [[ 2.2408e-02,  2.0455e-02,  1.3967e-02],\n",
       "           [ 1.1255e-02,  1.1044e-02,  1.7655e-03],\n",
       "           [-8.1749e-03, -3.6572e-03, -4.0077e-03]],\n",
       " \n",
       "          [[ 2.4394e-02,  1.8581e-02,  1.3874e-02],\n",
       "           [ 4.2353e-03,  2.1925e-03, -2.0251e-03],\n",
       "           [-1.2420e-02, -9.0449e-03, -4.9111e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.1330e-03, -7.2745e-03, -8.0769e-03],\n",
       "           [-7.8999e-03, -1.5042e-02, -1.8750e-02],\n",
       "           [-2.2688e-02, -2.6590e-02, -2.7619e-02]],\n",
       " \n",
       "          [[ 8.9104e-03,  4.2596e-03,  2.5619e-03],\n",
       "           [ 2.7947e-03, -2.5400e-03, -7.5966e-03],\n",
       "           [-7.8805e-03, -1.0031e-02, -1.5190e-02]],\n",
       " \n",
       "          [[ 2.0444e-02,  2.1313e-02,  2.3284e-02],\n",
       "           [ 1.2689e-02,  1.6189e-02,  1.9406e-02],\n",
       "           [ 3.1306e-03,  1.0654e-02,  1.4740e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.3486e-03,  1.3131e-02,  1.1691e-02],\n",
       "           [-9.4635e-03, -1.3305e-02, -7.8270e-03],\n",
       "           [ 9.5630e-03,  9.5463e-04, -1.9023e-02]],\n",
       " \n",
       "          [[ 2.1438e-02,  4.0195e-02,  3.4836e-02],\n",
       "           [ 7.0478e-03,  1.2247e-02,  1.2002e-02],\n",
       "           [ 3.7986e-02,  3.3450e-02,  1.2248e-02]],\n",
       " \n",
       "          [[ 2.7238e-02,  5.3890e-02,  4.0694e-02],\n",
       "           [ 2.6702e-02,  4.0474e-02,  2.4115e-02],\n",
       "           [ 5.0875e-02,  5.2237e-02,  2.1182e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5852e-02, -2.7238e-02, -3.5584e-02],\n",
       "           [-2.8404e-02, -2.5150e-02, -3.6756e-02],\n",
       "           [-3.8276e-02, -3.2950e-02, -4.2925e-02]],\n",
       " \n",
       "          [[-5.7706e-04, -1.6987e-02, -2.3517e-02],\n",
       "           [-9.1772e-03, -1.3431e-02, -2.3066e-02],\n",
       "           [-2.5295e-02, -2.4550e-02, -3.5010e-02]],\n",
       " \n",
       "          [[-1.1752e-02, -2.3059e-02, -2.9382e-02],\n",
       "           [-1.2503e-02, -1.4826e-02, -2.2048e-02],\n",
       "           [-2.3312e-02, -2.3719e-02, -3.1106e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1362e-02, -1.1293e-02, -1.0476e-02],\n",
       "           [-9.0234e-03, -1.1604e-02, -1.5020e-02],\n",
       "           [-1.6231e-02, -1.9352e-02, -1.9791e-02]],\n",
       " \n",
       "          [[-9.5433e-03, -1.1550e-02, -9.7188e-03],\n",
       "           [-7.7989e-03, -1.1785e-02, -1.3076e-02],\n",
       "           [-1.6286e-02, -1.8967e-02, -1.8959e-02]],\n",
       " \n",
       "          [[ 5.9075e-03,  2.8030e-03,  2.7929e-03],\n",
       "           [ 7.6743e-03,  5.1941e-03,  6.3457e-03],\n",
       "           [ 1.3396e-03,  1.5137e-03,  6.2732e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.2675e-03, -8.2762e-03, -1.2600e-02],\n",
       "           [-2.9835e-04, -5.0042e-03, -1.1396e-02],\n",
       "           [-4.4780e-03, -7.3509e-03, -1.2696e-02]],\n",
       " \n",
       "          [[ 3.3361e-04, -5.4825e-03, -8.5032e-03],\n",
       "           [ 2.7627e-03, -2.0438e-03, -7.8143e-03],\n",
       "           [-4.7624e-03, -7.5408e-03, -1.2184e-02]],\n",
       " \n",
       "          [[ 6.4269e-03,  2.0773e-03, -3.8477e-03],\n",
       "           [ 7.5088e-03,  3.1764e-03, -4.4251e-03],\n",
       "           [-3.7946e-03, -6.1063e-03, -1.1107e-02]]]], device='mps:0'),\n",
       " 'model.0.1.weight': tensor([-0.0609, -0.0491,  0.0329, -0.0967, -0.0118,  0.0179, -0.0212, -0.0072,\n",
       "          0.0625,  0.0523, -0.0102, -0.0580, -0.0060, -0.0226, -0.0200, -0.0287,\n",
       "         -0.0254, -0.0225,  0.0176,  0.0292,  0.0359, -0.0064, -0.0259,  0.0275,\n",
       "         -0.0004, -0.0011, -0.0032,  0.0467,  0.0273, -0.0275, -0.0036,  0.0054],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.bias': tensor([ 0.0067,  0.0208, -0.0177, -0.0114,  0.0369,  0.0291, -0.0407,  0.0543,\n",
       "         -0.0370,  0.0259, -0.0461, -0.0136,  0.0412,  0.0394, -0.0017, -0.0404,\n",
       "         -0.0020,  0.0453,  0.0093,  0.0270,  0.0137, -0.0131, -0.0110,  0.0100,\n",
       "          0.0247, -0.0286,  0.0175,  0.0122, -0.0234,  0.0296, -0.0050,  0.0179],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_mean': tensor([ 0.0813, -0.0293,  0.0787, -0.1529,  0.1071, -0.0089, -0.0316,  0.0773,\n",
       "         -0.0842,  0.0022, -0.0386, -0.1034,  0.0660,  0.1633, -0.0583, -0.0788,\n",
       "          0.0630,  0.0562, -0.0340,  0.0265, -0.1071, -0.0791, -0.0542,  0.0747,\n",
       "         -0.0983, -0.0191, -0.0819,  0.0334, -0.0132,  0.1659,  0.0031,  0.1093],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_var': tensor([ 0.2810,  0.2454,  0.5046,  1.5267,  0.9684,  0.1016,  0.3382,  0.5751,\n",
       "         -0.2303, -0.0372, -1.4290,  0.2300,  0.1553,  1.1861,  0.1613,  0.7026,\n",
       "          0.4574, -0.0613, -1.0159,  0.2655,  0.9203,  0.8322,  0.2654,  0.1325,\n",
       "          0.5293,  0.3259,  0.7365,  0.8463, -0.0212,  0.0209,  0.2011,  1.0625],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.1.0.weight': tensor([[[[ 2.5200e-03,  4.9969e-03,  7.6354e-03],\n",
       "           [ 2.6879e-03,  4.7899e-03,  3.5814e-03],\n",
       "           [ 5.9695e-03,  9.5227e-03,  8.0898e-03]],\n",
       " \n",
       "          [[-6.6822e-04,  1.0536e-03,  2.4990e-03],\n",
       "           [ 1.8382e-03,  3.9865e-03,  1.4481e-03],\n",
       "           [ 1.1402e-03,  1.9530e-03, -3.5727e-03]],\n",
       " \n",
       "          [[-4.1274e-03, -4.6057e-03, -9.2558e-03],\n",
       "           [-6.3222e-03, -6.0006e-03, -1.0044e-02],\n",
       "           [-8.1867e-03, -7.7672e-03, -1.1726e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7909e-03, -9.5725e-03, -1.2838e-02],\n",
       "           [-8.5822e-04,  1.2804e-03, -2.3547e-03],\n",
       "           [ 6.1171e-04,  1.6237e-04, -2.3177e-03]],\n",
       " \n",
       "          [[-7.3179e-03, -6.7557e-03, -1.1115e-02],\n",
       "           [-5.2998e-03, -4.2612e-03, -6.7168e-03],\n",
       "           [-6.9124e-03, -5.0854e-03, -7.0385e-03]],\n",
       " \n",
       "          [[ 3.7576e-03,  1.1390e-03, -1.1721e-03],\n",
       "           [ 3.0300e-03,  1.0847e-03, -8.7085e-04],\n",
       "           [-2.0659e-03, -4.1888e-03, -6.6950e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2569e-02,  1.2116e-02,  1.1013e-02],\n",
       "           [ 1.5781e-02,  1.1196e-02,  1.0360e-02],\n",
       "           [ 1.9568e-02,  1.8538e-02,  1.6678e-02]],\n",
       " \n",
       "          [[ 1.0080e-02,  6.4496e-03, -5.1572e-03],\n",
       "           [ 1.2003e-02,  3.5136e-03, -3.9987e-03],\n",
       "           [ 1.1416e-02,  2.0297e-03,  3.8432e-04]],\n",
       " \n",
       "          [[-3.2266e-03, -7.3828e-03, -1.1801e-02],\n",
       "           [-2.7418e-03, -7.5969e-03, -6.8429e-03],\n",
       "           [ 4.7585e-03, -5.5694e-03, -1.0049e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.1832e-03, -4.0298e-03, -1.0361e-02],\n",
       "           [ 5.8816e-03,  4.2329e-03,  3.5031e-03],\n",
       "           [ 6.0951e-03,  7.6377e-03,  9.2239e-03]],\n",
       " \n",
       "          [[-1.1972e-02, -1.3060e-02, -1.5801e-02],\n",
       "           [-1.0977e-02, -1.0840e-02, -1.1023e-02],\n",
       "           [-9.1846e-03, -1.3357e-02, -1.5298e-02]],\n",
       " \n",
       "          [[-5.9644e-03, -9.6843e-03, -1.5296e-02],\n",
       "           [-3.6067e-03, -6.4546e-03, -8.8959e-03],\n",
       "           [-4.6216e-03, -9.7059e-03, -1.0140e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0652e-03,  9.3555e-04, -1.3000e-04],\n",
       "           [ 7.6228e-03,  3.7571e-03,  4.5518e-03],\n",
       "           [ 1.4604e-02,  1.3554e-02,  1.2585e-02]],\n",
       " \n",
       "          [[ 2.9307e-03,  4.0755e-03, -7.8104e-03],\n",
       "           [ 9.6704e-03,  3.6729e-03, -1.3697e-03],\n",
       "           [ 3.7947e-03, -1.6020e-03, -3.7565e-03]],\n",
       " \n",
       "          [[-9.4601e-03, -1.2300e-02, -1.0260e-02],\n",
       "           [-1.0446e-02, -9.6703e-03, -4.8960e-03],\n",
       "           [-1.1926e-02, -1.2257e-02, -1.7868e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.7436e-03,  5.8570e-03,  9.4202e-03],\n",
       "           [ 1.1287e-02,  1.1069e-02,  1.4895e-02],\n",
       "           [ 6.7725e-03,  6.9910e-03,  1.2593e-02]],\n",
       " \n",
       "          [[-6.8477e-03, -6.7741e-03, -5.9071e-03],\n",
       "           [-1.2978e-02, -1.0088e-02, -4.4393e-03],\n",
       "           [-9.3921e-03, -1.0197e-02, -2.9033e-03]],\n",
       " \n",
       "          [[-3.0053e-03, -5.0228e-03, -3.6624e-03],\n",
       "           [ 3.1261e-03, -2.1440e-03, -3.7968e-04],\n",
       "           [ 7.4912e-03,  9.8689e-04,  1.0705e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 5.9595e-03,  8.1846e-03,  1.0939e-02],\n",
       "           [ 3.3292e-03,  6.1129e-03,  1.3597e-02],\n",
       "           [ 3.0127e-04,  1.2067e-03,  5.3000e-03]],\n",
       " \n",
       "          [[ 6.2312e-03,  2.2619e-03,  8.9475e-03],\n",
       "           [ 3.7541e-03,  2.0137e-03,  8.5804e-03],\n",
       "           [-8.7334e-04, -5.9667e-04,  5.7188e-03]],\n",
       " \n",
       "          [[ 1.4050e-04,  6.2907e-03,  5.3319e-03],\n",
       "           [ 2.4940e-03,  6.8418e-03,  5.2028e-03],\n",
       "           [-2.1052e-04,  4.3324e-03,  7.0176e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.6415e-03,  3.1624e-03,  4.1088e-03],\n",
       "           [ 4.6173e-03,  4.9710e-03,  7.5964e-03],\n",
       "           [-2.9127e-03, -1.3721e-03, -2.2586e-03]],\n",
       " \n",
       "          [[ 9.5231e-04,  1.0585e-03,  2.3308e-04],\n",
       "           [ 2.2556e-03,  1.6868e-03,  1.8221e-03],\n",
       "           [-3.4081e-03, -3.3228e-03,  1.9063e-04]],\n",
       " \n",
       "          [[-6.4673e-04, -6.1836e-05,  2.2500e-03],\n",
       "           [-6.0664e-03, -4.0367e-03, -7.3966e-04],\n",
       "           [-1.3440e-02, -1.1377e-02, -7.3802e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.9185e-02, -2.0370e-02, -2.2675e-02],\n",
       "           [-9.5638e-03, -9.4360e-03, -1.4352e-02],\n",
       "           [-1.3988e-02, -1.4317e-02, -2.0357e-02]],\n",
       " \n",
       "          [[-1.0417e-02, -7.6343e-03, -7.0248e-03],\n",
       "           [-1.2956e-02, -1.0242e-02, -1.1115e-02],\n",
       "           [-1.3013e-02, -5.7864e-03, -6.9354e-03]],\n",
       " \n",
       "          [[-3.0609e-03, -2.5295e-03, -4.7975e-03],\n",
       "           [-3.5974e-03, -7.8710e-03, -6.9366e-03],\n",
       "           [-2.5538e-03, -5.7695e-03, -4.8880e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.8748e-03,  1.0828e-02,  3.4485e-03],\n",
       "           [-7.7088e-03, -3.9973e-03, -9.4141e-04],\n",
       "           [-1.7059e-02, -1.3655e-02, -5.5741e-03]],\n",
       " \n",
       "          [[ 4.4448e-03,  5.3658e-03,  3.4716e-03],\n",
       "           [-7.7005e-04, -2.3068e-03, -1.0096e-03],\n",
       "           [-5.5051e-03, -7.0246e-03, -5.0638e-03]],\n",
       " \n",
       "          [[-9.5144e-04, -2.8090e-04, -5.0231e-03],\n",
       "           [-1.0904e-02, -8.0537e-03, -8.1102e-03],\n",
       "           [-4.4208e-03, -2.9100e-03, -2.2383e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.0318e-03, -7.8083e-04, -6.7692e-03],\n",
       "           [ 3.3022e-03,  1.8979e-03, -1.5656e-03],\n",
       "           [ 1.0476e-03, -1.6375e-04, -4.9214e-03]],\n",
       " \n",
       "          [[ 1.3789e-02,  1.1030e-02,  1.9396e-03],\n",
       "           [ 9.7450e-03,  9.8353e-03,  6.8766e-04],\n",
       "           [ 8.0080e-03,  8.0017e-03, -6.2388e-04]],\n",
       " \n",
       "          [[-2.2170e-02, -1.9484e-02, -1.4444e-02],\n",
       "           [-1.9753e-02, -1.6136e-02, -8.2429e-03],\n",
       "           [-7.6618e-03, -6.1232e-03, -1.0266e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.8933e-03, -3.4554e-03, -7.2042e-03],\n",
       "           [-7.9227e-03, -5.9493e-03, -6.2456e-03],\n",
       "           [-9.0986e-03, -7.7098e-03, -6.0506e-03]],\n",
       " \n",
       "          [[-8.4920e-03, -3.7336e-03,  5.1472e-04],\n",
       "           [-3.7948e-03,  2.0914e-04,  3.8034e-03],\n",
       "           [ 1.9823e-03,  2.2661e-03,  3.8741e-03]],\n",
       " \n",
       "          [[ 3.5115e-03,  2.8064e-03,  6.1113e-04],\n",
       "           [-1.2731e-03, -2.5104e-03, -4.9992e-03],\n",
       "           [-1.6708e-03, -3.7841e-03, -6.2347e-03]]]], device='mps:0'),\n",
       " 'model.1.1.weight': tensor([-0.0493,  0.0148,  0.0245, -0.0203, -0.0193, -0.0186,  0.0181, -0.0234,\n",
       "          0.0072,  0.0086,  0.0318, -0.0168,  0.0283, -0.0370,  0.0034, -0.0237,\n",
       "         -0.1155, -0.0100,  0.0311,  0.0694, -0.0117, -0.0016, -0.0124, -0.0291,\n",
       "         -0.0325,  0.0054,  0.0209,  0.0420,  0.0065,  0.0139,  0.0231, -0.0714],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.bias': tensor([-0.0570, -0.0050,  0.0300, -0.0437, -0.0383, -0.0148,  0.0309, -0.0035,\n",
       "         -0.0873,  0.0127,  0.0364, -0.0025,  0.0585, -0.0072, -0.0196, -0.0217,\n",
       "         -0.0355, -0.0005,  0.0443, -0.0058, -0.0376,  0.0114,  0.0409, -0.0277,\n",
       "         -0.0617, -0.0691,  0.0392,  0.0611, -0.0257, -0.0066,  0.0287, -0.0881],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_mean': tensor([-0.4236, -0.1223, -0.3024, -0.2352,  0.0958,  0.0330, -0.1193, -0.5452,\n",
       "          0.2765,  0.2755, -0.1846,  0.2399, -0.0609, -0.3698, -0.3081, -0.0839,\n",
       "          0.1762, -0.0679, -0.0246, -0.2859, -0.1864, -0.2695, -0.3094, -0.3194,\n",
       "         -0.1110, -0.0336, -0.3329, -0.3204, -0.0564, -0.1211, -0.5051, -0.1050],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_var': tensor([-0.1474, -0.2996,  0.3699,  0.9230,  0.1659,  1.1516, -0.9567, -0.7459,\n",
       "         -4.0413,  0.7908, -0.5407,  0.2668,  0.7219,  0.2024,  0.1887, -0.2498,\n",
       "         -0.1047, -0.3503,  0.2760,  0.2572,  0.4942,  0.3118,  0.0179, -0.3218,\n",
       "         -1.3714, -8.8947,  0.6194, -0.2970, -0.7712, -3.0767, -0.2627,  1.3458],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.2.0.weight': tensor([[[[ 3.3358e-03, -1.5977e-03, -2.2774e-03],\n",
       "           [ 4.6922e-03, -4.3742e-03,  1.9932e-03],\n",
       "           [ 8.3557e-04, -4.9592e-03,  1.1314e-03]],\n",
       " \n",
       "          [[ 2.0948e-02,  1.0265e-02,  7.2582e-03],\n",
       "           [ 1.1749e-02,  6.8610e-03,  1.1623e-02],\n",
       "           [ 2.1901e-02,  7.6236e-03,  5.2128e-03]],\n",
       " \n",
       "          [[-1.0358e-02, -6.6292e-03,  3.8385e-05],\n",
       "           [ 1.8803e-03, -1.0678e-02, -2.7577e-03],\n",
       "           [-8.2586e-03, -8.1551e-04,  1.5665e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0954e-03,  2.3554e-03, -6.3487e-03],\n",
       "           [ 2.5444e-03,  5.7535e-03, -6.2516e-03],\n",
       "           [ 3.1337e-03,  1.8025e-02, -3.8466e-03]],\n",
       " \n",
       "          [[-7.2282e-03, -7.6339e-03, -4.2939e-03],\n",
       "           [ 6.8355e-03,  4.0850e-03,  3.4942e-03],\n",
       "           [ 1.7034e-02,  1.2713e-02,  8.3342e-03]],\n",
       " \n",
       "          [[ 3.1692e-03,  4.2574e-03,  5.9575e-03],\n",
       "           [ 1.2055e-02,  7.8527e-03,  1.1082e-02],\n",
       "           [ 1.7581e-02,  1.2371e-02,  1.4126e-02]]],\n",
       " \n",
       " \n",
       "         [[[-6.1969e-03, -3.3197e-03, -2.7577e-03],\n",
       "           [ 3.5921e-03,  5.4353e-03,  2.7968e-03],\n",
       "           [ 9.0631e-03,  8.4831e-03,  5.4640e-03]],\n",
       " \n",
       "          [[-3.3159e-03,  1.4270e-02,  4.7788e-03],\n",
       "           [ 1.5345e-02, -1.3321e-03, -1.3273e-03],\n",
       "           [-1.6172e-02, -1.5282e-03, -1.9268e-03]],\n",
       " \n",
       "          [[-6.2937e-03, -1.5886e-03, -3.9419e-03],\n",
       "           [-1.1935e-02, -7.1745e-03, -3.5772e-03],\n",
       "           [-1.2227e-02,  2.4765e-03, -6.1859e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.5657e-03,  7.9373e-04,  8.7081e-04],\n",
       "           [-3.7424e-04,  1.1685e-03, -1.2215e-03],\n",
       "           [-6.9618e-03,  3.1444e-03, -9.9672e-04]],\n",
       " \n",
       "          [[-2.8738e-05, -4.0801e-03,  9.0016e-04],\n",
       "           [-6.4497e-04,  1.7530e-03,  1.0435e-02],\n",
       "           [-1.2396e-04,  1.0821e-03,  6.1708e-03]],\n",
       " \n",
       "          [[-3.3251e-03,  1.1736e-03, -1.0134e-03],\n",
       "           [-7.9864e-03, -4.5019e-03, -8.4798e-03],\n",
       "           [-5.0244e-03,  3.1076e-04,  2.3254e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2823e-04, -5.2437e-04,  6.7632e-03],\n",
       "           [-2.7689e-04,  1.9618e-03,  7.6463e-04],\n",
       "           [-4.8714e-03, -2.3092e-03, -3.9048e-03]],\n",
       " \n",
       "          [[-3.7524e-03, -9.3239e-03, -7.4536e-03],\n",
       "           [ 6.4701e-03, -1.5710e-02, -1.4321e-02],\n",
       "           [-1.7829e-02, -1.4990e-02, -8.2498e-03]],\n",
       " \n",
       "          [[ 6.7038e-03,  2.5849e-03,  1.0322e-02],\n",
       "           [-7.6173e-03, -8.9366e-05, -4.1267e-03],\n",
       "           [ 9.9916e-03,  8.1374e-03,  6.8321e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7199e-03,  2.1069e-03, -1.7139e-02],\n",
       "           [-2.8554e-03, -3.1245e-03, -9.4666e-03],\n",
       "           [ 1.3391e-04, -3.0240e-03,  2.2426e-03]],\n",
       " \n",
       "          [[ 2.9424e-02,  2.9545e-02,  2.9482e-02],\n",
       "           [ 3.3052e-02,  3.3571e-02,  2.6653e-02],\n",
       "           [ 2.2904e-02,  1.3300e-02,  4.6669e-03]],\n",
       " \n",
       "          [[-1.0823e-02, -5.0131e-03, -7.0529e-04],\n",
       "           [-8.5711e-03, -8.6412e-03, -8.3424e-03],\n",
       "           [-4.9838e-03, -6.3767e-03, -5.6398e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-6.0222e-03, -9.8887e-03, -1.5835e-02],\n",
       "           [-6.0364e-04, -5.7673e-03, -2.8817e-03],\n",
       "           [ 1.8837e-03,  5.8584e-03,  1.1767e-02]],\n",
       " \n",
       "          [[ 6.2720e-04, -3.2781e-03,  2.4058e-02],\n",
       "           [ 1.1947e-02, -9.8853e-04,  1.0005e-03],\n",
       "           [-1.5760e-02, -1.0040e-02,  1.8193e-03]],\n",
       " \n",
       "          [[ 6.4517e-03,  4.7228e-03,  7.4024e-03],\n",
       "           [-3.1788e-03,  7.6358e-03,  5.1370e-03],\n",
       "           [ 7.5801e-03,  2.9740e-03, -1.6435e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3766e-02, -6.3229e-03, -3.7966e-03],\n",
       "           [-1.6311e-02, -5.8814e-03, -7.5012e-03],\n",
       "           [-2.0378e-02, -2.5570e-03, -1.1243e-02]],\n",
       " \n",
       "          [[ 5.0532e-03, -1.0645e-03, -5.1385e-03],\n",
       "           [ 2.4632e-03, -3.8590e-04, -1.9758e-03],\n",
       "           [ 9.1857e-03,  9.5311e-03,  1.1518e-02]],\n",
       " \n",
       "          [[ 6.2039e-03, -6.9888e-04,  3.4342e-03],\n",
       "           [-2.6861e-03, -5.9521e-03, -6.9581e-03],\n",
       "           [ 5.6483e-04, -6.3526e-03, -2.2750e-03]]],\n",
       " \n",
       " \n",
       "         [[[-1.6944e-03,  5.6978e-03, -3.0260e-03],\n",
       "           [-2.7072e-03, -8.1253e-04, -5.8536e-03],\n",
       "           [-2.6205e-03, -2.9867e-03,  2.2057e-03]],\n",
       " \n",
       "          [[-9.6850e-03, -9.8591e-03, -1.2619e-02],\n",
       "           [-9.3544e-03, -7.8351e-03, -6.1393e-03],\n",
       "           [ 3.9283e-03,  1.3802e-02,  3.8838e-03]],\n",
       " \n",
       "          [[ 8.6528e-03,  1.1355e-02,  1.5170e-02],\n",
       "           [ 8.2428e-03,  1.2357e-02,  7.8076e-03],\n",
       "           [-1.9337e-03,  1.7554e-03, -6.5707e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.2536e-03,  7.2810e-03,  9.8580e-03],\n",
       "           [-8.3056e-03, -7.8747e-04,  7.3418e-03],\n",
       "           [-7.4943e-03,  6.5732e-03,  6.1599e-03]],\n",
       " \n",
       "          [[ 1.0784e-03, -1.2331e-05, -5.0197e-03],\n",
       "           [-4.2800e-03, -5.3953e-03, -9.5972e-03],\n",
       "           [-4.3052e-03, -2.8856e-03,  2.0099e-03]],\n",
       " \n",
       "          [[-6.1018e-03, -7.5287e-03, -1.5596e-02],\n",
       "           [-5.8495e-03, -3.7883e-03, -9.8991e-03],\n",
       "           [-1.3665e-02, -5.3274e-03, -9.3394e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.3901e-03, -3.5602e-03, -1.1995e-03],\n",
       "           [ 4.2533e-03,  3.1142e-03,  6.5884e-03],\n",
       "           [-6.1365e-03, -1.2232e-02, -7.3953e-03]],\n",
       " \n",
       "          [[ 1.1064e-02,  2.4819e-02,  1.4557e-02],\n",
       "           [-7.1572e-03,  6.1056e-03,  3.5442e-03],\n",
       "           [ 2.3303e-02,  1.2268e-02,  6.5003e-03]],\n",
       " \n",
       "          [[ 1.1539e-02, -3.1709e-03,  6.2604e-03],\n",
       "           [ 1.4876e-02,  1.3429e-02,  1.9914e-02],\n",
       "           [ 7.7953e-03,  5.3013e-03,  1.9887e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.0096e-03,  9.4662e-03, -9.9338e-03],\n",
       "           [ 2.2746e-03,  1.4942e-02, -1.1300e-02],\n",
       "           [-7.8655e-03,  1.5041e-02, -1.3044e-02]],\n",
       " \n",
       "          [[-5.0997e-03, -3.2002e-03, -1.9040e-03],\n",
       "           [-6.0254e-03,  1.9832e-04,  7.7014e-04],\n",
       "           [ 4.0722e-03,  3.8728e-03,  2.9073e-03]],\n",
       " \n",
       "          [[ 2.0402e-02,  2.3728e-02,  2.5594e-02],\n",
       "           [ 1.0420e-02,  1.4480e-02,  1.6088e-02],\n",
       "           [ 6.5538e-03,  1.0954e-02,  1.9848e-02]]]], device='mps:0'),\n",
       " 'model.2.1.weight': tensor([ 0.0426,  0.0078,  0.0146, -0.0266, -0.0350, -0.0196,  0.0235, -0.0210,\n",
       "         -0.0035,  0.0160,  0.0035,  0.0025, -0.0454,  0.0529, -0.0756, -0.0127,\n",
       "         -0.0450, -0.0116, -0.0037,  0.0030, -0.0314, -0.0275, -0.0288, -0.0119,\n",
       "         -0.0218, -0.0550,  0.0190,  0.0114,  0.0474,  0.0230,  0.0222,  0.0532,\n",
       "          0.0079, -0.0109,  0.0039, -0.0491, -0.0251, -0.0321,  0.0428, -0.0026,\n",
       "         -0.0113, -0.0484, -0.0060,  0.0515, -0.0456,  0.0386, -0.0234, -0.0190,\n",
       "          0.0106,  0.0189,  0.0195, -0.0188,  0.0074, -0.0188, -0.0138, -0.0145,\n",
       "          0.0630, -0.0014,  0.0379,  0.0066,  0.0014, -0.0085,  0.0249, -0.0178],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.bias': tensor([ 0.0071, -0.0202,  0.0653,  0.0406, -0.0687, -0.0160,  0.0407, -0.0368,\n",
       "          0.0151,  0.0154,  0.0138, -0.0468, -0.0160,  0.0500, -0.0504, -0.0156,\n",
       "         -0.0398,  0.0119, -0.0256, -0.0265, -0.0107, -0.0259, -0.0369,  0.0137,\n",
       "         -0.0254, -0.0436,  0.0025, -0.0051,  0.0423,  0.0141,  0.0599,  0.0365,\n",
       "          0.0021, -0.0018, -0.0124, -0.0418,  0.0035, -0.0289,  0.0353, -0.0148,\n",
       "         -0.0043, -0.0267, -0.0203, -0.0253, -0.1125,  0.0621, -0.0424, -0.0262,\n",
       "         -0.0099, -0.0441, -0.0090, -0.0311, -0.0468, -0.0134, -0.0399, -0.0236,\n",
       "          0.0274,  0.0113,  0.0515,  0.0389,  0.0140,  0.0052, -0.0159, -0.0298],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_mean': tensor([ 0.2140,  0.0975, -0.0241, -0.0744, -0.1555, -0.0250, -0.0366,  0.0446,\n",
       "          0.0263, -0.1330,  0.1286,  0.0146, -0.0644, -0.1716,  0.1409, -0.1075,\n",
       "          0.0290,  0.1803, -0.2485, -0.2255, -0.2474,  0.0333,  0.1073, -0.1613,\n",
       "          0.1786, -0.2219,  0.1065,  0.1635, -0.0651, -0.0188,  0.0206,  0.0580,\n",
       "          0.3034,  0.1370, -0.0867, -0.0560, -0.0377,  0.1789, -0.1180, -0.0290,\n",
       "         -0.2028,  0.0915,  0.2005,  0.1190,  0.0222,  0.0656, -0.0016, -0.0942,\n",
       "          0.2103, -0.0874,  0.1940, -0.0745,  0.0851, -0.3041, -0.0825,  0.1119,\n",
       "          0.1513,  0.0245, -0.0256,  0.0319, -0.0185,  0.1375, -0.0102,  0.1293],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_var': tensor([-0.4715,  0.5929, -0.4339,  0.5654, -0.1380,  0.2572,  0.1679,  0.2061,\n",
       "          0.2047,  0.1249,  0.7378,  0.2322, -0.4595,  0.3220,  0.4550,  0.3694,\n",
       "         -0.2469,  0.1889, -0.0216,  0.6473,  0.3779,  0.0289,  0.0415,  0.5792,\n",
       "         -0.4005,  1.2180,  0.7216,  0.8520,  0.2553,  0.3662, -0.1013,  0.1310,\n",
       "          0.5430,  0.1856,  1.1557,  0.0858,  0.6518,  0.3079,  0.2410, -0.5870,\n",
       "          0.5770,  0.4991,  0.2795,  0.3619,  0.0676,  0.5238, -0.0429, -0.0335,\n",
       "          0.4255,  0.2851, -0.2757,  0.2823,  0.3885, -0.3277,  0.4326,  0.9883,\n",
       "         -0.4033,  0.0186,  0.3519,  0.2983,  0.1163,  0.2390, -0.4947, -0.2620],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.3.0.weight': tensor([[[[ 4.9826e-03, -9.0481e-03, -5.6392e-03],\n",
       "           [-6.7838e-03, -1.5491e-03,  5.9176e-03],\n",
       "           [ 4.0068e-03,  2.6900e-03, -6.1711e-03]],\n",
       " \n",
       "          [[-7.3918e-03,  3.4351e-03, -7.4734e-03],\n",
       "           [ 1.0698e-02, -8.0187e-03,  5.9524e-03],\n",
       "           [ 4.5172e-03,  6.7075e-03, -8.0327e-03]],\n",
       " \n",
       "          [[ 8.6537e-04,  1.7836e-03,  1.5258e-02],\n",
       "           [-1.5345e-02, -2.4349e-03,  5.8792e-03],\n",
       "           [ 5.5681e-03,  8.7045e-03,  1.5549e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0450e-03,  6.6013e-03,  3.6500e-03],\n",
       "           [-3.6385e-03,  9.9057e-03, -6.4178e-03],\n",
       "           [ 6.2930e-03,  8.8931e-03,  6.9411e-03]],\n",
       " \n",
       "          [[-8.8329e-03,  1.6260e-02, -1.1649e-02],\n",
       "           [ 4.8371e-03,  4.4178e-03, -1.1559e-02],\n",
       "           [-5.8572e-03, -8.3057e-03, -1.4319e-02]],\n",
       " \n",
       "          [[ 1.2658e-03,  1.3852e-02,  1.3109e-02],\n",
       "           [-8.0599e-03,  1.9596e-03, -1.1251e-02],\n",
       "           [-1.1878e-03, -6.9080e-03, -2.6498e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8656e-03,  1.0526e-02,  1.0633e-02],\n",
       "           [ 2.1709e-03,  2.8693e-04, -1.0204e-04],\n",
       "           [ 9.3330e-03,  1.5712e-03,  2.0978e-03]],\n",
       " \n",
       "          [[ 4.4691e-03,  1.6135e-03,  8.1540e-03],\n",
       "           [ 7.3635e-03,  4.9425e-03,  4.0509e-03],\n",
       "           [ 4.4445e-03, -1.7539e-03,  4.4861e-03]],\n",
       " \n",
       "          [[ 5.3051e-03,  6.9025e-03, -2.5581e-03],\n",
       "           [-6.3310e-04,  3.0138e-03,  9.5184e-04],\n",
       "           [-4.0868e-03, -3.3995e-03, -1.4531e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0619e-03,  1.2837e-03,  3.3470e-03],\n",
       "           [ 4.1837e-03,  6.3661e-03,  1.3581e-03],\n",
       "           [ 6.4320e-03, -9.9062e-04,  1.8365e-03]],\n",
       " \n",
       "          [[ 1.4188e-03, -7.8453e-03,  6.9582e-03],\n",
       "           [ 2.9040e-03, -2.9242e-04,  1.0820e-04],\n",
       "           [-3.1717e-03, -1.7504e-03,  6.1221e-03]],\n",
       " \n",
       "          [[ 4.2976e-03, -4.4346e-04, -1.0643e-02],\n",
       "           [ 1.3365e-03,  4.0065e-03, -2.4182e-03],\n",
       "           [ 1.1189e-02,  7.0418e-03,  1.3408e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.8983e-02,  3.9694e-03, -2.8899e-03],\n",
       "           [ 9.6258e-03,  1.2554e-03,  8.9127e-03],\n",
       "           [ 1.4442e-02,  5.8843e-03,  1.2980e-02]],\n",
       " \n",
       "          [[ 1.1749e-03,  3.4402e-03,  2.2069e-03],\n",
       "           [ 5.0170e-03,  3.7081e-03,  4.5236e-04],\n",
       "           [ 4.3228e-03,  1.7018e-03,  6.2364e-03]],\n",
       " \n",
       "          [[-1.7491e-03, -1.0251e-02, -1.0214e-02],\n",
       "           [ 2.8154e-03, -7.0960e-03, -6.0495e-03],\n",
       "           [ 3.5228e-03, -2.0228e-03, -9.1791e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2195e-03,  9.0621e-03,  7.0227e-03],\n",
       "           [-2.1163e-03, -1.4900e-03, -1.1447e-02],\n",
       "           [-3.5567e-03,  4.9223e-03, -1.0581e-02]],\n",
       " \n",
       "          [[ 1.9321e-03,  8.0594e-03,  3.2410e-03],\n",
       "           [ 6.5344e-03, -6.7017e-03, -3.1213e-03],\n",
       "           [-2.9517e-03, -1.5560e-02,  5.2068e-03]],\n",
       " \n",
       "          [[-1.2957e-02, -7.6048e-03,  7.0233e-04],\n",
       "           [-1.6029e-02,  7.3096e-03,  3.2141e-03],\n",
       "           [-1.2672e-02, -9.5625e-04, -7.6644e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.2142e-03,  6.9317e-03,  5.3943e-03],\n",
       "           [-2.9726e-04,  1.8991e-02,  2.1028e-02],\n",
       "           [ 2.5357e-03,  1.1299e-02,  6.9075e-03]],\n",
       " \n",
       "          [[ 7.3977e-05,  4.5691e-03, -7.4261e-03],\n",
       "           [-5.6989e-03,  1.5481e-03,  1.3841e-04],\n",
       "           [ 1.2977e-02, -4.2620e-04,  6.2205e-03]],\n",
       " \n",
       "          [[-8.6637e-03, -7.4594e-03, -1.8593e-02],\n",
       "           [-9.6220e-03, -2.7928e-03, -1.1189e-02],\n",
       "           [-4.0564e-03, -1.5600e-03, -1.3004e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.9546e-04,  1.5353e-02, -7.2790e-04],\n",
       "           [-7.1058e-03,  1.1728e-02,  6.8470e-03],\n",
       "           [-8.7322e-04, -6.9375e-04,  1.4241e-02]],\n",
       " \n",
       "          [[ 5.0023e-03,  8.6045e-04,  3.7505e-03],\n",
       "           [ 1.9693e-02,  7.1298e-03, -2.5348e-03],\n",
       "           [ 1.0284e-02,  1.2086e-02, -4.6493e-03]],\n",
       " \n",
       "          [[-1.0669e-02, -9.4093e-04, -4.9378e-03],\n",
       "           [ 3.5518e-03,  1.5776e-03,  9.8021e-04],\n",
       "           [ 8.8787e-03,  5.0321e-03,  1.8586e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.0251e-04,  3.0527e-03, -1.2866e-02],\n",
       "           [-8.7172e-03,  1.5247e-03, -2.9254e-03],\n",
       "           [-5.5876e-03, -2.3123e-03, -6.3033e-03]],\n",
       " \n",
       "          [[ 3.0073e-03,  2.1975e-03, -4.1723e-03],\n",
       "           [ 5.9064e-03,  3.0045e-03, -4.7434e-03],\n",
       "           [ 6.0830e-03,  6.0422e-04, -2.7576e-03]],\n",
       " \n",
       "          [[-1.0434e-03,  1.3079e-03,  8.4693e-03],\n",
       "           [-8.1258e-03, -8.0167e-03, -3.2531e-03],\n",
       "           [-8.1927e-03, -1.5085e-02, -1.1414e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.3064e-03,  4.1975e-04, -8.1651e-03],\n",
       "           [-7.0150e-03,  2.6603e-03, -8.6636e-03],\n",
       "           [-7.3471e-03,  6.8312e-03, -6.4552e-03]],\n",
       " \n",
       "          [[ 6.0377e-03, -4.0648e-04, -2.3102e-03],\n",
       "           [ 5.6821e-03,  2.5453e-03,  7.3080e-04],\n",
       "           [-2.7642e-03,  6.9431e-03,  2.8514e-03]],\n",
       " \n",
       "          [[ 1.1442e-04,  1.2571e-02,  1.4010e-02],\n",
       "           [ 2.2422e-03,  9.1282e-03,  1.1590e-02],\n",
       "           [ 3.3981e-04,  5.6402e-03,  6.7581e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4987e-02,  1.4340e-03, -4.5295e-03],\n",
       "           [-4.1928e-03, -3.3672e-03, -4.9173e-03],\n",
       "           [-8.3889e-03, -9.3705e-03, -1.1141e-02]],\n",
       " \n",
       "          [[-1.2916e-03, -4.0337e-03, -7.9635e-03],\n",
       "           [-1.0422e-02, -5.0252e-03, -2.1793e-03],\n",
       "           [ 1.5885e-02,  1.4979e-03,  3.8738e-03]],\n",
       " \n",
       "          [[ 2.4321e-03,  2.7151e-03,  8.5161e-04],\n",
       "           [-2.3076e-03, -1.6956e-03,  9.9809e-04],\n",
       "           [-4.4622e-03, -1.6577e-03, -2.2520e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8140e-03, -3.8220e-03, -4.0806e-04],\n",
       "           [-3.0155e-03, -5.9120e-03,  6.0332e-03],\n",
       "           [-4.2151e-03,  1.1946e-02,  3.0382e-03]],\n",
       " \n",
       "          [[ 5.3831e-03, -7.8050e-03, -3.0170e-03],\n",
       "           [ 1.6806e-02,  2.0282e-03, -2.2357e-03],\n",
       "           [ 1.6480e-02,  9.2184e-03,  1.2488e-03]],\n",
       " \n",
       "          [[-2.2640e-02, -9.6782e-04, -8.7574e-04],\n",
       "           [-1.5427e-02,  5.4486e-05, -3.8981e-03],\n",
       "           [ 3.7637e-04, -1.9921e-03,  4.8008e-03]]]], device='mps:0'),\n",
       " 'model.3.1.weight': tensor([-0.0248, -0.0060, -0.0018,  0.0296, -0.0047,  0.0388, -0.0250,  0.0039,\n",
       "         -0.0071,  0.0227, -0.0652,  0.0399,  0.0299, -0.0291,  0.0227, -0.0193,\n",
       "          0.0170,  0.0235,  0.0370,  0.0449, -0.0026, -0.0537, -0.0372, -0.0090,\n",
       "         -0.0358, -0.0244, -0.0203, -0.0127, -0.0472, -0.0123,  0.0669,  0.0490,\n",
       "          0.0231, -0.0068, -0.0176, -0.0181,  0.0066,  0.0021,  0.0713,  0.0121,\n",
       "          0.0147,  0.0238,  0.0014, -0.0239,  0.0121, -0.0376,  0.0153,  0.0035,\n",
       "          0.0060, -0.0141,  0.0391, -0.0303,  0.0392,  0.0223,  0.0084,  0.0164,\n",
       "         -0.0091, -0.0019,  0.0121, -0.0390,  0.0142, -0.0266,  0.0160, -0.0449],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.bias': tensor([-0.0415, -0.0288, -0.0160, -0.0265,  0.0070,  0.0325, -0.0136,  0.0051,\n",
       "          0.0076,  0.0188, -0.0524, -0.0192, -0.0027, -0.0321,  0.0382,  0.0169,\n",
       "          0.0088,  0.0051,  0.0494,  0.0635, -0.0085, -0.0244, -0.0348,  0.0109,\n",
       "         -0.0301,  0.0036, -0.0173, -0.0069, -0.0414,  0.0003,  0.0164,  0.0050,\n",
       "          0.0114,  0.0151, -0.0103,  0.0209,  0.0125, -0.0142,  0.0310,  0.0017,\n",
       "         -0.0137, -0.0058,  0.0070, -0.0029,  0.0374, -0.0187,  0.0143,  0.0147,\n",
       "          0.0128, -0.0083,  0.0288, -0.0365,  0.0372,  0.0302, -0.0011,  0.0158,\n",
       "         -0.0294, -0.0083,  0.0237, -0.0405,  0.0229, -0.0277,  0.0207, -0.0143],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_mean': tensor([ 0.1319,  0.2707, -0.1081,  0.0435, -0.0703,  0.0104,  0.1204, -0.0914,\n",
       "         -0.0748,  0.0384, -0.2947, -0.1094,  0.0346, -0.1987,  0.0338,  0.0204,\n",
       "          0.0685,  0.0396,  0.1102, -0.1766,  0.0146,  0.1039, -0.0151, -0.0553,\n",
       "         -0.0057, -0.0476,  0.0221,  0.0312, -0.1879,  0.0445,  0.0969,  0.0429,\n",
       "          0.0682,  0.0774, -0.0258, -0.0571,  0.0524,  0.0817, -0.0185, -0.1953,\n",
       "          0.0643, -0.1481, -0.1674,  0.0945,  0.1030,  0.1061,  0.1516,  0.1655,\n",
       "          0.2344, -0.1409, -0.1182, -0.1360, -0.1012,  0.0249, -0.1240,  0.0766,\n",
       "          0.1007, -0.0857,  0.0379, -0.0571,  0.1282,  0.0142,  0.2257, -0.0298],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_var': tensor([ 0.3219, -0.4409,  0.4636, -0.1853,  0.4742, -0.0661,  0.0439,  0.5691,\n",
       "          0.2829,  0.0503,  0.4853, -0.4068,  0.0280, -0.5041, -0.0186,  0.2541,\n",
       "         -0.1126,  0.1447,  0.8568,  0.1178,  0.1036, -0.0999,  0.9257, -0.0034,\n",
       "          0.1596,  0.0934,  0.3126,  0.1751,  0.0012,  0.1846, -0.0681,  0.0962,\n",
       "         -0.1432,  0.2033, -0.3666, -0.0572,  0.2189,  0.6869, -0.3310,  0.2112,\n",
       "          0.1494,  0.0289,  0.6808,  0.1678,  0.2397, -0.0585,  0.0897,  0.0964,\n",
       "         -0.0858,  0.1028,  0.1808,  0.2323, -0.2036,  0.5438, -0.0180,  0.5175,\n",
       "          0.1627,  0.1726,  0.3148, -0.1410,  0.2319,  0.3322, -0.0262, -0.3670],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.4.0.weight': tensor([[[[-5.4366e-04,  8.2138e-03, -3.1323e-03],\n",
       "           [-2.0293e-03,  3.8964e-03, -4.7715e-03],\n",
       "           [ 5.2717e-03,  6.5219e-03,  1.1815e-02]],\n",
       " \n",
       "          [[ 6.8812e-03,  1.0667e-03,  6.0485e-03],\n",
       "           [ 8.5238e-03,  2.6981e-03,  1.1627e-02],\n",
       "           [ 6.1024e-03,  5.0087e-03,  1.6695e-02]],\n",
       " \n",
       "          [[ 6.2146e-03,  6.0606e-03,  1.7481e-03],\n",
       "           [ 5.9143e-03,  2.2395e-03,  5.6924e-04],\n",
       "           [ 4.3939e-03, -3.6442e-04,  4.2657e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4191e-03, -2.0324e-03, -8.4530e-03],\n",
       "           [-1.0877e-03, -3.4024e-03, -1.7631e-03],\n",
       "           [-4.4991e-04,  1.3639e-03, -4.9482e-04]],\n",
       " \n",
       "          [[ 2.2094e-03,  1.1953e-03,  2.8360e-03],\n",
       "           [ 2.7955e-03,  1.0293e-03,  4.8131e-03],\n",
       "           [ 7.4137e-03,  7.2989e-03,  6.6943e-03]],\n",
       " \n",
       "          [[ 2.0734e-03,  8.7373e-03,  9.4675e-03],\n",
       "           [ 7.3762e-03,  1.1455e-02,  1.2200e-02],\n",
       "           [ 1.1089e-03,  2.8603e-03,  6.3257e-03]]],\n",
       " \n",
       " \n",
       "         [[[-7.4899e-03, -5.3057e-03,  8.4131e-03],\n",
       "           [-1.6698e-02, -5.2570e-03,  8.8096e-03],\n",
       "           [-1.5749e-03,  1.6358e-02,  2.2699e-02]],\n",
       " \n",
       "          [[ 4.1224e-03,  6.7711e-03,  8.7328e-03],\n",
       "           [ 7.3404e-03,  2.5802e-03, -3.6643e-03],\n",
       "           [ 1.1256e-02,  2.1263e-03,  1.9954e-03]],\n",
       " \n",
       "          [[-9.2126e-04, -6.0700e-03, -3.7637e-03],\n",
       "           [-5.6626e-04, -5.1200e-03, -1.0831e-02],\n",
       "           [ 3.6368e-03,  1.7811e-03, -8.2605e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.2789e-03,  1.6647e-03,  9.8011e-04],\n",
       "           [-1.0088e-02, -8.8414e-03, -7.2553e-03],\n",
       "           [-2.3393e-03, -1.1287e-03,  2.3383e-03]],\n",
       " \n",
       "          [[-8.2796e-03, -8.2317e-03, -5.5559e-03],\n",
       "           [-5.9247e-03, -3.7459e-03, -2.5446e-03],\n",
       "           [-3.3101e-03, -3.7494e-03, -2.5444e-03]],\n",
       " \n",
       "          [[-1.3907e-03, -7.7846e-03, -1.8271e-02],\n",
       "           [ 4.2737e-03, -3.8444e-03, -3.5880e-03],\n",
       "           [ 5.8979e-03,  1.4177e-02,  8.2913e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5585e-02,  4.3734e-03, -1.6077e-03],\n",
       "           [ 7.5149e-04, -7.7672e-03, -1.4673e-02],\n",
       "           [-1.2543e-03, -1.3057e-02, -2.2499e-02]],\n",
       " \n",
       "          [[ 6.9634e-03,  1.0109e-02,  1.0026e-02],\n",
       "           [-9.3718e-04, -7.3598e-04, -1.7731e-03],\n",
       "           [ 9.5480e-04,  1.5824e-03,  3.9066e-03]],\n",
       " \n",
       "          [[-5.9962e-03, -4.5222e-03,  2.2235e-03],\n",
       "           [-2.8509e-03,  7.0135e-04,  5.0799e-03],\n",
       "           [ 1.1738e-03,  3.8555e-03,  7.4527e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.6677e-03, -1.1567e-02,  5.7705e-03],\n",
       "           [-6.5697e-03, -2.0887e-02, -6.0914e-03],\n",
       "           [-6.3169e-03, -1.2510e-02,  1.7087e-03]],\n",
       " \n",
       "          [[ 6.5919e-04,  4.7257e-03,  4.4965e-03],\n",
       "           [-1.8291e-03, -3.2341e-03,  3.2083e-03],\n",
       "           [-2.5865e-03, -2.5214e-03,  1.4819e-03]],\n",
       " \n",
       "          [[-3.3699e-04, -7.1987e-04,  5.1203e-03],\n",
       "           [ 4.2492e-03, -3.0630e-03,  1.3230e-04],\n",
       "           [ 1.5954e-02,  1.4038e-02,  2.0732e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-7.7035e-03,  1.7530e-03,  5.3890e-03],\n",
       "           [-8.1956e-03,  2.0922e-03,  5.6499e-03],\n",
       "           [-1.6687e-02, -3.2996e-03, -4.5359e-03]],\n",
       " \n",
       "          [[-3.9014e-03, -4.8077e-03, -1.0891e-02],\n",
       "           [ 7.0819e-04, -5.6962e-03, -6.8437e-03],\n",
       "           [ 7.0215e-05,  1.0434e-03,  3.3060e-03]],\n",
       " \n",
       "          [[ 9.0560e-04,  1.3365e-03,  1.5076e-03],\n",
       "           [ 2.9075e-03,  5.9113e-03,  7.4042e-03],\n",
       "           [-2.8161e-03, -3.1394e-03, -1.3505e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-7.6212e-03, -1.9423e-04,  2.5728e-04],\n",
       "           [-2.5337e-03,  3.6893e-03,  6.2259e-03],\n",
       "           [-5.8342e-03, -8.6927e-03, -4.3902e-03]],\n",
       " \n",
       "          [[ 1.9582e-03,  8.5292e-03,  5.4706e-03],\n",
       "           [ 4.7376e-03,  8.8644e-03,  5.3076e-03],\n",
       "           [ 5.9742e-03,  6.5519e-03,  2.1712e-03]],\n",
       " \n",
       "          [[ 7.3985e-03, -8.0435e-03, -1.1836e-02],\n",
       "           [ 2.1606e-02,  1.0305e-02, -5.6907e-03],\n",
       "           [ 5.4141e-03,  8.0938e-03,  8.3643e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.1630e-02,  2.0720e-02,  9.4336e-03],\n",
       "           [ 4.0050e-03,  2.3912e-03, -7.9407e-03],\n",
       "           [ 7.5593e-04, -1.7388e-02, -3.0582e-02]],\n",
       " \n",
       "          [[ 2.1778e-03,  7.4421e-03,  9.3021e-03],\n",
       "           [-1.6090e-02, -5.9524e-03,  4.9846e-03],\n",
       "           [-1.5986e-02, -1.5653e-02, -9.8996e-03]],\n",
       " \n",
       "          [[ 1.9631e-03,  9.5623e-03,  2.0183e-02],\n",
       "           [-6.4058e-03, -1.3642e-03,  9.7715e-03],\n",
       "           [ 9.2748e-03,  1.2392e-02,  1.4513e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7115e-02,  9.0735e-04, -1.1567e-02],\n",
       "           [-1.6195e-02, -6.5966e-03, -1.2098e-02],\n",
       "           [-1.9516e-03, -1.1055e-03, -6.1511e-03]],\n",
       " \n",
       "          [[-2.6517e-03,  1.0072e-02,  1.7503e-02],\n",
       "           [-8.0577e-03,  8.9244e-03,  1.2101e-02],\n",
       "           [-5.5798e-03,  8.0791e-03,  1.1009e-02]],\n",
       " \n",
       "          [[ 1.3508e-03,  1.2011e-02,  1.3719e-02],\n",
       "           [-4.9820e-03, -1.3109e-02, -7.7090e-03],\n",
       "           [ 2.3558e-03, -1.0467e-02, -1.1883e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0307e-02, -2.9855e-03, -2.0927e-03],\n",
       "           [ 3.5450e-03,  8.2804e-03, -9.9740e-03],\n",
       "           [ 2.0650e-02,  1.7920e-02,  1.3669e-02]],\n",
       " \n",
       "          [[-6.4724e-03, -1.1481e-02, -1.5557e-02],\n",
       "           [-1.1980e-02, -1.3505e-02, -1.9116e-02],\n",
       "           [-2.8326e-04, -2.5092e-03, -9.0657e-03]],\n",
       " \n",
       "          [[ 8.5923e-03,  6.8987e-03,  3.8130e-03],\n",
       "           [ 2.9038e-03,  3.9832e-03,  2.4776e-03],\n",
       "           [ 1.1594e-02,  9.4120e-03,  5.9620e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.0632e-02, -2.8246e-03,  6.9429e-03],\n",
       "           [-1.5995e-02, -6.0140e-03,  6.2041e-03],\n",
       "           [-1.9346e-02, -7.8578e-03,  7.1864e-04]],\n",
       " \n",
       "          [[-1.2233e-02, -1.5159e-02, -7.3857e-03],\n",
       "           [-1.1818e-02, -1.0715e-02, -6.3451e-03],\n",
       "           [-4.7593e-03, -3.2848e-03, -1.8770e-03]],\n",
       " \n",
       "          [[ 2.9862e-03, -2.9970e-03, -1.2150e-02],\n",
       "           [ 4.7639e-03,  9.8164e-03,  5.6548e-03],\n",
       "           [ 5.9816e-03,  1.0735e-02,  6.0726e-03]]]], device='mps:0'),\n",
       " 'model.4.1.weight': tensor([ 0.0437,  0.0264,  0.0571, -0.0040, -0.0158,  0.0177, -0.0303, -0.0227,\n",
       "         -0.0236, -0.0222, -0.0296,  0.0038, -0.0105, -0.0122,  0.0399,  0.0254,\n",
       "          0.0020,  0.0222, -0.0072,  0.0048, -0.0052,  0.0141, -0.0134, -0.0932,\n",
       "          0.0111,  0.0009, -0.0060, -0.0153,  0.0396,  0.0150,  0.0612, -0.0229,\n",
       "          0.0502,  0.0676,  0.0247,  0.0566, -0.0128, -0.0219,  0.0172,  0.0453,\n",
       "          0.0051, -0.0078, -0.0299, -0.0095, -0.0185,  0.0065,  0.0244, -0.0344,\n",
       "         -0.0374,  0.0125, -0.0065, -0.0350, -0.0292, -0.0044, -0.0208,  0.0432,\n",
       "         -0.0451,  0.0317,  0.0241, -0.0197, -0.0110,  0.0065,  0.0878,  0.0027],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.bias': tensor([ 0.0153,  0.0221,  0.0417,  0.0196,  0.0113,  0.0251, -0.0013, -0.0328,\n",
       "         -0.0264, -0.0168,  0.0006,  0.0100,  0.0031, -0.0188,  0.0445, -0.0126,\n",
       "         -0.0018,  0.0130, -0.0032, -0.0190, -0.0128,  0.0282, -0.0020,  0.0051,\n",
       "          0.0190,  0.0079,  0.0020,  0.0336,  0.0058,  0.0201,  0.0349, -0.0198,\n",
       "          0.0249,  0.0260,  0.0119,  0.0876, -0.0090, -0.0034, -0.0162,  0.0280,\n",
       "         -0.0179, -0.0042, -0.0024, -0.0253,  0.0044,  0.0105,  0.0300, -0.0110,\n",
       "         -0.0168,  0.0151, -0.0301, -0.0197, -0.0488,  0.0194, -0.0067,  0.0697,\n",
       "         -0.0536,  0.0074,  0.0059, -0.0106, -0.0091,  0.0201,  0.0636,  0.0143],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_mean': tensor([-0.0235,  0.0890, -0.1168, -0.0650, -0.1158, -0.1082, -0.0814, -0.2448,\n",
       "          0.0586, -0.0250, -0.1095, -0.0697, -0.0375, -0.1073, -0.2537, -0.1275,\n",
       "          0.1428, -0.0162, -0.1409,  0.0471, -0.1590, -0.1058, -0.0676,  0.1245,\n",
       "          0.0224, -0.2491, -0.1917, -0.1392, -0.0794, -0.0615,  0.1151, -0.0128,\n",
       "          0.0426,  0.0393,  0.1242, -0.4306,  0.1259, -0.0818,  0.0425,  0.1963,\n",
       "          0.0792,  0.0187, -0.2558, -0.1395, -0.3659, -0.1540,  0.4013, -0.2134,\n",
       "          0.1887, -0.0841, -0.0307,  0.0155, -0.0523, -0.1746, -0.1190, -0.2061,\n",
       "         -0.2771, -0.0655,  0.0833, -0.1036, -0.0323, -0.0186,  0.0686, -0.0657],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_var': tensor([ 0.0815,  0.3425, -0.1003,  0.3776,  0.0948,  0.1806, -0.0563,  0.2762,\n",
       "          0.0569,  0.1422,  0.5485,  0.2258,  0.2769, -0.3022,  0.0037,  0.3508,\n",
       "          0.2822,  0.1304,  0.2415,  0.2008,  0.0800,  0.4226, -0.1524, -0.0036,\n",
       "          0.2678,  0.0769, -0.0839, -0.0869,  0.0926, -0.1212,  0.1753,  0.7389,\n",
       "          0.1171,  0.3442,  0.5249,  0.3939,  0.3624,  0.1873,  0.2221, -0.2705,\n",
       "          0.1458,  0.2154,  0.3207, -0.0671,  0.0202,  0.1836,  0.2144,  0.1957,\n",
       "          1.1224,  0.1115,  0.2403,  0.4128, -0.0495,  0.1955,  0.0555, -0.2771,\n",
       "          0.6356, -0.1181,  0.4063,  0.1567,  0.3817,  0.3323,  0.6373,  0.0563],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.5.0.weight': tensor([[[[-1.3576e-03, -5.0554e-03, -6.0772e-04],\n",
       "           [-3.1712e-03, -1.0249e-02, -6.2147e-03],\n",
       "           [-3.8982e-03, -1.7731e-02, -2.0006e-03]],\n",
       " \n",
       "          [[-3.0076e-03,  8.2977e-03,  1.4363e-02],\n",
       "           [ 5.6676e-03,  2.1771e-02,  1.0986e-02],\n",
       "           [ 8.5485e-03,  1.1575e-02,  1.0350e-02]],\n",
       " \n",
       "          [[-6.0596e-03,  3.7109e-04,  1.4457e-03],\n",
       "           [ 7.4677e-04, -5.2068e-03, -3.9226e-03],\n",
       "           [ 2.8886e-03, -6.1304e-04,  3.5346e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.1844e-03, -7.1022e-04, -3.3923e-03],\n",
       "           [-4.6760e-03,  5.1007e-05,  6.4520e-04],\n",
       "           [ 7.5895e-04,  5.3291e-03,  5.8232e-03]],\n",
       " \n",
       "          [[-4.4513e-03,  3.8133e-03,  4.1642e-03],\n",
       "           [ 1.0371e-03,  5.6607e-03,  3.5498e-03],\n",
       "           [-8.2975e-03, -3.4430e-03, -1.5722e-03]],\n",
       " \n",
       "          [[ 6.8502e-03,  3.2719e-03,  8.1820e-03],\n",
       "           [ 4.7204e-03,  6.7113e-03,  2.7637e-03],\n",
       "           [ 4.4394e-03,  4.4650e-03,  3.9377e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.9169e-03,  1.1688e-02,  6.0305e-05],\n",
       "           [ 7.3457e-03,  7.3229e-04, -1.6854e-03],\n",
       "           [-6.0369e-03, -4.1462e-03, -1.2537e-02]],\n",
       " \n",
       "          [[-8.5006e-03, -2.8860e-03,  4.3771e-03],\n",
       "           [-2.1184e-03,  2.6872e-03,  5.2178e-03],\n",
       "           [-2.8684e-03, -6.5307e-03, -6.6801e-03]],\n",
       " \n",
       "          [[-1.5449e-02, -1.2775e-02, -6.8589e-03],\n",
       "           [-1.6438e-02, -1.1093e-02, -1.2479e-02],\n",
       "           [-1.5360e-03, -6.7744e-03, -6.2554e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3395e-03, -1.1387e-02, -1.2842e-02],\n",
       "           [-6.2682e-03, -2.1417e-02, -1.3034e-02],\n",
       "           [-1.4543e-02, -1.6537e-02, -1.2625e-02]],\n",
       " \n",
       "          [[ 1.7406e-03,  1.2545e-02, -4.7929e-03],\n",
       "           [ 3.6960e-03,  9.4965e-03, -3.7678e-03],\n",
       "           [-1.7741e-03,  4.6726e-03,  3.1669e-03]],\n",
       " \n",
       "          [[ 5.4693e-03,  1.2207e-03,  3.8944e-03],\n",
       "           [ 3.7746e-03, -9.6900e-05,  4.0972e-03],\n",
       "           [ 9.1776e-03,  6.5677e-03,  7.1622e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.9022e-03, -1.1979e-02, -3.6004e-03],\n",
       "           [ 2.9990e-03, -3.0795e-03, -6.1170e-04],\n",
       "           [ 2.6341e-03, -5.3557e-03, -1.2865e-02]],\n",
       " \n",
       "          [[ 3.4712e-03, -8.1092e-03, -3.9924e-03],\n",
       "           [-4.4124e-03, -5.7006e-03, -6.5054e-03],\n",
       "           [-5.9573e-03,  1.1660e-03, -1.3166e-03]],\n",
       " \n",
       "          [[-1.3752e-03,  1.3636e-03, -4.3022e-03],\n",
       "           [ 1.0944e-03,  1.6326e-03, -3.2393e-03],\n",
       "           [-6.4795e-03, -2.8923e-03,  1.0843e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.3958e-03, -1.6673e-04,  1.4183e-03],\n",
       "           [-3.3560e-03, -3.4438e-03,  1.1804e-02],\n",
       "           [-4.5683e-03, -6.4795e-03,  8.5663e-03]],\n",
       " \n",
       "          [[-5.9868e-03,  7.2834e-03,  1.1660e-03],\n",
       "           [ 2.8266e-03,  1.8176e-02,  1.0733e-02],\n",
       "           [ 7.3415e-03,  2.1603e-03,  7.3948e-03]],\n",
       " \n",
       "          [[-6.7208e-03, -3.4283e-03,  9.5200e-04],\n",
       "           [ 2.0033e-03, -4.3179e-03, -9.1438e-04],\n",
       "           [-2.3581e-03, -1.2073e-03,  4.9944e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 2.2854e-03,  9.3736e-03,  4.5181e-03],\n",
       "           [ 3.8276e-03,  1.1293e-02,  2.2043e-03],\n",
       "           [-8.1962e-03, -1.4681e-03, -3.5871e-05]],\n",
       " \n",
       "          [[-6.1085e-03, -8.5735e-03,  3.9512e-03],\n",
       "           [-6.9577e-03, -8.1523e-04,  1.1318e-02],\n",
       "           [-2.6326e-03,  3.5791e-03, -2.5647e-03]],\n",
       " \n",
       "          [[-4.9683e-03,  2.3979e-03,  1.1232e-03],\n",
       "           [-1.4525e-02, -1.3531e-02, -1.1279e-02],\n",
       "           [-6.1564e-03, -7.0740e-03, -4.2432e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.2781e-03, -7.0618e-03, -1.1704e-02],\n",
       "           [-3.7341e-03, -1.3537e-02, -1.6055e-02],\n",
       "           [-5.9020e-03, -1.3964e-02, -1.3775e-02]],\n",
       " \n",
       "          [[-1.1225e-02, -7.0945e-03, -9.0991e-03],\n",
       "           [-1.2161e-02, -1.4522e-02, -1.6612e-02],\n",
       "           [ 1.0807e-03, -5.5292e-03,  4.2024e-03]],\n",
       " \n",
       "          [[ 5.7550e-03,  5.7534e-03,  1.0008e-02],\n",
       "           [ 1.2984e-02,  1.3183e-02,  9.3539e-03],\n",
       "           [ 2.9971e-03, -7.5478e-04, -2.8241e-05]]],\n",
       " \n",
       " \n",
       "         [[[ 4.0956e-03,  1.9040e-03,  6.2961e-04],\n",
       "           [-4.5821e-04, -1.3891e-03,  2.3189e-04],\n",
       "           [-6.7394e-04, -2.8689e-03, -7.3090e-03]],\n",
       " \n",
       "          [[-5.2482e-04, -1.5215e-03, -4.2811e-03],\n",
       "           [ 3.4478e-03, -6.3183e-03, -6.9929e-03],\n",
       "           [ 3.4794e-05, -1.2327e-02, -1.0089e-02]],\n",
       " \n",
       "          [[-2.0218e-03, -3.4129e-03, -3.8124e-03],\n",
       "           [-9.8649e-03, -2.7620e-03, -5.4081e-03],\n",
       "           [-2.9656e-03, -1.4607e-04,  1.0724e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0207e-03,  1.5807e-03,  7.4668e-03],\n",
       "           [ 1.8675e-03, -6.7441e-04,  7.0004e-03],\n",
       "           [ 5.7279e-03, -3.9755e-03,  3.7853e-03]],\n",
       " \n",
       "          [[ 4.3562e-03,  1.4035e-03, -3.6728e-03],\n",
       "           [-1.9922e-03,  3.0931e-03, -4.8592e-04],\n",
       "           [-4.7026e-03, -2.3222e-04, -2.2747e-03]],\n",
       " \n",
       "          [[ 8.3997e-04, -2.2547e-03, -3.1534e-03],\n",
       "           [ 8.0391e-04, -1.5348e-03, -2.1693e-03],\n",
       "           [ 2.3109e-03,  3.0168e-03,  4.6638e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 7.8223e-03,  8.6255e-03,  8.4306e-03],\n",
       "           [ 6.5464e-03,  5.8566e-03,  6.8162e-04],\n",
       "           [-1.5785e-03, -7.7375e-04, -9.4473e-03]],\n",
       " \n",
       "          [[ 1.1597e-02, -9.1483e-04, -4.7388e-03],\n",
       "           [ 1.2891e-02, -3.7761e-03,  3.2947e-03],\n",
       "           [ 3.7214e-03, -2.1547e-03,  3.7580e-03]],\n",
       " \n",
       "          [[-1.2473e-03, -1.4469e-03, -1.7626e-03],\n",
       "           [-9.3240e-05,  3.5323e-03,  9.7716e-04],\n",
       "           [-2.6859e-03, -4.9577e-03, -3.3462e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0657e-03,  8.5140e-03,  1.0126e-03],\n",
       "           [ 6.5766e-03,  6.9124e-03,  2.5829e-03],\n",
       "           [ 2.2272e-03,  1.4326e-03,  2.2567e-03]],\n",
       " \n",
       "          [[-8.1449e-03, -3.7677e-04, -2.1203e-03],\n",
       "           [-1.1198e-02, -4.4819e-03, -1.9681e-03],\n",
       "           [-4.6384e-03,  3.8915e-03,  2.9564e-03]],\n",
       " \n",
       "          [[-2.4027e-03, -9.3972e-03, -6.5498e-03],\n",
       "           [-2.3548e-04, -3.0301e-03, -2.2803e-03],\n",
       "           [-1.1193e-03,  9.1503e-04,  2.1777e-03]]]], device='mps:0'),\n",
       " 'model.5.1.weight': tensor([ 0.0182,  0.0092,  0.0065,  0.0127,  0.0456,  0.0232,  0.0009, -0.0095,\n",
       "         -0.0518, -0.0048,  0.0116,  0.0088,  0.0330,  0.0074,  0.0178,  0.0211,\n",
       "         -0.0165,  0.0245, -0.0075, -0.0340,  0.0179,  0.0235, -0.0523, -0.0053,\n",
       "         -0.0187, -0.0149, -0.0144,  0.0052,  0.0338, -0.0105, -0.0081, -0.0343,\n",
       "          0.0008,  0.0383,  0.0257,  0.0321,  0.0076,  0.0241, -0.0179,  0.0160,\n",
       "         -0.0114,  0.0062,  0.0310,  0.0105,  0.0192,  0.0091,  0.0012, -0.0062,\n",
       "         -0.0339, -0.0167,  0.0049, -0.0643, -0.0232, -0.0133, -0.0278, -0.0216,\n",
       "         -0.0506,  0.0104,  0.0242, -0.0166,  0.0494, -0.0418,  0.0075,  0.0088,\n",
       "          0.0028,  0.0468, -0.0106,  0.0213, -0.0110,  0.0406,  0.0114,  0.0057,\n",
       "         -0.0072,  0.0313,  0.0378,  0.0193,  0.0266,  0.0101,  0.0070,  0.0079,\n",
       "          0.0350, -0.0084, -0.0121,  0.0155, -0.0074, -0.0064, -0.0214,  0.0238,\n",
       "         -0.0463, -0.0229, -0.0487,  0.0203,  0.0011, -0.0595, -0.0572,  0.0464,\n",
       "          0.0142, -0.0036,  0.0141, -0.0008,  0.0031, -0.0329,  0.0147, -0.0284,\n",
       "         -0.0067, -0.0100, -0.0142,  0.0083,  0.0217,  0.0050,  0.0050,  0.0011,\n",
       "          0.0240, -0.0191, -0.0137, -0.0235, -0.0085, -0.0043, -0.0110, -0.0113,\n",
       "          0.0025, -0.0075,  0.0616, -0.0025, -0.0070, -0.0333,  0.0010, -0.0274],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.bias': tensor([ 3.6864e-02, -5.2853e-03,  8.3351e-03,  1.9025e-03,  2.7929e-02,\n",
       "         -1.5692e-03, -1.3566e-03, -5.5720e-03, -3.7509e-02,  1.9331e-03,\n",
       "          7.9545e-03,  9.0599e-03,  3.4660e-05, -1.3421e-03,  5.7296e-03,\n",
       "         -6.2264e-03, -3.6915e-02,  7.7527e-03,  2.3207e-02, -2.2164e-02,\n",
       "          1.4653e-02, -1.4569e-02, -2.6418e-02,  7.7331e-03, -1.5108e-02,\n",
       "         -9.0893e-03, -1.6116e-03,  1.0662e-02,  1.8742e-02, -9.7895e-03,\n",
       "          4.9084e-03, -2.4800e-02, -3.9521e-02,  1.7230e-02,  1.3347e-02,\n",
       "          2.0713e-02,  1.5456e-02,  1.8565e-02, -2.5364e-02,  1.1530e-02,\n",
       "         -2.2778e-02, -2.4475e-02,  4.6317e-02,  3.7790e-03,  7.9167e-03,\n",
       "          7.7714e-04,  5.7407e-03, -9.1790e-03, -9.5951e-03, -1.4538e-02,\n",
       "         -5.2309e-03, -7.1778e-02, -3.8057e-02,  6.5109e-03, -1.2252e-02,\n",
       "         -2.5099e-02, -4.0542e-02, -7.1723e-03,  2.5297e-02, -2.4445e-02,\n",
       "          3.0571e-02, -3.2524e-02,  4.3340e-03, -9.4705e-03,  5.6923e-03,\n",
       "          3.0787e-03, -1.7130e-02, -3.9437e-03,  2.4605e-02,  2.7523e-02,\n",
       "          3.6093e-03, -7.0995e-04, -1.5063e-02,  2.0693e-02,  1.5348e-02,\n",
       "          7.0482e-03,  8.1182e-03,  1.9892e-02,  5.6972e-03, -9.0244e-03,\n",
       "          2.2028e-02, -1.2679e-02, -2.2872e-02,  1.9744e-02,  6.2950e-03,\n",
       "         -8.7817e-03, -4.0558e-03,  1.3698e-02, -2.6976e-02, -2.7746e-02,\n",
       "         -4.5429e-02,  5.3183e-03, -8.1593e-03, -2.2966e-02, -1.9835e-02,\n",
       "          3.5966e-02,  4.0371e-03, -2.8270e-03, -2.1122e-03, -1.7579e-02,\n",
       "          1.0553e-02, -2.2266e-02,  1.9671e-02,  1.1104e-02, -1.8715e-02,\n",
       "          5.3031e-03, -1.4854e-02, -7.1751e-03,  7.6924e-03, -7.7404e-03,\n",
       "          1.5309e-02, -2.8798e-03,  8.0121e-03, -6.3360e-03, -5.0917e-03,\n",
       "         -1.4627e-02, -1.3488e-02, -9.5865e-03, -1.5979e-02, -4.0388e-02,\n",
       "         -4.3088e-03, -1.6506e-02,  2.0095e-02,  3.0428e-04, -4.3422e-04,\n",
       "         -1.6318e-02,  3.0567e-03, -4.1157e-02], device='mps:0'),\n",
       " 'model.5.1.running_mean': tensor([ 7.7916e-02,  6.0894e-02, -1.1549e-01,  2.4818e-01,  4.8869e-02,\n",
       "          5.0907e-02,  1.2290e-01, -1.8011e-02,  5.5243e-02, -1.5887e-01,\n",
       "          3.0439e-02, -3.6996e-03,  5.5066e-02,  4.4235e-02,  6.2149e-02,\n",
       "         -1.5011e-01, -7.4450e-02, -7.5818e-02, -4.6138e-02, -7.0938e-02,\n",
       "         -6.5878e-02,  1.2535e-01, -1.2636e-01,  5.4585e-02,  1.4108e-03,\n",
       "          1.1182e-01,  9.6716e-02, -8.2085e-02,  4.7522e-02, -7.4445e-02,\n",
       "          7.9997e-02, -4.6057e-02,  1.4368e-01, -3.6114e-02, -5.1370e-02,\n",
       "          1.2207e-01,  1.0595e-01,  4.2438e-02,  4.8134e-03,  6.6936e-02,\n",
       "          6.4878e-03, -1.4950e-01,  1.6534e-01,  5.9343e-03,  1.5499e-02,\n",
       "         -4.9253e-02, -4.1885e-02, -4.7000e-02, -4.1101e-02,  3.1759e-02,\n",
       "          2.3881e-02, -1.0221e-01,  7.4813e-04, -1.2848e-01, -1.0283e-01,\n",
       "          7.8125e-02, -9.2602e-02,  1.1595e-01,  8.1983e-02, -6.8145e-02,\n",
       "          9.0188e-02, -2.1967e-02, -8.1197e-02,  2.5817e-03,  5.7645e-02,\n",
       "         -1.1973e-01, -1.1848e-01, -1.2246e-02,  1.1738e-02,  1.2689e-01,\n",
       "         -1.7829e-02, -9.8495e-02, -1.6484e-01,  1.2102e-01,  1.7837e-01,\n",
       "         -6.4998e-02,  1.2495e-01,  1.6414e-01,  1.2934e-01,  1.8954e-01,\n",
       "          1.0260e-02,  6.5948e-02,  4.7405e-02,  7.0883e-02, -1.1985e-01,\n",
       "         -2.4036e-03, -1.9840e-01,  1.4843e-01, -1.1871e-01,  1.2433e-01,\n",
       "          1.0878e-01,  3.4402e-02,  5.9968e-02,  1.4430e-02, -5.8400e-02,\n",
       "         -5.4959e-03, -7.6403e-02, -6.1590e-02,  2.8938e-03, -3.0973e-02,\n",
       "         -1.0170e-01, -1.4121e-01,  3.7705e-02, -1.1796e-01,  1.1435e-01,\n",
       "         -3.5430e-02,  1.7262e-02, -1.6099e-03,  1.4971e-01, -9.2876e-02,\n",
       "         -1.8456e-02, -1.4151e-01,  2.1100e-04,  5.9666e-02, -9.5647e-02,\n",
       "          4.2416e-02, -2.7990e-02,  1.7154e-01,  8.4691e-02,  1.1588e-01,\n",
       "          8.2857e-02,  8.7308e-02,  5.9512e-02, -5.9012e-02, -3.5544e-02,\n",
       "         -3.0975e-01, -4.2242e-02,  2.5923e-02], device='mps:0'),\n",
       " 'model.5.1.running_var': tensor([ 0.2115,  0.3403, -0.0463,  0.1534,  0.2472,  0.0723,  0.1632,  0.2370,\n",
       "          0.0983, -0.0688,  0.2038,  0.1623,  0.0674,  0.2069,  0.0144,  0.3651,\n",
       "          0.0239,  0.1004,  0.0612,  0.1207,  0.0401, -0.0969,  0.0322,  0.1513,\n",
       "          0.2205, -0.0049, -0.0939,  0.1443,  0.1378,  0.1176,  0.0151, -0.0880,\n",
       "          0.1998, -0.1143, -0.0611,  0.1731,  0.0084,  0.1127,  0.0234,  0.0459,\n",
       "          0.1915, -0.0592,  0.3270,  0.2091,  0.2248,  0.0105,  0.2122,  0.0797,\n",
       "          0.0062,  0.0571,  0.0081,  0.2809,  0.1360,  0.3072,  0.1306,  0.1241,\n",
       "          0.2568,  0.0096,  0.2356,  0.2362,  0.2199, -0.0818,  0.0942,  0.2415,\n",
       "         -0.0393,  0.0716,  0.1095,  0.1689,  0.0644,  0.1211,  0.0685,  0.1111,\n",
       "          0.1893, -0.1039,  0.3912,  0.1807,  0.0104,  0.0470,  0.1578, -0.0758,\n",
       "         -0.0438, -0.0908,  0.0771,  0.0600,  0.3515, -0.0179, -0.0354,  0.1319,\n",
       "         -0.0850,  0.0745,  0.1665,  0.1022, -0.0526,  0.0366,  0.0208,  0.1176,\n",
       "          0.1549,  0.2569,  0.1684,  0.2120,  0.0518,  0.3050,  0.3108,  0.2070,\n",
       "          0.1468,  0.3369, -0.0834,  0.0641,  0.0342,  0.2261, -0.0164,  0.0225,\n",
       "         -0.2155,  0.1497,  0.0687,  0.0050,  0.1415,  0.0680, -0.0537, -0.1317,\n",
       "         -0.0527,  0.2133, -0.0398,  0.1743, -0.0286,  0.1859,  0.1123,  0.0953],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.6.0.weight': tensor([[[[ 1.3071e-04, -8.3420e-04,  2.7519e-03],\n",
       "           [-5.0059e-03, -5.0105e-04,  3.7691e-04],\n",
       "           [-4.1772e-03,  1.5525e-03,  7.3677e-04]],\n",
       " \n",
       "          [[ 4.8309e-03,  2.4301e-04,  2.2649e-03],\n",
       "           [ 2.3899e-03, -3.5950e-03, -3.8654e-04],\n",
       "           [-3.8148e-03, -2.4047e-03, -6.7456e-03]],\n",
       " \n",
       "          [[ 1.1801e-02,  9.6137e-03,  5.0352e-03],\n",
       "           [ 1.7471e-02,  7.5466e-03,  2.0555e-03],\n",
       "           [ 1.9464e-02,  1.8352e-03,  5.3173e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0588e-02,  3.5197e-03, -3.6164e-04],\n",
       "           [ 5.7178e-03, -8.6636e-03, -9.9473e-03],\n",
       "           [ 4.0018e-03,  6.3593e-03,  5.2831e-03]],\n",
       " \n",
       "          [[ 1.3818e-03,  5.2816e-03,  6.6115e-03],\n",
       "           [-3.8222e-03, -2.7086e-03, -2.7691e-04],\n",
       "           [-4.5063e-03, -1.6946e-03, -7.8629e-03]],\n",
       " \n",
       "          [[ 4.4776e-03, -2.9290e-03, -7.4693e-03],\n",
       "           [-4.9684e-03, -5.5952e-03, -3.2085e-03],\n",
       "           [-1.8952e-02, -1.1485e-02, -8.4496e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 8.7175e-03,  7.4017e-03,  1.1259e-02],\n",
       "           [-2.0112e-04,  7.7636e-03,  9.4757e-03],\n",
       "           [ 1.8476e-02,  9.9177e-03,  4.9130e-03]],\n",
       " \n",
       "          [[-3.2731e-04, -1.3023e-03,  5.0363e-03],\n",
       "           [-6.6298e-03, -5.6470e-03,  7.1063e-04],\n",
       "           [ 6.7283e-03,  7.0223e-03,  3.2773e-03]],\n",
       " \n",
       "          [[-4.6412e-03,  1.3160e-02,  2.5170e-02],\n",
       "           [ 3.3684e-03,  1.3348e-02,  2.9761e-02],\n",
       "           [ 5.6772e-03,  8.4063e-03,  7.2301e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0680e-04,  1.3669e-03,  5.7116e-03],\n",
       "           [-6.0497e-03, -7.8742e-03, -7.4860e-03],\n",
       "           [-9.2280e-03, -9.5451e-03, -9.5957e-03]],\n",
       " \n",
       "          [[ 4.1725e-03, -2.9591e-03,  3.6508e-03],\n",
       "           [ 7.9609e-03,  1.1777e-02,  1.2574e-02],\n",
       "           [-1.4665e-03,  6.0045e-03,  8.6456e-03]],\n",
       " \n",
       "          [[ 4.2829e-03,  6.9809e-03,  3.3218e-03],\n",
       "           [ 6.9872e-03,  2.7766e-03,  6.0032e-03],\n",
       "           [-2.8412e-04, -1.8718e-03, -2.7152e-05]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1635e-03, -2.6378e-03, -5.7682e-03],\n",
       "           [ 6.7215e-03,  2.3702e-03, -1.1404e-03],\n",
       "           [ 5.6517e-03,  4.8717e-03,  1.9173e-03]],\n",
       " \n",
       "          [[ 5.2406e-03,  2.4070e-04, -6.0615e-04],\n",
       "           [ 5.6720e-03,  6.8970e-03,  5.2383e-03],\n",
       "           [ 3.7951e-03,  3.9678e-03,  6.5244e-03]],\n",
       " \n",
       "          [[ 2.0578e-03,  3.4715e-04,  2.3942e-03],\n",
       "           [-4.3271e-03,  1.3291e-04,  3.2989e-03],\n",
       "           [-6.1903e-03,  3.3228e-03,  6.0347e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8113e-03, -7.1381e-03, -4.4908e-03],\n",
       "           [-6.2412e-04, -6.9677e-04, -7.2239e-03],\n",
       "           [ 5.4343e-03,  6.2272e-03,  7.2483e-04]],\n",
       " \n",
       "          [[-1.7669e-03, -1.1508e-03, -2.9769e-03],\n",
       "           [-7.5915e-03, -2.1074e-03, -6.9185e-04],\n",
       "           [-9.8641e-03, -9.1083e-03, -1.5793e-03]],\n",
       " \n",
       "          [[ 2.5735e-03, -1.7119e-03, -3.2889e-03],\n",
       "           [-4.4964e-03, -7.5780e-03, -5.0982e-03],\n",
       "           [-1.3017e-02, -9.2235e-03, -2.3061e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.9603e-03,  7.6505e-03,  8.1853e-03],\n",
       "           [-7.5409e-03,  1.4072e-02, -1.8232e-05],\n",
       "           [ 3.4841e-03,  1.4134e-02, -3.2083e-03]],\n",
       " \n",
       "          [[ 5.2799e-05, -7.5899e-04,  6.0133e-04],\n",
       "           [-1.2173e-03, -1.9764e-03,  5.4880e-03],\n",
       "           [ 6.2444e-03, -1.8553e-03,  1.6158e-03]],\n",
       " \n",
       "          [[-2.1231e-03, -1.5506e-03, -8.1180e-03],\n",
       "           [-1.0315e-02,  2.1179e-03, -4.9908e-03],\n",
       "           [-1.4892e-02, -7.1474e-03, -1.0305e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 6.0903e-03, -1.9860e-03, -5.4517e-03],\n",
       "           [ 9.0153e-03, -8.0686e-03, -1.7720e-03],\n",
       "           [ 3.2407e-03, -2.9961e-03,  4.5671e-03]],\n",
       " \n",
       "          [[ 5.1286e-03,  1.5657e-03,  3.4360e-03],\n",
       "           [-2.1009e-03,  1.9623e-03,  5.3630e-03],\n",
       "           [-1.6642e-03,  2.4997e-03,  1.6314e-03]],\n",
       " \n",
       "          [[ 3.1037e-03,  1.6359e-03, -6.2217e-03],\n",
       "           [ 1.1253e-03,  9.8863e-04, -1.2686e-03],\n",
       "           [-1.2000e-03,  2.6653e-03, -2.0712e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3984e-02,  7.0614e-03,  8.5258e-03],\n",
       "           [ 9.7816e-03, -2.0075e-03, -9.8999e-03],\n",
       "           [ 1.0799e-02,  1.1317e-02,  1.0288e-03]],\n",
       " \n",
       "          [[-1.6736e-03, -3.5030e-04, -2.0032e-03],\n",
       "           [ 2.4073e-03,  4.2016e-04,  1.7613e-03],\n",
       "           [ 8.8198e-03,  2.1385e-03, -3.3931e-04]],\n",
       " \n",
       "          [[-1.6432e-02, -8.4488e-03, -7.2635e-03],\n",
       "           [-1.4892e-02, -9.4809e-03, -3.9988e-03],\n",
       "           [-3.4802e-03, -4.9492e-03,  2.1920e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.4760e-03, -6.9575e-03, -3.4218e-04],\n",
       "           [-5.3337e-03,  1.3419e-02,  1.3833e-02],\n",
       "           [ 1.4047e-02,  2.7491e-03,  5.7668e-03]],\n",
       " \n",
       "          [[-1.1248e-03, -5.7738e-03, -2.9962e-03],\n",
       "           [ 2.4716e-03, -9.4326e-03, -8.0704e-03],\n",
       "           [ 2.1817e-03, -2.8931e-03, -7.0935e-03]],\n",
       " \n",
       "          [[-2.1612e-03,  1.0901e-04, -3.2147e-03],\n",
       "           [ 8.5674e-04, -1.0803e-02, -7.4146e-03],\n",
       "           [ 6.0898e-03, -5.2569e-03, -1.3220e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.1409e-03, -9.8115e-03, -6.5792e-03],\n",
       "           [ 8.8220e-03,  1.8119e-03, -5.6575e-04],\n",
       "           [ 5.4309e-03,  1.8115e-03, -1.0438e-02]],\n",
       " \n",
       "          [[-4.2065e-03, -2.3282e-03, -5.1664e-03],\n",
       "           [-7.7414e-03, -7.8428e-04,  5.4668e-04],\n",
       "           [-3.0250e-03, -4.4081e-03, -8.1251e-04]],\n",
       " \n",
       "          [[ 1.1481e-02,  1.6215e-02,  2.0489e-02],\n",
       "           [ 1.3467e-02,  3.1448e-02,  3.4977e-02],\n",
       "           [-4.6600e-03,  3.8300e-03,  2.0071e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1216e-02, -6.1035e-03, -6.4660e-03],\n",
       "           [-1.0299e-02, -1.1143e-02, -1.5746e-02],\n",
       "           [-6.5158e-03, -1.7121e-03,  1.4655e-04]],\n",
       " \n",
       "          [[ 3.4629e-03,  4.1537e-03,  3.3596e-03],\n",
       "           [-4.0203e-03, -4.7075e-04,  6.0632e-03],\n",
       "           [-2.5957e-03, -3.5838e-03,  3.5211e-03]],\n",
       " \n",
       "          [[ 6.0216e-03,  6.8414e-03,  4.0750e-03],\n",
       "           [-7.1723e-03, -3.5747e-03, -1.8690e-03],\n",
       "           [-7.0710e-03, -1.3561e-02, -3.5530e-03]]]], device='mps:0'),\n",
       " 'model.6.1.weight': tensor([ 0.0749,  0.0107, -0.0454, -0.0127, -0.0536, -0.0338,  0.0172, -0.0101,\n",
       "         -0.0075,  0.0121,  0.0586,  0.0323,  0.0363,  0.0110,  0.0411, -0.0328,\n",
       "         -0.0331, -0.0061, -0.0143,  0.0336,  0.0024, -0.0434,  0.0147,  0.0368,\n",
       "          0.0117,  0.0327, -0.0280, -0.0037,  0.0455,  0.0146, -0.0249, -0.0215,\n",
       "         -0.0492,  0.0107, -0.0264,  0.0309, -0.0108,  0.0251, -0.0033,  0.0337,\n",
       "         -0.0405,  0.0061, -0.0115, -0.0548, -0.0548,  0.0061,  0.0077, -0.0141,\n",
       "         -0.0169,  0.0159, -0.0232, -0.0392,  0.0377, -0.0181,  0.0427, -0.0026,\n",
       "         -0.0196, -0.0027,  0.0189, -0.0022,  0.0114, -0.0413, -0.0001,  0.0137,\n",
       "         -0.0536, -0.0309,  0.0046,  0.0196, -0.0068, -0.0008,  0.0182, -0.0326,\n",
       "          0.0155,  0.0285,  0.0349,  0.0378,  0.0508,  0.0244,  0.0196,  0.0268,\n",
       "          0.0341, -0.0156,  0.0314,  0.0504, -0.0483, -0.0271,  0.0209,  0.0203,\n",
       "         -0.0712, -0.0103, -0.0121, -0.0274,  0.0090,  0.0084,  0.0377, -0.0247,\n",
       "         -0.0153, -0.0284, -0.0127,  0.0958,  0.0591,  0.0430, -0.0148,  0.0102,\n",
       "         -0.0243, -0.0066, -0.0723, -0.0060, -0.0222, -0.0148,  0.0023,  0.0053,\n",
       "         -0.0064, -0.0048,  0.0152,  0.0030, -0.0430,  0.0334, -0.0577, -0.0110,\n",
       "         -0.0204,  0.0035, -0.0193, -0.0062,  0.0066, -0.0145, -0.0086, -0.0022],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.bias': tensor([ 0.0485, -0.0102, -0.0135, -0.0086, -0.0381, -0.0205,  0.0104,  0.0189,\n",
       "         -0.0121, -0.0038,  0.0211,  0.0183,  0.0120, -0.0108,  0.0139, -0.0213,\n",
       "         -0.0275, -0.0019, -0.0170,  0.0397,  0.0051, -0.0220, -0.0024,  0.0028,\n",
       "          0.0106,  0.0236, -0.0207, -0.0080,  0.0416, -0.0112, -0.0274, -0.0283,\n",
       "         -0.0334, -0.0148, -0.0256,  0.0034, -0.0085,  0.0024, -0.0133,  0.0280,\n",
       "         -0.0282,  0.0018, -0.0035, -0.0285, -0.0406,  0.0105, -0.0133, -0.0014,\n",
       "         -0.0118,  0.0093, -0.0191, -0.0519,  0.0222, -0.0106,  0.0075, -0.0065,\n",
       "         -0.0123,  0.0201,  0.0041, -0.0040,  0.0068, -0.0137,  0.0004, -0.0034,\n",
       "         -0.0242, -0.0320, -0.0179,  0.0147, -0.0094, -0.0063,  0.0139, -0.0167,\n",
       "          0.0039,  0.0212,  0.0024,  0.0280,  0.0286,  0.0084,  0.0063,  0.0035,\n",
       "          0.0116, -0.0109, -0.0137,  0.0449, -0.0375, -0.0203,  0.0077,  0.0267,\n",
       "         -0.0438, -0.0091, -0.0289, -0.0056, -0.0040,  0.0068,  0.0148, -0.0127,\n",
       "         -0.0243, -0.0296, -0.0099,  0.0462,  0.0230,  0.0259, -0.0173, -0.0174,\n",
       "         -0.0042, -0.0209, -0.0403, -0.0054, -0.0283, -0.0175, -0.0057,  0.0121,\n",
       "         -0.0104, -0.0035,  0.0208, -0.0096, -0.0444, -0.0029, -0.0494, -0.0014,\n",
       "         -0.0307, -0.0287, -0.0341, -0.0067, -0.0071, -0.0138,  0.0113, -0.0205],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.running_mean': tensor([ 4.0775e-01,  3.6565e-01,  7.0715e-02, -3.8217e-02, -2.0926e-01,\n",
       "         -3.4874e-01, -5.7410e-02, -2.0018e-02,  4.5776e-05,  1.2545e-01,\n",
       "          5.5051e-02,  1.4735e-01, -7.0158e-03, -4.5565e-02,  6.1781e-01,\n",
       "          1.1757e-01, -3.2534e-01, -2.1180e-01, -4.4862e-02, -1.0404e-01,\n",
       "         -7.0423e-02, -3.8209e-02, -2.3393e-01,  5.4976e-01,  5.9028e-02,\n",
       "         -4.8257e-02,  1.2555e-03,  8.3138e-02,  2.0848e-01,  2.1181e-01,\n",
       "          2.3012e-01,  1.7227e-01, -2.3465e-02, -1.5088e-01,  7.0272e-02,\n",
       "          2.5600e-01, -1.1491e-01,  1.5889e-01, -1.1964e-01, -2.0707e-02,\n",
       "         -2.3607e-02, -2.4769e-01, -3.2298e-02, -5.1103e-02, -1.9076e-01,\n",
       "         -3.0832e-02,  3.2090e-01, -1.7061e-01,  1.7259e-01,  1.8071e-01,\n",
       "         -1.5639e-01, -5.3894e-02,  2.4118e-01,  3.9100e-01, -4.9806e-02,\n",
       "         -1.1537e-01,  9.0838e-03,  2.9238e-03, -7.5868e-02,  1.8657e-01,\n",
       "          3.2502e-02,  8.2923e-02,  2.6505e-01,  9.9540e-02, -6.4914e-01,\n",
       "         -7.5485e-02,  4.8967e-02,  6.4885e-02, -6.7689e-02,  1.0961e-01,\n",
       "          3.2838e-02, -3.8011e-01,  2.3890e-01, -2.8920e-01,  2.1448e-01,\n",
       "          2.4188e-01,  4.4968e-02,  1.6390e-01,  1.0382e-01,  7.4917e-02,\n",
       "          2.6933e-01,  2.4581e-01, -5.5546e-01, -7.6547e-02,  9.7852e-02,\n",
       "         -3.5204e-01,  8.8855e-03,  1.6319e-01, -2.6196e-01,  1.1740e-01,\n",
       "         -2.5600e-01,  1.4697e-01,  5.5000e-02, -1.9334e-01, -1.6323e-01,\n",
       "          4.2741e-02, -1.0113e-01, -1.7530e-02,  3.6765e-02,  4.4286e-01,\n",
       "          1.2853e-01,  2.2949e-02, -1.0744e-01,  1.4811e-01,  4.8700e-02,\n",
       "         -3.3912e-01, -1.1815e-01,  2.7387e-01,  2.0213e-02, -2.7048e-01,\n",
       "          1.8166e-01,  7.4559e-02,  9.5798e-02,  1.3143e-01,  1.7736e-01,\n",
       "         -2.0074e-01, -7.7164e-02,  2.0018e-01, -5.2231e-01,  1.4989e-01,\n",
       "         -2.8056e-01, -2.1627e-01, -1.0542e-01, -1.4632e-01,  6.3541e-03,\n",
       "          3.8067e-02,  3.6427e-01, -9.9205e-02], device='mps:0'),\n",
       " 'model.6.1.running_var': tensor([ 0.4318,  0.0257,  0.4285,  0.3674,  0.1404,  0.0936,  0.2344,  0.4419,\n",
       "          0.0417, -0.1975,  0.3023,  0.0327,  0.4439, -0.0687,  0.3297,  0.2987,\n",
       "          0.4202,  0.1442,  0.3022,  0.0444,  0.0301,  0.4122,  0.3759, -0.0746,\n",
       "          0.1219,  0.2268,  0.0526, -0.0854,  0.1017, -0.0351,  0.1011,  0.2399,\n",
       "          0.2148,  0.3559,  0.3552,  0.1056,  0.0514, -0.1128,  0.2829,  0.3496,\n",
       "          0.0704,  0.3496,  0.1128,  0.2377,  0.2954, -0.0010,  0.3143,  0.2001,\n",
       "          0.0123, -0.3128,  0.1816,  0.0959,  0.2775,  0.1452, -0.1999,  0.3606,\n",
       "         -0.0085,  0.0136, -0.0200,  0.1754,  0.3309, -0.0239,  0.2109,  0.0145,\n",
       "          0.0863,  0.2073,  0.3250,  0.3108,  0.0937, -0.1517,  0.0485,  0.2622,\n",
       "          0.2106,  0.2967,  0.0617,  0.0696, -0.0203,  0.0047, -0.0267,  0.2837,\n",
       "          0.2358,  0.0612,  0.3469,  0.1324,  0.1534,  0.3414, -0.1232,  0.0344,\n",
       "          0.1602, -0.0082, -0.0046,  0.0782, -0.0590,  0.2944,  0.1315,  0.1639,\n",
       "         -0.0208,  0.0241,  0.1858,  0.2163,  0.0210, -0.3128,  0.2167,  0.2149,\n",
       "          0.0960,  0.3537, -0.1582,  0.1021,  0.1859, -0.0988, -0.1915,  0.0793,\n",
       "          0.1676,  0.0416,  0.0390,  0.1257,  0.3840,  0.2572,  0.3216,  0.1064,\n",
       "          0.1344,  0.1689,  0.2848, -0.0745, -0.2154,  0.1880,  0.3082,  0.2977],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.7.0.weight': tensor([[[[ 2.0517e-03,  6.2334e-03,  6.1817e-03],\n",
       "           [ 8.8101e-04,  3.9758e-03,  2.3903e-03],\n",
       "           [-2.6057e-03, -1.8735e-03, -1.3249e-03]],\n",
       " \n",
       "          [[-3.8049e-03, -7.9315e-03, -7.7281e-03],\n",
       "           [ 1.7235e-03, -8.2732e-04, -1.8267e-03],\n",
       "           [-1.4006e-03, -2.9209e-03, -3.3566e-03]],\n",
       " \n",
       "          [[ 6.7115e-04,  2.0139e-03,  1.6210e-03],\n",
       "           [ 1.8421e-03,  1.5969e-03,  1.7253e-03],\n",
       "           [ 2.5406e-03, -7.6881e-04, -6.0456e-05]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0357e-03,  9.4351e-04,  2.2469e-03],\n",
       "           [-1.9503e-03, -3.3493e-03,  9.2529e-04],\n",
       "           [-1.8532e-03, -3.2571e-03,  5.6979e-04]],\n",
       " \n",
       "          [[-5.8863e-04,  9.6448e-05, -6.2571e-04],\n",
       "           [ 4.9668e-03,  3.0550e-03, -8.1595e-04],\n",
       "           [ 4.3146e-03,  2.5875e-03,  1.0734e-03]],\n",
       " \n",
       "          [[ 5.8763e-03,  6.7789e-03,  5.3061e-03],\n",
       "           [ 1.3170e-03,  1.5828e-03,  1.6041e-03],\n",
       "           [ 2.2008e-03, -4.6824e-04, -7.6468e-04]]],\n",
       " \n",
       " \n",
       "         [[[-3.3013e-03, -2.9695e-03, -4.8749e-04],\n",
       "           [-2.8518e-03, -5.5628e-04, -1.0022e-04],\n",
       "           [ 2.7214e-03,  4.2079e-03,  3.4405e-03]],\n",
       " \n",
       "          [[ 1.4861e-03,  6.4128e-04, -3.2528e-04],\n",
       "           [-3.3090e-04,  3.0589e-03, -6.0342e-04],\n",
       "           [ 2.2960e-03,  5.7082e-03,  4.7179e-03]],\n",
       " \n",
       "          [[ 3.0858e-03,  1.7860e-03,  9.1179e-04],\n",
       "           [-1.1371e-04, -1.1476e-04, -3.3080e-05],\n",
       "           [-1.7638e-03, -2.3521e-04,  1.2956e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7597e-05,  7.0792e-04,  4.3287e-03],\n",
       "           [-4.2399e-03, -4.6480e-03,  2.6342e-04],\n",
       "           [-2.1896e-03, -5.4366e-03, -1.6472e-03]],\n",
       " \n",
       "          [[ 1.4177e-03,  4.0003e-03,  7.2125e-03],\n",
       "           [ 4.0778e-03,  6.3569e-03,  4.4102e-03],\n",
       "           [ 1.1977e-03,  1.5139e-03,  1.8052e-03]],\n",
       " \n",
       "          [[ 1.9175e-04, -2.5381e-03, -1.3535e-03],\n",
       "           [-5.0462e-03, -6.4214e-03, -4.6157e-03],\n",
       "           [-8.3368e-03, -8.6313e-03, -7.8882e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1979e-03,  2.5365e-03,  6.4927e-03],\n",
       "           [-6.0639e-03,  7.8006e-04,  1.0093e-02],\n",
       "           [-9.5285e-03, -3.2773e-03,  4.6850e-03]],\n",
       " \n",
       "          [[-3.7322e-03, -4.6615e-03, -3.0010e-03],\n",
       "           [-2.8917e-03, -1.6872e-03,  3.2566e-04],\n",
       "           [ 1.2589e-03,  2.7461e-03,  4.0369e-03]],\n",
       " \n",
       "          [[ 2.7707e-03,  3.6473e-03,  2.9769e-03],\n",
       "           [ 3.3579e-04,  2.8721e-03,  4.3871e-03],\n",
       "           [-2.3934e-03,  2.2317e-03,  4.0505e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.4473e-03,  5.4112e-03,  9.8907e-03],\n",
       "           [-6.9979e-04,  4.7423e-03,  1.2974e-02],\n",
       "           [-4.2422e-03, -8.2389e-04,  9.2937e-03]],\n",
       " \n",
       "          [[-4.6577e-03, -7.2509e-03, -1.1860e-03],\n",
       "           [-5.6639e-03, -5.1932e-03, -5.0337e-03],\n",
       "           [-2.7726e-03, -7.8620e-04, -3.2809e-03]],\n",
       " \n",
       "          [[ 5.1064e-03,  5.6184e-03,  2.0396e-03],\n",
       "           [ 5.8045e-03,  2.7727e-03,  1.8455e-04],\n",
       "           [ 2.9482e-03,  1.0386e-03, -3.4929e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.5364e-03,  3.4322e-03,  8.5285e-04],\n",
       "           [ 2.5221e-03,  8.2131e-03,  7.0117e-03],\n",
       "           [ 1.3172e-03,  5.0226e-03,  6.3715e-03]],\n",
       " \n",
       "          [[-1.1621e-03,  2.4127e-03,  5.7933e-03],\n",
       "           [-2.1721e-03, -7.2049e-04,  1.6963e-03],\n",
       "           [-5.9237e-03, -4.4604e-03, -3.8483e-03]],\n",
       " \n",
       "          [[ 1.9700e-03,  4.3975e-03,  4.2839e-03],\n",
       "           [ 3.5023e-03,  5.2855e-03,  6.0703e-03],\n",
       "           [ 5.9597e-03,  7.3261e-03,  8.4118e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.4643e-03, -2.8993e-03, -3.5025e-03],\n",
       "           [-1.2233e-03,  1.9946e-04,  6.4261e-03],\n",
       "           [ 8.7179e-04,  1.6797e-03,  1.0265e-02]],\n",
       " \n",
       "          [[ 1.4581e-03,  1.0123e-03,  3.8785e-04],\n",
       "           [ 2.4447e-03,  3.1031e-03,  4.4312e-03],\n",
       "           [ 4.1535e-03,  5.5489e-03,  4.8246e-03]],\n",
       " \n",
       "          [[ 6.4126e-04, -3.9622e-05,  1.3498e-03],\n",
       "           [-4.6531e-03,  1.3612e-03, -8.8678e-04],\n",
       "           [-8.7683e-03, -3.3554e-03, -7.4451e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0237e-03,  3.3631e-03,  3.6602e-04],\n",
       "           [-2.3637e-03,  1.0927e-03,  1.7803e-03],\n",
       "           [-2.7856e-03, -1.0822e-03, -8.1450e-04]],\n",
       " \n",
       "          [[-1.4756e-03, -2.3105e-03, -1.9275e-04],\n",
       "           [ 5.0105e-07, -1.0276e-03, -2.1561e-03],\n",
       "           [ 2.1364e-03,  2.8472e-03,  1.6264e-03]],\n",
       " \n",
       "          [[-9.5171e-04, -1.2036e-03, -1.0611e-03],\n",
       "           [ 3.8115e-04,  5.9136e-04,  1.4889e-04],\n",
       "           [ 2.9628e-04,  1.6490e-03,  1.2008e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8188e-05,  5.2266e-03,  6.2848e-03],\n",
       "           [-6.2217e-04,  2.9119e-03,  4.9431e-03],\n",
       "           [ 4.9753e-03,  2.8818e-03,  6.3979e-03]],\n",
       " \n",
       "          [[-2.4784e-03, -9.8208e-04, -7.0310e-04],\n",
       "           [-3.2900e-03, -4.5560e-03, -3.7802e-03],\n",
       "           [ 3.1355e-03,  9.2456e-04, -2.2160e-03]],\n",
       " \n",
       "          [[ 2.1681e-03,  2.2919e-03,  8.1043e-04],\n",
       "           [ 4.9940e-03,  6.0274e-03, -7.9509e-04],\n",
       "           [ 3.4490e-03,  6.2072e-03,  3.6299e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.9193e-03,  3.7278e-03,  4.4395e-03],\n",
       "           [ 1.7038e-03,  2.3888e-03,  3.9227e-03],\n",
       "           [ 2.7619e-03,  3.0468e-03,  4.7566e-03]],\n",
       " \n",
       "          [[-7.3673e-03, -9.2118e-03, -7.7539e-03],\n",
       "           [-5.7497e-03, -5.7562e-03, -2.7590e-03],\n",
       "           [-2.3307e-03,  1.1184e-04,  2.1159e-03]],\n",
       " \n",
       "          [[ 1.3650e-03,  3.3322e-03,  1.5204e-03],\n",
       "           [ 2.0019e-03,  4.4938e-03,  2.2653e-03],\n",
       "           [ 1.5398e-03,  2.0443e-03,  1.4217e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0564e-04, -9.3416e-04,  5.2884e-04],\n",
       "           [-1.6868e-03, -2.4106e-04,  2.5715e-04],\n",
       "           [-6.6623e-04,  2.3624e-03,  1.1503e-03]],\n",
       " \n",
       "          [[ 2.5028e-03, -7.0855e-04, -3.3105e-03],\n",
       "           [-1.2545e-04, -7.0709e-04, -2.7345e-03],\n",
       "           [ 4.4332e-04,  3.0481e-04,  7.4930e-04]],\n",
       " \n",
       "          [[ 1.6831e-03,  2.6950e-04, -1.8566e-03],\n",
       "           [-9.6814e-04, -4.7298e-03, -7.0419e-03],\n",
       "           [-6.6508e-05, -5.6737e-03, -9.4894e-03]]]], device='mps:0'),\n",
       " 'model.7.1.weight': tensor([-0.0023,  0.0052, -0.0105, -0.0076,  0.0005,  0.0007,  0.0014,  0.0156,\n",
       "         -0.0011, -0.0018, -0.0075,  0.0111,  0.0066, -0.0191, -0.0065, -0.0004,\n",
       "         -0.0105, -0.0004, -0.0081,  0.0033, -0.0051,  0.0122, -0.0012, -0.0040,\n",
       "          0.0082, -0.0155, -0.0016, -0.0026,  0.0078, -0.0073,  0.0246,  0.0103,\n",
       "          0.0014,  0.0064,  0.0065,  0.0007, -0.0031,  0.0107, -0.0086,  0.0054,\n",
       "         -0.0066, -0.0009,  0.0001,  0.0073, -0.0073, -0.0033, -0.0041,  0.0177,\n",
       "          0.0029,  0.0078,  0.0072,  0.0011, -0.0059,  0.0044,  0.0039,  0.0040,\n",
       "          0.0070, -0.0053,  0.0081,  0.0103,  0.0059,  0.0012, -0.0002, -0.0017,\n",
       "         -0.0029, -0.0069,  0.0021, -0.0052, -0.0017,  0.0165, -0.0078,  0.0134,\n",
       "         -0.0129,  0.0100, -0.0060,  0.0073,  0.0089, -0.0069, -0.0088,  0.0032,\n",
       "         -0.0160, -0.0097, -0.0019, -0.0019,  0.0118,  0.0063,  0.0009,  0.0135,\n",
       "          0.0012,  0.0003, -0.0029,  0.0075, -0.0006,  0.0149,  0.0032, -0.0129,\n",
       "          0.0071,  0.0011,  0.0167,  0.0046,  0.0102, -0.0026,  0.0023,  0.0089,\n",
       "         -0.0088, -0.0015, -0.0075, -0.0118, -0.0030,  0.0042, -0.0056, -0.0230,\n",
       "          0.0130, -0.0078,  0.0139, -0.0024, -0.0051,  0.0165, -0.0060, -0.0035,\n",
       "          0.0267, -0.0061, -0.0036, -0.0131, -0.0061,  0.0027,  0.0177,  0.0031,\n",
       "         -0.0024, -0.0048,  0.0035,  0.0074, -0.0179, -0.0062, -0.0112,  0.0091,\n",
       "          0.0055,  0.0153,  0.0180,  0.0100,  0.0007, -0.0116, -0.0134, -0.0349,\n",
       "          0.0015, -0.0056,  0.0063, -0.0102,  0.0014,  0.0022,  0.0142, -0.0043,\n",
       "         -0.0056, -0.0191, -0.0073,  0.0030, -0.0071, -0.0185,  0.0043, -0.0035,\n",
       "         -0.0034,  0.0093,  0.0112,  0.0096, -0.0111, -0.0066,  0.0061,  0.0008,\n",
       "         -0.0026,  0.0010,  0.0052, -0.0074,  0.0149, -0.0021,  0.0208, -0.0076,\n",
       "         -0.0113, -0.0175,  0.0067,  0.0154,  0.0067, -0.0011, -0.0160, -0.0115,\n",
       "         -0.0039, -0.0063,  0.0193, -0.0057,  0.0023,  0.0118,  0.0085, -0.0112,\n",
       "          0.0030,  0.0064,  0.0085, -0.0074,  0.0008, -0.0052,  0.0023, -0.0142,\n",
       "          0.0021, -0.0229, -0.0173, -0.0023,  0.0158,  0.0070, -0.0020,  0.0082,\n",
       "         -0.0117, -0.0043, -0.0039,  0.0141, -0.0224, -0.0073, -0.0118,  0.0092,\n",
       "          0.0050, -0.0032, -0.0080,  0.0094,  0.0015, -0.0118, -0.0046,  0.0107,\n",
       "          0.0205,  0.0032, -0.0069, -0.0006, -0.0004, -0.0007,  0.0104, -0.0043,\n",
       "          0.0006,  0.0036, -0.0170,  0.0037, -0.0009, -0.0135, -0.0060,  0.0107,\n",
       "          0.0040, -0.0027, -0.0087, -0.0065,  0.0115, -0.0188, -0.0266,  0.0044,\n",
       "          0.0011,  0.0198, -0.0008,  0.0011, -0.0016, -0.0046, -0.0118,  0.0131],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.bias': tensor([-4.5565e-03,  4.7289e-03, -3.6447e-03,  2.0715e-04, -5.0656e-03,\n",
       "         -3.1018e-03,  6.0310e-04,  7.9931e-03, -2.4715e-03, -3.0658e-03,\n",
       "         -3.2584e-03,  5.9539e-03, -1.3502e-03, -1.8057e-02, -6.3726e-03,\n",
       "          6.8097e-04, -2.0397e-04,  1.2742e-03, -8.7223e-03,  3.7523e-04,\n",
       "         -8.3646e-03,  8.7659e-03,  6.7918e-03, -6.3662e-03,  6.1445e-03,\n",
       "         -1.3393e-02,  2.5458e-03, -5.1503e-03, -1.0376e-03, -1.0977e-02,\n",
       "         -1.3685e-03,  6.8332e-03,  3.5739e-04, -3.8469e-03,  2.5738e-03,\n",
       "         -3.1061e-03, -4.0488e-03,  7.1965e-03, -5.3161e-04,  8.6524e-03,\n",
       "         -1.0123e-03, -5.2310e-03, -1.8362e-03,  6.0408e-03, -6.8454e-03,\n",
       "         -7.0953e-03, -3.0891e-03,  9.9596e-04, -5.5119e-04,  5.5030e-03,\n",
       "          1.1418e-02,  2.3152e-03, -1.3828e-02,  4.0906e-03,  1.2442e-03,\n",
       "          3.7924e-03,  7.4065e-03, -5.7501e-03,  7.9478e-03, -1.0778e-03,\n",
       "         -2.6481e-03, -4.1661e-03, -3.2738e-03, -6.4284e-03,  2.0916e-03,\n",
       "         -1.6258e-02,  5.0572e-03, -9.1019e-03, -4.8046e-03,  8.0586e-03,\n",
       "          1.5994e-03,  1.9920e-03,  8.1807e-06,  4.0066e-03, -6.0474e-03,\n",
       "          2.6236e-03,  1.0083e-02, -1.0068e-02, -5.1233e-03, -6.6950e-03,\n",
       "         -3.8418e-03, -9.6992e-03, -4.1421e-03, -1.0314e-03,  1.0838e-02,\n",
       "         -6.4204e-03, -2.8218e-04,  6.5524e-03, -6.0133e-03,  9.5695e-04,\n",
       "         -7.1173e-03, -1.6291e-03, -4.2416e-03, -3.9190e-03,  2.8521e-03,\n",
       "         -6.8512e-03,  4.6960e-03, -4.1883e-03,  1.3551e-02,  1.1760e-04,\n",
       "          8.0980e-03, -8.7813e-05,  5.4335e-04,  4.7504e-03, -3.8087e-03,\n",
       "         -3.6404e-04, -7.4137e-03, -1.0998e-02, -3.7262e-03,  4.4520e-03,\n",
       "         -2.7591e-03, -1.5311e-02,  8.6341e-03,  2.5073e-04, -1.2658e-03,\n",
       "          1.7631e-03, -1.0163e-02,  1.0807e-02,  1.4880e-04, -5.4533e-03,\n",
       "          5.5416e-03, -3.2033e-03, -6.0060e-03, -8.1240e-03, -3.3737e-03,\n",
       "          3.4252e-04,  3.2949e-03, -5.8619e-03,  8.0231e-04, -1.3618e-02,\n",
       "          3.9566e-03,  9.5317e-03, -1.7240e-02, -9.6886e-03, -7.5062e-03,\n",
       "          1.1710e-02,  2.7347e-03,  1.8008e-03,  8.3226e-03,  1.7554e-03,\n",
       "          2.2309e-03, -1.0771e-03, -1.1368e-02, -3.1175e-02,  2.2874e-03,\n",
       "         -5.6357e-03, -6.4757e-03, -6.3653e-03, -5.1141e-04, -2.2259e-03,\n",
       "          1.9779e-03, -9.7266e-03,  1.2562e-03, -2.3044e-02,  6.0949e-04,\n",
       "         -2.3656e-03, -1.1436e-02, -1.1132e-02, -4.5262e-03, -1.4372e-03,\n",
       "         -2.6797e-03,  2.5620e-03,  7.8155e-03, -1.5132e-03, -4.6074e-03,\n",
       "         -5.0445e-03,  1.9106e-03,  2.6067e-03,  1.8874e-03, -7.2910e-03,\n",
       "          7.2243e-03, -6.3456e-03,  1.3670e-02,  6.4695e-03,  1.4289e-02,\n",
       "         -5.9657e-03, -1.3399e-02, -1.5856e-02,  1.5663e-03,  5.9080e-03,\n",
       "          1.5552e-03,  6.2490e-03, -1.9931e-02, -7.8980e-03, -7.2941e-03,\n",
       "         -1.0491e-02,  3.4988e-03, -1.4228e-02, -4.0471e-03,  4.6208e-03,\n",
       "         -2.9241e-03, -6.4159e-03,  5.3625e-03,  7.2872e-03,  6.4268e-03,\n",
       "         -1.0137e-02,  2.4958e-03, -1.4912e-02, -6.4938e-04, -5.9331e-03,\n",
       "          8.7079e-03, -1.1128e-02, -3.2630e-03, -8.7999e-04,  8.1410e-03,\n",
       "          1.5807e-03,  3.8120e-03,  1.1610e-03, -8.8160e-03, -6.0358e-03,\n",
       "         -3.0124e-03, -1.2868e-03, -1.0864e-02, -9.4283e-03, -2.1874e-02,\n",
       "          1.2089e-02,  3.3202e-03, -1.4795e-02, -6.8872e-03,  6.2302e-03,\n",
       "         -1.4962e-04, -7.5111e-03, -3.2837e-03,  1.0223e-02,  2.9658e-03,\n",
       "          1.0076e-02, -2.0868e-03, -3.8309e-03, -6.5590e-03, -4.5099e-03,\n",
       "          1.0844e-03, -5.2356e-03,  4.1233e-03, -7.6887e-03, -7.0789e-03,\n",
       "         -4.7408e-04, -4.3668e-03, -1.6331e-02, -1.5983e-02,  9.7346e-04,\n",
       "         -8.0358e-03, -5.2041e-03, -2.5228e-03, -8.4471e-03,  8.9741e-03,\n",
       "         -7.6938e-03, -2.4961e-02, -4.0291e-03, -4.5770e-03, -1.3439e-03,\n",
       "         -7.5173e-04, -1.7836e-03, -4.0254e-03, -8.8186e-03, -1.4457e-02,\n",
       "         -7.4933e-04], device='mps:0'),\n",
       " 'model.7.1.running_mean': tensor([ 0.0354,  0.0395, -0.0824,  0.0932, -0.0943,  0.0874,  0.0045,  0.1031,\n",
       "         -0.0546, -0.0184, -0.0391,  0.0558,  0.1633, -0.0530, -0.0942,  0.0417,\n",
       "         -0.1443, -0.1178,  0.0487,  0.0899,  0.1369,  0.0834, -0.0100,  0.1302,\n",
       "          0.0701, -0.1322, -0.0062, -0.0043,  0.1277, -0.0908,  0.0591,  0.0686,\n",
       "          0.0570,  0.0093,  0.0419,  0.0812,  0.0288,  0.0950,  0.0284,  0.0159,\n",
       "         -0.1173,  0.0849, -0.0473,  0.0209, -0.0510,  0.0779, -0.1104, -0.0306,\n",
       "         -0.0125, -0.0717,  0.0167, -0.0087, -0.1108,  0.0057, -0.0637,  0.0876,\n",
       "          0.0982,  0.0107,  0.0776,  0.0878,  0.1244,  0.1762, -0.0343,  0.0375,\n",
       "          0.1013, -0.0396,  0.0481, -0.0271, -0.0061,  0.0054, -0.0080, -0.0282,\n",
       "          0.0787,  0.0381, -0.0911,  0.0018,  0.0710, -0.0887,  0.0534,  0.0335,\n",
       "         -0.1339, -0.1165,  0.0406,  0.0213,  0.0383,  0.0175,  0.0425,  0.0882,\n",
       "          0.0401, -0.0224,  0.1740,  0.0145,  0.1256, -0.0331,  0.0290, -0.0999,\n",
       "          0.1042, -0.0474,  0.0179,  0.0256,  0.1560,  0.0216, -0.0105,  0.0328,\n",
       "          0.0687,  0.1175,  0.0073, -0.0982, -0.0251,  0.0524, -0.1268,  0.0852,\n",
       "          0.0358, -0.0695,  0.0574, -0.0341, -0.0357,  0.0283, -0.0657, -0.0869,\n",
       "          0.0733, -0.0129, -0.0509, -0.0142, -0.0534,  0.0024,  0.0686,  0.0453,\n",
       "          0.0056,  0.0128,  0.1047, -0.0399, -0.0564,  0.0037, -0.1528, -0.1488,\n",
       "          0.0763, -0.0279,  0.0898,  0.1764,  0.0214, -0.0909, -0.0783, -0.0699,\n",
       "         -0.0929, -0.0293,  0.2117,  0.1192,  0.1214,  0.1962, -0.0520, -0.0874,\n",
       "         -0.0551, -0.0816,  0.0962,  0.0754, -0.0766, -0.0969,  0.0819,  0.0564,\n",
       "         -0.1126,  0.0852,  0.0570,  0.0080, -0.0920,  0.0143,  0.1251,  0.0736,\n",
       "         -0.0376,  0.0394, -0.0744,  0.1261,  0.0064, -0.0466,  0.0613, -0.0366,\n",
       "          0.0878, -0.0559,  0.0577, -0.0715, -0.0132,  0.0613,  0.0549,  0.1219,\n",
       "         -0.0361,  0.0222,  0.2053,  0.0725, -0.0039,  0.0304,  0.0625, -0.1129,\n",
       "         -0.0797,  0.0024,  0.0852, -0.0888,  0.1461,  0.0234,  0.0318,  0.0339,\n",
       "          0.0557,  0.0309, -0.0328,  0.1334,  0.0899,  0.0703,  0.0377, -0.0020,\n",
       "          0.0304,  0.0030,  0.0617,  0.0508, -0.0262, -0.0754,  0.1739, -0.0351,\n",
       "         -0.0077,  0.0078,  0.0654,  0.1204,  0.1324, -0.0252, -0.0519,  0.0089,\n",
       "         -0.0527,  0.0873, -0.0927,  0.0995,  0.0190, -0.0965,  0.1836, -0.1142,\n",
       "          0.0587,  0.0967, -0.0476,  0.0280,  0.1096,  0.1197, -0.0776,  0.1576,\n",
       "         -0.0176,  0.0076,  0.0024,  0.0533,  0.0635, -0.1028, -0.1091,  0.1363,\n",
       "          0.1192,  0.0054,  0.0499,  0.0334,  0.1286, -0.1429, -0.0185,  0.0938],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.running_var': tensor([ 6.9679e-02,  1.8804e-03,  8.1287e-02,  9.1219e-04, -8.7469e-03,\n",
       "         -3.0077e-02, -2.4744e-02,  2.2271e-03,  7.1813e-02,  7.4637e-02,\n",
       "          1.5299e-01,  1.0981e-01, -4.4526e-02, -3.0663e-02,  1.1247e-01,\n",
       "          5.9056e-02,  3.0621e-02, -8.6014e-03,  7.6832e-02,  5.9607e-02,\n",
       "          5.5855e-02,  5.2065e-02,  6.3415e-02,  6.4637e-03, -9.8621e-03,\n",
       "          4.8471e-02,  7.4555e-02,  1.1981e-01,  4.1129e-02,  3.0962e-02,\n",
       "          1.7243e-01,  4.9841e-02, -2.6636e-02,  4.7323e-02,  6.1849e-02,\n",
       "         -3.4259e-02,  7.8832e-02,  1.4018e-01,  1.3308e-01,  2.0947e-02,\n",
       "          7.1194e-03, -1.1263e-02,  4.6119e-02, -4.8663e-02,  3.1726e-02,\n",
       "          4.6435e-02,  6.8187e-02,  1.3966e-01,  3.6591e-02,  4.8578e-02,\n",
       "         -3.6682e-03,  7.4817e-02,  1.1394e-01,  8.9680e-03,  7.4471e-02,\n",
       "          6.2386e-02, -3.7449e-02,  3.5168e-02,  1.4092e-01,  1.6924e-02,\n",
       "          6.4598e-02,  7.6232e-02,  1.0271e-02, -8.4220e-03,  5.8437e-02,\n",
       "          7.0997e-02,  1.1700e-02,  5.1161e-02,  1.7607e-02,  8.5831e-02,\n",
       "          1.3278e-01,  6.9547e-02,  8.3653e-02,  2.3560e-02,  3.6889e-02,\n",
       "          2.6925e-03,  1.0528e-02,  6.2937e-02, -1.6055e-02, -4.7661e-03,\n",
       "          3.3525e-02,  5.7503e-02,  1.3304e-01,  9.1781e-02,  9.1315e-02,\n",
       "          4.4895e-02,  3.3722e-02,  5.0625e-02,  3.3136e-02,  6.3097e-02,\n",
       "          1.2166e-01,  2.9471e-02,  1.0233e-01,  9.0502e-02,  8.2697e-02,\n",
       "         -1.3157e-02,  3.2477e-02,  4.3450e-02,  3.4996e-02,  9.7184e-03,\n",
       "          2.3829e-03,  1.8125e-02, -2.1299e-02, -2.5373e-02,  1.1014e-02,\n",
       "          2.5512e-01,  1.4337e-01,  6.6719e-02,  6.7655e-02,  4.0246e-02,\n",
       "          5.0195e-02,  1.7582e-01,  7.7681e-02, -2.9949e-02,  2.8936e-02,\n",
       "          3.0862e-02,  8.7791e-02,  4.3081e-02, -5.8252e-03,  6.0953e-02,\n",
       "          1.1809e-01,  8.4821e-02,  1.5468e-02,  6.5310e-02,  1.7886e-02,\n",
       "         -1.7538e-02,  8.6004e-02,  2.5028e-02, -1.7064e-02,  1.7202e-04,\n",
       "          1.1705e-01,  1.7753e-03,  1.9464e-03,  2.8358e-02,  5.8363e-02,\n",
       "          5.6578e-02, -1.4057e-02,  3.9833e-02,  1.2633e-01,  9.6825e-02,\n",
       "          8.8968e-02,  1.7573e-01,  2.1674e-02,  1.5386e-01,  1.0206e-02,\n",
       "         -1.2032e-02,  5.7442e-02,  1.8822e-01,  1.0513e-01,  4.3114e-02,\n",
       "         -3.0255e-02, -3.4614e-02,  3.2559e-02,  1.2674e-01,  1.0344e-01,\n",
       "         -1.5105e-02,  1.0751e-01,  5.8931e-02,  1.4985e-02,  4.6113e-02,\n",
       "          1.1136e-01,  4.6662e-02,  7.4924e-02, -2.3192e-02, -3.5102e-03,\n",
       "          1.3062e-01, -2.0452e-02, -3.4316e-03,  8.2640e-02,  2.2205e-01,\n",
       "          4.3334e-02, -3.7827e-03,  1.4568e-01,  7.0052e-03,  4.3619e-02,\n",
       "          1.0654e-02,  5.3169e-02,  1.0177e-01,  4.8500e-02,  1.3695e-01,\n",
       "          3.9601e-02,  3.4895e-02,  2.2457e-02,  4.4832e-02,  3.8743e-02,\n",
       "          8.4398e-02,  5.7232e-04, -1.1322e-02, -1.5766e-02, -1.1055e-02,\n",
       "         -3.3162e-02,  7.5921e-02,  1.3255e-01,  1.4679e-01,  6.6896e-02,\n",
       "          2.3296e-02,  1.5025e-01,  3.6828e-02,  5.4549e-02,  5.0382e-02,\n",
       "          7.5294e-02,  4.7960e-02,  7.4526e-02, -4.7406e-02,  1.1297e-02,\n",
       "         -3.2072e-02,  7.4780e-02,  8.8335e-02, -4.4751e-02,  9.8052e-02,\n",
       "          2.9194e-02,  7.0517e-02,  1.2775e-01,  1.4779e-01,  9.2201e-02,\n",
       "          9.3487e-02, -1.8389e-02,  8.4669e-02,  5.0331e-02,  7.6869e-03,\n",
       "         -3.6781e-02,  4.4068e-02,  3.8490e-02,  6.6633e-02,  3.0181e-03,\n",
       "          1.3051e-01,  1.8888e-01,  9.4604e-02,  3.7280e-03,  8.9169e-02,\n",
       "          3.8487e-02,  3.5241e-02, -3.7157e-02,  9.0762e-03,  5.0697e-02,\n",
       "          1.0937e-03,  5.4233e-02,  4.0716e-02, -4.6120e-02,  8.7126e-02,\n",
       "         -2.2258e-02,  6.1884e-02,  4.6615e-02,  3.0538e-02,  2.2038e-02,\n",
       "          1.5614e-01,  1.6655e-01, -1.5412e-02,  4.3932e-02,  1.0146e-01,\n",
       "          4.2755e-02,  2.1295e-02,  6.3833e-02,  4.1134e-02,  1.4524e-02,\n",
       "          8.2085e-03], device='mps:0'),\n",
       " 'model.7.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'model.8.0.weight': tensor([[[[ 1.0740e-03,  1.6858e-03,  1.4910e-03],\n",
       "           [ 5.0294e-04,  6.6265e-04,  2.9766e-04],\n",
       "           [ 1.1491e-03,  1.3240e-03,  7.1226e-04]],\n",
       " \n",
       "          [[ 1.8466e-03,  1.5779e-03,  1.8594e-03],\n",
       "           [ 6.3967e-04,  4.5447e-05,  1.7523e-04],\n",
       "           [-6.8116e-04, -1.3399e-03, -6.3176e-04]],\n",
       " \n",
       "          [[ 2.8072e-03,  2.8124e-03,  2.4662e-03],\n",
       "           [ 1.8736e-03,  1.0619e-03,  8.1767e-04],\n",
       "           [ 5.1177e-04,  3.1295e-04,  2.1499e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.5308e-03, -1.6524e-03, -1.9575e-03],\n",
       "           [-1.5929e-03, -2.4144e-03, -2.9436e-03],\n",
       "           [ 1.0405e-03,  2.3044e-04, -8.1054e-04]],\n",
       " \n",
       "          [[ 1.7641e-03,  1.5366e-03,  8.3419e-04],\n",
       "           [ 1.1004e-03,  6.6200e-04,  2.2354e-04],\n",
       "           [ 8.8269e-04,  2.3944e-04, -5.7464e-04]],\n",
       " \n",
       "          [[ 8.0814e-04,  4.5913e-04,  7.3533e-05],\n",
       "           [ 1.5271e-03,  1.5949e-03,  1.1902e-03],\n",
       "           [ 2.8126e-03,  2.9130e-03,  2.1995e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 5.8928e-04,  4.8015e-04, -1.6781e-04],\n",
       "           [ 1.1629e-04,  2.6199e-04, -2.5813e-04],\n",
       "           [-1.7059e-03, -1.3768e-03, -1.2667e-03]],\n",
       " \n",
       "          [[ 8.4055e-05,  5.9532e-04, -1.0288e-03],\n",
       "           [-1.4511e-04,  8.3495e-04, -4.8429e-04],\n",
       "           [-8.2982e-04, -1.7627e-04, -7.3789e-04]],\n",
       " \n",
       "          [[-2.5967e-03, -1.8049e-03, -1.4581e-03],\n",
       "           [-9.1513e-04, -6.3578e-05,  3.0416e-04],\n",
       "           [-4.3979e-04, -4.8312e-04,  2.1514e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.8921e-04, -1.3678e-03, -2.4479e-03],\n",
       "           [-7.5156e-04, -2.1713e-03, -4.3266e-03],\n",
       "           [-1.1464e-03, -2.8330e-03, -5.2886e-03]],\n",
       " \n",
       "          [[-1.5629e-03, -6.2977e-04, -1.7747e-03],\n",
       "           [-7.0471e-04, -8.1779e-06, -1.4088e-03],\n",
       "           [-8.0628e-04, -2.8300e-04, -1.1736e-03]],\n",
       " \n",
       "          [[-1.3232e-03, -1.1060e-03, -1.0230e-03],\n",
       "           [-7.9600e-04, -5.3122e-04, -6.2549e-04],\n",
       "           [-6.7995e-04, -5.1007e-04, -4.6249e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.8751e-03, -1.7473e-03, -5.0876e-04],\n",
       "           [ 9.9098e-04,  1.0576e-03,  1.6449e-03],\n",
       "           [ 2.3856e-03,  1.6450e-03,  1.1930e-03]],\n",
       " \n",
       "          [[ 1.8742e-03,  4.1429e-04,  5.0437e-04],\n",
       "           [ 2.1272e-03,  1.1366e-03,  1.0783e-03],\n",
       "           [ 4.3610e-03,  2.5250e-03,  1.6300e-03]],\n",
       " \n",
       "          [[ 6.7172e-04,  9.2898e-04, -7.6273e-05],\n",
       "           [ 1.5695e-03,  5.1936e-04, -1.2724e-03],\n",
       "           [ 2.1023e-03,  1.4770e-03, -4.8208e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7299e-03,  6.8409e-04, -4.6816e-04],\n",
       "           [ 2.5781e-03,  1.6854e-03, -5.6364e-05],\n",
       "           [ 3.3384e-03,  2.2927e-03,  5.0925e-04]],\n",
       " \n",
       "          [[ 1.4354e-03,  1.7080e-03,  2.3786e-03],\n",
       "           [-6.2257e-04, -6.1539e-04,  6.1545e-05],\n",
       "           [ 1.5217e-03,  4.1332e-04,  2.5486e-04]],\n",
       " \n",
       "          [[ 6.6634e-04, -1.3553e-04, -2.7100e-04],\n",
       "           [-5.7749e-04, -3.6241e-04,  1.7777e-04],\n",
       "           [-2.6590e-03, -2.0132e-03, -7.6975e-04]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 6.9207e-04,  1.3844e-03,  1.6512e-03],\n",
       "           [-3.6369e-04, -3.8760e-04, -1.8046e-04],\n",
       "           [ 6.0085e-04,  3.7323e-04,  5.8043e-04]],\n",
       " \n",
       "          [[-5.6764e-04, -1.7006e-03, -7.8897e-04],\n",
       "           [ 2.6392e-05, -1.0761e-03, -7.0848e-04],\n",
       "           [ 1.4524e-03,  5.9987e-04,  6.5863e-04]],\n",
       " \n",
       "          [[ 6.2452e-05,  3.0468e-04, -1.2966e-04],\n",
       "           [ 7.1246e-04,  9.7631e-04,  8.4396e-04],\n",
       "           [ 7.5110e-04,  1.0440e-03,  2.6135e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3627e-03, -3.7913e-03, -3.7461e-03],\n",
       "           [-2.0672e-03, -3.4771e-03, -2.6902e-03],\n",
       "           [-9.7428e-04, -1.9125e-03, -7.2911e-04]],\n",
       " \n",
       "          [[ 1.8678e-03,  1.4885e-03,  1.9562e-03],\n",
       "           [ 1.7413e-03,  1.1754e-03,  1.6167e-03],\n",
       "           [ 2.5944e-03,  2.1911e-03,  1.6582e-03]],\n",
       " \n",
       "          [[-7.5730e-05, -2.5194e-05,  3.8111e-04],\n",
       "           [ 1.0511e-04,  3.3979e-04,  6.7720e-04],\n",
       "           [ 4.5638e-04,  8.2275e-04,  1.3615e-03]]],\n",
       " \n",
       " \n",
       "         [[[-6.9047e-04, -7.1952e-04, -3.2166e-04],\n",
       "           [ 1.9615e-04,  6.5921e-04,  8.6715e-04],\n",
       "           [ 1.4030e-03,  1.4063e-03,  1.2401e-03]],\n",
       " \n",
       "          [[-7.1654e-04, -7.8938e-04,  6.0007e-04],\n",
       "           [-1.2828e-04, -1.0060e-04,  8.3679e-04],\n",
       "           [-3.9494e-04, -1.7759e-04,  1.1670e-04]],\n",
       " \n",
       "          [[ 3.0613e-04,  8.4658e-04,  1.1004e-03],\n",
       "           [ 2.3674e-03,  2.5060e-03,  2.0883e-03],\n",
       "           [ 2.3742e-03,  3.4570e-03,  2.8427e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.8385e-04, -1.2079e-03, -1.2604e-03],\n",
       "           [ 1.1429e-05,  2.9085e-04,  3.2148e-04],\n",
       "           [-6.2072e-04,  1.1726e-04,  4.3239e-04]],\n",
       " \n",
       "          [[ 6.9818e-04, -5.8202e-05, -2.4990e-05],\n",
       "           [ 2.0687e-04, -2.8985e-05,  3.6061e-05],\n",
       "           [ 5.1825e-04,  7.4383e-04,  4.2630e-04]],\n",
       " \n",
       "          [[ 3.6542e-04, -1.1407e-04, -4.3032e-04],\n",
       "           [-2.6138e-04, -6.2434e-04, -1.0195e-03],\n",
       "           [-2.6136e-04, -8.0968e-04, -1.2565e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.0453e-04, -3.5994e-04, -9.5835e-04],\n",
       "           [-2.0753e-03, -2.1046e-03, -2.1842e-03],\n",
       "           [-1.5014e-04, -5.8247e-04, -9.3550e-04]],\n",
       " \n",
       "          [[ 1.8967e-04,  1.6918e-04, -4.5165e-04],\n",
       "           [-6.5346e-04, -6.5700e-04, -7.8118e-04],\n",
       "           [-1.1144e-03, -1.1100e-03, -5.8004e-04]],\n",
       " \n",
       "          [[ 2.7039e-04,  3.1316e-04,  1.8469e-04],\n",
       "           [-4.8291e-04, -3.2484e-04, -9.3454e-05],\n",
       "           [-5.3997e-04, -2.3873e-04, -2.2707e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.9677e-05,  1.1066e-04,  2.1105e-04],\n",
       "           [-4.2585e-04, -7.3775e-04, -6.4492e-04],\n",
       "           [ 2.6788e-04, -7.2606e-04, -4.6665e-04]],\n",
       " \n",
       "          [[ 6.1540e-04,  5.9804e-04,  3.7607e-04],\n",
       "           [-9.2825e-04, -6.9669e-04, -6.4305e-04],\n",
       "           [-6.3884e-04, -1.0624e-04, -5.8294e-04]],\n",
       " \n",
       "          [[ 1.3975e-03,  1.0989e-03,  6.7647e-04],\n",
       "           [ 1.8117e-04,  8.1220e-05,  3.2222e-04],\n",
       "           [ 1.1803e-05,  1.1838e-04,  1.1939e-04]]]], device='mps:0'),\n",
       " 'model.8.1.weight': tensor([-0.0092, -0.0051, -0.0070, -0.0181, -0.0073, -0.0134,  0.0101, -0.0220,\n",
       "         -0.0172, -0.0073, -0.0058, -0.0025, -0.0104, -0.0147, -0.0037, -0.0099,\n",
       "         -0.0225, -0.0155, -0.0068, -0.0027, -0.0005, -0.0188, -0.0086, -0.0009,\n",
       "          0.0037,  0.0044, -0.0040, -0.0041, -0.0022,  0.0017, -0.0140, -0.0106,\n",
       "         -0.0251, -0.0084, -0.0303, -0.0328, -0.0106, -0.0007, -0.0099, -0.0151,\n",
       "         -0.0014, -0.0151, -0.0195, -0.0012,  0.0051, -0.0132, -0.0103, -0.0123,\n",
       "          0.0003, -0.0078, -0.0076, -0.0351, -0.0159, -0.0103, -0.0353, -0.0036,\n",
       "         -0.0074, -0.0120, -0.0042, -0.0197, -0.0314, -0.0403,  0.0004, -0.0077,\n",
       "         -0.0114, -0.0387, -0.0133, -0.0033, -0.0004, -0.0098, -0.0074, -0.0147,\n",
       "          0.0037, -0.0026,  0.0018, -0.0044, -0.0198, -0.0218, -0.0237, -0.0022,\n",
       "         -0.0020, -0.0122,  0.0090, -0.0018, -0.0037,  0.0024, -0.0048, -0.0005,\n",
       "         -0.0038, -0.0039, -0.0004, -0.0246, -0.0121, -0.0113, -0.0137, -0.0171,\n",
       "          0.0008, -0.0070, -0.0126, -0.0066, -0.0010, -0.0110, -0.0123,  0.0027,\n",
       "         -0.0058, -0.0161, -0.0082, -0.0014, -0.0193, -0.0265, -0.0196, -0.0054,\n",
       "         -0.0252, -0.0058, -0.0109, -0.0159, -0.0054, -0.0059,  0.0029, -0.0285,\n",
       "         -0.0133, -0.0342,  0.0092, -0.0277, -0.0115, -0.0200, -0.0054,  0.0025,\n",
       "          0.0096, -0.0109, -0.0097, -0.0090,  0.0060, -0.0026, -0.0221,  0.0008,\n",
       "         -0.0062, -0.0093, -0.0096, -0.0143, -0.0026,  0.0020, -0.0160, -0.0048,\n",
       "         -0.0061, -0.0151,  0.0055,  0.0036, -0.0198, -0.0049,  0.0091,  0.0038,\n",
       "         -0.0518, -0.0129, -0.0109, -0.0217, -0.0002, -0.0172, -0.0091, -0.0244,\n",
       "         -0.0005, -0.0035,  0.0095, -0.0081, -0.0322, -0.0120, -0.0186, -0.0081,\n",
       "         -0.0158, -0.0056, -0.0147, -0.0009, -0.0033, -0.0212, -0.0006, -0.0112,\n",
       "         -0.0002, -0.0040, -0.0128, -0.0029,  0.0064, -0.0249,  0.0149, -0.0002,\n",
       "         -0.0135, -0.0087, -0.0012, -0.0108, -0.0010, -0.0085, -0.0310, -0.0203,\n",
       "         -0.0250, -0.0159, -0.0069, -0.0268, -0.0032, -0.0027, -0.0116, -0.0036,\n",
       "         -0.0321, -0.0036, -0.0265, -0.0257, -0.0135, -0.0140, -0.0011, -0.0016,\n",
       "          0.0016, -0.0009, -0.0181,  0.0124, -0.0184, -0.0088, -0.0172, -0.0232,\n",
       "         -0.0023, -0.0316, -0.0469,  0.0018,  0.0024, -0.0021,  0.0002, -0.0066,\n",
       "         -0.0011, -0.0013, -0.0326, -0.0037, -0.0051, -0.0074, -0.0170,  0.0055,\n",
       "          0.0113,  0.0065, -0.0122, -0.0104,  0.0037, -0.0112, -0.0223, -0.0071,\n",
       "         -0.0100, -0.0058, -0.0376, -0.0169, -0.0516, -0.0177,  0.0086, -0.0126,\n",
       "         -0.0344, -0.0108,  0.0172, -0.0212, -0.0137,  0.0111,  0.0004, -0.0168],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.bias': tensor([-3.6895e-03, -5.6908e-03, -3.7153e-03, -4.9520e-03, -6.2257e-03,\n",
       "         -7.1844e-03,  7.1700e-03, -1.2713e-02, -1.3508e-02, -7.7962e-03,\n",
       "         -6.8431e-03, -2.6956e-03, -5.7505e-03, -8.9524e-03, -1.4069e-03,\n",
       "         -1.0099e-02, -1.2502e-02, -1.2454e-02, -8.4443e-03,  5.8082e-04,\n",
       "         -2.4657e-03, -1.1119e-02, -5.7276e-03, -3.6200e-03,  2.6721e-03,\n",
       "          3.0894e-03, -4.0139e-03, -3.0636e-03,  2.0701e-04,  1.6941e-03,\n",
       "         -1.4061e-02, -5.9117e-03, -1.8893e-02, -6.4950e-03, -2.1538e-02,\n",
       "         -2.0199e-02, -7.3891e-03, -6.1280e-04, -8.5773e-03, -1.2391e-02,\n",
       "         -1.9501e-03, -1.3669e-02, -2.3200e-02, -2.0710e-03,  6.6145e-03,\n",
       "         -8.7254e-03, -4.0935e-03, -9.8706e-03, -2.4519e-03, -8.9251e-03,\n",
       "         -4.5675e-03, -1.9976e-02, -1.2660e-02, -7.3099e-03, -2.9534e-02,\n",
       "         -3.0900e-03, -5.5124e-03, -6.8988e-03, -4.8643e-03, -1.4786e-02,\n",
       "         -2.0884e-02, -2.1494e-02, -3.5252e-03, -6.6519e-03, -6.7269e-03,\n",
       "         -3.1206e-02, -4.7044e-03, -7.9360e-03, -9.6866e-04, -9.2224e-03,\n",
       "         -6.9297e-03, -1.0228e-02,  1.4381e-03, -2.6647e-03, -1.9923e-03,\n",
       "         -3.7019e-03, -1.4146e-02, -1.1911e-02, -1.6186e-02, -2.5444e-03,\n",
       "         -1.7804e-04, -8.7999e-03,  7.4193e-03, -7.3627e-04,  8.7678e-05,\n",
       "          9.7245e-04, -6.0849e-03, -1.6516e-03, -2.9898e-03, -9.1425e-03,\n",
       "         -6.2822e-03, -1.3983e-02, -8.6046e-03, -6.3068e-03, -8.6698e-03,\n",
       "         -7.1728e-03,  3.8117e-04, -5.0375e-03, -1.7682e-02, -5.2779e-03,\n",
       "         -4.1417e-03, -7.5221e-03, -1.5570e-02,  1.0000e-03, -3.7514e-03,\n",
       "         -1.2025e-02, -2.9358e-03, -3.2806e-03, -1.7719e-02, -1.6060e-02,\n",
       "         -9.8853e-03, -3.7461e-03, -1.4341e-02, -4.6618e-03, -6.6973e-03,\n",
       "         -1.4417e-02, -4.8943e-03, -8.3233e-03,  4.3401e-03, -1.3725e-02,\n",
       "         -1.1194e-02, -2.0550e-02,  7.3744e-03, -1.8915e-02, -7.3262e-03,\n",
       "         -1.5327e-02, -4.3011e-03,  1.8086e-03,  2.6743e-03, -9.5802e-03,\n",
       "         -6.8349e-03, -8.4091e-03,  1.3785e-03,  1.3604e-03, -1.4078e-02,\n",
       "          1.3323e-03, -1.4511e-03, -9.8497e-03, -1.0267e-02, -9.8406e-03,\n",
       "         -3.4138e-03,  1.0101e-03, -1.0180e-02, -5.7570e-03, -7.2241e-03,\n",
       "         -6.1425e-03,  4.9399e-03, -1.0051e-03, -1.1580e-02, -4.2059e-03,\n",
       "          3.5122e-03,  3.2555e-03, -3.5542e-02, -9.7385e-03, -9.5773e-03,\n",
       "         -1.5675e-02, -1.3904e-03, -1.2772e-02, -6.8340e-03, -1.3214e-02,\n",
       "         -1.6366e-03, -4.9503e-03,  4.1249e-03, -4.8337e-03, -2.0885e-02,\n",
       "         -9.9270e-03, -1.0480e-02, -6.8137e-03, -1.6598e-02, -6.0768e-03,\n",
       "         -1.1983e-02, -2.6523e-03, -8.2765e-03, -1.0370e-02, -4.9677e-04,\n",
       "         -1.0225e-02, -3.8370e-03, -3.7636e-03, -1.1654e-02, -6.2794e-03,\n",
       "         -3.9201e-03, -1.6082e-02,  1.0026e-02, -6.5103e-04, -1.2685e-02,\n",
       "         -3.5874e-03,  2.7749e-04, -1.0828e-02, -2.0106e-03, -9.0509e-03,\n",
       "         -1.3965e-02, -1.2117e-02, -1.8486e-02, -9.2219e-03, -2.8093e-03,\n",
       "         -1.7091e-02, -6.1598e-03, -5.4437e-03, -6.9797e-03, -3.1442e-03,\n",
       "         -1.6675e-02, -2.5655e-03, -1.9915e-02, -1.5532e-02, -9.4615e-03,\n",
       "         -1.2357e-02, -4.5616e-03, -2.2272e-03, -2.5168e-03, -5.6157e-03,\n",
       "         -1.8717e-02,  8.0668e-03, -1.0333e-02, -7.0215e-03, -1.4615e-02,\n",
       "         -1.3957e-02, -2.2743e-03, -1.8005e-02, -3.5020e-02,  1.3311e-03,\n",
       "          1.6763e-03,  3.1629e-04, -4.3799e-03, -5.9512e-03, -1.7168e-03,\n",
       "         -4.7117e-04, -1.2035e-02, -1.6885e-03, -1.1097e-03, -8.6320e-03,\n",
       "         -1.2943e-02,  4.8208e-03,  5.1787e-03,  6.2421e-03, -1.1864e-02,\n",
       "         -7.1515e-03,  3.0125e-03, -6.0245e-03, -1.8354e-02, -4.4365e-03,\n",
       "         -8.2314e-03,  1.2086e-03, -2.6164e-02, -7.5684e-03, -2.9539e-02,\n",
       "         -7.5375e-03,  6.1095e-03, -8.3638e-03, -2.6865e-02, -1.2278e-02,\n",
       "          1.5709e-02, -2.2941e-02, -1.2776e-02,  9.2249e-03, -2.6318e-03,\n",
       "         -1.2965e-02], device='mps:0'),\n",
       " 'model.8.1.running_mean': tensor([ 7.6701e-02, -9.9057e-04, -1.0439e-01, -1.0405e-01, -1.5292e-02,\n",
       "          1.6566e-02, -1.6968e-02,  6.8607e-02, -5.6338e-02,  7.3334e-02,\n",
       "          1.3299e-01,  1.7797e-02,  3.3937e-02,  6.0625e-03, -7.2538e-02,\n",
       "         -1.0179e-01,  6.9920e-02, -1.2436e-01, -2.6889e-02, -1.9480e-01,\n",
       "          1.1848e-02,  4.9438e-02,  4.5552e-02,  6.1082e-02,  1.0779e-02,\n",
       "         -2.0955e-02,  8.3009e-02,  9.7089e-02, -5.0629e-02, -5.7997e-03,\n",
       "          5.9691e-03,  5.9561e-02,  7.5626e-04, -3.0608e-02,  5.0774e-03,\n",
       "          1.1817e-01, -6.4884e-03,  1.0030e-01,  7.4885e-02,  8.2999e-02,\n",
       "          5.8127e-02, -1.1321e-01,  1.0962e-01,  5.9943e-03, -6.4405e-03,\n",
       "          1.0523e-01, -5.7532e-02, -6.7834e-02,  3.1678e-02,  3.7399e-02,\n",
       "          4.5598e-02,  1.9541e-01, -4.9726e-02, -4.9794e-02,  2.0769e-02,\n",
       "          2.0011e-03,  1.8736e-02, -2.3771e-01,  7.7313e-02,  2.4288e-02,\n",
       "          1.0642e-01,  1.9782e-01,  2.4733e-02,  6.6080e-02, -9.2621e-02,\n",
       "          1.0158e-01, -8.2522e-02, -1.3905e-02, -9.2971e-02, -7.6430e-02,\n",
       "         -4.6933e-03,  2.0071e-02,  9.2639e-03, -5.3044e-02, -3.8543e-02,\n",
       "         -3.7435e-02,  5.4345e-02, -2.5384e-02,  1.5586e-01, -3.8873e-02,\n",
       "         -3.8922e-02, -3.0344e-02, -3.4743e-02, -1.8795e-01, -1.1780e-01,\n",
       "          4.8716e-02,  9.9519e-02, -1.4206e-02, -1.0050e-02,  7.4868e-02,\n",
       "          1.3507e-02,  2.9880e-02, -7.8687e-02, -7.4365e-02, -9.4557e-03,\n",
       "          1.1530e-01, -1.3660e-01,  6.9452e-02,  1.1057e-01, -7.0446e-02,\n",
       "         -5.2519e-02,  3.1063e-03,  3.8007e-02,  2.7432e-02,  1.0011e-01,\n",
       "          8.2992e-02, -9.8469e-02,  4.1961e-02,  2.3865e-01, -5.0417e-02,\n",
       "          6.0641e-02, -4.5187e-02,  2.5510e-02, -1.2120e-02,  1.1541e-01,\n",
       "         -4.3686e-02,  1.8310e-02,  6.0400e-02,  1.1465e-02,  2.5820e-02,\n",
       "          2.8423e-02,  7.8647e-02,  4.1036e-02,  9.2251e-02, -5.7998e-02,\n",
       "         -1.0517e-01, -8.2294e-03,  2.3248e-02,  3.4752e-02, -6.4384e-03,\n",
       "         -9.6139e-02, -3.6764e-02, -3.5540e-02, -8.8725e-02,  1.2447e-01,\n",
       "          6.0409e-03, -2.6430e-02, -2.5128e-02,  7.6849e-02,  4.7350e-02,\n",
       "          3.7168e-02, -9.0870e-02, -5.2358e-02, -3.3613e-02,  1.5404e-01,\n",
       "         -3.1397e-02, -1.1037e-02,  7.9607e-02, -1.6944e-01,  5.8348e-02,\n",
       "         -3.0730e-02, -8.2936e-02, -6.2696e-02, -3.3786e-03, -6.8326e-02,\n",
       "          8.1821e-02,  3.7548e-02, -6.9476e-02,  3.1679e-03,  1.6222e-02,\n",
       "          1.2729e-01,  3.6812e-02, -1.2955e-01,  9.7027e-03,  1.3227e-01,\n",
       "          3.4658e-02, -2.4448e-03,  8.4803e-02,  6.4157e-02, -2.6283e-02,\n",
       "          3.5485e-02,  1.4420e-02,  2.9898e-02,  3.4962e-02,  4.8269e-02,\n",
       "         -1.0408e-01, -1.1936e-01,  1.2722e-03, -2.2003e-03,  2.2802e-02,\n",
       "         -5.5695e-02, -2.6247e-03,  5.7331e-02,  2.4239e-02,  8.2256e-02,\n",
       "          1.7133e-02, -3.3455e-02,  8.0913e-05,  3.6822e-02,  1.0852e-01,\n",
       "         -1.3835e-02,  8.9349e-02, -9.6949e-03,  1.2451e-01, -2.3070e-02,\n",
       "          7.1175e-02,  1.0585e-01,  4.2959e-02,  3.7559e-02,  8.8584e-03,\n",
       "          7.5155e-02, -1.3459e-01, -4.1046e-02, -2.8470e-02,  5.4816e-02,\n",
       "         -4.0851e-03,  2.8649e-02,  2.6676e-02,  2.5798e-02, -1.1118e-02,\n",
       "         -1.7022e-02, -3.7547e-02,  7.1098e-02,  1.1556e-01,  7.4787e-02,\n",
       "          8.4056e-02, -6.9991e-02,  4.0966e-03,  3.1801e-01,  6.7956e-02,\n",
       "         -1.6856e-02, -4.8278e-02,  1.2742e-02, -1.7395e-02, -1.9939e-02,\n",
       "         -1.8740e-02,  1.5561e-01,  3.8063e-04, -9.1446e-02,  1.3286e-01,\n",
       "          8.6665e-02,  9.9438e-02,  2.5207e-03,  6.6566e-02,  1.1960e-02,\n",
       "          1.3640e-01,  1.0193e-01, -8.3188e-03,  5.1746e-02, -5.6325e-02,\n",
       "         -1.4747e-02,  1.6923e-03,  1.2410e-03, -2.3278e-02,  2.7331e-01,\n",
       "          5.6152e-02,  1.0354e-03, -3.5265e-02, -1.5118e-01,  3.2969e-02,\n",
       "          4.4969e-02, -1.0062e-02, -1.5154e-02,  1.3810e-02, -3.6751e-02,\n",
       "          7.6552e-02], device='mps:0'),\n",
       " 'model.8.1.running_var': tensor([ 0.3939,  0.1592,  0.1613,  0.4959,  0.0290,  0.1566,  0.6811,  0.3738,\n",
       "          0.0350,  0.0018,  0.2694,  0.2825, -0.0131,  0.0273,  0.1462,  0.0754,\n",
       "          0.6141,  0.1154,  0.3660,  0.2358,  0.5272,  0.1845,  0.0768,  1.0490,\n",
       "          0.2747,  0.3258,  0.9945,  0.3883,  0.2041,  0.4575,  0.4282,  0.1309,\n",
       "          0.2635,  0.2318,  0.2153,  0.3493,  0.4514,  0.7338,  0.2359,  0.5072,\n",
       "          0.0055,  0.1302,  0.5215,  0.3971,  0.4877,  0.1884,  0.1081,  0.0600,\n",
       "         -0.0543,  0.5068,  0.1557,  0.5990,  0.1937,  0.0718,  0.3220,  0.2668,\n",
       "          0.2280,  0.4078, -0.0122,  0.5213,  0.3781,  0.4661,  0.5500,  0.2678,\n",
       "          0.4195,  0.2488,  0.3029,  0.2254,  0.0817,  0.3277,  0.3297, -0.0033,\n",
       "          0.3466,  0.2251,  0.3522,  0.2576,  0.0692,  0.2784,  0.7033,  0.2435,\n",
       "          0.0367,  0.2430,  0.3725,  0.5102,  0.2589,  0.4620,  0.8706,  0.3026,\n",
       "          0.1425,  0.0123,  1.1327,  0.4688,  0.2077,  0.1423,  0.2068,  0.2731,\n",
       "          0.2664,  0.0142,  0.2420,  0.2490,  0.1847,  0.2095,  0.4238,  0.8320,\n",
       "          0.3584,  0.2590,  0.5273,  1.0409,  1.0314,  0.1985,  0.1313,  0.3115,\n",
       "          0.4519,  0.0545,  0.1812,  0.2038,  0.2172,  0.7352,  0.7176,  0.1014,\n",
       "          0.1645,  0.5856,  0.6765,  0.3915,  0.3522,  0.0084,  0.0541,  0.0976,\n",
       "          0.5055,  0.2803,  0.3767,  0.2077,  0.2797,  0.0236,  0.1054,  1.0469,\n",
       "          0.3677,  0.0353,  0.0278,  0.2142,  0.6687,  0.2246,  0.2528,  0.1707,\n",
       "          0.0588,  0.4805,  0.5544,  1.3976,  0.2741, -0.0281,  0.8427,  0.2311,\n",
       "          0.3330,  0.1098,  0.1821, -0.0168,  0.2308,  0.1218,  0.1803,  0.2201,\n",
       "          0.6308,  0.6403, -0.0079,  0.6257,  0.1086,  0.4566,  0.2871,  0.3388,\n",
       "         -0.0506,  0.3596,  0.1295,  0.0159,  0.4090,  0.4009,  0.2941,  0.0529,\n",
       "          0.2082, -0.0606,  0.3285,  0.6692,  0.2460,  0.0627,  0.6653,  0.1889,\n",
       "          0.9104,  0.1399,  0.4074,  0.2030,  0.5621,  0.2502,  0.0789,  0.2684,\n",
       "          0.1727,  0.3077,  0.5337,  0.1529,  0.5531,  0.4498,  0.4993,  0.0254,\n",
       "          0.4850,  0.2307,  0.1597,  0.0263,  0.0533,  0.0067,  0.4577,  0.1453,\n",
       "          0.2822,  0.2541,  0.0907, -0.1458,  0.1804,  0.1370,  0.0708, -0.0098,\n",
       "          0.1668,  0.4292,  1.0367,  0.3787,  0.1204, -0.0442,  1.1254,  0.0668,\n",
       "          0.2704,  0.6946,  0.7974,  0.0414,  0.3940,  0.0647,  0.3644,  0.9933,\n",
       "          0.0109,  1.4298,  0.0125,  0.4376,  0.5151,  0.6040,  0.2857,  0.0798,\n",
       "          0.1375,  0.7317,  0.4642,  0.7129,  0.5187,  0.3926,  0.4909,  0.1096,\n",
       "          0.4096,  0.0558,  1.1526,  0.2396,  0.1629,  0.6498,  0.1356,  0.2897],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.num_batches_tracked': tensor(40., device='mps:0'),\n",
       " 'classifier.weight': tensor([[-3.5655e-03, -1.9065e-03, -4.1060e-03,  ...,  7.0214e-05,\n",
       "          -1.4665e-03, -5.2476e-03],\n",
       "         [ 1.4721e-03, -1.4277e-03,  1.2915e-03,  ..., -3.0310e-03,\n",
       "           9.2912e-04,  1.6359e-03],\n",
       "         [ 3.4789e-03,  5.5311e-03,  1.1220e-02,  ..., -5.5215e-03,\n",
       "          -2.4371e-03,  6.1973e-03],\n",
       "         ...,\n",
       "         [-3.1053e-04, -9.9510e-05,  1.9950e-03,  ..., -5.4586e-04,\n",
       "           4.8032e-03,  2.6822e-03],\n",
       "         [-1.2812e-02, -4.3093e-03,  3.9149e-03,  ..., -2.7399e-04,\n",
       "          -2.8274e-03, -2.7776e-03],\n",
       "         [ 9.2979e-03,  8.3807e-03,  5.4074e-03,  ...,  1.2728e-02,\n",
       "           4.4645e-03,  4.6760e-03]], device='mps:0'),\n",
       " 'classifier.bias': tensor([-0.0242, -0.0082,  0.0214, -0.0063, -0.0270, -0.0114,  0.0199, -0.0020,\n",
       "          0.0026,  0.0351], device='mps:0')}"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "bcfdcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sigmoid_on_cutoff(a,c=0.005, left = False):\n",
    "#     def f(x):\n",
    "#         if(not left and x > (a + 2)):\n",
    "#             return 0\n",
    "#         if(left and x < (a - 2)):\n",
    "#             return 0\n",
    "#         exponent = (-(x-a))/(c if left else -1*c)\n",
    "#         return 1/(1 + (math.e**(exponent)))\n",
    "#     return f \n",
    "\n",
    "# def make_double_sigmoid(a,b):\n",
    "#     left = make_sigmoid_on_cutoff(a, left = True)\n",
    "#     right = make_sigmoid_on_cutoff(b, left = False)\n",
    "#     def f(x):\n",
    "#         return left(x)*right(x)\n",
    "#     return f\n",
    "# baseline2.devices[0]['net']\n",
    "\n",
    "def make_test_device(trainset):\n",
    "    data_idxs = iid_sampler(trainset, 1, .1)\n",
    "    return create_device(ConvNet().to(mps), 0, trainset, data_idxs[0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5be3a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c289183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_noise_attack(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "8cfc77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device['net'].state_dict()['model.0.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "d447ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a3cdcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [x[1] for x in trainset if x[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "ee5f3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "5d3f0146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def swap_classes_dataset(s, a, b):\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if s[i][1] == a:\n",
    "            s[i] = s[i][0],b\n",
    "        if s[i][1] == b:\n",
    "            s[i] = s[i][0],a \n",
    "    \n",
    "    return s\n",
    "\n",
    "# Make switch classes attack\n",
    "def switch_classes_attack(a,b, train_epochs):\n",
    "    transform_train = transforms.Compose([                                   \n",
    "        transforms.RandomCrop(32, padding=4),                                       \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    evil_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "    evil_trainset = swap_classes_dataset(evil_trainset, a,b)\n",
    "    print(\"swapping\\n\")\n",
    "    \n",
    "    # Load testing data\n",
    "    transform_test = transforms.Compose([                                           \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    evil_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transform_test)\n",
    "    \n",
    "    evil_testset = swap_classes_dataset(evil_testset, a,b)\n",
    "    \n",
    "    evil_testloader = torch.utils.data.DataLoader(evil_testset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    attack_idx = iid_sampler(evil_trainset, 1, 1)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    evil_device_trainset = DatasetSplit(evil_trainset, attack_idx)\n",
    "    evil_device_trainloader = torch.utils.data.DataLoader(evil_device_trainset,\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        device['dataloader'] = evil_device_trainloader\n",
    "\n",
    "        for local_epoch in range(train_epochs):\n",
    "            train(local_epoch, device, criterion)\n",
    "        \n",
    "        print(\"Confirm the attack worked. (This should be high)\")  \n",
    "        test(0, device, criterion,testloader =  evil_testloader)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    return attack\n",
    "\n",
    "sca = switch_classes_attack(0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b090d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a4ed4ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Now let's make an instance of this attack that performs 25 epochs of training on the evil device with the misclassified data.\n",
    "# Specifically, we switch cars and airplanes\n",
    "sca2 = switch_classes_attack(0,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "1c32c53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 30/Epoch 3) Train Loss: 0.448 | Train Acc: 84.700 | Test Loss: 0.389 | Test Acc: 87.390\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 218.5696198940277 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 3/Epoch 3) Train Loss: 0.327 | Train Acc: 88.8800 | Test Loss: 0.382 | Test Acc: 87.490\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 425.6108150482178 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 14/Epoch 3) Train Loss: 0.222 | Train Acc: 92.600 | Test Loss: 0.408 | Test Acc: 86.950\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 632.2491769790649 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 25/Epoch 3) Train Loss: 0.335 | Train Acc: 88.440 | Test Loss: 0.419 | Test Acc: 86.930\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 830.303952217102 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 40/Epoch 3) Train Loss: 0.231 | Train Acc: 93.040 | Test Loss: 0.383 | Test Acc: 87.780\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1036.1185810565948 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 42/Epoch 3) Train Loss: 0.255 | Train Acc: 91.180 | Test Loss: 0.392 | Test Acc: 87.840\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1244.9114549160004 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 38/Epoch 3) Train Loss: 0.280 | Train Acc: 90.120 | Test Loss: 0.390 | Test Acc: 87.540\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1455.037827014923 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 48/Epoch 3) Train Loss: 0.292 | Train Acc: 89.680 | Test Loss: 0.370 | Test Acc: 88.290\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1667.519868850708 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 42/Epoch 3) Train Loss: 0.345 | Train Acc: 87.840 | Test Loss: 0.369 | Test Acc: 88.460\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1876.9336681365967 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 18/Epoch 3) Train Loss: 0.186 | Train Acc: 93.520 | Test Loss: 0.377 | Test Acc: 88.280\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2105.277766227722 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 14/Epoch 3) Train Loss: 0.225 | Train Acc: 92.440Attacking!\n",
      "\n",
      "(Device 2/Epoch 24) Train Loss: 0.013 | Train Acc: 99.5780Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.855 | Test Acc: 85.830\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.376 | Test Acc: 88.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3514.256497144699 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 49/Epoch 3) Train Loss: 0.228 | Train Acc: 92.280 | Test Loss: 0.363 | Test Acc: 88.500\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3872.9786880016327 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 19/Epoch 3) Train Loss: 0.176 | Train Acc: 94.480 | Test Loss: 0.369 | Test Acc: 88.470\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4388.051183223724 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 12/Epoch 3) Train Loss: 0.181 | Train Acc: 93.920 | Test Loss: 0.368 | Test Acc: 88.760\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4672.941226005554 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 38/Epoch 3) Train Loss: 0.166 | Train Acc: 94.120 | Test Loss: 0.368 | Test Acc: 88.920\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4955.253675937653 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 34/Epoch 3) Train Loss: 0.158 | Train Acc: 94.380 | Test Loss: 0.365 | Test Acc: 89.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5454.384433269501 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 42/Epoch 3) Train Loss: 0.237 | Train Acc: 93.120 | Test Loss: 0.349 | Test Acc: 89.640\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5803.5099267959595 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 40/Epoch 3) Train Loss: 0.209 | Train Acc: 92.960 | Test Loss: 0.355 | Test Acc: 88.940\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6158.822886943817 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 12/Epoch 3) Train Loss: 0.298 | Train Acc: 90.6200 | Test Loss: 0.376 | Test Acc: 89.040\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6527.806505918503 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 46/Epoch 3) Train Loss: 0.197 | Train Acc: 93.1000 | Test Loss: 0.364 | Test Acc: 89.170\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6739.291934967041 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 13/Epoch 3) Train Loss: 0.243 | Train Acc: 91.7600 | Test Loss: 0.358 | Test Acc: 89.550\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6952.29815196991 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 15/Epoch 3) Train Loss: 0.188 | Train Acc: 93.9600 | Test Loss: 0.350 | Test Acc: 89.550\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7167.842609167099 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 7/Epoch 3) Train Loss: 0.195 | Train Acc: 94.0000 | Test Loss: 0.347 | Test Acc: 89.590\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7389.792389154434 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 34/Epoch 3) Train Loss: 0.107 | Train Acc: 96.5800 | Test Loss: 0.354 | Test Acc: 89.690\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7609.542908191681 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 0/Epoch 3) Train Loss: 0.172 | Train Acc: 94.1200 | Test Loss: 0.381 | Test Acc: 89.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7972.639851093292 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 37/Epoch 3) Train Loss: 0.071 | Train Acc: 97.7000 | Test Loss: 0.347 | Test Acc: 90.250\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8186.583430051804 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 49/Epoch 3) Train Loss: 0.076 | Train Acc: 97.6600 | Test Loss: 0.347 | Test Acc: 90.240\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8406.754409074783 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 13/Epoch 3) Train Loss: 0.071 | Train Acc: 98.1800 | Test Loss: 0.349 | Test Acc: 90.220\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8638.34443116188 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 26/Epoch 3) Train Loss: 0.067 | Train Acc: 97.8200 | Test Loss: 0.350 | Test Acc: 90.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8878.929777145386 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 24/Epoch 3) Train Loss: 0.071 | Train Acc: 98.1400 | Test Loss: 0.352 | Test Acc: 90.350\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 9122.999819993973 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 9140.565530061722 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_no_defense = run_federated_test(                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca2, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_no_defense.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "227a32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_classes_no_defense = load_result(\"switch_classes_no_defense.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ef19dc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.2,\n",
       " 44.42,\n",
       " 54.68,\n",
       " 60.89,\n",
       " 65.69,\n",
       " 69.14,\n",
       " 71.45,\n",
       " 73.38,\n",
       " 76.61,\n",
       " 77.53,\n",
       " 79.7,\n",
       " 77.91,\n",
       " 79.95,\n",
       " 81.38,\n",
       " 82.4,\n",
       " 82.86,\n",
       " 83.43,\n",
       " 83.6,\n",
       " 84.71,\n",
       " 85.13,\n",
       " 85.46,\n",
       " 85.9,\n",
       " 85.79,\n",
       " 86.54,\n",
       " 86.48,\n",
       " 87.19,\n",
       " 87.33,\n",
       " 87.52,\n",
       " 87.52,\n",
       " 87.37,\n",
       " 87.48,\n",
       " 87.65,\n",
       " 87.62,\n",
       " 87.56,\n",
       " 87.58,\n",
       " 87.7,\n",
       " 87.63,\n",
       " 87.62,\n",
       " 87.8,\n",
       " 87.76,\n",
       " 87.92,\n",
       " 87.82,\n",
       " 87.87,\n",
       " 87.91,\n",
       " 87.96,\n",
       " 87.89,\n",
       " 88.11,\n",
       " 87.85,\n",
       " 87.89,\n",
       " 88.12,\n",
       " 88.09,\n",
       " 87.96,\n",
       " 88.01,\n",
       " 87.94,\n",
       " 88.05,\n",
       " 88.0,\n",
       " 87.96,\n",
       " 88.07,\n",
       " 88.05,\n",
       " 88.0,\n",
       " 88.17,\n",
       " 88.07,\n",
       " 88.23,\n",
       " 88.07,\n",
       " 88.08,\n",
       " 87.99,\n",
       " 88.1,\n",
       " 88.11,\n",
       " 88.13,\n",
       " 88.12,\n",
       " 88.09,\n",
       " 88.12,\n",
       " 88.08,\n",
       " 88.12,\n",
       " 88.13,\n",
       " 88.11,\n",
       " 88.06,\n",
       " 88.12,\n",
       " 88.07,\n",
       " 88.15,\n",
       " 88.1,\n",
       " 88.06,\n",
       " 88.16,\n",
       " 88.12,\n",
       " 88.14,\n",
       " 88.14,\n",
       " 88.18,\n",
       " 88.12,\n",
       " 88.11,\n",
       " 88.09,\n",
       " 88.07,\n",
       " 88.08,\n",
       " 88.16,\n",
       " 88.09,\n",
       " 88.23,\n",
       " 88.22,\n",
       " 88.13,\n",
       " 88.04,\n",
       " 88.13,\n",
       " 88.05,\n",
       " 87.39,\n",
       " 87.49,\n",
       " 86.95,\n",
       " 86.93,\n",
       " 87.78,\n",
       " 87.84,\n",
       " 87.54,\n",
       " 88.29,\n",
       " 88.46,\n",
       " 88.28,\n",
       " 88.34,\n",
       " 88.5,\n",
       " 88.47,\n",
       " 88.76,\n",
       " 88.92,\n",
       " 89.23,\n",
       " 89.64,\n",
       " 88.94,\n",
       " 89.04,\n",
       " 89.17,\n",
       " 89.55,\n",
       " 89.55,\n",
       " 89.59,\n",
       " 89.69,\n",
       " 89.05,\n",
       " 90.25,\n",
       " 90.24,\n",
       " 90.22,\n",
       " 90.33,\n",
       " 90.35]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_classes_no_defense.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0c4baa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_device = make_test_device(trainset)\n",
    "test_device['net'].load_state_dict(switch_classes_no_defense.avg_weight_history[112])\n",
    "# def test(epoch, device, criterion, testloader = testloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "cb9c2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.368 | Test Acc: 88.560\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "0657ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_test_set(s, labels):\n",
    "    s = list(s)\n",
    "    s = [s for s in s if s[1] in labels]\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def make_testloader_subset(labels):\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "    \n",
    "    restricted_test_set = limit_test_set(testset, labels)\n",
    "    print(len(restricted_test_set))\n",
    "#     restricted_test_set = swap_classes_dataset(restricted_test_set, 0, 1)\n",
    "    \n",
    "    restricted_testloader = torch.utils.data.DataLoader(restricted_test_set, batch_size=128, shuffle=False)\n",
    "    return restricted_testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c69742b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "checker_test_set = make_testloader_subset([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "51054b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.392 | Test Acc: 89.400\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), checker_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a3778876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-327-34489808078c>:16: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"-k\" (-> color='k'). The keyword argument will take precedence.\n",
      "  [plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.lines.Line2D at 0x51a17e0d0>],\n",
       " [<matplotlib.lines.Line2D at 0x51a17efa0>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f57be0>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f57d60>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f57970>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f57e80>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f575b0>],\n",
       " [<matplotlib.lines.Line2D at 0x4f8f572e0>],\n",
       " [<matplotlib.lines.Line2D at 0x51a0260a0>]]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+uklEQVR4nO29eXxV1dX//1mZQxCQGUEEFVEccEAqzlasiOJQhwdUaq2WarXWoVrnPrU+dfxqJ5UiRRwYHBBHxAkrIqgERQQEjQEkjGEOJCG5yfr98bn7d05u7k1Oknu5yc16v17ndXP32eecvQP57HXWXnttUVUYhmEYqUtashtgGIZhJBYTesMwjBTHhN4wDCPFMaE3DMNIcUzoDcMwUpyMZDcgGp07d9Y+ffokuxmGYRgthgULFmxS1S7RzjVLoe/Tpw/y8/OT3QzDMIwWg4isinXOXDeGYRgpTr1CLyL7ishHIvKtiCwRkd9HqSMi8g8RKRCRRSJytO/cMBFZHj53e7w7YBiGYdRNEIs+BOAWVT0EwHEArhORARF1zgLQL3yMAfAUAIhIOoAnwucHABgV5VrDMAwjgdQr9Kq6TlW/DP9cAuBbAD0jqp0H4DklnwHoICI9AAwGUKCqhapaAWBquK5hGIaxh2iQj15E+gA4CsDnEad6Aljt+14ULotVHu3eY0QkX0Tyi4uLG9IswzAMow4CC72ItAUwDcCNqroj8nSUS7SO8tqFquNUdZCqDurSJWqEkGEYhtEIAoVXikgmKPKTVPXVKFWKAOzr+94LwFoAWTHKDcMwjD1EvUIvIgLgPwC+VdXHYlR7A8D1IjIVwE8AbFfVdSJSDKCfiPQFsAbASACXxqfphtF4tm4Fli/nsX070LcvcMABQPfuwK5dQEkJUFoKVFUBqvysrAQqKnhUVvIIhXi/tDRAhOd27+anK09L864PhbxrKytZJz2dh7uHCJCVBbRtC+y1F5CdzTZUV7N+RgaQmcnPWFRV8VmhEK9zh4j3rKoqr54Iy9LTvTa49jhUax8OV9f1193H1YmVDT3WedeGyDr+etHaEYvIe0VrR31tjXWPyDZFq1Pf8x05OcAFF9RdpzEEsehPADAawDcisjBcdieA3gCgqmMBzAAwHEABgFIAV4bPhUTkegDvAkgHMEFVl8SzA0bqoQps3AisWgX8+CNQXAxs3gxs2QKUlVFId++mWG/cyPMZGUCnTkDHjhQZJ7bp6UD79jx27wYKC3ls3pzsXhpGbbp1S4zQS3PceGTQoEFqK2MTx6rw+rkePWg5NpVly4DJk4E1a4ABA4DDDqPwzp4NfPwxrWZnSTqrt6KClmR6OuumpXnWbnm5Z+36adsWaNOGFm5WFrD33kCXLjxCIQ4EmzfTcs3KYr1QiBb7jh20gvffn8cBBwD9+/Po0AFYsQIoKODA4SzpvDzP+k1L4z0zM3m4n51V7Sxu99ysLPa1uppWc3q6V9/dw13r6lRXe5ZlRQWwcyeP8nKvDare78lZ4pGo8t7uTcEdzsJ21n1amlcP8Cx81wb3BuHHWdr+w18/8vBb5tHa6i/3W72xLGL//SLbE4tY94rVt2h1XJtinY9sU7T+1Pd7APhvceCBsc/XhYgsUNVB0c41yxQIRuKYNAm4/HLve5cuFB0nNP7Xdido2dmeGAAU286daUEvXgwsWMD6nToBEyZ49dLSgCOPBM4+m/d0IuKEMCPDcx1UVXkimJ0N9OwJ7Lcf0Ls3rZyOHVmeKLp2BX7yk8Tdvy6cEPtp04YDkGHEAxP6VsTXXwO//jVw4onAL38JFBUBa9d6FmdaOAbLWWOhkOcmcdadKn3Xa9YACxfSp/3YY8DIkXxD2LQJWLKELpYhQ+gyMQwjuZjQtxK2bKHvb++9gVdeoZWcCDp3Bk45JTH3NgyjcZjQtwKqqoDLLqMFP3t24kTeMIzmiQl9K+Cf/wRmzgSeego49ljg2WfpM+/alT76Dh28yJTMzOj38IcXpqczDCw9nS6dbds4CVpa6k0aVlfTfVNWxuv8E4KuvKKCfvecHPrs3f1DIbapa1f6/auqvGtcNE1FBX36ubm8fvduTrpu28bJSxdaWFbGidgdO9g+N5GZlsZJ17ZteQ83QVpRwUnZggK6p9xcRUZG7Qm3+sIP3USzm2x210VOXrqfI8sicfMnbvI2so67tqoq+nVuMjdy4tTVd3WqqrwQUr/LLlo4oz+kMnJyNhZ1natrorIh96nrvkFDHeu7T5DyhtKlC/DVV/G5lx8T+hRnxQrgrrs4Ifqb3wDjxwNjxsSu70Q8O5t/8E5Yo0Vg+CdxmztpaZzgdKJdXc14+fLy2nX32gvo14+ROUDNeHmgpuC5CWyHEz7Am+coK6t5jX+QiIw798exxxpE/JFA/vP+8shr/VEw/mf752ZcvfR0L6oocpI4mqBHDlax2h9NbP1ExqPHqlPffeq7r594DCzxDFxs1y5+9/JjQp/CqFLU09NpzZeUAHffDZxwAvDMM4w/Ly6mFbx9Ow9/nHp6uhch447MzJrWemamF7+el1dT/Jy1nZVVM3QvN5dHVhYHkfJyfroon7Q0xsi7+Hlnuefmeu3JzKSIlpezHTk53ltJmzaeJe3Kc3Oj/1GHQrT03QImF48fLwvNMJoDJvQpzMSJwAcfUOT33Re44w7Gib/1Fi3Wfv2S3cLkk5GROCvKMJoLtsNUilJUBNx8M3DyybTqV6xgGOTo0fTTG4bRejChT0HWrgVOP52ukqefpivkj3+k9frXvya7dYZh7GlM6FOMdeuAn/6UYj9zJnDQQcALLwAvvwzcdhvQq1eyW2gYxp7GhD6F2LiRIl9UBLzzDnD88UxJ8ItfAKeeSqE3DKP1YUKfIqgCV18NrFxJkT/xRE7CXnUVcMYZwNtvM/LEMIzWh0XdpAiTJwNvvgk8+ihw0klMXvbb3wIjRgAvvcQwQ8MwWieWpjgFWL8eOPRQ+uPnzGHa4MGDgWOOYXhlPFIRG4bRvKkrTbG5blo4qsB113GV54QJXPxz4YVc3fniiybyhmGY66ZFs2sXwyVffRV48EHg4IOBSy8Fvv+elnyPHsluoWEYzYEge8ZOAHAOgI2qeliU87cCuMx3v0MAdFHVLSKyEkAJgCoAoVivFUbDqKoCnnuO6QzWrqW433QTV75OnUrxP+20ZLfSMIzmQhDXzUQAw2KdVNVHVPVIVT0SwB0APlbVLb4qp4XPm8jHiZtvBn71K6Y1mDMH+M9/GEL50ENcBfvHPya7hYZhNCfqFXpVnQ1gS331wowCMKVJLTLq5OuvgX/9i4I+bx7dNWecQX/8Qw8BY8fWzGpoGIYRN0kQkTag5T/NV6wA3hORBSJSR3JcQETGiEi+iOQXFxfHq1kphSrwu98xU+SDDzLa5pRTgPnzKfS33WZZFw3DqE08J2NHAPg0wm1zgqquFZGuAN4XkWXhN4RaqOo4AOMAhlfGsV0pw5QpwCefAOPGMaXw0KHAhg1cIGU+ecMwYhHPl/yRiHDbqOra8OdGANMBDI7j81oVO3cCt97K2PiTTuLK1y1bgA8/NJE3DKNu4iL0ItIewCkAXveV5YnIXu5nAD8DsDgez2uN/O//MsLmn//kTlHl5cDHH3NhlGEYRl0ECa+cAuBUAJ1FpAjAnwBkAoCqjg1XuwDAe6q6y3dpNwDThU7jDACTVXVm/Jreevjvf5lLfswY7rw0ezbw5JPA4Ycnu2WGYbQELAVCM2frVmDgQOaqWbCALpvSUmDp0tgbeRuG0fqoKwWCrYxt5lx3HXPMz50LvP46sGgRF0WZyBuGERQT+mbMpEmMtLn/fuCII4CLLwaOPpqfhmEYQTGhb6asXk1r/oQTgNtv52KoVau8rQENwzCCYpLRDFHlhiGhEPDss4y0uesuZqUcOjTZrTMMo6VhFn0z5KmngPff5+dLLwF33kmRnzzZVr4ahtFwzKJvZhQUcGHUmWcCJSUU+csu4wSs5ZY3DKMxmEXfzPjNbyjojzwCDBkCnHsu3Tfp6clumWEYLRUT+mbEJ58As2YBjz9OC760FHjgARN5wzCahgl9M+L++4GuXYGLLgIGDGAY5YAByW6VYRgtHfPRNxO++AJ47z3gllsYQllSwh2kDMMwmopZ9M2E++9nnvlLLwUOOwy44ALLZWMYRnwwi74ZsHAh8OabwI03AhMnMtf8PfckuVGGYaQMZtE3A/76V6BdO+4DO3AgcPbZwFFHJbtVhmGkCmbRJ5kffgBeeQX47W+Bl18GNm9m7LxhGEa8MIs+yfztb0BGBuPnTzoJOPlk4Pjjk90qwzBSCRP6JLJ1KzBhAidgZ80CiooYcWMYhhFP6nXdiMgEEdkoIlG3ARSRU0Vku4gsDB/3+s4NE5HlIlIgIrfHs+GpwL//zUVRN9wAPPww/fJnnpnsVhmGkWoEsegnAvgXgOfqqPOJqp7jLxCRdABPADgDQBGA+SLyhqoubWRbU4qKCmalHDoUWLECWL4cePFFS1pmGEb8qdeiV9XZALY04t6DARSoaqGqVgCYCuC8RtwnJZk6lZt933QTo24OPJAZKg3DMOJNvKJuhojI1yLyjogcGi7rCWC1r05RuKzVU1UFPPoo0xuUlABffsm4ectpYxhGIojHZOyXAPZT1Z0iMhzAawD6AYjmhIi5E7mIjAEwBgB69+4dh2Y1X55+GvjmG+D555nm4PDDmYrYMAwjETTZolfVHaq6M/zzDACZItIZtOD39VXtBWBtHfcZp6qDVHVQly5dmtqsZsumTYyTP+00YMcO5p+3DJWGYSSSJlv0ItIdwAZVVREZDA4emwFsA9BPRPoCWANgJIBLm/q8ls6dd9Jd89BDwIgRjJsfPjzZrTIMI5WpV+hFZAqAUwF0FpEiAH8CkAkAqjoWwEUArhWREIAyACNVVQGEROR6AO8CSAcwQVWXJKQXLYQvvgDGj+cE7LvvAhs2AK+9ZpE2hmEkFqEmNy8GDRqk+fn5yW5GXKmqAo47jouiZs8GjjmGoZWvvprslhmGkQqIyAJVHRTtnK2M3UOMHQvk5wOTJgEPPgiUl9N9YxiGkWhM6PcAa9fSNz90KNC/P3D55dxgpF+/ZLfMMIzWgAn9HuDmm4Hdu4Enn2Qq4s6dbfcowzD2HCb0Cebdd5na4L77gK++AubMYY6b9u2T3TLDMFoLNhmbQMrKuC1gZiZFfsAACvyCBRY3bxhGfLHJ2CTxwANAYSFTEH/zDbByJfDCCybyhmHsWWyHqQTx/feMqrnsMq6CnTGD8fLDhiW7ZYZhtDZM6BOAKnD99UBODpOXART6444DOnVKbtsMw2h9mNAngGnTgPfeA/7yF6B7d66AnT/fUh0YhpEcTOjjTGkpcOONwJFHcsNvgJE3gAm9YRjJwSZj48zrrwNr1gDPPMNNvwG6bbp3p/gbhmHsacyijzOTJgG9egGnn87voRAt+rPOAtLst20YRhIw6YkjmzZR1C+91BP1zz4Dtm0zt41hGMnDhD6OvPQSLXj/blEzZjBu/owzktcuwzBaNyb0ceSFF7gS9ogjvLIZM4ATT7SUB4ZhJA8T+jhRWAjMm1fTmv/hB+Drr4Gzz05euwzDMEzo48TkyfwcNcorGz+evvpLW/0GioZhJJN6hV5EJojIRhFZHOP8ZSKyKHzMFZGBvnMrReQbEVkoIi0/S1kMVBltc/LJwH77sayykiGWZ58N9OyZ3PYZhtG6CWLRTwRQV4aWFQBOUdUjAPwFwLiI86ep6pGxsqqlAgsWAMuW1XTbvPUWV8T++tfJa5dhGAYQYMGUqs4WkT51nJ/r+/oZgF5xaFeLYvx4IDcXuOQSr2zcOGCffRg/bxiGkUzi7aO/CsA7vu8K4D0RWSAiY+q6UETGiEi+iOQXFxfHuVmJY+dOum0uuQTo0IFlq1Yxnv6qq7zVsYZhGMkibjIkIqeBQn+ir/gEVV0rIl0BvC8iy1R1drTrVXUcwm6fQYMGNb/dUGLw4osU+zG+YWzCBH5edVVy2mQYhuEnLha9iBwBYDyA81R1sytX1bXhz40ApgMYHI/nNSfGjePOUUOG8HtVFYX+Zz/zJmYNwzCSSZOFXkR6A3gVwGhV/c5Xnicie7mfAfwMQNTInZbK118DX3xBa16EZe+9BxQVAVdfndy2GYZhOOp13YjIFACnAugsIkUA/gQgEwBUdSyAewF0AvCkUO1C4QibbgCmh8syAExW1ZkJ6EPSePppIDsbGD3aK3vmGW4ucu65yWuXYRiGnyBRN6PqOX81gFr2q6oWAhhY+4rUoLSUKQ8uugjo2JFlW7YwTfE11wBZWcltn2EYhsNWxjaS558Htm+vOQk7eTJQUQFceWXy2mUYhhGJCX0jCIW48ffgwcBJJ3nlEycCAwfaBiOGYTQvTOgbwdSpwIoVwF13eZOw33zDFbJmzRuG0dwwoW8g1dXAAw8wHfE553jlzzwDZGbWTINgGIbRHLB1mw3ktdeApUvpj3e7SFVWcmJ2xAigc+ekNs8wDKMWZtE3AFXg//4POPDAmnltZs0CiouBK65IXtsMwzBiYRZ9A/jwQ+DLL5nELD3dK58xA8jJse0CDcNonphF3wCmTAHatQMuv7xm+YwZwE9/ygyWhmEYzQ0T+oCEQlwMNWIEV8M6vv8eKCiwdMSGYTRfTOgD8vHHwObNwIUX1ix/J5yUefjwPd8mwzCMIJjQB2TaNKBNG+DMM2uWz5gB9O8P7L9/ctplGIZRHyb0AaiuBqZPp9Xepo1XXloK/Pe/Zs0bhtG8MaEPwNy5wPr1td02H30E7N5tQm8YRvPGhD4A06ZxAvbss2uWz5gB5OXVzHdjGIbR3DChrwdVCv3PfgbstVfN8hkzgNNPrxmFYxiG0dwwoa+H+fOB1atru22WLQNWrjS3jWEYzR8T+np44QVuIjJiRM3y6dP5GenOMQzDaG7UK/QiMkFENopI1P1ehfxDRApEZJGIHO07N0xElofP3R7Phu8Jdu0Cnn225i5Sjpdf5obgvXolp22GYRhBCWLRTwQwrI7zZwHoFz7GAHgKAEQkHcAT4fMDAIwSkQFNaeyeZsoUYMcObg3op6AAWLiQA4BhGEZzp16hV9XZALbUUeU8AM8p+QxABxHpAWAwgAJVLVTVCgBTw3VbBKrAU08Bhx4KnHhizXOvvMJPE3rDMFoC8fDR9wSw2ve9KFwWqzwqIjJGRPJFJL+4uDgOzWoa+fnMVHnttd4uUo6XX+Y2gr17J6dthmEYDSEeQi9RyrSO8qio6jhVHaSqg7p06RKHZjWNp55ijPzo0TXLCws5AFx8cXLaZRiG0VDikY++CMC+vu+9AKwFkBWjvNmzdSv3hR09mmmJ/ZjbxjCMlkY8LPo3APwiHH1zHIDtqroOwHwA/USkr4hkARgZrtvseeIJoKyMbptIXn4ZGDQI6NNnjzfLMAyjUdRr0YvIFACnAugsIkUA/gQgEwBUdSyAGQCGAygAUArgyvC5kIhcD+BdAOkAJqjqkgT0Ia58/jnw5z9zgdSRR9Y8t3IlffcPPZSMlhmGYTSOeoVeVUfVc14BXBfj3AxwIGgRbN0K/M//AD17crvASF57jZ+Rq2QNwzCaM7ZnbBhV4OqrgTVrgE8+ATp0qF3nrbeAAQOAAw7Y480zDMNoNJYCIcy4ccCrrwIPPAAcd1zt8zt2ALNnW8oDwzBaHib0ADZsAG67jZkob745ep333wcqK4FzztmzbTMMw2gqJvQAbr2VUTZPPgmkxfiNvP023TnHH79Hm2YYhtFkWr3Qz54NPP88xf6gg6LXqa5m7vlhw4AMm9UwDKOF0aqFvrISuO46YL/9gLvuil1vwQK6d8w/bxhGS6RV26dPPgksXsywSf+m35G8/Tbz3QyrK4enYRhGM6VVW/RjxzIz5bnn1l3v7beZe75z5z3TLsMwjHjSaoV+6VJuBzhyZO3slH7WreNqWHPbGIbRUmm1Qv/qq/y84IK6682cyU8TesMwWiqtVuinTWOo5D771F1v9my6bI44Ys+0yzAMI960SqEvLORWgD//ef11P/0UOOGEut07hmEYzZlWKfTObVOf0G/cCHz/PYXeMAyjpdJqhf7oo4G+feuuN3cuP03oDcNoybQ6oV+zBpg3L7jbJjsbOOaYxLfLMAwjUbQ6oZ8+nZ9Bcsp/+il3k8rOTmybDMMwEkmrE/pp04BDDgEOPrjueuXlTH1gbhvDMFo6gYReRIaJyHIRKRCR26Ocv1VEFoaPxSJSJSIdw+dWisg34XP58e5AQ1i3Dvj4Y+4iVR/5+UBFhQm9YRgtnyB7xqYDeALAGQCKAMwXkTdUdamro6qPAHgkXH8EgJtUdYvvNqep6qa4trwRvPwyd5IKIvRz5vDT0hIbhtHSCWLRDwZQoKqFqloBYCqA8+qoPwrAlHg0Lt5MnQoMHFi/2wagf75/f8tvYxhGyyeI0PcEsNr3vShcVgsRaQNgGIBpvmIF8J6ILBCRMbEeIiJjRCRfRPKLi4sDNKthrFzJaJuRI+uvW13N0Epz2xiGkQoEEfpoa0I1Rt0RAD6NcNucoKpHAzgLwHUicnK0C1V1nKoOUtVBXbp0CdCshvHSS/wM4rZZvhzYssWE3jCM1CCI0BcB2Nf3vReAtTHqjkSE20ZV14Y/NwKYDrqC9jhTpwI/+Un9i6QAum0AE3rDMFKDIEI/H0A/EekrIlmgmL8RWUlE2gM4BcDrvrI8EdnL/QzgZwAWx6PhDWH5cuCrr4K5bQC6bTp1ir21oGEYRkui3qgbVQ2JyPUA3gWQDmCCqi4RkWvC58eGq14A4D1V3eW7vBuA6cKMYBkAJqvqzHh2IAgvvsikZBdfHKz+3LmMtrFEZoZhpAKBthJU1RkAZkSUjY34PhHAxIiyQgADm9TCJqJKt81JJwE9o04h12TTJr4BXHll4tuWLMrKeFRX8/eTmcnVv9nZQFozXEKnCoRCXMRWXg7s3s0jFGIfqqqArVu5r++GDVz/kJnJIyPD+7mignMvW7YAO3fyWvc7cFRVeb+fsjJeU1HB/YU11syUDxH+DmMZCareUV1d/3n3TP99/XUi2xT5XP/5yOui3SPa8/3nRbzDlUdrR+Szm0K87rMnntHU+3TuDHz+eXza4ifl94z9+mvg22+BG24IVn/ePH6mavz8xx9zE5Vdu6KfT0ujOKanAzk5QG4ujwzf/5T0dCAri0daGsUxUjTT0rw6mZmecIjwXhkZ/LmkBNi+ne3JyOBgk5lJId6xg4cblOKFCJCXx36kp9cUx7Q0r885Od4AmJlZ/yAYKZLRxN4JthNtfx3VmkLqHzAi7xt5uDr++/if6f851hHZRvfpyiIHB/91kfeI9uymsCferqM9I/J3WV95rPsEpX37xl9bFykv9FOmUEAuuihY/blz+Uc9aFBi25UM1q4FLrkE2Gsv4LzzPCF2wpaZSdEuL6e4+sW2qsq7T3o664pQeNLTKQiqtH5DIc8CLi8HSktripEbHACgbVugRw/eQ9UbNPbdF2jXjm1t356bt2dn1xRfNyClpbFO9+5At26sU1nJw7WlspL1O3Zk3eb45mIYiSKlhb66mm6bM84IvvDp00+Zwjg3N7Ft29NUVgLDh9M1VV0NTJ5cu47/dTwIOTkU4rIyinlDrO6cHIr8li31X5eZyX+/zp29waO8nGKdmekNVm3a8OjYkTuH7bMP771mDY9QiINBjx6s41w77k3CvX34cefdQOR/Y/Fb5pH4LXc3GLk3CDfI+O8Xed9olnq0Nrn7RV4X61o/0dwybsCOdB05/Ja+v1/+z7pcV0ZySGmhnzcP+PFH4P77g9WvqADmzweuvTax7dqTlJdzE/RrrqEbq0MHYMIE4MgjeW7XLvq1i4po8ael0a3Rpg0t6g4daAFnZfF+qsDmzVyAtmIFr3dvBHvtRTHu1IlCvmsXXTPl5Z6oVlXx+uJinuvShVZ4p04U4t27Wd9Z9pWV9L8XF3OQci6l7GzvDcL57EtL6QYqLKSwl5WxzW3bAr168fmffMLnG4knljvHnYskcq6grvvWdZ/GPG9PEKSt3brxbzHepLTQT5lCUTj//GD1Fy6kyLRU//yWLRTxH36gEH//PUXP/Yfu35+uqY4dk9rMPYIqXU4iHLD8VFQA27ZxMHGuHTdgVFbWtIZdnVCotqXsJoKjPdsdVVXeoOV+jja56b/WzXf4idYm5x5z949lhdflY/ZPrPrnACJ99P5+ufb5++Uvi9UH/31iUZ+IBx0MGvO8RBK0rW3bJub5KSv0oRBXw44YQUszCG6hVEsU+u3bgaFDuV6gY0da5UVF/A+2337ApZcCf/5zbddEqiISe2IrKwvo2nXPtscwkknKTkl9+CFf90eNCn7N3LlAnz707bYkSkuBc84BvvkGeOMN9nn1avrkFy6kdf/Xv7YekTcMoyYpa9FPmcJX9rPOClZflUJ/6qkJbVbc2b2b2yLOnQuMGwf861/Ae+8Bf/gD8OCD9GlHsnUr/d0lJfSj+0Mh/ZN86ene99xcvlY6X71hGC2HlBT6qirg9dfpm8/JCXbNqlWcjGwJ+W1UaaVPnEhxX78e+MUvgNtuo1/66aeBq6+ufV11NfDAA8Cf/hTdtxyEzEy+8Rx6KI8DD2QUi4tkcQuU8vLoMrPoC8NIPikp9AsWcLItqDUP0CIGmqd/vqwMuOceumW2bKE/PhTiuW7dgH79gOee4+rfJ54ADj+89j02bgQuvxx4/31m8DznHApxXl7N6BU30ecmDt338nLG1ZeUcFBcsgT44ANeF4vcXA4AvXpxIrh/f2D//fnMnBweeXl8U8jL8+LkMzI4KLkVqS7G3zCMxpGSQv/BB/z86U+DXzN7NgXnsMMS06bG4nLo//gjBTAUYihi//50Ta1cSUF84QVOuLoIihkzaNm78MbvvqNQjxtHaz8elnYoxO0Z3bFtmxcNUlLCN41169j26dPpLmosOTnsb+fO3sKoUIiD3vbt/N20a8cjK8uLcsjK4qRsu3YcLFwoZlYW0Ls3j86dOc9RWsrfpVsRnJNTO5WCc2n5I0v88ehuMZl/NXBVFX/fkXH0QO24dPcsexMy4klKCv2HH3InqaCRFdXVdPUMG1ZzqX8y2LaNbxcffgi8+SZDJAFauxdeCFx/PXDccbGFYMkS4Oab6afv1YsRN7m5nHu45x7giCPi19aMDK5g3Xff+usCfBtZtcpbeVtWxjmCnTv56WLoXa4aN2dQWsqBY8cOTrCvXw988QXrOBGvquK5ggLvbUeE99yxg9c7srM5GMUzrUK8cQNCtFQF/lA9/0Isf/4cf4hkZLikf8CJNh/jX/gERA/X9A9cdcXLx6KuFA3Rfm7oPeNRryH3aUwfotXbe2++nceblBP60lLu9/q73wW/5rPPKB4XXJC4dtVHVRWt7VtvrZmHpm9fhkVeeCEXMQEMoczP56KngQNZ9vbbwLPPAm+9RZfM448Dv/1t85o87dgxeTH8zg3lUjeEQpyTWbWKk9NuVW1mprfytrzcS59QWVnTreVfAeq30KuqvPpODN1q08g4+mhx6f7UDZGJxSJzzPjfGFybIs/5r/c/JzK23983fz1/LhvXZqB2/HxDFh/FioVvTIx8rPp15aiJB03tQ6x65eVNb1s0Uk7oP/2UFuHQocGvefVV/oGffXbi2lUX8+ZRlBcu5PeuXYHf/IZl3bt79ZYto1X+yiteWVYWBWrbNrozbrmFg4XtdVsTZ306MjI8141hpDopJ/QffEDRPumkYPVVKfRDhyYuc1w0QiHgtddoec+d61ljd9zBqBi/JV5ZCdx5J/DYY3TD3HMP/fGLFzOl6ebNTNr2s58l3/VkGEbzI+Vk4YMPGDmTlxes/qJFzNly552JbdfmzbS2Fy/2cr3s2sWJVRHggAOA55/ndod+1q1jlMwnnwBjxgB/+Ys393DwwcGzchqG0XoJtDJWRIaJyHIRKRCR26OcP1VEtovIwvBxb9Br48mmTfRfN9Rtk5YGnHtu4tq1aBFw7LFcxNWlC3DiicCvfsX0DJs3M9Txyy9ri/wnnzCT5oIFwKRJwL//bUv3DcNoOPUKvYikA3gCwFkABgAYJSIDolT9RFWPDB/3NfDauPDRR3TFNFToTzopMQKqym0Mhwxh9Mfs2Qx7vPpqboby5pvA73/P0EN/MqNQCLj3XkbKtG3LyeJLL41/+wzDaB0EsegHAyhQ1UJVrQAwFcB5Ae/flGsbzAcfMNQu6KYh331HV0q8o23Ky71UwCNHMjJm/nw+b+BACviXXwJPPQX87W81JwkLC4GTT6aLZvRo1ou2AMowDCMoQYS+J4DVvu9F4bJIhojI1yLyjogc2sBr48IHHwCnnRZ8QnL6dH7GS+i//54RL/vuC1x1FcPOnn4aePdd4O67maZABBg/nknHrrnGu7ayEnj4YYr60qXcMGXixOCZNw3DMGIRRBKjhfxHRoh+CWA/Vd0pIsMBvAagX8Br+RCRMQDGAEDvRsS8lZXRD96QtAdTpvCapoTYqXJx0iOPcJFTejr9/b/7HS33TZuYRXLOHLpj/vSn2jm+Z80CbryRbxfnnw/84x/BFyEZhmHURxChLwLgl51eANb6K6jqDt/PM0TkSRHpHORa33XjAIwDgEGDBjV4WUNuLq3goCxcyB2XnniioU8ioRBzz/z1r5ws7dmT7pZf/cpLc/zWW8B11zHPzNSpjJ5xbN7MBU5PP834+N69uTo3kZPCDrftn9s6z5bbG0ZqE0To5wPoJyJ9AawBMBJAjalBEekOYIOqqogMBl1CmwFsq+/aZDFxIoVu5Mjg16hy6f2kSZxk3biR2RvHj2fCsOxs1isooIX+9tvAIYdwEvbYY737LF1Ka7+4mKGgzzzDTbvdytdEsGMHXVUvvMA3j8hl9O7wr6B0e7K6hGJupyX/tenp3mbdIjVXlLq9TdPSau7GlJXFPDIuJ43b1Sgnh7+D3Fxvab1/39XIHDP+VZ9u4Zg78vJ4uPxA/sOf/iBy/9OMDC/hWlZWzRQBfvy/MyB6moDIPVn956J9j5bqoK7rY52v73n+9kbuWxu5h21kuyLb64i2X22sZyeKyJ26GnpNcyA3ly7eeFOv0KtqSESuB/AugHQAE1R1iYhcEz4/FsBFAK4VkRCAMgAjVVUBRL02/t1oGBUVFOvzzgu+JH/jRvrUp0+nqI0YAVx2GUMj/XMC8+YxmVpGBvDoo8ANN9TMvFhQwKig9HSmMTjmmPj2zbFwId8WfviB6wRWrKDA7b8/8Mc/Mn6/ooKHfzm8f2m/27PVLed3uVD8rqfKSi9RmKq3f6zbH9Ytq/dfV1Hh5bRxz3KbfpeW0g3nF3N/eoDIDbedsFRWMpfO6tW8x65dPKqqvHa7xGSRm337n+H2rXVtMIw9SbduiRF60T29Q24ABg0apPn5+Qm7//Tp3KxjxoxgPv3p05mSYPt25p259troq2jXrqVwt2lDK75nxLTzjz8ylLO0FPj4Y2BAAgJNV63iytkXXmA7Dj6Y+XIOPJBuoboSohk1iUzXHG1/1Vj5YCL3ZHVEy8nivyZaTpu6rq8voVhkTpVo1nakte7/2d+eyPb67xttv9o9KS1B3pyCXBOPdjTl7ystjWLfGERkgapGjTlMuZWxQZg4kXnSzzij7nobN9IFM2UKFy599BE324hGeTkHj5IS5nyPFPmiIuD00+lCmTUr/iJfUsL5gscf5/dbbwVuv53Z8IzG4VxPhtHSSdk9Y2OxYQN956NHx/4jVqXf/OCDgWnTgP/9Xy5aiiXyqpx0/fxzphiNzGn/44/AKadw4HjnHeCoo+LXn+pqDlwHHcStAy+5hPH6Dz1kIm8YBml19sqkSXzd/uUvo59XZdbIsWO5reDTT3NCtb57TpjAWPmf/7zmuZUrGdu/dSst/cGD49ELtvPNN+mmWbSILpnXXqudRsEwDAOq2uyOY445RhPBihWqXbqoDhkSu84jj9DjeMstqlVV9d9z3TrVvffmPUOhmueWLlXt3Vu1QwfV+fOb1PT/n6oq1TffVB08mO3s10918uRgbTUMI3UBkK8xNLXVuG527mSUTUUF3TLRmD6dG2xffDFXqabV89txLpvSUlr0/hC8OXP4RlBeTp980LQMsSgr48Ykhx7KiJ/16xnWuXQpMGpU/W01DKP10ipcN9XV9MkvXkwfef/+tevk5zNccvBgLmQKIpwvv8ykaA8+SH++49VXmYSsd29g5kyGNDaWH38EnnySLqQtWzgpPGkSByPbMNswjCC0CqG/7z76r//+d27OEcnatQw97NqVq1Nzc+u/56ZN3L/12GOZZ97x0UcU4Z/8hCtnG7rTU1UVE5nNmsXcPbNmsfz88xmTf/LJFh5pGEbDSHmhLylhHppLLom+j2xZGUV0xw4udgoaw/rQQ0xj8OGHXvTOli18czjwQOa/8aceDkJBAfeGXbSI3w89lK6ka67hJt+GYRiNIeWF/qWX6EO/6abalrAqc8PPn0//fNB0wBs30p0yapR3jSp3gNq4kaGYDRX5t9+m6yg9nXMIZ53V+IUThmEYflJ+Cs/Fw0cLO/z734HJk4H776dVH5THHuObwN13e2UTJjDm/v776UcPSnU1V9uecw59+QsWMPTTRN4wjLgRKxwnmUe8wiuXLWMI4sMP1z5XUqLasaPqsGGq1dXB71lcrJqXpzpqlFc2fTrLfvrThoU5bt2qes45bOPo0aqlpcGvNQzD8IPWGl45cSJdIaNH1z43fjx96vfe27DJzcceoyvonnuYfXLkSG5c0q8fV8UGDXNcsoQRPjNnAv/8JyN9gkwCG4ZhNJSU9dGHQhTP4cOB7t1rnquspGCfdBL3cw3K5s0U5Usuocvl0EOBbduYh/6Pfwwe7jhvHjBsGIV91iy2I1Fs28bkbXPmMFNn797Mw5Oe7mWtdJkdMzKYmjc7m5/+bJUuVa/LAJmV5eWzd6mIHS5ZVKwBNDJpl2EYiSVlhf6994B164Arr6x9bsoUprMdOzb4/VQZ/VJaCtx5p3ffL7+sndumLubM4URr9+4U+cbsJLVjByeQlyzhUVjIsp07mWK3XTvmuams5KASCnFLwtJSLyd8vHF53f0ZDN2gkZ7OtlRU8NNPmzacuM7Lq5kF0Q08mZlevnuX897VS0/3Bht/LvucHK9+VRXTFe/cyee7trpr3eGuycjg/EtpKX+Xrn6snOzRsjn6r4l1fX2/y6B53d3vK9pz6numO+dP9xwrv3597awrx/6eoqnPag5GR5s2zI4bb1I2TfFFFzFVcFER/5Ad1dXAEUfwP/TXXwf/x334YVrtjzzCa2+5hQNGQzYu+fhj4OyzgV69KPJuJ6r6KCtjwrSPPmJs/eefe4LdqRPdRu3bUzCzsyn627ZRVE87jSuCBw9m39etA9as8YTSibPbkMPlqN+9m2UuFa873OYdrp7LZx+Zd7662rtPVZUnqM76d/nunQjv2lVTdFz+eX+++/Jy9tkJi6vjzrtc9uXlXllaGge5tm29jU6Amv119/YLZm6ut5FMrFS9jlhpiiOv9b/JxCLyWdGe5y/3i7QT/cjn1fUso3nRrRtXvTeGVpemuKyM4YpXX11T5AGWL1kCPP98cJF//33gjjvosjn/fA4U55xTc2vA+sjPpxupTx/G3ke6kxyFhQzPLCriW8fChdzVym3SceyxTD98yikM7ezWLXg/0tL4BtFa9qOtz4UUiRvE3JtDayBycHC7fQHBB6TIASPWgJhImvqs5jLoJer/XUoK/ezZtNCGD69Zrsqc7b17BxfpVasYLz9gACdwzz+fVulTTwX/RykspCXftWtskV+3jmGW48d71nr79kzXcMMNFPYTTwQ6dAj2TKPhfzStMf+8c2MZqU2g/9YiMgzA38HtAMer6oMR5y8D8Mfw150ArlXVr8PnVgIoAVAFIBTr1SKevPsurbJTTqlZPmMGreV//zvYxGllJV0zlZXAXXfRHTRrFkW+V69gbdm8mT75ykrm2YkU+U2buFnI3/5Gq/3aazkX0Ls3XQ6GYRhNJlbcpTtAcf8BwP4AsgB8DWBARJ3jAewd/vksAJ/7zq0E0Lm+5/iPpsbRDxigesYZNcuqqlSPPFJ1//1VKyqC3efWW/liOmAAPzt3Zkx+0Fj5ZctUjztONTtb9ZNPap4rKlK98UbVNm1470suUf3++2D3NQzDiAR1xNEHsegHAyhQ1UIAEJGpAM4DsNQ3WMz11f8MQEB7N/6sXs3Uvb/6Vc3yadPo737uufqt+U2bmDLhhRf4fft2Wt2//jWjQ+rjxx+ZSG3iREZzTJpEtwvASdIHHuCq3FCIWS5vvz0x+8cahmEACGTRXwS6a9z30QD+VUf9P0TUXwHgSwALAIyp47oxAPIB5Pfu3bvRo9r48bSQv/nGKwuFVA8+mJZ55OYgfqqqeH2HDrxH27aqU6eqVlYGe/ayZapXXaWalcXjxhtVN2zguepq1X/8g6txRbgStrCw0d00DMOoAZpo0Ueb0oo6Ry0ipwG4CsCJvuITVHWtiHQF8L6ILFPV2VEGnHEAxgEMrwzQrqjMnMkFQf79XSdNApYtA155pebEkyqTkK1YAfzwA63s+fMZnZKbW/c+sX6++45ROdOnc27gqqtopffuzfMVFUx49uyz3JD84YeBI49sbA8NwzAaRhChLwLgD8jrBWBtZCUROQLAeABnqepmV66qa8OfG0VkOugKqiX08SAUYpz5BRd4ERfV1Uw0dtRRLAcozJMm8fjhh8h+0J1y993RNyjxU1LCez/+OF00d97JCJmuXb0627cz9fCHH9Kdc/fdrSd0zzCMZkIsU189l0oGgEIAfeFNxh4aUac3gAIAx0eU5wHYy/fzXADD6ntmYydj586ly2XqVK/s7bdZNnky3SdXXMHvIqqHH666zz78npPDc999F+xZM2Z41/7yl9w7NpLVq/mMjAzViRMb1SXDMIxAoCmuG1UNicj1AN4FI3AmqOoSEbkmfH4sgHsBdALwpNBcdWGU3QBMD5dlAJisqjObPjxF5913aS0PHeqV/eMfQI8etKoff5zuk+uvp6X9/PNc/HTvvQyjbN++/mdUVDDU8tFHmfpg2jTguONq1/vmG4ZVlpTQnXT66fHrp2EYRkNIqRQIQ4bQ7/7ZZ/y+fDlz0d93H1MBnHoqBXfTJuaoue02ul6CxNTv2kW30P/9H/34114L/L//Fz3j5KxZdBPttRdj9484osFdSRjffMO5hB07vJWgeXlciNW+fc1cMW3bssylV8jLYy6OrCxzPxlGc6NVpEAoK6Pv/frrvbJ//YuidMEFwJlncpHTkiUU7ddf5z6xsdi5k5uAfP45c9R8+CFzonTqxEndCy/06paXA199Rcv9nXeY7mDAAP6cjHQD69czO+f06dyC8PDDgS5d+Pbx5ZcU6TZtvOyU/oRfQUlL4/U5ORwEXD4Z93NurpfZEvDyyoRCNRNhpaV52TFzc73BxCUlc4nRXMbM9HTvutxcPssd7vkukZrLtumfgK+u5r9XRYW37D0yn4/L3aNaO6Gaw/9zZCqAutIDREt2Fo1Y9pdLU+COaM+KVubPhxPt3v5/j1h1gtqEDc1KGg+joa62xcuWTZRN7L9venpiNCOlLPpQiH/EbdvSYu3ZkyK/fTvdOn37MofMnDnAwIHR77FqFSNmXnrJS3J14IFMYXDuuUwpvHs3RXzGDA4GS5dSHNLSuJPV8OEccBKVrmDrVu4rW1bmJfFyCcYWLWIahYoKboS+aRMHt7IyTkhfeSVTOkRuWl5ezhh/lxCsvJwDwPbtLN+1i0nDdu3yBNv9vnfupIuqpITnS0q8TJkuMZo/qRlQO79KKMQ27trFIzLLZVNIS+NAodrwAc0w9iSW1CwAGRneXq0TJ1KAzj0XuPhi4KCDgO+/B958M7rI79zJDb8ffZTfb7qJbp5jj/VE8auveK+ZMz3rfvBgYMQIbh946qksSwQ7dvAt5MUXmYI5lhBmZAC/+AUHq379WFZVxU1WunSJff+cnNiJ1pKBE+Xdu2tm1fRbs6Wl3gCzc6c34LiMmm6gcde7rJQ5OZ77yR3uDcD/FiDC69zg52+b/+dYaYwjy6JZ3ZF9DpKa2GUIrSslsT8TqN+6j5ZW2H/eJTWLZZXXZ31H9jFI/XhR17Pi5WpsyH2C9D/yvonafCilhN5RXs7cMUOGAHPn8j/8d98xR81ZZ9Wsu2IFXTz/+Q+t11GjgAcf9GLgAYrFgw8y6djeewO/+Q1dNyeckNiEUBUV9Pc/9xzdMOXlbNfvf894/HbtvHS6zmJu146Hw6UCLi3lALF0KQc8/0Dh31jEiYgTCT9+N4vLFe+vJ8Iy57Lxi41zj6h6ycOiPc/97O7jXDbuZ9cn90fk8tD7B6m68qRH20jFXxbp3ojM1+5/RjRi1Yn2c1153OP1jLqIJeT1PdfmZ1oeKSn0Dz1EAf/73xkTX11NV8o113h1SkqAm2/mpt4iTFh288200P0sWsTFTp9/zsicJ57gTk3xJBTiJOlnn/FYvpxpFNavp+B07MiUDpddxsFr507mlF+/Hli5kpkv3bFhA901mzfTit+5s/bzOnTwLAdnxTkL2FnLkRuUOPHz1zGM+ggyWLVUEtGHbt34tx1vUk7oCwqYS+Z//gdYu5ZC16MHLXLH559TNFesoHV80021J0BWr+a+sM89Ryu+oZuMRKO6mm0qLOSxcCEjeL76iv5pgP/Qhx3GuYCsLG9yctUqDlYrV9JHH0lWFjcy6d6dcxOHH84Bol07TlS2b0/31YABdbtwGtIXt9mIv8xtFuImM91A4nc3+Dcw8Q8s/olGdx+3K5U7Ii31yEGprolQ//1d2/3zCO6I5m7xD2x1TZQG/TlW++L5jLqINdla33MjPxv6jKDXNncS1Qfneo43KSX0qhTDrCxGnQwKT0s88wwFc+dOCv6DDzIC57//rblf64YNnLR95x26SlS5k9Qdd9S04jdtoqX/3Xc1/Z7Op1xWRou8sJDCvH27N3Hq/w+Sk0NRHzqUP5eXs/6cOTV9wjk5nEju04cx+336sP09enBg6N6dg9GetJLS0mpv6mIYRvMkpYR+2jQK9d/+xs1H1q3jZOrQoYxEueceujtGj6bYFxZyEdWCBQyJXL6c9+nalROat95K6/mll+jb/vZbRrCsW1d/W7p2Bfbfn1E4zlWybZs3EBQX83n+4KI+fZhb58wzaX0fdBAjfnr0qLn5tmEYRkNImfDKkhLgkEPolpg3j66YTZtotf/hDxTUww+n6+Lbb4HFi73X8X32oWXdpQsjbHbupKB/9ZVnWefl8f4DBnAB1MCBzIWj6oUTZmezXm4urftt2/iWMGMG8OqrDO0EeL5/f97jmGN4HHFE4l7bDMNIfeoKr0wZoQ+FgH/+k66NO+7gIqejj2bSst27aVWvX093w6mnctK1d2+e/+gj7svq6NKFK2oHD+b9DjmEbpWCAmbBXLKER0FBsLjs7Gxa6RdeSFfRfvuZhW4YRnxpFUIPUOx//nPGynfoQIu6XTvGoJ90EnDFFRTbrVuZ+uDZZzkZN3gw4+2HDqWlnZXFsMz33qMraNEi7xkidMkceijr7r03LfE2bbxJvlCIZR068Bg0yLYFNAwjsbSKBVOlpRTxmTMZG71tG90ou3czCqdvX4Ywjh7Nydb0dP584YUU+zVruKPUvHnA119TrDMzGSt/33102TifeaIWNRiGYSSClLHoS0sZVrhtG0VcldEoffpQvF03MzJix4Hn5dG6HzKEAn/yyeY3NwyjZdAqLPp16xjGmJnJeOvsbMasrw1vkdKhgxfJsu++dLl07MjJ1549eXTtmtiVroZhGMkgZYS+a1da7ytW8Pvu3ZxUveIKLo4aODA1VuMZhmE0lJQR+g0bPJHv0YOx9BdfbOJuGIaRMkJ/wAFMJXzeeUzFm5EyPTMMw2gagaK5RWSYiCwXkQIRuT3KeRGRf4TPLxKRo4NeGy9EgLfeAn79axN5wzAMP/UKvYikA3gCwFkABgAYJSIDIqqdBaBf+BgD4KkGXGsYhmEkkCAW/WAABapaqKoVAKYCOC+iznkAngtvRv4ZgA4i0iPgtYZhGEYCCSL0PQGs9n0vCpcFqRPkWgCAiIwRkXwRyS8uLg7QLMMwDCMIQYQ+WtxK5CqrWHWCXMtC1XGqOkhVB3WJR8J0wzAMA0CwqJsiAP5tOXoBWBuwTlaAaw3DMIwEEsSinw+gn4j0FZEsACMBvBFR5w0AvwhH3xwHYLuqrgt4rWEYhpFA6rXoVTUkItcDeBdAOoAJqrpERK4Jnx8LYAaA4QAKAJQCuLKuaxPSE8MwDCMqKZPUzDAMozXT4vLRi0gxgFWNvLwzgE1xbE5LoDX2GWid/W6NfQZaZ78b2uf9VDVqJEuzFPqmICL5sUa1VKU19hlonf1ujX0GWme/49ln29DOMAwjxTGhNwzDSHFSUejHJbsBSaA19hlonf1ujX0GWme/49bnlPPRG4ZhGDVJRYveMAzD8GFCbxiGkeKkjNDvqQ1Oko2I7CsiH4nItyKyRER+Hy7vKCLvi8j34c+9k93WeCMi6SLylYi8Ff7eGvrcQUReEZFl4X/zIanebxG5Kfx/e7GITBGRnFTss4hMEJGNIrLYVxaznyJyR1jflovImQ15VkoIfSvb4CQE4BZVPQTAcQCuC/f1dgAfqmo/AB+Gv6cavwfwre97a+jz3wHMVNWDAQwE+5+y/RaRngBuADBIVQ8DU6eMRGr2eSKAYRFlUfsZ/hsfCeDQ8DVPhnUvECkh9GhFG5yo6jpV/TL8cwn4h98T7O+z4WrPAjg/KQ1MECLSC8DZAMb7ilO9z+0AnAzgPwCgqhWqug0p3m8wB1euiGQAaANmvE25PqvqbABbIopj9fM8AFNVdbeqrgDzig0O+qxUEfrAG5ykEiLSB8BRAD4H0C2cMRThz65JbFoi+BuA2wBU+8pSvc/7AygG8EzYZTVeRPKQwv1W1TUAHgXwI4B1YCbc95DCfY4gVj+bpHGpIvSBNzhJFUSkLYBpAG5U1R3Jbk8iEZFzAGxU1QXJbsseJgPA0QCeUtWjAOxCargsYhL2SZ8HoC+AfQDkicjlyW1Vs6BJGpcqQh9kc5SUQUQyQZGfpKqvhos3hPfpRfhzY7LalwBOAHCuiKwE3XI/FZEXkNp9Bvj/ukhVPw9/fwUU/lTu91AAK1S1WFUrAbwK4Hikdp/9xOpnkzQuVYS+1WxwIiIC+my/VdXHfKfeAHBF+OcrALy+p9uWKFT1DlXtpap9wH/bWap6OVK4zwCgqusBrBaR/uGi0wEsRWr3+0cAx4lIm/D/9dPBeahU7rOfWP18A8BIEckWkb4A+gH4IvBdVTUlDnDjk+8A/ADgrmS3J4H9PBF8ZVsEYGH4GA6gEzhL/334s2Oy25qg/p8K4K3wzynfZwBHAsgP/3u/BmDvVO83gD8DWAZgMYDnAWSnYp8BTAHnISpBi/2quvoJ4K6wvi0HcFZDnmUpEAzDMFKcVHHdGIZhGDEwoTcMw0hxTOgNwzBSHBN6wzCMFMeE3jAMI8UxoTcMw0hxTOgNwzBSnP8PUIm+6sT3yuQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weight_history_to_layer_max_magnitude_and_means(w_avg, include_batch_norm = True):\n",
    "    weight_keys = [x for x in w_avg.keys() if \".0.weight\" in x]\n",
    "    if include_batch_norm:\n",
    "        weight_keys += [x for x in w_avg.keys() if \".1.weight\" in x]\n",
    "    def max_magnitude(t):\n",
    "        return torch.max(torch.abs(t))\n",
    "    def mean_magnitude(t):\n",
    "        return torch.mean(torch.abs(t))\n",
    "    all_means = [mean_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    all_max = [max_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    return all_means, all_max\n",
    "max_history = [weight_history_to_layer_max_magnitude_and_means(baseline.avg_weight_history[t], include_batch_norm = False) for t in range(100)]\n",
    "max_history = [x[1] for x in max_history]\n",
    "by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "[plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d35b2be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model.0.0.weight': tensor([[[[-3.7603e-02, -1.3233e-02,  1.1132e-02],\n",
       "           [-5.7451e-02, -2.4503e-02, -1.1117e-02],\n",
       "           [-1.0219e-01, -6.1738e-02, -4.3983e-02]],\n",
       " \n",
       "          [[ 1.1228e-02,  1.7567e-02,  5.9407e-02],\n",
       "           [ 4.2183e-03,  2.1169e-02,  5.1397e-02],\n",
       "           [-2.2507e-02,  6.4356e-03,  2.9973e-02]],\n",
       " \n",
       "          [[-2.1787e-02, -2.8352e-03,  5.5353e-02],\n",
       "           [-6.3840e-03,  2.4491e-02,  6.3223e-02],\n",
       "           [-2.4264e-02,  1.8343e-02,  4.6849e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2990e-02,  1.9336e-02,  2.4006e-02],\n",
       "           [ 2.1089e-03,  2.0810e-02,  5.3625e-02],\n",
       "           [ 9.2238e-03,  3.2443e-02,  5.7530e-02]],\n",
       " \n",
       "          [[ 1.5595e-02,  2.4539e-04, -9.6424e-03],\n",
       "           [-2.7026e-03, -9.6087e-03,  8.4838e-03],\n",
       "           [ 1.7049e-03,  3.3893e-03,  1.7342e-02]],\n",
       " \n",
       "          [[ 8.5722e-04, -8.4956e-03, -1.5597e-02],\n",
       "           [-3.8379e-03, -3.7762e-03,  1.3678e-02],\n",
       "           [-6.3070e-03, -1.5458e-03,  1.4570e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5506e-02,  1.5084e-02,  9.5858e-03],\n",
       "           [ 1.1672e-02, -5.2103e-03, -1.8314e-02],\n",
       "           [-1.3357e-02, -1.1514e-02, -2.8014e-02]],\n",
       " \n",
       "          [[ 1.0380e-02,  1.8982e-02,  1.7885e-02],\n",
       "           [ 8.1018e-03,  2.4996e-03, -4.0462e-03],\n",
       "           [-7.1253e-03,  3.7759e-03, -3.9130e-03]],\n",
       " \n",
       "          [[ 1.3209e-02,  2.4413e-02,  2.3303e-02],\n",
       "           [ 9.0905e-03,  1.2498e-02,  9.6388e-03],\n",
       "           [-1.6381e-02,  5.0515e-05, -5.5143e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7742e-02,  1.2579e-02,  3.7447e-02],\n",
       "           [ 7.3706e-03,  2.9116e-03,  3.3668e-02],\n",
       "           [-1.0146e-02, -9.7933e-03,  2.4013e-02]],\n",
       " \n",
       "          [[-3.0252e-02, -2.3376e-02,  1.2625e-03],\n",
       "           [-2.6906e-02, -7.5434e-03,  1.9202e-02],\n",
       "           [-3.4303e-02, -1.5111e-02,  1.5474e-02]],\n",
       " \n",
       "          [[ 6.0426e-03,  1.5346e-02,  1.7903e-02],\n",
       "           [ 1.6314e-02,  4.0867e-02,  4.7620e-02],\n",
       "           [ 3.0592e-03,  2.5172e-02,  4.0436e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.8394e-02, -3.7934e-02, -4.0301e-02],\n",
       "           [-5.6390e-02, -3.7032e-02,  3.8413e-03],\n",
       "           [-5.1214e-02, -4.3251e-02,  3.2145e-02]],\n",
       " \n",
       "          [[ 4.3607e-02,  6.3013e-02,  3.5791e-02],\n",
       "           [ 2.2921e-02,  4.0435e-02,  5.0077e-02],\n",
       "           [ 1.5788e-02,  2.0206e-02,  6.6867e-02]],\n",
       " \n",
       "          [[ 6.1395e-03,  3.2508e-02,  2.5244e-02],\n",
       "           [-8.1200e-03,  2.1583e-02,  3.5183e-02],\n",
       "           [-4.0698e-02, -2.2311e-02,  2.6801e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.4775e-02, -5.0329e-02, -6.7153e-02],\n",
       "           [-7.6537e-02, -8.8155e-02, -7.5338e-02],\n",
       "           [-7.6750e-02, -8.6688e-02, -5.6929e-02]],\n",
       " \n",
       "          [[ 5.1085e-02,  5.7759e-02,  4.1892e-02],\n",
       "           [ 2.8218e-02,  1.3904e-02,  1.7184e-02],\n",
       "           [ 3.5576e-02,  1.8298e-02,  3.2633e-02]],\n",
       " \n",
       "          [[ 4.9593e-02,  5.1240e-02,  4.1649e-02],\n",
       "           [ 3.6149e-02,  1.7160e-02,  1.7683e-02],\n",
       "           [ 1.8223e-02, -4.1269e-03,  1.3247e-02]]],\n",
       " \n",
       " \n",
       "         [[[-9.1571e-03, -4.0523e-03, -6.2613e-03],\n",
       "           [-3.0906e-02, -2.9654e-02, -2.4255e-02],\n",
       "           [-1.9215e-02, -2.9115e-02, -1.7014e-02]],\n",
       " \n",
       "          [[-2.9378e-02, -1.3832e-02, -1.8171e-02],\n",
       "           [-3.9944e-02, -3.0317e-02, -2.9570e-02],\n",
       "           [-2.8219e-02, -3.2169e-02, -2.3257e-02]],\n",
       " \n",
       "          [[-1.9733e-02, -2.6267e-03, -1.1837e-02],\n",
       "           [-1.4665e-02, -3.4321e-03, -1.0347e-02],\n",
       "           [-5.6864e-03, -7.3562e-03, -4.0594e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.4942e-02, -3.2366e-02, -5.0809e-02],\n",
       "           [-3.4541e-02, -2.1414e-02, -2.6719e-02],\n",
       "           [-5.4774e-02, -5.2711e-02, -4.8039e-02]],\n",
       " \n",
       "          [[-4.1151e-02, -4.4625e-02, -5.0445e-02],\n",
       "           [-3.5040e-02, -3.2369e-02, -2.9254e-02],\n",
       "           [-3.3642e-02, -3.9609e-02, -3.3262e-02]],\n",
       " \n",
       "          [[ 5.3749e-03,  5.1841e-03,  9.0014e-03],\n",
       "           [ 1.0421e-02,  1.7915e-02,  2.9618e-02],\n",
       "           [ 1.5177e-02,  1.5747e-02,  3.0840e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.8564e-02, -2.6639e-02,  5.0148e-02],\n",
       "           [ 4.5691e-02, -3.0452e-02, -2.7856e-02],\n",
       "           [-9.6473e-02, -1.5793e-01, -5.8479e-02]],\n",
       " \n",
       "          [[ 5.1269e-02,  2.8851e-02,  8.4538e-02],\n",
       "           [ 1.6707e-01,  4.7703e-02,  3.4201e-02],\n",
       "           [ 6.2476e-02, -2.6806e-02,  5.3658e-02]],\n",
       " \n",
       "          [[-3.9988e-02, -6.8723e-02, -1.7419e-02],\n",
       "           [ 1.1290e-01, -7.8795e-03, -4.3482e-02],\n",
       "           [ 1.3694e-02, -8.9640e-02, -5.0644e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.2473e-02, -3.4874e-02, -3.5672e-02],\n",
       "           [-5.5701e-02, -7.4321e-02, -7.6327e-02],\n",
       "           [-6.9276e-02, -9.1518e-02, -9.5845e-02]],\n",
       " \n",
       "          [[-1.3579e-02, -2.2436e-02, -1.7986e-02],\n",
       "           [-3.3031e-02, -4.6621e-02, -4.5915e-02],\n",
       "           [-2.6784e-02, -4.4032e-02, -5.2583e-02]],\n",
       " \n",
       "          [[ 1.6215e-03, -1.0554e-02, -4.5504e-03],\n",
       "           [-7.8357e-03, -2.3892e-02, -2.6984e-02],\n",
       "           [-1.0012e-02, -2.4667e-02, -3.6585e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5655e-02, -2.2111e-03, -6.7435e-03],\n",
       "           [-1.9740e-02, -2.6382e-02, -2.6716e-02],\n",
       "           [-3.8043e-02, -4.1996e-02, -4.5954e-02]],\n",
       " \n",
       "          [[-2.7200e-02, -9.2675e-03, -9.8199e-03],\n",
       "           [-1.2460e-02, -1.5471e-02, -2.1232e-02],\n",
       "           [-2.5001e-02, -2.5892e-02, -3.4709e-02]],\n",
       " \n",
       "          [[-2.7744e-02,  1.0613e-04,  9.4146e-04],\n",
       "           [-1.3876e-02, -7.0572e-03, -1.4933e-02],\n",
       "           [-3.3893e-02, -3.0750e-02, -3.9947e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.8636e-02, -8.9912e-02, -3.7896e-02],\n",
       "           [-2.4003e-02, -2.1811e-02,  6.6518e-03],\n",
       "           [ 1.2753e-02,  1.5692e-02,  5.5299e-03]],\n",
       " \n",
       "          [[-6.5140e-02, -7.8732e-02, -4.2371e-02],\n",
       "           [ 1.4703e-02,  7.9827e-03,  1.7581e-02],\n",
       "           [ 3.3197e-02,  3.1503e-02,  1.1494e-02]],\n",
       " \n",
       "          [[-5.7541e-02, -7.2608e-02, -5.2423e-02],\n",
       "           [ 2.2826e-02,  2.4982e-02,  2.7940e-02],\n",
       "           [ 3.3496e-02,  4.6792e-02,  3.2011e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.9708e-02, -5.1769e-02, -2.0161e-02],\n",
       "           [-4.2260e-02, -6.5640e-02, -1.3444e-02],\n",
       "           [ 1.4346e-02, -9.7188e-03, -7.7614e-03]],\n",
       " \n",
       "          [[ 6.4519e-03, -7.7240e-03, -3.1860e-03],\n",
       "           [-3.7146e-03, -3.8992e-02, -7.2667e-03],\n",
       "           [ 2.7514e-02, -4.6862e-03, -1.0006e-02]],\n",
       " \n",
       "          [[ 7.0860e-03, -5.5481e-03, -3.8866e-03],\n",
       "           [-2.0520e-02, -5.3825e-02, -2.1440e-02],\n",
       "           [-1.2596e-02, -5.0033e-02, -4.4239e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 7.7574e-03,  2.0232e-02, -1.2887e-02],\n",
       "           [ 4.7134e-03,  3.2861e-02, -5.1152e-03],\n",
       "           [-2.2360e-02,  9.4650e-03, -4.9659e-02]],\n",
       " \n",
       "          [[-1.4312e-02, -8.7948e-03, -8.4649e-03],\n",
       "           [-4.4716e-02, -3.2431e-02, -3.2657e-02],\n",
       "           [-6.8451e-02, -4.8886e-02, -6.3538e-02]],\n",
       " \n",
       "          [[ 4.5319e-02,  5.4194e-02,  5.5809e-02],\n",
       "           [ 2.4267e-02,  3.5050e-02,  3.4832e-02],\n",
       "           [-1.5921e-02, -8.5298e-03, -1.8452e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.8920e-02, -3.5200e-02, -3.7107e-02],\n",
       "           [-3.3192e-02, -3.2363e-02, -3.9608e-02],\n",
       "           [-3.4858e-02, -4.5965e-02, -5.6058e-02]],\n",
       " \n",
       "          [[ 6.9678e-04,  7.9425e-03,  4.5413e-03],\n",
       "           [ 8.4028e-03,  1.2707e-02,  3.5885e-03],\n",
       "           [ 1.9795e-03, -6.7245e-03, -1.7863e-02]],\n",
       " \n",
       "          [[ 1.2259e-02,  1.7734e-02,  8.9833e-03],\n",
       "           [ 1.2300e-02,  1.5702e-02,  4.0235e-03],\n",
       "           [-2.1502e-03, -1.1432e-02, -2.4488e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.1003e-02,  1.8537e-02,  5.2048e-02],\n",
       "           [ 1.5210e-02,  4.6699e-02,  6.0599e-02],\n",
       "           [-9.5027e-03,  1.5830e-02,  1.0678e-03]],\n",
       " \n",
       "          [[ 7.5156e-03,  2.9948e-02,  5.6938e-02],\n",
       "           [ 2.1443e-02,  4.1518e-02,  5.4065e-02],\n",
       "           [-4.9353e-03,  8.6084e-03, -4.5844e-03]],\n",
       " \n",
       "          [[-2.4866e-03,  1.8382e-02,  4.6917e-02],\n",
       "           [-1.2061e-02,  6.6716e-03,  2.7169e-02],\n",
       "           [-4.1776e-02, -2.6521e-02, -3.2296e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.0943e-02,  3.3200e-02,  3.2992e-02],\n",
       "           [ 5.0602e-04,  7.6590e-03,  1.8382e-02],\n",
       "           [-2.5863e-02, -2.2420e-02, -2.7311e-03]],\n",
       " \n",
       "          [[ 1.6399e-03,  1.0103e-02,  1.2496e-02],\n",
       "           [-2.4019e-02, -1.2481e-02, -9.7085e-04],\n",
       "           [-4.8327e-02, -4.2370e-02, -2.2413e-02]],\n",
       " \n",
       "          [[-3.5219e-04,  1.0960e-02,  8.5959e-03],\n",
       "           [-1.9221e-02, -3.3103e-03,  5.9089e-03],\n",
       "           [-4.1002e-02, -2.9216e-02, -1.1064e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.8533e-03, -1.1980e-02, -1.9637e-03],\n",
       "           [ 1.6881e-02,  5.5510e-03,  1.5090e-02],\n",
       "           [ 4.1246e-02,  2.8226e-02,  2.1058e-02]],\n",
       " \n",
       "          [[ 2.8934e-02,  2.0896e-02,  1.9640e-02],\n",
       "           [ 4.2861e-02,  3.2449e-02,  3.5818e-02],\n",
       "           [ 4.6332e-02,  3.2677e-02,  2.4944e-02]],\n",
       " \n",
       "          [[ 2.5281e-02,  1.7488e-02,  1.1941e-02],\n",
       "           [ 2.1270e-02,  8.5929e-03,  1.2547e-02],\n",
       "           [ 2.2414e-02,  5.6712e-03,  2.7088e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2931e-02,  1.0914e-02, -1.6639e-02],\n",
       "           [-1.2264e-02, -2.5667e-02, -3.8477e-02],\n",
       "           [-2.0059e-02, -3.1636e-02, -4.2242e-02]],\n",
       " \n",
       "          [[-2.0999e-02, -2.3792e-02, -4.1767e-02],\n",
       "           [-3.4285e-02, -4.3308e-02, -5.5747e-02],\n",
       "           [-3.8965e-02, -4.9073e-02, -6.3143e-02]],\n",
       " \n",
       "          [[ 5.0619e-05,  3.8274e-03, -7.3652e-03],\n",
       "           [ 2.1639e-03, -6.1589e-04, -1.2505e-02],\n",
       "           [ 3.0287e-03, -3.1130e-03, -2.1449e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.4567e-02,  1.6569e-01,  6.7214e-02],\n",
       "           [ 1.0700e-01,  1.5544e-01,  1.1044e-01],\n",
       "           [-2.5000e-02,  1.0950e-02, -1.0166e-02]],\n",
       " \n",
       "          [[-7.1921e-03,  4.2597e-02, -2.1033e-02],\n",
       "           [ 3.2825e-02,  7.9962e-02,  5.8384e-02],\n",
       "           [-5.8540e-02, -1.9668e-02, -4.1979e-02]],\n",
       " \n",
       "          [[-3.9124e-02, -1.4380e-02, -8.9321e-02],\n",
       "           [ 1.6052e-02,  5.7493e-02,  1.8652e-03],\n",
       "           [-7.6044e-02, -3.1335e-02, -9.3665e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4363e-03,  4.0067e-03, -2.4154e-02],\n",
       "           [-8.6429e-03,  1.0985e-03, -9.6020e-03],\n",
       "           [ 4.8630e-02,  4.2225e-02,  1.7309e-02]],\n",
       " \n",
       "          [[ 1.7296e-02,  3.3953e-02,  3.4604e-03],\n",
       "           [-2.3890e-04,  2.5289e-02,  1.0347e-02],\n",
       "           [ 2.3503e-02,  3.1555e-02,  7.9194e-03]],\n",
       " \n",
       "          [[-3.3818e-03,  5.1747e-03, -3.3787e-02],\n",
       "           [-2.5890e-02, -1.1570e-02, -3.0071e-02],\n",
       "           [-1.6732e-02, -1.3969e-02, -3.2030e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3373e-02, -1.8897e-02, -1.8347e-02],\n",
       "           [ 2.4045e-03, -4.4898e-03, -1.1008e-02],\n",
       "           [-2.7421e-03, -1.2833e-02, -1.6035e-02]],\n",
       " \n",
       "          [[-5.0747e-04,  1.8079e-03,  7.3409e-03],\n",
       "           [ 1.6390e-02,  1.5247e-02,  1.1726e-02],\n",
       "           [ 1.0386e-02,  1.8095e-03, -1.6238e-03]],\n",
       " \n",
       "          [[ 5.5352e-03,  7.2116e-03,  1.1753e-02],\n",
       "           [ 1.8262e-02,  1.5143e-02,  1.1207e-02],\n",
       "           [ 1.2616e-02,  3.1374e-03, -8.2451e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.6714e-01, -1.5297e-01, -7.9451e-02],\n",
       "           [-1.4795e-01, -1.2065e-01, -6.0737e-02],\n",
       "           [-1.2131e-01, -7.1314e-02, -2.5272e-02]],\n",
       " \n",
       "          [[-1.2065e-01, -1.2018e-01, -6.8695e-02],\n",
       "           [-1.1902e-01, -1.1551e-01, -7.2055e-02],\n",
       "           [-9.1861e-02, -5.9658e-02, -1.7070e-02]],\n",
       " \n",
       "          [[-1.0635e-01, -1.3134e-01, -1.0060e-01],\n",
       "           [-1.3091e-01, -1.6270e-01, -1.3471e-01],\n",
       "           [-1.2830e-01, -1.3856e-01, -1.0316e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.2346e-02, -2.3272e-02, -2.6706e-02],\n",
       "           [-1.5474e-02, -2.8956e-02, -3.1472e-02],\n",
       "           [-2.1735e-02, -4.2482e-02, -3.3658e-02]],\n",
       " \n",
       "          [[ 3.9304e-02,  2.6330e-02,  2.2669e-02],\n",
       "           [ 2.8622e-02,  6.0555e-03, -8.7356e-04],\n",
       "           [ 2.4874e-02, -6.6590e-03, -7.3011e-03]],\n",
       " \n",
       "          [[ 5.0041e-02,  3.1375e-02,  3.0286e-02],\n",
       "           [ 4.4831e-02,  1.8785e-02,  1.4431e-02],\n",
       "           [ 4.1628e-02,  1.0115e-02,  1.0189e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3592e-02, -2.4808e-02, -1.2058e-02],\n",
       "           [-4.8845e-02,  9.7467e-03, -5.4824e-02],\n",
       "           [-8.3218e-03,  5.2496e-02, -1.0421e-02]],\n",
       " \n",
       "          [[ 4.5069e-02,  1.4360e-02,  4.5830e-02],\n",
       "           [-1.1408e-02,  7.6367e-02,  1.1897e-02],\n",
       "           [ 4.3497e-02,  1.3131e-01,  3.7285e-02]],\n",
       " \n",
       "          [[ 2.9838e-02, -5.6125e-02, -3.4912e-02],\n",
       "           [-1.3653e-02,  1.4067e-02, -3.4075e-02],\n",
       "           [ 5.2587e-02,  9.7553e-02, -1.0483e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.3567e-02,  4.7746e-02,  3.5538e-02],\n",
       "           [ 2.0088e-02,  5.6525e-02,  6.3184e-02],\n",
       "           [ 2.2187e-02,  5.2962e-02,  3.7938e-02]],\n",
       " \n",
       "          [[-8.5279e-04, -5.5333e-03, -1.1594e-02],\n",
       "           [-1.4475e-02,  2.1392e-03,  1.0821e-02],\n",
       "           [-1.2729e-02,  1.9152e-03, -1.5979e-02]],\n",
       " \n",
       "          [[-2.6594e-03, -2.4098e-03, -1.3532e-02],\n",
       "           [-1.0236e-02,  8.5844e-03,  7.1881e-03],\n",
       "           [-1.5480e-02,  3.0216e-03, -1.5721e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.2994e-02,  1.4908e-02,  3.4044e-02],\n",
       "           [-1.8878e-02, -7.2750e-03,  1.2536e-02],\n",
       "           [-1.2610e-02, -1.0353e-02,  2.7261e-02]],\n",
       " \n",
       "          [[ 3.6013e-02,  4.1812e-02,  4.7547e-02],\n",
       "           [ 1.6335e-02,  4.5352e-02,  4.9549e-02],\n",
       "           [ 2.1738e-02,  3.5047e-02,  5.9060e-02]],\n",
       " \n",
       "          [[-4.5410e-02, -5.1915e-02, -4.0102e-02],\n",
       "           [-4.6516e-02, -3.1939e-02, -1.4673e-02],\n",
       "           [-2.2015e-02, -1.8531e-02,  1.9608e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.2275e-02,  2.9163e-02,  1.1039e-02],\n",
       "           [ 1.8936e-02,  7.9088e-03, -2.1370e-02],\n",
       "           [-2.0246e-02, -2.0855e-02, -2.1580e-02]],\n",
       " \n",
       "          [[ 4.4274e-02,  4.5308e-02,  3.1963e-02],\n",
       "           [ 3.2974e-02,  2.7600e-02,  6.3756e-03],\n",
       "           [-5.1170e-03, -1.8061e-03,  3.5642e-03]],\n",
       " \n",
       "          [[ 3.9375e-02,  3.7933e-02,  2.0258e-02],\n",
       "           [ 3.8567e-02,  3.7783e-02,  1.5436e-02],\n",
       "           [ 1.9933e-03,  1.5837e-02,  1.7029e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.4772e-02, -4.9933e-02, -5.5090e-02],\n",
       "           [-6.2429e-02, -4.1381e-02, -5.7801e-03],\n",
       "           [-6.8592e-02, -5.8116e-02, -4.3740e-02]],\n",
       " \n",
       "          [[-3.2810e-02, -4.7046e-02, -3.1281e-02],\n",
       "           [ 1.4830e-02,  2.4616e-02,  8.0475e-02],\n",
       "           [ 5.6559e-02,  5.5455e-02,  8.2893e-02]],\n",
       " \n",
       "          [[-7.0592e-02, -8.7003e-02, -6.2904e-02],\n",
       "           [ 6.3341e-03,  3.5733e-02,  8.2699e-02],\n",
       "           [ 5.8484e-02,  7.8845e-02,  9.2333e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2279e-02,  1.4098e-02,  1.7752e-02],\n",
       "           [ 5.4157e-02,  6.1378e-02,  3.8292e-02],\n",
       "           [ 7.3919e-03,  1.1007e-02, -3.2078e-02]],\n",
       " \n",
       "          [[ 3.3081e-02,  4.1223e-02,  4.4800e-02],\n",
       "           [ 7.1325e-02,  8.3847e-02,  6.2696e-02],\n",
       "           [ 5.1420e-03,  6.2840e-03, -3.1714e-02]],\n",
       " \n",
       "          [[ 2.6024e-02,  4.0154e-02,  4.4415e-02],\n",
       "           [ 4.1261e-02,  5.8713e-02,  5.1764e-02],\n",
       "           [-1.8834e-02, -1.0637e-02, -3.4135e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.3655e-02, -4.2090e-02, -3.7314e-02],\n",
       "           [-2.3648e-03, -5.7098e-03, -1.3317e-02],\n",
       "           [ 3.1542e-03,  4.7396e-03, -2.7594e-03]],\n",
       " \n",
       "          [[-6.4215e-03, -1.6420e-02, -1.7631e-02],\n",
       "           [ 8.7087e-03,  1.1497e-02,  8.8155e-04],\n",
       "           [-4.9573e-04,  4.3537e-03, -1.5566e-03]],\n",
       " \n",
       "          [[ 4.1859e-03, -1.3374e-02, -2.4658e-02],\n",
       "           [ 2.2240e-03,  1.3208e-03, -8.1552e-03],\n",
       "           [-1.0633e-02, -6.3024e-03, -9.1502e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.5700e-02,  3.1624e-03,  5.8382e-03],\n",
       "           [ 3.3899e-02,  1.3222e-02,  8.3112e-03],\n",
       "           [ 4.0122e-02,  1.7752e-02,  1.0322e-02]],\n",
       " \n",
       "          [[-2.2784e-02, -3.2424e-02, -3.4557e-02],\n",
       "           [ 1.1914e-02, -6.4841e-03, -2.0755e-02],\n",
       "           [ 3.2568e-02,  1.4158e-02, -2.7979e-03]],\n",
       " \n",
       "          [[-4.2358e-02, -5.5176e-02, -6.6403e-02],\n",
       "           [-1.0817e-02, -3.6916e-02, -6.3347e-02],\n",
       "           [ 1.1663e-02, -1.7214e-02, -4.5777e-02]]]], device='mps:0'),\n",
       " 'model.0.1.weight': tensor([-0.0874, -0.0984, -0.0506,  0.0539, -0.0483, -0.0435,  0.0776,  0.0239,\n",
       "         -0.0818, -0.1591,  0.0472,  0.0192, -0.0156,  0.0297, -0.0535,  0.0322,\n",
       "         -0.0694,  0.0478, -0.0424, -0.0917,  0.0011, -0.1165, -0.0522, -0.0386,\n",
       "          0.2048, -0.0367,  0.0110, -0.0600,  0.0614,  0.0246,  0.0595,  0.0178],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.bias': tensor([ 0.0808,  0.0009,  0.1024, -0.0007,  0.1595, -0.0817, -0.1136, -0.1185,\n",
       "          0.1073,  0.0866,  0.0574, -0.0014, -0.0238,  0.0080, -0.1259, -0.0064,\n",
       "         -0.0010,  0.0635, -0.0309, -0.1262, -0.0495,  0.0057, -0.0640,  0.0117,\n",
       "          0.0617,  0.0487, -0.1597,  0.1244,  0.1700,  0.0392,  0.0197,  0.0382],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_mean': tensor([ 0.0144, -0.1262, -0.0390,  0.1397,  0.0495,  0.0852,  0.2536,  0.0193,\n",
       "          0.0194,  0.2833,  0.0676,  0.0330,  0.1469,  0.0655,  0.1942, -0.0566,\n",
       "          0.0373, -0.1302,  0.0983, -0.1303, -0.0060,  0.0337,  0.7315,  0.0436,\n",
       "          0.0657, -0.1541, -0.0974, -0.0487,  0.0138, -0.1802,  0.0614,  0.0313],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.running_var': tensor([ 1.5788,  1.0277,  0.4229,  0.8118,  1.1227,  1.1753,  0.7498,  2.3024,\n",
       "          0.5382,  2.7946,  4.8755,  0.2133,  1.6350,  0.7244, -1.7144,  0.7521,\n",
       "          0.5699,  1.6399,  4.3919,  0.1901,  0.0279,  0.4088, 10.1813,  0.6840,\n",
       "          0.2419,  1.0767,  0.4538,  1.7368,  0.4548,  1.5172,  0.5019,  1.5939],\n",
       "        device='mps:0'),\n",
       " 'model.0.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.1.0.weight': tensor([[[[-0.0021, -0.0057,  0.0069],\n",
       "           [ 0.0033, -0.0075, -0.0043],\n",
       "           [ 0.0221,  0.0062,  0.0013]],\n",
       " \n",
       "          [[-0.0014, -0.0050,  0.0170],\n",
       "           [-0.0029, -0.0037,  0.0107],\n",
       "           [-0.0099, -0.0071,  0.0021]],\n",
       " \n",
       "          [[ 0.0112,  0.0091,  0.0060],\n",
       "           [ 0.0133,  0.0174,  0.0183],\n",
       "           [ 0.0045,  0.0096,  0.0086]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0117,  0.0040, -0.0183],\n",
       "           [ 0.0115,  0.0095, -0.0150],\n",
       "           [ 0.0057,  0.0128, -0.0075]],\n",
       " \n",
       "          [[ 0.0129,  0.0119, -0.0003],\n",
       "           [ 0.0086,  0.0147,  0.0078],\n",
       "           [ 0.0012,  0.0142,  0.0082]],\n",
       " \n",
       "          [[ 0.0079, -0.0071, -0.0257],\n",
       "           [ 0.0028, -0.0002, -0.0142],\n",
       "           [-0.0034, -0.0005, -0.0066]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0430,  0.0066, -0.0101],\n",
       "           [ 0.0270,  0.0119,  0.0273],\n",
       "           [ 0.0133,  0.0162,  0.0322]],\n",
       " \n",
       "          [[ 0.0114, -0.0524, -0.0379],\n",
       "           [ 0.0208, -0.0171,  0.0008],\n",
       "           [ 0.0160, -0.0054,  0.0288]],\n",
       " \n",
       "          [[-0.0453, -0.0400, -0.0028],\n",
       "           [-0.0364, -0.0255, -0.0040],\n",
       "           [-0.0265, -0.0107, -0.0028]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0051,  0.0157, -0.0013],\n",
       "           [-0.0128, -0.0101, -0.0004],\n",
       "           [ 0.0129,  0.0254,  0.0217]],\n",
       " \n",
       "          [[-0.0517, -0.0211,  0.0159],\n",
       "           [-0.0311, -0.0182, -0.0074],\n",
       "           [-0.0367, -0.0187, -0.0063]],\n",
       " \n",
       "          [[-0.0034,  0.0034,  0.0065],\n",
       "           [ 0.0069,  0.0065,  0.0075],\n",
       "           [ 0.0178,  0.0137, -0.0035]]],\n",
       " \n",
       " \n",
       "         [[[-0.0388, -0.0294, -0.0035],\n",
       "           [-0.0308, -0.0312, -0.0157],\n",
       "           [-0.0019,  0.0165,  0.0302]],\n",
       " \n",
       "          [[-0.0065, -0.0091,  0.0006],\n",
       "           [-0.0404, -0.0206,  0.0066],\n",
       "           [-0.0354, -0.0021,  0.0246]],\n",
       " \n",
       "          [[ 0.0013,  0.0263, -0.0026],\n",
       "           [-0.0160,  0.0017, -0.0122],\n",
       "           [-0.0226, -0.0197, -0.0234]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0318,  0.0321,  0.0425],\n",
       "           [ 0.0542,  0.0397,  0.0165],\n",
       "           [-0.0068,  0.0137,  0.0367]],\n",
       " \n",
       "          [[ 0.0168,  0.0242,  0.0104],\n",
       "           [ 0.0060,  0.0183,  0.0033],\n",
       "           [-0.0269, -0.0262, -0.0209]],\n",
       " \n",
       "          [[ 0.0417,  0.0270,  0.0116],\n",
       "           [ 0.0312,  0.0366,  0.0360],\n",
       "           [-0.0089,  0.0025,  0.0186]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0122, -0.0096, -0.0035],\n",
       "           [-0.0210, -0.0252, -0.0163],\n",
       "           [-0.0261, -0.0341, -0.0271]],\n",
       " \n",
       "          [[-0.0282, -0.0082, -0.0046],\n",
       "           [-0.0145, -0.0077,  0.0011],\n",
       "           [-0.0094,  0.0018,  0.0071]],\n",
       " \n",
       "          [[ 0.0145,  0.0047, -0.0034],\n",
       "           [ 0.0170,  0.0109, -0.0041],\n",
       "           [ 0.0252,  0.0201,  0.0027]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0178, -0.0369, -0.0468],\n",
       "           [-0.0050, -0.0247, -0.0290],\n",
       "           [ 0.0101, -0.0046, -0.0064]],\n",
       " \n",
       "          [[ 0.0131,  0.0074, -0.0035],\n",
       "           [ 0.0183,  0.0174,  0.0053],\n",
       "           [ 0.0186,  0.0216,  0.0141]],\n",
       " \n",
       "          [[-0.0211, -0.0242, -0.0279],\n",
       "           [-0.0116, -0.0113, -0.0095],\n",
       "           [ 0.0029,  0.0085,  0.0112]]],\n",
       " \n",
       " \n",
       "         [[[-0.0007, -0.0102, -0.0014],\n",
       "           [ 0.0030, -0.0188, -0.0074],\n",
       "           [-0.0034, -0.0347, -0.0286]],\n",
       " \n",
       "          [[-0.0122, -0.0284, -0.0179],\n",
       "           [-0.0105, -0.0376, -0.0207],\n",
       "           [-0.0021, -0.0334, -0.0179]],\n",
       " \n",
       "          [[-0.0289, -0.0140, -0.0078],\n",
       "           [-0.0130,  0.0133,  0.0117],\n",
       "           [-0.0016,  0.0318,  0.0295]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0206,  0.0159,  0.0056],\n",
       "           [ 0.0480,  0.0279,  0.0066],\n",
       "           [ 0.0413,  0.0390,  0.0188]],\n",
       " \n",
       "          [[-0.0245, -0.0013,  0.0061],\n",
       "           [-0.0083,  0.0224,  0.0167],\n",
       "           [-0.0038,  0.0276,  0.0285]],\n",
       " \n",
       "          [[ 0.0193,  0.0321,  0.0298],\n",
       "           [ 0.0041,  0.0057, -0.0083],\n",
       "           [-0.0078, -0.0013, -0.0031]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0102,  0.0230,  0.0037],\n",
       "           [ 0.0063,  0.0145,  0.0014],\n",
       "           [ 0.0097,  0.0113,  0.0027]],\n",
       " \n",
       "          [[ 0.0036,  0.0186,  0.0183],\n",
       "           [-0.0065,  0.0120,  0.0014],\n",
       "           [-0.0134, -0.0040, -0.0101]],\n",
       " \n",
       "          [[-0.0023, -0.0386, -0.0259],\n",
       "           [ 0.0062, -0.0188, -0.0116],\n",
       "           [ 0.0163, -0.0140, -0.0129]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0242,  0.0314,  0.0345],\n",
       "           [-0.0025, -0.0019, -0.0019],\n",
       "           [ 0.0180,  0.0106,  0.0080]],\n",
       " \n",
       "          [[-0.0051, -0.0224, -0.0091],\n",
       "           [-0.0067, -0.0177, -0.0157],\n",
       "           [ 0.0091, -0.0081, -0.0116]],\n",
       " \n",
       "          [[ 0.0385,  0.0392,  0.0329],\n",
       "           [ 0.0219,  0.0189,  0.0076],\n",
       "           [ 0.0128,  0.0096,  0.0013]]]], device='mps:0'),\n",
       " 'model.1.1.weight': tensor([-0.0468, -0.0480, -0.0592,  0.0608, -0.0723, -0.0490,  0.0998, -0.0223,\n",
       "          0.1010,  0.0560, -0.0793,  0.0272,  0.0211, -0.0610, -0.3088, -0.0516,\n",
       "         -0.0156, -0.0250, -0.0906, -0.0007, -0.0158,  0.0568,  0.0612, -0.0557,\n",
       "         -0.0393,  0.2388,  0.1766,  0.0041,  0.0942,  0.0154,  0.0761,  0.0034],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.bias': tensor([-0.0162, -0.0951, -0.0685, -0.0118, -0.0543,  0.0463,  0.0770,  0.0516,\n",
       "         -0.0888, -0.0712,  0.0115,  0.0551,  0.0101, -0.0605, -0.1511, -0.0446,\n",
       "         -0.0882, -0.1262, -0.1573,  0.0148,  0.0149, -0.1181, -0.1026, -0.0564,\n",
       "         -0.0160, -0.1863, -0.0755,  0.0176,  0.0063, -0.0821,  0.0166, -0.0796],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_mean': tensor([ 1.8292,  1.7207,  1.5453, -0.1095, -2.4043,  0.3962, -0.7511, -1.6456,\n",
       "          0.9258, -0.2643, -0.5215,  1.2534, -0.8931, -0.0855,  0.0707, -0.0963,\n",
       "         -1.3079,  2.8336,  1.4511, -0.0656, -1.1473,  0.2111,  1.2125,  0.2036,\n",
       "          1.4083,  0.2237, -1.2746,  1.6774,  0.4127, -0.2655, -0.5621, -0.3835],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.running_var': tensor([-0.6237,  0.0660, -0.7841,  2.2541,  3.2504,  3.2918,  0.4248,  0.8634,\n",
       "         18.1871,  1.8356,  1.7140,  3.3661,  5.7715,  0.9228,  1.2054,  2.6456,\n",
       "          1.0998, -0.1713, -0.5140,  5.4090,  2.5656,  4.4976, -3.9543,  3.3687,\n",
       "          3.5681, 39.5576, -0.8253,  2.8556,  0.2844,  7.4303,  1.9567,  2.1662],\n",
       "        device='mps:0'),\n",
       " 'model.1.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.2.0.weight': tensor([[[[ 7.0081e-03,  1.7419e-02,  1.3509e-02],\n",
       "           [ 2.4292e-02,  4.0899e-02,  2.9082e-02],\n",
       "           [ 1.1784e-02,  1.8257e-02,  2.0642e-02]],\n",
       " \n",
       "          [[-1.0704e-03, -1.4293e-02, -2.7853e-02],\n",
       "           [ 2.9398e-02,  3.2730e-03,  5.0247e-02],\n",
       "           [ 1.6675e-02,  2.9329e-02,  4.2103e-02]],\n",
       " \n",
       "          [[-6.6874e-04,  1.3680e-02,  3.1891e-02],\n",
       "           [ 1.2278e-03, -1.3118e-02, -2.8903e-03],\n",
       "           [-2.6962e-02, -5.0441e-02, -4.8364e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.1860e-02, -3.8201e-02, -4.2502e-02],\n",
       "           [ 4.0074e-02, -1.1172e-02, -2.2070e-02],\n",
       "           [ 1.9095e-02,  1.4590e-02, -8.5742e-03]],\n",
       " \n",
       "          [[-4.8246e-03, -2.0450e-02, -4.3879e-03],\n",
       "           [ 1.2754e-02,  4.7029e-03,  9.1291e-03],\n",
       "           [ 2.2356e-02,  7.0508e-03,  1.3662e-02]],\n",
       " \n",
       "          [[ 4.5194e-03,  1.8611e-02,  2.6574e-02],\n",
       "           [ 1.6983e-02,  3.1482e-02,  3.6720e-02],\n",
       "           [-1.4533e-03,  9.5311e-03,  1.8779e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5089e-02, -1.0874e-02, -1.9516e-03],\n",
       "           [-4.2590e-03, -1.3526e-02, -1.1587e-02],\n",
       "           [ 2.3010e-03, -1.0254e-02, -6.9734e-03]],\n",
       " \n",
       "          [[ 3.4873e-03,  3.6265e-02,  3.1976e-02],\n",
       "           [-2.8161e-02,  2.8438e-03, -4.6256e-02],\n",
       "           [ 3.1512e-02,  2.8443e-03,  9.0559e-03]],\n",
       " \n",
       "          [[ 4.4698e-04,  1.3486e-02,  1.6910e-02],\n",
       "           [ 2.6923e-03, -2.8080e-02,  9.5227e-03],\n",
       "           [-2.2003e-02, -3.8816e-02, -3.1477e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.0875e-02, -2.3745e-02, -5.3525e-03],\n",
       "           [-2.5889e-02, -7.1161e-03,  1.4624e-02],\n",
       "           [-4.2648e-02, -1.8681e-03,  1.1663e-02]],\n",
       " \n",
       "          [[ 8.6740e-03, -8.1773e-04,  1.0015e-02],\n",
       "           [ 5.0079e-03,  7.8533e-03,  1.1573e-02],\n",
       "           [-1.3010e-02, -1.1700e-02, -4.5749e-03]],\n",
       " \n",
       "          [[ 2.3941e-02, -4.7746e-03,  2.0515e-02],\n",
       "           [-1.0016e-02, -4.6263e-02, -1.6272e-02],\n",
       "           [ 6.3500e-03, -2.6432e-02, -2.0742e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.2712e-03,  5.8980e-03,  2.2974e-03],\n",
       "           [-5.4839e-03,  9.1862e-03,  5.8583e-03],\n",
       "           [ 3.0668e-02,  3.4467e-02,  1.7656e-02]],\n",
       " \n",
       "          [[-3.2411e-02,  9.2387e-03,  7.4086e-03],\n",
       "           [ 3.3817e-02, -2.0282e-02, -1.6653e-02],\n",
       "           [-3.3121e-02,  2.7901e-03,  1.5976e-02]],\n",
       " \n",
       "          [[ 1.2388e-02, -7.3624e-03,  2.5312e-02],\n",
       "           [-1.4799e-02, -1.5423e-02, -4.9745e-03],\n",
       "           [ 1.0853e-02, -2.7829e-02,  8.1655e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.6119e-03, -3.0169e-04, -2.7304e-02],\n",
       "           [-4.0095e-03, -1.2371e-03, -2.5367e-02],\n",
       "           [ 2.4281e-05,  1.6496e-03, -6.4008e-03]],\n",
       " \n",
       "          [[-9.2847e-03, -9.3638e-03, -9.7299e-03],\n",
       "           [-1.2581e-03,  9.9514e-03,  7.4125e-03],\n",
       "           [-9.3237e-03, -1.9876e-03, -3.2203e-03]],\n",
       " \n",
       "          [[-1.8357e-02, -1.4261e-02, -1.5330e-02],\n",
       "           [-9.2834e-03, -3.7780e-03, -1.0204e-02],\n",
       "           [ 1.4233e-02,  2.6713e-02,  1.9053e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 4.3135e-02,  4.6628e-02,  3.7291e-02],\n",
       "           [ 5.0475e-02,  5.1441e-02,  6.4004e-02],\n",
       "           [ 6.1721e-02,  6.9605e-02,  6.4755e-02]],\n",
       " \n",
       "          [[ 5.0226e-02,  3.1237e-02,  2.7188e-02],\n",
       "           [ 8.4758e-02,  1.2656e-01,  3.7592e-02],\n",
       "           [ 6.6354e-02, -2.5683e-02,  1.7903e-02]],\n",
       " \n",
       "          [[ 4.8848e-02,  4.1784e-02,  3.7946e-02],\n",
       "           [ 4.0438e-02, -9.9736e-03, -3.1279e-02],\n",
       "           [ 4.1101e-03,  1.1360e-02,  1.4470e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 5.0545e-02,  1.0813e-02,  8.1645e-03],\n",
       "           [ 4.5354e-02,  2.9555e-02,  2.3576e-03],\n",
       "           [ 5.2837e-02,  1.6287e-02, -1.0515e-02]],\n",
       " \n",
       "          [[-1.0326e-02,  2.9493e-03, -1.4059e-02],\n",
       "           [ 2.1235e-02,  2.5103e-02,  6.5413e-03],\n",
       "           [ 1.0708e-02,  2.8118e-02,  3.6384e-03]],\n",
       " \n",
       "          [[ 1.0723e-02,  1.3727e-02,  2.1440e-02],\n",
       "           [ 3.2591e-02,  3.5029e-02,  2.4712e-02],\n",
       "           [ 2.0691e-02,  7.7132e-03,  6.3666e-03]]],\n",
       " \n",
       " \n",
       "         [[[-9.3416e-03, -1.0549e-02, -3.0652e-02],\n",
       "           [-1.0326e-02, -8.3120e-03, -2.3479e-02],\n",
       "           [-3.0695e-02, -2.7111e-02, -2.6895e-02]],\n",
       " \n",
       "          [[ 2.3222e-02,  3.1563e-02,  3.6306e-02],\n",
       "           [-6.7511e-02, -3.5773e-02, -7.8461e-03],\n",
       "           [ 1.7468e-02,  3.2043e-02,  3.4125e-03]],\n",
       " \n",
       "          [[-5.7917e-03,  1.2632e-03, -2.1470e-02],\n",
       "           [-4.1982e-03,  1.2825e-02,  2.4746e-02],\n",
       "           [ 6.0060e-03,  2.7375e-02,  1.3836e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1316e-02,  1.0177e-02, -5.4290e-03],\n",
       "           [-2.6483e-02, -5.3794e-03,  1.4030e-03],\n",
       "           [-2.0225e-02, -1.4104e-02, -9.5954e-03]],\n",
       " \n",
       "          [[-1.0601e-02, -1.2373e-02, -3.7289e-02],\n",
       "           [ 1.4703e-02,  2.5243e-02,  4.0387e-03],\n",
       "           [-6.3410e-03,  2.3099e-02,  1.0081e-02]],\n",
       " \n",
       "          [[-1.3436e-02, -1.4574e-02, -7.7797e-03],\n",
       "           [ 1.2802e-02, -4.9714e-03, -1.0160e-02],\n",
       "           [ 1.2117e-02, -1.1422e-02, -1.4991e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.6829e-04, -9.3712e-03,  1.4195e-02],\n",
       "           [ 2.1013e-03, -1.3948e-02, -2.7664e-03],\n",
       "           [-3.3749e-04,  6.0630e-03,  8.1903e-03]],\n",
       " \n",
       "          [[ 1.6567e-02, -5.1199e-02, -5.6248e-02],\n",
       "           [ 9.1866e-04, -1.7714e-02, -3.6684e-04],\n",
       "           [ 3.1850e-02,  2.0576e-02, -3.5834e-02]],\n",
       " \n",
       "          [[ 1.0909e-02,  2.1574e-02,  2.8490e-02],\n",
       "           [ 3.2107e-02,  3.2414e-02, -1.2900e-03],\n",
       "           [ 1.0167e-02, -1.4450e-03,  2.1463e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.2575e-03,  1.1782e-03, -5.9216e-03],\n",
       "           [-1.8488e-02, -1.4176e-02,  2.3786e-02],\n",
       "           [-1.4043e-02, -2.6554e-02,  3.4289e-02]],\n",
       " \n",
       "          [[-4.8895e-03, -3.0896e-03, -8.2423e-03],\n",
       "           [-5.1955e-03, -4.0442e-03, -1.6707e-02],\n",
       "           [-4.3185e-03, -5.6740e-03, -1.5145e-02]],\n",
       " \n",
       "          [[ 1.2991e-02, -2.2378e-03, -1.5146e-02],\n",
       "           [ 3.2276e-02,  1.8560e-02, -8.2058e-03],\n",
       "           [-5.6546e-04,  7.9354e-03, -7.2440e-03]]]], device='mps:0'),\n",
       " 'model.2.1.weight': tensor([ 0.0391,  0.0110,  0.0420,  0.0865,  0.0376,  0.0737,  0.0463,  0.0016,\n",
       "          0.0336, -0.0116, -0.0270,  0.0055, -0.0703, -0.0222,  0.1010,  0.0100,\n",
       "          0.0645,  0.0072, -0.0751, -0.0026, -0.0563, -0.0336,  0.0876,  0.0174,\n",
       "         -0.0422, -0.1104,  0.1080, -0.0304,  0.0575,  0.0125, -0.0303, -0.0284,\n",
       "         -0.1288,  0.0861, -0.0074,  0.0160, -0.0465,  0.0055, -0.0072,  0.0678,\n",
       "          0.0032,  0.0232,  0.0261,  0.0624,  0.0358,  0.0017, -0.0032,  0.0730,\n",
       "          0.0346,  0.0461,  0.0456, -0.0442, -0.0520,  0.0035,  0.0489, -0.0716,\n",
       "          0.1336, -0.0412,  0.0821,  0.1652, -0.0421, -0.0124,  0.1090, -0.1244],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.bias': tensor([ 0.0272, -0.0641,  0.0754,  0.0797,  0.0986,  0.0784, -0.0450,  0.0797,\n",
       "          0.0025, -0.0327,  0.0341, -0.1684, -0.0342, -0.1103,  0.0050,  0.0024,\n",
       "         -0.0471, -0.0176, -0.0998, -0.0220,  0.0842, -0.0649,  0.0301, -0.0235,\n",
       "         -0.0327, -0.0034,  0.0160, -0.0172, -0.0497,  0.0357, -0.0346,  0.0207,\n",
       "         -0.1000,  0.0276,  0.0475,  0.0289, -0.0583, -0.0823,  0.0003, -0.0148,\n",
       "         -0.0745,  0.1971, -0.0933, -0.1112, -0.0179, -0.0432, -0.0278,  0.0415,\n",
       "          0.0545, -0.0137,  0.0147, -0.0418, -0.0485,  0.0279,  0.0187, -0.0865,\n",
       "          0.0471, -0.0017,  0.0360,  0.0345, -0.1088, -0.1239,  0.0939, -0.1255],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_mean': tensor([ 0.6606, -0.2900, -0.4727, -0.2627,  0.5196,  0.0334,  0.8999, -0.3214,\n",
       "         -0.0141, -0.6329, -0.1741, -0.3791, -0.2148,  0.0546,  0.0208,  0.3591,\n",
       "          0.6083, -0.5664, -0.7963, -0.3943,  0.0287, -0.5389, -0.0595,  0.4791,\n",
       "          0.2938,  0.1120,  0.0820,  0.0681,  0.2404,  0.2937, -0.1202,  0.1785,\n",
       "          1.0434,  0.3234, -0.9140,  0.5762, -1.0700,  0.2747,  0.6354, -0.3013,\n",
       "          0.7369, -0.1666,  0.5259, -0.1777,  0.1251, -0.3988,  0.1892,  0.0764,\n",
       "         -0.4957,  0.2729, -0.3426, -0.1845, -0.0753, -0.2052, -0.3858, -0.2869,\n",
       "          0.6697,  1.3069,  0.5059, -0.5087,  0.5114,  1.3965,  0.3458, -0.3444],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.running_var': tensor([ 4.6468,  0.1466,  6.6731,  3.1466,  3.4557,  1.3760,  0.6472,  2.0197,\n",
       "          1.1983,  1.5915,  1.8248,  1.6773,  2.9744,  1.8237,  0.5408,  1.1939,\n",
       "         -0.4946,  1.7283,  1.3621, -0.0395,  2.2040,  0.3120,  1.8602,  2.6075,\n",
       "          4.6910,  3.1346,  1.6775, -0.0811,  1.0963,  0.7425,  7.0820,  2.0633,\n",
       "          2.3924,  2.2246,  0.4481,  1.3222,  6.5154,  0.0422,  1.4346, -1.0081,\n",
       "          1.7132,  4.4831,  1.2583, -0.1360,  0.8316,  3.4589,  1.9215,  2.7793,\n",
       "          1.4906,  3.5526,  1.5527,  2.1772, -0.1627,  1.1689,  1.4111,  1.5543,\n",
       "          0.4740,  2.1605,  2.4008,  0.2809,  2.2490,  1.1479,  2.0907,  2.8727],\n",
       "        device='mps:0'),\n",
       " 'model.2.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.3.0.weight': tensor([[[[ 0.0021,  0.0084,  0.0385],\n",
       "           [ 0.0413,  0.0061,  0.0127],\n",
       "           [-0.0133, -0.0330, -0.0400]],\n",
       " \n",
       "          [[-0.0239,  0.0242,  0.0070],\n",
       "           [ 0.0273,  0.0007,  0.0088],\n",
       "           [-0.0320, -0.0180,  0.0148]],\n",
       " \n",
       "          [[-0.0226, -0.0071, -0.0171],\n",
       "           [-0.0209, -0.0078, -0.0309],\n",
       "           [-0.0238, -0.0246, -0.0050]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0197, -0.0117, -0.0367],\n",
       "           [-0.0543,  0.0236, -0.0456],\n",
       "           [-0.0367,  0.0206, -0.0043]],\n",
       " \n",
       "          [[ 0.0208,  0.0060,  0.0211],\n",
       "           [ 0.0121,  0.0194,  0.0031],\n",
       "           [ 0.0041,  0.0219, -0.0056]],\n",
       " \n",
       "          [[-0.0082,  0.0192,  0.0233],\n",
       "           [ 0.0051,  0.0040,  0.0177],\n",
       "           [ 0.0110, -0.0007,  0.0408]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0230, -0.0119, -0.0166],\n",
       "           [-0.0024,  0.0028,  0.0022],\n",
       "           [-0.0010,  0.0087, -0.0145]],\n",
       " \n",
       "          [[-0.0048, -0.0086,  0.0017],\n",
       "           [-0.0101, -0.0036, -0.0007],\n",
       "           [ 0.0076,  0.0084, -0.0006]],\n",
       " \n",
       "          [[ 0.0075, -0.0078,  0.0030],\n",
       "           [ 0.0055, -0.0073, -0.0142],\n",
       "           [ 0.0016, -0.0140, -0.0287]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0282, -0.0316,  0.0013],\n",
       "           [-0.0194, -0.0208,  0.0086],\n",
       "           [-0.0172,  0.0021,  0.0038]],\n",
       " \n",
       "          [[-0.0068,  0.0179,  0.0117],\n",
       "           [-0.0016,  0.0033, -0.0118],\n",
       "           [ 0.0054, -0.0005, -0.0074]],\n",
       " \n",
       "          [[ 0.0110,  0.0179,  0.0079],\n",
       "           [ 0.0137,  0.0187,  0.0213],\n",
       "           [ 0.0135,  0.0244,  0.0269]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0103,  0.0120, -0.0335],\n",
       "           [ 0.0616,  0.0289,  0.0226],\n",
       "           [ 0.0426,  0.0010,  0.0146]],\n",
       " \n",
       "          [[ 0.0572,  0.0413,  0.0058],\n",
       "           [ 0.0282,  0.0242,  0.0159],\n",
       "           [ 0.0156,  0.0045,  0.0065]],\n",
       " \n",
       "          [[-0.0289, -0.0221, -0.0310],\n",
       "           [ 0.0012, -0.0239, -0.0433],\n",
       "           [-0.0139, -0.0252, -0.0542]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0145,  0.0303,  0.0149],\n",
       "           [-0.0007,  0.0252,  0.0230],\n",
       "           [-0.0060,  0.0214, -0.0188]],\n",
       " \n",
       "          [[ 0.0023,  0.0176,  0.0272],\n",
       "           [ 0.0340,  0.0460,  0.0459],\n",
       "           [ 0.0173,  0.0214,  0.0118]],\n",
       " \n",
       "          [[-0.0132, -0.0088,  0.0049],\n",
       "           [ 0.0073,  0.0025,  0.0138],\n",
       "           [ 0.0328,  0.0227,  0.0306]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0047, -0.0015, -0.0349],\n",
       "           [-0.0194, -0.0417, -0.0567],\n",
       "           [ 0.0008, -0.0167, -0.0310]],\n",
       " \n",
       "          [[ 0.0194,  0.0035, -0.0415],\n",
       "           [ 0.0219, -0.0119, -0.0387],\n",
       "           [ 0.0264,  0.0271, -0.0141]],\n",
       " \n",
       "          [[-0.0144,  0.0018,  0.0046],\n",
       "           [-0.0257, -0.0171,  0.0011],\n",
       "           [ 0.0195,  0.0082,  0.0104]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0627, -0.0189, -0.0179],\n",
       "           [-0.0301, -0.0250, -0.0379],\n",
       "           [-0.0156, -0.0250, -0.0507]],\n",
       " \n",
       "          [[-0.0453, -0.0137,  0.0048],\n",
       "           [-0.0094, -0.0074, -0.0191],\n",
       "           [ 0.0027, -0.0416, -0.0033]],\n",
       " \n",
       "          [[ 0.0051,  0.0144,  0.0341],\n",
       "           [ 0.0289,  0.0082, -0.0238],\n",
       "           [ 0.0562,  0.0178, -0.0076]]],\n",
       " \n",
       " \n",
       "         [[[-0.0017, -0.0207, -0.0260],\n",
       "           [ 0.0119, -0.0022, -0.0098],\n",
       "           [ 0.0138,  0.0026, -0.0191]],\n",
       " \n",
       "          [[-0.0095, -0.0198, -0.0086],\n",
       "           [-0.0063, -0.0195, -0.0129],\n",
       "           [ 0.0022,  0.0118, -0.0142]],\n",
       " \n",
       "          [[ 0.0021, -0.0151, -0.0175],\n",
       "           [ 0.0027, -0.0120, -0.0084],\n",
       "           [ 0.0106,  0.0031,  0.0029]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0249,  0.0086,  0.0212],\n",
       "           [ 0.0172,  0.0236,  0.0403],\n",
       "           [ 0.0223,  0.0572,  0.0494]],\n",
       " \n",
       "          [[ 0.0005,  0.0031, -0.0162],\n",
       "           [-0.0194, -0.0076, -0.0266],\n",
       "           [-0.0016, -0.0150, -0.0134]],\n",
       " \n",
       "          [[ 0.0011,  0.0022,  0.0383],\n",
       "           [ 0.0170,  0.0147,  0.0364],\n",
       "           [ 0.0173,  0.0212,  0.0247]]],\n",
       " \n",
       " \n",
       "         [[[-0.0091,  0.0141, -0.0021],\n",
       "           [ 0.0032,  0.0370,  0.0317],\n",
       "           [ 0.0104,  0.0424,  0.0647]],\n",
       " \n",
       "          [[ 0.0036,  0.0264, -0.0038],\n",
       "           [-0.0126,  0.0255,  0.0388],\n",
       "           [ 0.0206, -0.0226,  0.0165]],\n",
       " \n",
       "          [[ 0.0286,  0.0281,  0.0098],\n",
       "           [ 0.0273,  0.0239,  0.0006],\n",
       "           [-0.0030, -0.0139, -0.0119]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0424,  0.0139,  0.0120],\n",
       "           [-0.0532, -0.0127, -0.0070],\n",
       "           [-0.0533,  0.0063, -0.0006]],\n",
       " \n",
       "          [[-0.0010, -0.0216, -0.0198],\n",
       "           [-0.0395, -0.0281, -0.0135],\n",
       "           [-0.0298, -0.0122, -0.0048]],\n",
       " \n",
       "          [[ 0.0185,  0.0233, -0.0077],\n",
       "           [-0.0087,  0.0055, -0.0298],\n",
       "           [ 0.0091,  0.0081, -0.0104]]]], device='mps:0'),\n",
       " 'model.3.1.weight': tensor([-0.0020, -0.0354,  0.0350, -0.0132,  0.0405,  0.0049,  0.0187,  0.1392,\n",
       "          0.0479, -0.0240,  0.0061,  0.0386,  0.0475, -0.0048,  0.0535, -0.0070,\n",
       "          0.1084,  0.0810,  0.0787,  0.0382,  0.0389,  0.0077,  0.1274, -0.0783,\n",
       "          0.0475, -0.0239,  0.1105,  0.0256,  0.0223, -0.1254,  0.0105, -0.0007,\n",
       "          0.1012,  0.0633,  0.0194, -0.0631,  0.1279, -0.0712,  0.0305, -0.0178,\n",
       "          0.0586, -0.0438,  0.0099, -0.0457,  0.0275, -0.0488, -0.0654,  0.0190,\n",
       "         -0.0317, -0.0834,  0.0028,  0.1018,  0.0261,  0.0442, -0.0800, -0.0441,\n",
       "          0.0210, -0.1478,  0.0572,  0.0535,  0.0659,  0.0307, -0.0865,  0.0798],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.bias': tensor([-0.0575, -0.0096, -0.0466, -0.0417, -0.0112,  0.0426, -0.0284,  0.0607,\n",
       "          0.0807, -0.0335, -0.0437,  0.0093, -0.0372,  0.0779, -0.0381,  0.0191,\n",
       "          0.0256, -0.0667, -0.1558,  0.0982,  0.0137, -0.0233,  0.0245, -0.0336,\n",
       "          0.0324, -0.0015,  0.0655,  0.0245, -0.0225,  0.0434,  0.0597, -0.0635,\n",
       "          0.0414,  0.0653,  0.0668, -0.0880,  0.0793, -0.0335, -0.0324, -0.0339,\n",
       "          0.0006, -0.1138,  0.0422, -0.0156,  0.0102, -0.0304, -0.0318, -0.0205,\n",
       "         -0.0296, -0.1190, -0.0478,  0.0613,  0.0030,  0.0479, -0.0530, -0.0115,\n",
       "         -0.0182, -0.0503,  0.0175,  0.0460,  0.0125,  0.0933, -0.0244, -0.0084],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_mean': tensor([-0.3299,  0.0272,  0.6895,  0.4831,  0.5188, -0.4791, -0.0194,  0.7243,\n",
       "          0.3960, -0.0478,  0.5555, -0.2674,  0.1546, -0.8760, -0.3106,  0.5221,\n",
       "          0.0332,  0.4779,  0.2901, -0.3575, -0.1522,  0.7675, -0.0797,  0.6870,\n",
       "         -0.5608, -0.0292, -0.4264,  0.4480, -0.3506, -0.3101,  0.0295,  0.0678,\n",
       "          0.4663, -0.0913, -0.2160, -0.2475, -0.7194, -0.5501,  0.9074, -0.4293,\n",
       "          0.3652, -0.6279,  0.0247, -1.3427,  0.5245, -0.2319,  0.3041, -0.5265,\n",
       "          0.3489, -0.2116,  0.1110, -0.2825,  0.2211,  0.1661, -0.6591, -0.0954,\n",
       "          0.1917, -1.1117, -0.6115,  0.4774,  0.3830, -0.9657, -0.1356,  0.4890],\n",
       "        device='mps:0'),\n",
       " 'model.3.1.running_var': tensor([0.3013, 1.0586, 0.4660, 1.6746, 0.6603, 0.4413, 1.6812, 1.0626, 1.2061,\n",
       "         0.8552, 1.5067, 1.1494, 0.4521, 1.9187, 1.1454, 1.1012, 2.3656, 1.8397,\n",
       "         3.0649, 2.2171, 0.7532, 1.7172, 0.3629, 1.9908, 0.6414, 0.6508, 1.0931,\n",
       "         0.5444, 0.4461, 1.4834, 1.1658, 0.9144, 1.6574, 0.6273, 0.9119, 0.2159,\n",
       "         1.6585, 1.5320, 0.9012, 0.6509, 0.1049, 1.3799, 0.8251, 1.7573, 1.5976,\n",
       "         0.4918, 0.8587, 1.0671, 1.2393, 1.4308, 1.8724, 0.0995, 0.7079, 2.0961,\n",
       "         0.6667, 0.3768, 0.9906, 0.8291, 0.3261, 3.6049, 0.9705, 1.4265, 0.6300,\n",
       "         0.8376], device='mps:0'),\n",
       " 'model.3.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.4.0.weight': tensor([[[[ 3.1126e-02,  2.9534e-02,  1.2950e-02],\n",
       "           [ 3.8874e-02,  8.5759e-03,  1.1548e-02],\n",
       "           [ 1.3630e-02, -2.4901e-02,  8.5947e-03]],\n",
       " \n",
       "          [[-2.4061e-03, -1.3686e-02, -1.1382e-02],\n",
       "           [ 5.0539e-03, -7.5937e-03,  8.6062e-04],\n",
       "           [-1.8970e-03,  4.9720e-03,  1.1755e-02]],\n",
       " \n",
       "          [[-1.3759e-02, -1.4804e-02,  1.8225e-02],\n",
       "           [ 1.5004e-02,  9.9435e-03,  1.7456e-02],\n",
       "           [ 4.0476e-02,  1.2999e-02,  1.4483e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.2074e-02,  2.7606e-02, -1.3036e-02],\n",
       "           [ 1.7635e-02,  3.1151e-02,  2.7864e-03],\n",
       "           [-3.2118e-03,  2.2737e-02, -2.1936e-02]],\n",
       " \n",
       "          [[ 1.2946e-02,  8.3933e-03,  1.3079e-02],\n",
       "           [ 1.3688e-02,  1.1916e-02,  4.7669e-03],\n",
       "           [ 3.3249e-02,  2.7151e-02,  1.6324e-02]],\n",
       " \n",
       "          [[ 1.4721e-02,  2.7668e-02,  1.6895e-03],\n",
       "           [ 3.4229e-02,  1.8808e-02,  9.8329e-03],\n",
       "           [-6.7275e-03,  2.6864e-02,  1.1595e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.7784e-02, -1.6828e-02, -2.1277e-02],\n",
       "           [ 7.8601e-03, -3.1421e-03, -9.2959e-03],\n",
       "           [ 3.9610e-03,  1.5232e-02,  2.1120e-03]],\n",
       " \n",
       "          [[ 2.4510e-02,  1.6465e-02,  5.7217e-03],\n",
       "           [ 1.3628e-03, -3.6464e-03, -6.8428e-03],\n",
       "           [-1.7307e-02, -1.8948e-02, -1.2160e-02]],\n",
       " \n",
       "          [[ 9.6300e-03,  3.2213e-02,  2.3224e-02],\n",
       "           [-6.4543e-03, -3.4335e-03, -8.1405e-03],\n",
       "           [ 1.5772e-03,  9.7376e-03,  2.0531e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.3584e-03, -3.6458e-03,  1.7218e-02],\n",
       "           [ 1.4085e-02,  4.1084e-02,  6.0584e-02],\n",
       "           [ 3.0301e-02,  1.8769e-03,  4.2546e-02]],\n",
       " \n",
       "          [[ 2.4771e-02,  2.8285e-02,  2.1660e-02],\n",
       "           [ 2.8332e-02,  3.8175e-02,  2.9538e-02],\n",
       "           [ 3.0853e-02,  3.1727e-02,  1.9706e-02]],\n",
       " \n",
       "          [[ 4.0744e-02,  5.2328e-02,  2.2450e-02],\n",
       "           [ 9.1213e-03,  1.7917e-02,  4.9528e-02],\n",
       "           [ 4.2927e-02, -1.6763e-02,  5.4538e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.5108e-02,  1.6162e-03, -2.1097e-02],\n",
       "           [ 2.7981e-02, -1.1235e-02, -1.1988e-02],\n",
       "           [ 3.3187e-02,  8.1206e-03, -1.9196e-03]],\n",
       " \n",
       "          [[-1.7633e-02,  1.8469e-03,  1.4234e-02],\n",
       "           [-2.7989e-02, -1.8978e-02, -1.0175e-02],\n",
       "           [-2.9587e-02, -5.3087e-03, -5.6077e-03]],\n",
       " \n",
       "          [[ 1.4038e-04, -1.4245e-02, -2.0512e-02],\n",
       "           [ 1.2935e-02,  8.5057e-04,  7.9297e-05],\n",
       "           [-1.4768e-02, -3.4186e-02, -3.0931e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0383e-02,  5.0665e-03,  1.4791e-02],\n",
       "           [ 2.8198e-02,  1.1005e-02, -8.9149e-03],\n",
       "           [ 5.4386e-02,  3.2850e-02,  9.4413e-03]],\n",
       " \n",
       "          [[-3.8582e-02, -6.7329e-02, -5.5908e-02],\n",
       "           [-2.4708e-02, -4.1406e-02, -1.1269e-02],\n",
       "           [-6.7239e-03, -8.1727e-03,  6.1441e-03]],\n",
       " \n",
       "          [[-5.6822e-03, -1.7916e-02, -4.0444e-02],\n",
       "           [-2.1878e-02, -2.1330e-03, -4.2890e-02],\n",
       "           [-1.2866e-02,  5.8273e-03, -2.3386e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-2.2834e-02, -3.2347e-02, -2.1096e-02],\n",
       "           [-3.7581e-03, -2.8199e-02, -5.7984e-02],\n",
       "           [ 2.0064e-03,  7.5133e-04,  1.3043e-02]],\n",
       " \n",
       "          [[-9.6734e-03, -6.4667e-03, -7.4048e-03],\n",
       "           [-8.1745e-03, -5.1727e-03, -1.7542e-02],\n",
       "           [ 6.8329e-03,  5.9291e-03, -1.9795e-02]],\n",
       " \n",
       "          [[-8.1310e-03, -1.1055e-02,  4.8863e-03],\n",
       "           [-1.6980e-02, -1.9723e-02, -7.3729e-03],\n",
       "           [-1.1758e-02, -6.4172e-03,  1.5124e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.1942e-02,  2.0334e-02,  3.5196e-02],\n",
       "           [ 7.6834e-03,  1.0438e-02,  3.2845e-02],\n",
       "           [ 4.1824e-03,  3.6297e-03,  2.0675e-02]],\n",
       " \n",
       "          [[ 3.3886e-02,  4.5658e-02,  6.4393e-02],\n",
       "           [ 2.6206e-02,  2.2555e-02,  4.0270e-02],\n",
       "           [-6.8159e-03,  2.1759e-03,  1.0372e-02]],\n",
       " \n",
       "          [[ 9.8329e-03,  9.5015e-03, -5.3567e-02],\n",
       "           [ 1.5321e-02,  2.1901e-02, -7.8170e-03],\n",
       "           [ 4.1518e-02, -1.0226e-02, -4.4210e-03]]],\n",
       " \n",
       " \n",
       "         [[[-2.6721e-02, -6.2602e-02, -6.6214e-02],\n",
       "           [ 1.3469e-02, -2.6647e-02, -3.6097e-02],\n",
       "           [ 5.7105e-03, -3.4722e-02, -2.0740e-02]],\n",
       " \n",
       "          [[-4.4032e-02, -4.6007e-02, -3.3036e-02],\n",
       "           [-4.2774e-02, -2.4300e-02, -1.8621e-02],\n",
       "           [-2.9180e-02, -1.8517e-02, -2.1690e-02]],\n",
       " \n",
       "          [[ 1.2507e-03, -4.7406e-03, -6.2292e-03],\n",
       "           [ 1.6639e-02,  1.3766e-02,  1.1255e-02],\n",
       "           [ 1.8701e-02, -3.2545e-03, -1.9250e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5385e-02,  1.0161e-02, -3.6424e-03],\n",
       "           [ 1.2242e-02, -1.4425e-03, -2.2026e-02],\n",
       "           [-2.5185e-02, -2.4933e-02, -1.2885e-02]],\n",
       " \n",
       "          [[-1.8935e-02, -2.7637e-02, -3.3672e-02],\n",
       "           [-2.1802e-02, -3.7871e-02, -5.1438e-02],\n",
       "           [-1.8014e-02, -3.6663e-02, -3.6713e-02]],\n",
       " \n",
       "          [[-5.4037e-02, -2.8249e-02, -3.8178e-02],\n",
       "           [-3.6195e-02,  1.1414e-03,  1.9774e-02],\n",
       "           [-2.4969e-02, -9.2533e-04,  8.9489e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0196e-02,  2.1876e-03, -1.1888e-03],\n",
       "           [-3.3303e-02, -1.9143e-02, -6.9278e-03],\n",
       "           [ 1.6226e-02,  4.2713e-03,  1.0486e-02]],\n",
       " \n",
       "          [[ 9.5561e-04, -7.1140e-04,  6.1426e-03],\n",
       "           [-3.1115e-03, -3.8014e-03, -3.1270e-03],\n",
       "           [-1.3202e-03, -1.3998e-02, -1.3166e-02]],\n",
       " \n",
       "          [[ 2.9182e-02,  2.4020e-02,  3.9292e-02],\n",
       "           [ 6.7200e-03,  1.4660e-02,  1.4119e-02],\n",
       "           [ 3.5155e-02,  5.1814e-02,  5.2757e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.3826e-02, -4.0651e-02, -1.6871e-02],\n",
       "           [-2.9020e-02, -2.9702e-02, -1.2226e-02],\n",
       "           [-4.0085e-02, -3.8207e-02, -1.2713e-02]],\n",
       " \n",
       "          [[-7.7155e-04,  1.7222e-03, -8.0053e-04],\n",
       "           [-4.1815e-03, -3.3505e-03, -1.3650e-02],\n",
       "           [-4.8358e-03, -2.3776e-03, -1.0457e-02]],\n",
       " \n",
       "          [[ 1.5649e-02,  3.9908e-02,  1.4819e-02],\n",
       "           [ 3.6277e-02,  1.5152e-02,  2.6939e-02],\n",
       "           [ 1.1867e-02, -7.1281e-03, -1.5121e-02]]]], device='mps:0'),\n",
       " 'model.4.1.weight': tensor([-0.0118,  0.0157,  0.1298,  0.0347,  0.1416, -0.0092,  0.0750, -0.0197,\n",
       "         -0.0444, -0.0329,  0.1212,  0.0188, -0.0540,  0.1118, -0.0388, -0.0585,\n",
       "          0.0401,  0.0141,  0.0087,  0.0878, -0.0205, -0.0151,  0.1037, -0.0181,\n",
       "          0.0667, -0.0114,  0.0076,  0.0032,  0.0084, -0.0222,  0.1401, -0.0331,\n",
       "          0.0558,  0.1820,  0.0669, -0.0098, -0.0664, -0.0556,  0.0680, -0.0528,\n",
       "          0.1089,  0.0123,  0.0323, -0.0014, -0.0029,  0.0364,  0.0006, -0.0658,\n",
       "         -0.1088, -0.0771,  0.0580,  0.0616, -0.0237,  0.0682,  0.0824, -0.0587,\n",
       "          0.0201,  0.0712, -0.0917,  0.1266,  0.0739,  0.0146, -0.0819, -0.0959],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.bias': tensor([-0.0122, -0.0027, -0.0086,  0.0235,  0.0940, -0.0452, -0.0185, -0.0643,\n",
       "         -0.0489, -0.0456,  0.0704, -0.0565,  0.0361,  0.1144, -0.0724, -0.1472,\n",
       "         -0.0156, -0.0060, -0.0298,  0.0115, -0.0329, -0.0070,  0.0648,  0.0303,\n",
       "          0.0420, -0.0005,  0.0071,  0.0294,  0.0588, -0.0450, -0.0428,  0.0422,\n",
       "          0.0161,  0.1397,  0.0559, -0.0637, -0.0610,  0.0204, -0.0007, -0.1308,\n",
       "          0.0912,  0.0063,  0.0937,  0.0536, -0.0314,  0.0390,  0.0070, -0.0775,\n",
       "          0.0229, -0.0483,  0.0649,  0.0932, -0.0621,  0.0778,  0.0921, -0.0097,\n",
       "          0.0317,  0.0049, -0.0268, -0.1049,  0.0304, -0.0289,  0.0056, -0.0685],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_mean': tensor([ 0.0401,  0.2926,  0.4757,  0.2563, -0.3549, -0.3280, -0.1286, -0.1606,\n",
       "         -0.5123, -0.0358, -0.0321,  0.0734, -0.3378,  0.6137, -0.3562,  0.2410,\n",
       "          0.0068, -0.3283, -0.1626, -0.4776, -0.5565, -0.1583, -0.1584, -0.2079,\n",
       "         -0.1951, -0.2933, -0.4898, -0.5366, -0.6122, -0.0059,  0.3975, -0.6825,\n",
       "          0.4348, -0.5441,  0.2213, -0.0073,  0.5701,  0.2981, -0.6516, -0.2232,\n",
       "          0.0671,  0.8247,  0.0298, -0.2889, -0.2954, -0.3737, -0.4248, -0.1368,\n",
       "         -0.3240, -0.1591,  0.0057, -0.5678, -0.5830, -0.1826, -0.4029, -0.2705,\n",
       "         -0.1337, -0.1498, -0.3715,  0.2281, -0.2381,  0.1501, -0.4896, -0.5988],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.running_var': tensor([ 0.6405,  0.6231,  0.4276,  0.7993,  1.0625,  0.8674,  1.6913,  0.5629,\n",
       "          1.1561,  0.4760,  0.2597,  0.2270,  0.4503,  1.1495,  1.2007,  1.4646,\n",
       "          1.6012,  0.5784,  0.5208,  0.4891,  1.3493,  0.3959,  0.8722,  0.8449,\n",
       "          0.6000,  0.6454,  0.7606,  1.1104,  1.1843,  0.6236,  1.2457,  0.0137,\n",
       "          1.1880,  0.6670,  0.8459,  0.6928,  1.5782,  0.2068,  1.0229,  0.2225,\n",
       "          1.0507,  1.3695,  0.5431,  0.1283,  0.6307,  0.4959,  2.2502,  0.8150,\n",
       "          0.8274,  0.7506,  0.6450,  0.7492,  1.1370,  0.8126, -0.1313,  0.3055,\n",
       "          3.1383,  1.3238,  1.6678,  1.2892,  0.6508,  1.4359,  1.2631,  1.0102],\n",
       "        device='mps:0'),\n",
       " 'model.4.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.5.0.weight': tensor([[[[-1.0769e-02,  1.8189e-02,  3.8256e-03],\n",
       "           [-1.6621e-02,  1.5746e-02, -7.7073e-03],\n",
       "           [-9.6481e-03,  1.3050e-02, -1.0535e-02]],\n",
       " \n",
       "          [[ 2.5552e-02,  7.0674e-03,  1.7828e-02],\n",
       "           [ 3.6825e-02, -1.3914e-02,  3.8980e-03],\n",
       "           [ 1.5548e-02,  1.0362e-02,  5.9860e-03]],\n",
       " \n",
       "          [[ 5.0989e-03, -1.0306e-02,  2.6052e-03],\n",
       "           [ 2.7048e-02,  2.4382e-02,  2.5307e-02],\n",
       "           [ 1.5157e-02,  1.4834e-02,  2.4052e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.9561e-03,  1.5189e-02, -2.8796e-03],\n",
       "           [-6.6458e-03,  1.7935e-02, -6.2351e-03],\n",
       "           [ 2.6594e-03,  1.7499e-02,  1.0726e-02]],\n",
       " \n",
       "          [[ 3.4398e-02,  2.4561e-02,  2.9172e-02],\n",
       "           [ 1.9038e-02,  6.5034e-03, -4.2219e-03],\n",
       "           [ 1.9124e-02, -7.3555e-03,  7.3199e-03]],\n",
       " \n",
       "          [[ 4.2522e-03,  1.6939e-03, -3.8722e-03],\n",
       "           [ 1.6792e-02,  6.3488e-03, -1.8413e-03],\n",
       "           [-1.7906e-03,  1.7726e-02, -4.5249e-03]]],\n",
       " \n",
       " \n",
       "         [[[-6.2636e-03, -8.2732e-03,  1.8587e-02],\n",
       "           [ 4.8285e-03,  2.9842e-02,  3.6295e-02],\n",
       "           [ 2.5726e-02,  1.1661e-02,  2.0133e-02]],\n",
       " \n",
       "          [[ 1.3672e-02, -2.6941e-03, -2.6580e-02],\n",
       "           [ 2.9195e-02, -4.3986e-03, -1.1460e-02],\n",
       "           [ 2.5494e-02,  4.5319e-03, -7.0391e-03]],\n",
       " \n",
       "          [[ 9.8133e-03,  3.0963e-02,  3.9468e-02],\n",
       "           [ 3.4952e-02,  1.2389e-02,  1.2329e-02],\n",
       "           [-5.4726e-03,  3.5823e-03,  1.2552e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.9166e-03,  9.1704e-03, -7.9674e-03],\n",
       "           [ 1.3065e-03, -5.8933e-03, -1.8883e-02],\n",
       "           [-1.5739e-02, -2.2527e-02, -2.5575e-02]],\n",
       " \n",
       "          [[ 7.8221e-03,  3.0934e-02,  5.4595e-03],\n",
       "           [-3.9551e-02, -1.6672e-02, -1.6048e-02],\n",
       "           [ 1.5779e-02, -5.6725e-03,  9.0306e-03]],\n",
       " \n",
       "          [[-2.5246e-02, -5.1881e-03, -2.8875e-03],\n",
       "           [-8.2404e-03, -2.1249e-03, -1.0039e-02],\n",
       "           [-4.0337e-03, -1.5497e-02, -9.6469e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 6.9669e-03, -3.7875e-03, -4.4673e-03],\n",
       "           [ 2.9270e-02,  1.6530e-02, -2.6672e-03],\n",
       "           [ 1.4324e-03, -6.7747e-03,  1.4249e-02]],\n",
       " \n",
       "          [[-1.7491e-02, -1.4944e-02, -1.8215e-02],\n",
       "           [ 1.5807e-03,  1.8110e-03,  2.5602e-03],\n",
       "           [-3.3485e-02, -2.7553e-02, -4.5483e-02]],\n",
       " \n",
       "          [[-2.2329e-02, -1.5144e-02, -5.5201e-03],\n",
       "           [-1.7480e-02, -8.0119e-03,  4.1455e-03],\n",
       "           [-9.7423e-03, -2.9665e-02, -2.4202e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5301e-02, -1.2123e-02,  3.5003e-02],\n",
       "           [-1.2920e-02, -9.6814e-03,  3.2071e-02],\n",
       "           [-4.6146e-03, -2.1977e-02,  3.9891e-02]],\n",
       " \n",
       "          [[-9.7538e-03, -6.6197e-04, -1.7046e-02],\n",
       "           [-4.5070e-02, -4.7870e-02, -6.2559e-02],\n",
       "           [-4.0557e-02, -2.3230e-02, -6.6062e-03]],\n",
       " \n",
       "          [[-2.3239e-05, -7.0109e-03, -6.4756e-04],\n",
       "           [-1.7697e-02,  1.0495e-02,  1.0057e-02],\n",
       "           [ 1.6552e-02, -8.3183e-03, -3.8975e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-6.5548e-03, -1.0075e-03, -1.9623e-03],\n",
       "           [ 2.9480e-03,  2.4494e-03,  5.6557e-03],\n",
       "           [ 1.2113e-02,  2.8596e-02,  1.2751e-02]],\n",
       " \n",
       "          [[ 1.6831e-03,  1.8055e-04, -1.9330e-03],\n",
       "           [-1.0336e-02,  2.4713e-03,  2.3530e-02],\n",
       "           [ 1.0152e-02,  1.4250e-02, -7.8446e-03]],\n",
       " \n",
       "          [[-1.0622e-02, -1.1059e-02, -6.0732e-03],\n",
       "           [ 1.4185e-03,  1.4375e-02, -1.3340e-03],\n",
       "           [-4.5839e-03,  1.1925e-02, -3.6418e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.6631e-04, -3.6631e-03, -1.8722e-02],\n",
       "           [-1.0584e-02, -2.6106e-03, -2.5108e-02],\n",
       "           [-1.0386e-02, -9.2332e-03, -2.5327e-02]],\n",
       " \n",
       "          [[-1.1989e-02, -4.2161e-03,  6.6046e-03],\n",
       "           [ 2.5937e-02,  6.3511e-03,  1.0242e-02],\n",
       "           [ 3.2932e-02,  2.4796e-02,  7.2632e-03]],\n",
       " \n",
       "          [[-6.2813e-03, -3.9857e-03, -2.5344e-02],\n",
       "           [ 1.1779e-02,  2.2536e-02,  2.4926e-02],\n",
       "           [-2.9327e-02, -1.9003e-02, -1.0011e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.3964e-03, -2.0367e-02, -2.6910e-02],\n",
       "           [ 6.3327e-03,  1.4888e-02,  3.4441e-03],\n",
       "           [-4.5357e-04,  1.7593e-03,  2.4594e-04]],\n",
       " \n",
       "          [[-1.1731e-02, -1.5406e-02,  1.1454e-02],\n",
       "           [ 2.3759e-03,  1.5820e-02,  1.1157e-02],\n",
       "           [ 2.3935e-02,  1.2735e-02,  1.2465e-02]],\n",
       " \n",
       "          [[-1.1073e-03,  6.2257e-03,  7.5784e-03],\n",
       "           [-2.2095e-02, -1.5153e-02, -1.2226e-02],\n",
       "           [-2.0628e-03,  1.3492e-02,  6.0683e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 8.0603e-03, -1.5196e-02, -1.1303e-02],\n",
       "           [-1.0611e-02, -2.6896e-02, -9.2394e-03],\n",
       "           [-1.7586e-02, -2.3993e-02, -9.3764e-03]],\n",
       " \n",
       "          [[-2.0613e-02, -8.8794e-03, -2.3961e-02],\n",
       "           [-4.0006e-02, -2.6747e-02,  2.9364e-04],\n",
       "           [ 1.1260e-02,  1.8447e-02, -2.5267e-03]],\n",
       " \n",
       "          [[ 9.6796e-03,  2.9583e-03,  6.2725e-03],\n",
       "           [ 8.5005e-03,  1.1766e-02, -5.7940e-03],\n",
       "           [ 1.4711e-02,  1.2533e-02,  5.3559e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 1.1856e-02, -2.3550e-03,  8.8135e-03],\n",
       "           [ 3.8440e-03, -1.3793e-02, -2.0620e-04],\n",
       "           [ 7.4646e-03, -1.6424e-02,  1.0985e-02]],\n",
       " \n",
       "          [[ 1.6168e-02,  3.4872e-02,  2.6412e-02],\n",
       "           [-1.2063e-02,  2.8884e-02,  1.0541e-02],\n",
       "           [-1.1566e-03,  2.6948e-02,  3.7646e-02]],\n",
       " \n",
       "          [[ 3.2281e-02,  3.8526e-02,  3.4527e-02],\n",
       "           [ 6.9786e-04,  6.4036e-03, -1.1838e-04],\n",
       "           [-2.5508e-03, -4.9378e-03, -7.0935e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 7.9228e-03,  1.4835e-02, -3.3017e-03],\n",
       "           [ 5.1005e-03,  1.6694e-02,  9.8624e-03],\n",
       "           [ 2.0337e-02,  1.7118e-02,  3.2995e-02]],\n",
       " \n",
       "          [[-6.1694e-03, -1.5562e-03, -4.4382e-03],\n",
       "           [-2.1488e-02, -4.0474e-03,  4.2432e-03],\n",
       "           [-2.1752e-02, -1.6309e-02, -4.2793e-03]],\n",
       " \n",
       "          [[-2.9749e-02, -1.3962e-02, -9.6098e-03],\n",
       "           [-4.1482e-05, -9.6022e-03, -1.8016e-02],\n",
       "           [ 8.1759e-03,  1.2405e-02,  7.2585e-03]]]], device='mps:0'),\n",
       " 'model.5.1.weight': tensor([-0.0257,  0.0518,  0.0094, -0.0731,  0.0226,  0.0334, -0.0181, -0.0333,\n",
       "          0.0006,  0.0037, -0.1461, -0.0011,  0.0379, -0.0156,  0.0367, -0.0065,\n",
       "          0.0286,  0.0318,  0.0578,  0.0653, -0.0240, -0.0858, -0.0526, -0.0523,\n",
       "          0.0815,  0.0742, -0.0067,  0.0302,  0.0476,  0.0546, -0.0102, -0.0480,\n",
       "          0.0045,  0.0946, -0.0205, -0.0039,  0.0722,  0.0866, -0.0276,  0.0040,\n",
       "         -0.0358, -0.0172, -0.0234, -0.0092,  0.0222, -0.0463, -0.0223,  0.0023,\n",
       "          0.0107,  0.0582,  0.0170, -0.1188, -0.0950,  0.0894,  0.0483,  0.0457,\n",
       "          0.0359,  0.0167, -0.0099,  0.0517,  0.0297, -0.0065,  0.0409, -0.0065,\n",
       "         -0.0216, -0.0025, -0.0754, -0.1013, -0.1173,  0.0649,  0.0153,  0.0033,\n",
       "         -0.0270,  0.1162, -0.0396,  0.0603,  0.0403,  0.0260, -0.0825, -0.0118,\n",
       "         -0.0071, -0.0062, -0.0187, -0.0084, -0.0632, -0.0041,  0.0367, -0.0279,\n",
       "          0.1076, -0.0062, -0.0328, -0.0341,  0.0694,  0.0818, -0.0626,  0.0948,\n",
       "          0.0155, -0.0795,  0.0780,  0.0106, -0.0832,  0.0155, -0.0327, -0.0395,\n",
       "          0.0296,  0.0511,  0.0067,  0.0975,  0.1273, -0.0379, -0.0331, -0.0570,\n",
       "          0.1183, -0.0051,  0.0135, -0.0748, -0.0459,  0.0452, -0.0261, -0.0168,\n",
       "          0.0612,  0.0382,  0.0207,  0.0065,  0.0192, -0.0409,  0.0659,  0.0162],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.bias': tensor([-0.0252,  0.0480,  0.0031, -0.0461, -0.0386,  0.0466, -0.0018,  0.0021,\n",
       "         -0.0014, -0.0606, -0.0587,  0.0238, -0.0236,  0.0497, -0.0634, -0.0664,\n",
       "          0.0791,  0.0022, -0.0383, -0.0008, -0.0637, -0.0623, -0.0578, -0.0757,\n",
       "          0.0215, -0.0258,  0.0056, -0.0051, -0.0427,  0.0262, -0.0604,  0.0176,\n",
       "          0.0235,  0.0318, -0.0376, -0.1085, -0.0017, -0.0096, -0.0751, -0.0598,\n",
       "          0.0092, -0.0427, -0.0996, -0.0078, -0.0331, -0.0134, -0.0123, -0.0338,\n",
       "          0.0246,  0.0423,  0.0052, -0.1448, -0.0508,  0.0776,  0.0361,  0.0149,\n",
       "         -0.0019, -0.0270, -0.0521, -0.0142,  0.0455, -0.0295,  0.0229, -0.0033,\n",
       "          0.0102,  0.0011, -0.0507, -0.0802, -0.0628,  0.0049,  0.0279,  0.0065,\n",
       "         -0.0611,  0.0821, -0.0754,  0.0225, -0.0181, -0.0053, -0.1001,  0.0058,\n",
       "          0.0149, -0.0151,  0.0162,  0.0062, -0.0806, -0.0397,  0.0004, -0.0336,\n",
       "          0.0478, -0.0389, -0.0273, -0.0586,  0.0889, -0.0073, -0.0351,  0.0175,\n",
       "          0.0167, -0.0628,  0.0137,  0.0226, -0.0361, -0.0116, -0.0018, -0.0719,\n",
       "          0.0204,  0.0026, -0.0421,  0.0151,  0.0581, -0.0199,  0.0163, -0.0096,\n",
       "          0.0136, -0.0573, -0.0293, -0.0447, -0.0433,  0.0754, -0.0305, -0.0548,\n",
       "          0.0219,  0.0068,  0.0119,  0.0379, -0.0013, -0.0550,  0.0063, -0.0083],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.running_mean': tensor([-0.1142, -0.2239, -0.1845, -0.4038, -0.1999, -0.2209, -0.1941, -0.1584,\n",
       "         -0.1558, -0.0467, -0.1784, -0.3194, -0.4462, -0.3213,  0.0075,  0.1122,\n",
       "          0.3927,  0.4910,  0.3914, -0.1632, -0.5391,  0.3724, -0.0827, -0.0049,\n",
       "          0.2456,  0.0907, -0.5993, -0.0874,  0.1113,  0.0523, -0.0571,  0.3441,\n",
       "         -0.1778, -0.3706, -0.2638, -0.3267, -0.0911, -0.1270, -0.3653, -0.2433,\n",
       "          0.0092,  0.7109, -0.7420, -0.2486, -0.2826, -0.2353, -0.5108, -0.2124,\n",
       "         -0.1639,  0.0889, -0.2889, -0.3560,  0.2836, -0.1802,  0.6507, -0.0857,\n",
       "         -0.5921, -0.0437, -0.4526,  0.2607, -0.1638,  0.3114,  0.2794, -0.3691,\n",
       "         -0.2569, -0.2943, -0.2880, -0.1470,  0.1617, -0.2417,  0.1521, -0.5813,\n",
       "          0.0344,  0.2098,  0.0984,  0.2166,  0.0838,  0.0587,  0.1745,  0.6236,\n",
       "          0.1715, -0.0067, -0.5097, -0.5768, -0.0399,  0.2124,  0.3362, -0.6356,\n",
       "          0.5063, -0.0615, -0.0365, -0.1520,  0.4219,  0.6425, -0.3446,  0.2340,\n",
       "         -0.3295,  0.2267,  0.3488,  0.3315,  0.1219, -0.0896, -0.3919, -0.0771,\n",
       "         -0.1481, -0.4668, -0.1965,  0.6130,  0.5382, -0.0025, -0.0564,  0.1950,\n",
       "         -0.2382, -0.4001, -0.0605, -0.3274, -0.0994, -0.2081,  0.0506,  0.1663,\n",
       "          0.6432,  0.3962,  0.4272,  0.3695, -0.1882, -0.1165,  0.0159,  0.0018],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.running_var': tensor([ 0.6958,  0.3454,  1.2849,  0.7422,  0.9355,  0.8604,  0.5709,  0.2972,\n",
       "          0.1979,  0.3906,  1.2544,  0.7509,  0.4399,  0.4241,  0.9076,  1.0349,\n",
       "          1.2330,  1.2919,  0.4760,  0.4935,  0.5295,  0.9922,  0.7817,  0.9898,\n",
       "          0.4262,  0.6804,  1.4568,  0.6989,  0.3792,  0.3429,  1.1503,  0.3609,\n",
       "          0.8850,  0.0742,  0.9853,  0.8970,  1.2610,  0.8059,  1.0804,  0.8390,\n",
       "          0.9326,  1.4166,  1.4389,  0.7228,  0.5070,  0.6661,  0.7695,  0.7421,\n",
       "          1.1978,  0.6882,  0.3551,  1.1280,  1.8693,  0.4784, -0.1488,  0.1501,\n",
       "          0.1767,  0.5290,  0.0995,  1.9113,  0.9229,  0.6421,  0.7092, -0.1189,\n",
       "          0.5885,  0.9745,  0.8127,  1.1720,  0.3955,  0.3154,  0.4058,  1.3327,\n",
       "          0.1898,  0.5490,  1.4194,  0.2702,  0.4326,  0.6681,  0.1174,  1.6577,\n",
       "          0.6233,  1.3021,  0.4614,  1.0470,  1.8735,  0.9481,  0.5780,  0.7351,\n",
       "          0.5254,  1.1525,  0.8879,  0.4416,  0.6468,  1.4832,  1.0408,  0.9038,\n",
       "          0.2136,  0.9742,  0.3471,  1.1259,  0.8562,  0.7986,  0.4195,  0.7279,\n",
       "          0.6645,  1.0810,  0.3436,  0.7993,  0.7962,  0.8244,  0.8657,  0.9624,\n",
       "          0.8338,  0.5965,  0.5811,  1.1777,  0.3838,  0.9591,  0.4318,  0.3170,\n",
       "          0.9314,  0.6222,  0.7455,  0.9738,  0.3837,  0.7515,  0.2158,  0.5143],\n",
       "        device='mps:0'),\n",
       " 'model.5.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.6.0.weight': tensor([[[[-9.6699e-03, -8.7674e-03, -2.9344e-02],\n",
       "           [-1.5472e-04, -1.1154e-02, -1.7213e-02],\n",
       "           [-4.6532e-03, -2.4118e-02, -2.5160e-02]],\n",
       " \n",
       "          [[-9.4429e-03, -1.8907e-02, -9.5576e-03],\n",
       "           [-1.2743e-02, -1.9169e-02, -1.4725e-02],\n",
       "           [-1.8073e-02, -2.4278e-02, -1.7208e-02]],\n",
       " \n",
       "          [[ 2.5959e-02,  1.4967e-02,  1.1030e-02],\n",
       "           [ 1.1235e-02, -1.7000e-02, -1.0928e-02],\n",
       "           [ 2.4576e-03, -2.3727e-02, -3.5670e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.0196e-02, -2.1329e-03,  3.5674e-03],\n",
       "           [ 3.7990e-04,  1.7052e-03,  7.5539e-03],\n",
       "           [ 4.7099e-03, -6.5637e-03, -2.0924e-02]],\n",
       " \n",
       "          [[-1.7523e-02, -4.4873e-03, -4.6249e-04],\n",
       "           [-2.8895e-02, -2.1548e-02,  1.4715e-02],\n",
       "           [ 2.3488e-03, -1.1555e-02, -5.7388e-03]],\n",
       " \n",
       "          [[-2.3548e-03, -1.8632e-02, -7.6736e-03],\n",
       "           [-1.0813e-02,  1.1282e-03, -4.3985e-04],\n",
       "           [ 3.6270e-03, -3.3678e-03,  2.2310e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.4776e-03,  7.1244e-03,  1.7428e-02],\n",
       "           [ 3.2597e-02,  2.0980e-02,  7.1822e-03],\n",
       "           [ 1.1453e-02,  2.0821e-02,  6.8681e-03]],\n",
       " \n",
       "          [[ 2.4094e-02,  1.1941e-02,  5.4678e-03],\n",
       "           [-2.6577e-03, -4.8231e-03,  1.4951e-02],\n",
       "           [-1.1541e-02, -6.6015e-04, -2.5914e-02]],\n",
       " \n",
       "          [[ 4.8908e-02,  2.2574e-02,  3.8809e-03],\n",
       "           [ 2.3302e-03, -1.4504e-02, -1.3814e-03],\n",
       "           [ 5.8424e-03,  1.1963e-02, -1.6735e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7802e-02, -3.1573e-03,  3.0833e-03],\n",
       "           [-4.8450e-03, -1.6733e-02, -1.0499e-02],\n",
       "           [-1.2136e-02, -9.1964e-03, -7.3209e-03]],\n",
       " \n",
       "          [[-4.5614e-04, -1.2106e-02, -1.3936e-02],\n",
       "           [-1.4060e-02, -1.4706e-02, -9.8291e-03],\n",
       "           [-4.4102e-03, -1.9708e-03, -3.2758e-03]],\n",
       " \n",
       "          [[-6.9148e-03, -1.2561e-02, -1.4511e-02],\n",
       "           [-1.8293e-02, -2.9669e-02, -3.8557e-02],\n",
       "           [-1.7603e-02, -2.6170e-02, -3.3060e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 6.7948e-03,  3.7588e-04,  7.0391e-03],\n",
       "           [ 7.4844e-03,  2.4124e-03,  1.1626e-02],\n",
       "           [ 7.4108e-03,  2.0839e-02,  2.5198e-02]],\n",
       " \n",
       "          [[-1.1036e-02,  2.9962e-03,  6.7254e-03],\n",
       "           [-1.9340e-03, -3.9473e-03, -2.4611e-04],\n",
       "           [ 1.9976e-02,  2.5085e-02,  1.6317e-02]],\n",
       " \n",
       "          [[ 3.6232e-02,  1.2181e-02,  4.2581e-03],\n",
       "           [ 1.2492e-02, -1.0489e-02,  4.0040e-03],\n",
       "           [ 2.2169e-02, -2.0907e-02,  8.7429e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.0251e-03,  5.7300e-03,  1.8313e-02],\n",
       "           [-3.1890e-03, -6.1941e-03,  1.7534e-03],\n",
       "           [ 1.0499e-02, -8.2017e-03, -1.8880e-03]],\n",
       " \n",
       "          [[-1.4350e-02,  9.8270e-03,  8.8710e-03],\n",
       "           [-1.2843e-02,  2.5528e-03,  6.7338e-03],\n",
       "           [ 1.6622e-02,  1.9785e-02,  1.7224e-02]],\n",
       " \n",
       "          [[ 8.2741e-03,  4.5124e-03, -1.1150e-02],\n",
       "           [ 9.1957e-03,  8.0219e-03, -9.1265e-03],\n",
       "           [ 2.4866e-02,  3.9500e-03,  1.0824e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.9857e-04, -1.2871e-03, -9.9152e-03],\n",
       "           [-6.9196e-03,  2.7485e-02,  1.1650e-02],\n",
       "           [-3.9156e-03,  3.9678e-02,  2.5504e-02]],\n",
       " \n",
       "          [[-1.9720e-02, -9.3219e-03,  8.5478e-03],\n",
       "           [-1.0524e-02, -3.8178e-03,  8.9365e-03],\n",
       "           [-1.6411e-02, -3.0015e-02, -2.0843e-02]],\n",
       " \n",
       "          [[ 7.2912e-02,  8.3857e-02,  3.4939e-02],\n",
       "           [ 2.7471e-02,  4.5185e-02,  4.9221e-02],\n",
       "           [-1.5847e-02, -2.7916e-04,  7.6618e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-8.2272e-03, -4.1684e-03,  4.1144e-02],\n",
       "           [-2.8758e-02, -3.3141e-02, -1.5599e-02],\n",
       "           [-2.0843e-02, -2.8529e-03,  2.4863e-02]],\n",
       " \n",
       "          [[-2.9770e-02, -1.4071e-02, -6.7187e-03],\n",
       "           [-2.1312e-02, -1.3766e-02, -9.1281e-03],\n",
       "           [-1.1401e-02, -2.4907e-02, -1.5927e-02]],\n",
       " \n",
       "          [[-6.7125e-03, -7.2847e-03,  6.8652e-04],\n",
       "           [-1.9976e-02, -1.4038e-02, -3.6186e-03],\n",
       "           [-1.8981e-02, -1.3228e-02, -2.2967e-02]]],\n",
       " \n",
       " \n",
       "         [[[-8.5870e-03, -1.1931e-03, -2.9549e-03],\n",
       "           [-1.3107e-02,  5.1624e-03,  5.1511e-03],\n",
       "           [-8.7522e-03,  1.8276e-02,  2.0831e-02]],\n",
       " \n",
       "          [[-9.3224e-04, -1.5259e-02, -6.8429e-03],\n",
       "           [-4.3492e-03, -1.1891e-02,  4.9303e-03],\n",
       "           [-1.7588e-02, -1.7449e-02, -3.2387e-02]],\n",
       " \n",
       "          [[-1.3615e-03, -5.8231e-03,  1.4639e-02],\n",
       "           [-4.7032e-02, -3.5963e-02, -7.4108e-03],\n",
       "           [ 2.8376e-02, -2.1279e-03,  1.4756e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.9175e-02,  2.7908e-02,  2.6511e-02],\n",
       "           [ 5.7552e-03,  4.9633e-03,  3.3416e-03],\n",
       "           [-3.9524e-04, -7.9562e-03, -2.5160e-03]],\n",
       " \n",
       "          [[-3.4643e-02, -4.1534e-02, -3.4830e-02],\n",
       "           [-1.3535e-02, -1.8149e-02, -1.5942e-02],\n",
       "           [-1.1067e-02, -1.1593e-02, -1.7360e-02]],\n",
       " \n",
       "          [[-1.8973e-02, -4.3357e-03,  2.8745e-03],\n",
       "           [ 1.8907e-02,  5.7824e-03, -1.1475e-02],\n",
       "           [ 2.9073e-02, -1.3032e-02, -8.8392e-03]]],\n",
       " \n",
       " \n",
       "         [[[-3.0251e-02, -2.6175e-02, -1.0869e-02],\n",
       "           [ 5.1357e-04,  4.6218e-03,  9.9678e-03],\n",
       "           [-1.4488e-02, -3.5661e-02, -1.4129e-02]],\n",
       " \n",
       "          [[ 4.3237e-03, -1.7857e-02, -7.0030e-03],\n",
       "           [-5.8069e-05, -1.3152e-02,  2.2034e-03],\n",
       "           [-1.9968e-02, -2.7619e-02, -1.1116e-02]],\n",
       " \n",
       "          [[-3.2253e-02,  9.8018e-03,  1.4440e-02],\n",
       "           [-1.8568e-02,  1.8695e-02,  1.7818e-02],\n",
       "           [-1.0132e-02, -1.7570e-02, -2.3076e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.7840e-02,  1.2452e-02, -5.1830e-03],\n",
       "           [-1.0626e-02, -5.5322e-03, -6.5299e-03],\n",
       "           [-1.5096e-03,  2.0659e-02,  3.3932e-02]],\n",
       " \n",
       "          [[-6.7016e-03, -1.0546e-02, -1.4727e-02],\n",
       "           [-1.4163e-02, -2.6727e-02, -4.4898e-03],\n",
       "           [-1.3434e-02, -2.3277e-02, -7.5000e-03]],\n",
       " \n",
       "          [[-2.1790e-02, -8.3930e-03, -1.6633e-02],\n",
       "           [-2.6992e-02, -1.6964e-02, -2.4623e-02],\n",
       "           [-1.6749e-02, -1.9817e-02, -1.6110e-02]]]], device='mps:0'),\n",
       " 'model.6.1.weight': tensor([ 0.0360,  0.0324,  0.0541, -0.0966,  0.0093,  0.0254,  0.0746, -0.0341,\n",
       "          0.1050, -0.0130,  0.0609, -0.0880, -0.1148,  0.0444,  0.0270,  0.1123,\n",
       "          0.0514, -0.0292, -0.0690, -0.0247,  0.0700,  0.0108, -0.0045,  0.0042,\n",
       "          0.0292,  0.1043, -0.0701, -0.0129,  0.0289,  0.0607, -0.0009, -0.0997,\n",
       "          0.0432, -0.1274, -0.0752, -0.0161,  0.0066,  0.1011,  0.0527,  0.0584,\n",
       "         -0.0304, -0.0298,  0.0663, -0.0208, -0.0315,  0.0212, -0.0084,  0.0200,\n",
       "          0.0346,  0.0799,  0.0300, -0.0056,  0.1044,  0.0322, -0.0083, -0.0498,\n",
       "         -0.0215,  0.0475,  0.0556,  0.0064, -0.0319,  0.0503, -0.0872, -0.0689,\n",
       "          0.0676, -0.0314,  0.0493,  0.0239, -0.0072,  0.0017,  0.0389, -0.0197,\n",
       "         -0.0257, -0.1865,  0.0771, -0.0060,  0.0263,  0.0855,  0.0581,  0.0172,\n",
       "          0.0739,  0.0985, -0.0051, -0.0004,  0.0569, -0.0123,  0.0377, -0.1279,\n",
       "         -0.1221, -0.0023, -0.0028, -0.0214, -0.0673, -0.0260, -0.1343, -0.0291,\n",
       "          0.0949,  0.0345, -0.0900, -0.0580, -0.0355,  0.0262, -0.0191,  0.0617,\n",
       "         -0.0299,  0.0012, -0.0427,  0.0425, -0.0353, -0.0142, -0.0242,  0.0168,\n",
       "          0.0280, -0.0048, -0.0095, -0.0711,  0.0031,  0.0794, -0.0940,  0.0240,\n",
       "          0.0600,  0.0094, -0.0032,  0.1257, -0.0291, -0.0859, -0.0170,  0.1016],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.bias': tensor([ 0.0305, -0.0296, -0.0067, -0.0752, -0.0029, -0.0114,  0.0446, -0.0243,\n",
       "          0.0654, -0.0039,  0.0278, -0.0172, -0.0264,  0.0207, -0.0226,  0.0126,\n",
       "          0.0451,  0.0208, -0.0619,  0.0093,  0.0201,  0.0101,  0.0049,  0.0140,\n",
       "         -0.0221,  0.0469, -0.0447,  0.0046, -0.0537, -0.0016, -0.0951, -0.0371,\n",
       "         -0.0227, -0.0698, -0.0435, -0.0260, -0.0396,  0.0097, -0.0060,  0.0237,\n",
       "          0.0188, -0.0062, -0.0484, -0.0010,  0.0197,  0.0060, -0.0728, -0.0005,\n",
       "         -0.0300, -0.0115, -0.0104,  0.0395, -0.0088,  0.0815, -0.0087, -0.0475,\n",
       "         -0.0218,  0.0251,  0.0333, -0.0262, -0.0144,  0.0326, -0.0950, -0.0478,\n",
       "         -0.0376, -0.0262, -0.0306, -0.0278, -0.0547, -0.0479, -0.0072,  0.0016,\n",
       "         -0.0204, -0.1338,  0.0034,  0.0351, -0.0220,  0.0204, -0.0317, -0.0326,\n",
       "          0.0327,  0.0445,  0.0132, -0.0265,  0.0230, -0.0759,  0.0149, -0.0911,\n",
       "         -0.0946, -0.0204, -0.0917, -0.0465, -0.0724, -0.0546, -0.0254,  0.0432,\n",
       "          0.0438,  0.0351, -0.0512, -0.0429, -0.0258, -0.0490, -0.0369, -0.0190,\n",
       "         -0.0166,  0.0161, -0.0693, -0.0197, -0.0645, -0.0712, -0.0323, -0.0303,\n",
       "         -0.0556,  0.0128, -0.0393, -0.0443,  0.0040,  0.0176, -0.0707, -0.0286,\n",
       "          0.0439, -0.0204, -0.0748,  0.0015, -0.0277, -0.0725, -0.0891, -0.0078],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.running_mean': tensor([-0.1501,  0.0932,  0.7032, -0.9466,  0.3200,  0.1317,  0.4597,  0.3888,\n",
       "         -0.5977,  0.1513,  0.5955, -0.5693, -0.2170,  0.3258,  0.2916,  0.5373,\n",
       "         -0.3783,  0.6644, -0.5684, -0.4744, -0.2687,  0.2199, -0.6447,  0.6916,\n",
       "          0.1723, -0.2530, -0.0824,  0.2200,  0.1361,  0.3889, -0.1131,  0.3076,\n",
       "          0.2002, -0.4952, -0.3991, -0.1275, -0.1053,  0.1108,  0.0553,  0.6915,\n",
       "         -0.3746,  0.2537, -0.2689,  0.0791,  0.3971, -0.6797, -0.1394, -0.7749,\n",
       "         -0.4268,  0.9628, -0.4485, -0.7563,  0.4068,  0.3745, -0.0167, -1.1033,\n",
       "          0.2481,  0.3088, -0.7525, -0.0379, -0.0831, -0.8422, -1.4326,  0.6304,\n",
       "          0.0569, -0.0140, -0.1494, -0.8802,  0.4179, -0.1683, -0.4472,  1.1487,\n",
       "         -0.4373,  0.1077,  0.0396, -0.9285,  0.1792,  0.1198,  0.1039,  0.2737,\n",
       "          0.4717,  0.2396,  0.0099, -0.1595,  0.1949, -0.5213, -0.1279, -0.6582,\n",
       "         -0.4606, -0.8095, -0.4157, -0.3504,  0.0362,  0.4607, -0.4675,  1.2139,\n",
       "         -0.7343,  0.4016, -0.5884,  0.4343, -0.1774,  0.0755,  0.0530,  0.0594,\n",
       "          0.0144, -0.6166,  0.0224,  0.1387,  0.2170, -0.3100,  0.2691,  0.4233,\n",
       "          0.0316, -0.5389, -0.2780, -0.6107,  0.1910, -0.1177, -0.0467, -0.0896,\n",
       "          0.1801,  0.1036, -0.4685,  0.1565,  0.1924,  0.5097, -0.4090, -0.3282],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.running_var': tensor([ 0.7748,  1.1114,  0.4112,  1.4758,  0.2950,  1.6976,  1.3040,  0.7354,\n",
       "          1.3160,  0.4121,  1.3439,  0.7839,  0.3886,  1.8191,  1.6369,  1.5568,\n",
       "          0.4994,  1.4134,  0.8622,  0.4778,  1.2338,  0.2202,  1.7516,  0.7837,\n",
       "          0.4751,  0.3420,  1.7535, -0.1004,  1.1015, -0.0542,  0.7994,  0.6260,\n",
       "          0.6213,  0.9629,  1.7890,  1.4923, -0.1436,  1.4525,  0.3257,  0.8122,\n",
       "          0.2742,  0.4067,  1.4299,  1.1323,  2.8764,  2.5669,  0.2491,  0.7931,\n",
       "          0.8450,  1.1849,  1.1650,  0.9150,  1.2963,  1.0793,  1.1886,  1.7025,\n",
       "          0.7163,  1.5091,  0.3843,  0.7931,  1.4157,  1.0908,  1.7735,  1.4528,\n",
       "          1.2480,  0.5501,  0.6042,  0.3124,  0.7558,  0.5964,  0.9316,  1.1416,\n",
       "          1.2129,  1.1279,  1.0220,  0.9750,  0.4551,  0.9475,  0.7013,  0.9813,\n",
       "          1.4638,  0.5466,  1.3783,  0.4369,  0.7862,  0.6181,  1.5918,  0.8386,\n",
       "          0.7878,  1.0335,  0.9845,  1.4439,  0.8760,  1.0517,  0.5898,  1.9622,\n",
       "          0.9764,  0.5424,  1.2338,  1.2249,  0.9678,  1.6388,  0.7889,  1.0007,\n",
       "          0.7402,  2.6305,  0.2121,  1.3300,  1.0175,  1.5550,  2.0982,  1.5077,\n",
       "          0.5940,  1.8693,  0.5464,  0.8131,  0.8330,  0.7777,  0.7727,  0.8026,\n",
       "          0.7060,  0.3157,  1.3923,  0.8588,  1.2224,  2.8076,  1.0932,  0.9883],\n",
       "        device='mps:0'),\n",
       " 'model.6.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.7.0.weight': tensor([[[[-1.8356e-03,  1.7264e-03,  5.9007e-03],\n",
       "           [-2.5814e-03,  5.1853e-03,  1.3279e-02],\n",
       "           [-7.2373e-03, -2.9225e-03,  2.2705e-03]],\n",
       " \n",
       "          [[ 3.8361e-03, -6.5108e-03, -1.1765e-02],\n",
       "           [-5.8836e-03, -1.2802e-02, -8.7439e-03],\n",
       "           [-2.6479e-04,  1.6720e-03,  2.4140e-03]],\n",
       " \n",
       "          [[-1.0592e-03, -3.8688e-04, -2.8711e-03],\n",
       "           [-2.7478e-03,  3.9563e-04, -4.0273e-03],\n",
       "           [-3.8617e-03,  2.5918e-03, -2.4367e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.0511e-03, -1.0911e-02,  5.6485e-03],\n",
       "           [ 2.3387e-03, -1.1656e-02,  5.0876e-03],\n",
       "           [ 1.1479e-02, -2.8726e-03,  5.1688e-03]],\n",
       " \n",
       "          [[-5.1170e-03, -6.3479e-03, -4.6137e-03],\n",
       "           [ 2.2060e-03, -1.3745e-04, -2.7469e-03],\n",
       "           [ 7.3968e-03,  6.5599e-03,  9.0900e-03]],\n",
       " \n",
       "          [[ 1.1253e-02,  5.0037e-03,  3.0318e-03],\n",
       "           [ 7.7248e-03, -1.0296e-03,  1.9709e-03],\n",
       "           [ 1.8884e-03, -7.5970e-03, -6.3189e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 1.0140e-02,  3.0465e-03,  8.6918e-03],\n",
       "           [ 2.2504e-03, -5.1106e-03,  3.3312e-03],\n",
       "           [-2.9709e-03, -5.2720e-03,  7.9639e-05]],\n",
       " \n",
       "          [[-6.7174e-03, -9.0225e-03, -7.6508e-03],\n",
       "           [ 1.0671e-02,  5.6262e-04,  2.5393e-03],\n",
       "           [ 8.4206e-03,  8.8512e-03,  1.9344e-02]],\n",
       " \n",
       "          [[-1.5321e-03, -4.7287e-03, -5.0398e-03],\n",
       "           [ 4.1659e-03,  3.4099e-03,  4.8907e-03],\n",
       "           [-5.1218e-03, -1.0838e-03,  2.1799e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-3.9499e-03, -2.5452e-03, -1.2846e-02],\n",
       "           [-7.7495e-03, -4.5149e-03, -1.7856e-02],\n",
       "           [-2.1275e-03, -7.2489e-04, -1.0929e-02]],\n",
       " \n",
       "          [[-5.4123e-03, -6.4656e-03, -1.1617e-02],\n",
       "           [ 5.6081e-03, -1.3076e-03, -5.5093e-03],\n",
       "           [ 4.3574e-03,  6.7168e-03,  6.8277e-03]],\n",
       " \n",
       "          [[-1.6540e-03, -5.1565e-03, -3.3416e-03],\n",
       "           [ 4.0789e-03,  3.5035e-03,  1.0612e-03],\n",
       "           [-3.3999e-03,  4.4832e-04, -8.0068e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 2.7465e-02,  3.2047e-02,  3.0165e-02],\n",
       "           [ 1.0812e-02,  2.0041e-02,  1.8137e-02],\n",
       "           [-4.7735e-03,  2.0262e-03,  4.6311e-03]],\n",
       " \n",
       "          [[ 2.0204e-02,  2.0942e-02,  1.7986e-02],\n",
       "           [ 1.8600e-03, -3.1977e-03, -8.5605e-05],\n",
       "           [-6.2513e-03, -5.2090e-03, -4.5661e-03]],\n",
       " \n",
       "          [[ 8.1358e-04, -9.2880e-03, -7.4634e-03],\n",
       "           [ 3.0140e-03, -3.9808e-03, -1.0271e-02],\n",
       "           [ 8.3606e-03,  1.0104e-02, -6.2163e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.5492e-03,  5.1884e-03,  4.3360e-03],\n",
       "           [ 1.6403e-02,  6.7189e-03,  1.5007e-03],\n",
       "           [ 9.8359e-03, -6.6970e-03, -1.0675e-02]],\n",
       " \n",
       "          [[-1.4835e-02, -7.1641e-03, -7.8197e-03],\n",
       "           [-1.9966e-03,  2.0985e-03,  6.1322e-03],\n",
       "           [ 8.8363e-03,  4.8344e-03,  2.4329e-03]],\n",
       " \n",
       "          [[ 1.2940e-02,  1.2025e-02,  1.0150e-02],\n",
       "           [-1.5602e-04, -5.1880e-04,  3.6075e-03],\n",
       "           [-1.5425e-02, -1.9821e-02, -1.6968e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-5.7223e-03, -7.5607e-03, -5.6387e-03],\n",
       "           [-3.5713e-03, -5.4932e-03, -5.2370e-03],\n",
       "           [-2.5733e-03,  2.6668e-03,  3.0001e-03]],\n",
       " \n",
       "          [[ 4.6885e-03,  1.4921e-03,  4.4918e-03],\n",
       "           [-4.0603e-03, -9.2502e-03, -3.2712e-03],\n",
       "           [-1.9717e-02, -2.3075e-02, -9.7464e-03]],\n",
       " \n",
       "          [[-4.5196e-04, -3.6155e-04,  7.1483e-04],\n",
       "           [ 3.7751e-04, -1.5803e-03, -6.7883e-03],\n",
       "           [-2.5032e-03, -2.6632e-03, -7.1545e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.2564e-02,  2.8545e-02,  3.4371e-02],\n",
       "           [ 2.8189e-02,  1.8471e-02,  3.7249e-02],\n",
       "           [ 1.7714e-02,  1.1168e-02,  2.9253e-02]],\n",
       " \n",
       "          [[-3.1106e-03, -7.3226e-03, -1.6342e-02],\n",
       "           [ 2.6104e-03,  1.6826e-04, -5.1245e-03],\n",
       "           [-8.8557e-03, -8.8558e-03, -1.0231e-02]],\n",
       " \n",
       "          [[ 8.4406e-04,  1.3514e-02,  1.7641e-02],\n",
       "           [-5.9403e-03,  1.1096e-03,  8.7239e-04],\n",
       "           [-1.5745e-02, -1.6359e-02, -1.0165e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3933e-02, -2.2829e-02, -2.5679e-02],\n",
       "           [ 4.6439e-04, -4.3996e-03, -5.4398e-03],\n",
       "           [-5.3969e-03, -2.8029e-03, -3.9331e-03]],\n",
       " \n",
       "          [[-2.2814e-03, -4.2690e-03, -3.6338e-04],\n",
       "           [-8.7576e-03, -1.3153e-02, -1.8290e-02],\n",
       "           [-4.7109e-03, -1.3727e-02, -1.7678e-02]],\n",
       " \n",
       "          [[-1.9135e-02, -1.5491e-02, -1.4417e-02],\n",
       "           [-1.8249e-02, -4.6990e-03, -3.0855e-03],\n",
       "           [-1.8874e-02, -1.2077e-02,  7.2481e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.0038e-02,  1.8410e-02,  1.2951e-02],\n",
       "           [ 5.7994e-03,  2.0541e-02,  1.4935e-02],\n",
       "           [ 3.7133e-04,  1.7955e-02,  1.8175e-02]],\n",
       " \n",
       "          [[ 1.3127e-02, -7.6629e-03, -8.9689e-03],\n",
       "           [ 2.6954e-02,  2.2311e-02,  1.3098e-02],\n",
       "           [ 1.0052e-02,  1.9573e-02,  1.2985e-02]],\n",
       " \n",
       "          [[-7.2608e-03, -3.9490e-03,  6.9281e-03],\n",
       "           [-6.5879e-03, -2.2351e-03, -4.3041e-03],\n",
       "           [-1.6089e-02, -1.5796e-02, -1.4038e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.8146e-04,  4.2608e-03,  6.6502e-03],\n",
       "           [ 1.4980e-02,  1.4487e-02,  1.2340e-02],\n",
       "           [ 1.5325e-02,  1.6100e-02,  1.4646e-02]],\n",
       " \n",
       "          [[ 1.5001e-02,  5.2159e-03,  2.8526e-03],\n",
       "           [-7.0799e-04, -1.0805e-02, -1.0964e-02],\n",
       "           [-5.1188e-03, -3.5159e-03, -7.5562e-04]],\n",
       " \n",
       "          [[ 2.0724e-03,  4.8920e-03,  3.3888e-03],\n",
       "           [ 7.5158e-03,  6.7413e-03,  8.3652e-03],\n",
       "           [ 1.0498e-02,  1.1334e-02,  6.9899e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 9.7228e-03,  5.0041e-03,  2.5944e-03],\n",
       "           [ 1.3995e-02,  8.0030e-03,  4.1026e-03],\n",
       "           [ 1.6018e-02,  1.6388e-02,  1.0911e-02]],\n",
       " \n",
       "          [[-2.3810e-02, -9.7801e-03, -2.5624e-03],\n",
       "           [-4.0561e-03,  7.4257e-03,  8.0522e-03],\n",
       "           [ 1.6055e-02,  1.8206e-02,  1.1284e-02]],\n",
       " \n",
       "          [[ 4.7168e-03,  2.8336e-03,  1.1049e-02],\n",
       "           [ 1.4199e-02,  8.9305e-03,  1.4335e-02],\n",
       "           [ 1.1981e-02,  1.6001e-02,  1.6426e-02]]]], device='mps:0'),\n",
       " 'model.7.1.weight': tensor([-0.0029,  0.0145,  0.0054, -0.0014, -0.0116,  0.0080,  0.0057, -0.0121,\n",
       "         -0.0363,  0.0370, -0.0039, -0.0041, -0.0235,  0.0291,  0.0086,  0.0168,\n",
       "         -0.0090,  0.0124, -0.0168, -0.0145, -0.0100,  0.0152,  0.0055,  0.0103,\n",
       "         -0.0121, -0.0046,  0.0142,  0.0172,  0.0087,  0.0091,  0.0240,  0.0289,\n",
       "          0.0014,  0.0295,  0.0133, -0.0007,  0.0527,  0.0601, -0.0036, -0.0142,\n",
       "          0.0116,  0.0032,  0.0018, -0.0003,  0.0242,  0.0057, -0.0049, -0.0520,\n",
       "         -0.0141,  0.0127,  0.0315, -0.0129, -0.0135, -0.0030, -0.0064,  0.0040,\n",
       "          0.0132,  0.0047,  0.0164,  0.0135, -0.0294,  0.0031, -0.0123,  0.0476,\n",
       "          0.0047, -0.0114, -0.0277, -0.0157,  0.0018, -0.0241,  0.0010,  0.0014,\n",
       "         -0.0093, -0.0211,  0.0107, -0.0014,  0.0388,  0.0085,  0.0398, -0.0064,\n",
       "         -0.0127,  0.0093, -0.0186,  0.0140, -0.0284,  0.0072,  0.0056,  0.0057,\n",
       "         -0.0265,  0.0133, -0.0006,  0.0279, -0.0452, -0.0016,  0.0025, -0.0232,\n",
       "          0.0034,  0.0130,  0.0547,  0.0380,  0.0065, -0.0421,  0.0122,  0.0369,\n",
       "         -0.0145,  0.0431,  0.0024, -0.0018, -0.0490, -0.0247,  0.0120, -0.0369,\n",
       "          0.0162,  0.0012,  0.0444, -0.0645,  0.0078,  0.0500, -0.0061, -0.0414,\n",
       "         -0.0127,  0.0241, -0.0059, -0.0101, -0.0485, -0.0128, -0.0108, -0.0278,\n",
       "         -0.0830,  0.0090, -0.0564,  0.0219, -0.0029, -0.0499,  0.0279,  0.0085,\n",
       "         -0.0092, -0.0797, -0.0146,  0.0423,  0.0064, -0.0023,  0.0151, -0.0479,\n",
       "         -0.0170, -0.0024, -0.0296,  0.0023,  0.0349, -0.0080,  0.0062,  0.0051,\n",
       "         -0.0184, -0.0184, -0.0463,  0.0018, -0.0312, -0.0271,  0.0006,  0.0093,\n",
       "          0.0033,  0.0235,  0.0346,  0.0398,  0.0072, -0.0029, -0.0368,  0.0156,\n",
       "          0.0277, -0.0201, -0.0102, -0.0119,  0.0043, -0.0190,  0.0209,  0.0347,\n",
       "          0.0168,  0.0342,  0.0203,  0.0146, -0.0225,  0.0200, -0.0213,  0.0139,\n",
       "         -0.0190, -0.0094,  0.0454, -0.0185, -0.0162,  0.0073,  0.0079,  0.0249,\n",
       "         -0.0044,  0.0080,  0.0058,  0.0016, -0.0150, -0.0446, -0.0223, -0.0148,\n",
       "         -0.0117, -0.0107, -0.0169,  0.0009,  0.0030,  0.0037,  0.0169, -0.0200,\n",
       "         -0.0123, -0.0320, -0.0032,  0.0148, -0.0239,  0.0161, -0.0387, -0.0197,\n",
       "          0.0118,  0.0099, -0.0238, -0.0226,  0.0037,  0.0130,  0.0155,  0.0010,\n",
       "         -0.0016,  0.0443, -0.0229, -0.0671, -0.0107, -0.0374, -0.0215,  0.0134,\n",
       "         -0.0044, -0.0073, -0.0059, -0.0050, -0.0095, -0.0147,  0.0091,  0.0114,\n",
       "         -0.0329,  0.0113, -0.0170, -0.0294,  0.0037, -0.0245,  0.0006,  0.0344,\n",
       "         -0.0394, -0.0028,  0.0062,  0.0004, -0.0389,  0.0146,  0.0217,  0.0259],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.bias': tensor([-1.2563e-02,  1.1332e-02, -5.0020e-03, -1.2789e-02, -3.3913e-02,\n",
       "         -1.4771e-02,  8.1923e-03, -1.6201e-02, -2.6379e-02,  1.8879e-02,\n",
       "         -8.8674e-03, -1.1898e-02, -2.9188e-02, -3.6323e-02, -9.6568e-03,\n",
       "          7.3716e-03,  2.1437e-03,  6.4655e-03, -5.3979e-02, -2.0444e-02,\n",
       "         -1.0995e-02, -8.2587e-04, -8.5333e-04,  3.4814e-03, -1.1565e-02,\n",
       "         -5.9030e-03,  1.1005e-03, -1.6551e-02, -3.9999e-03, -3.3823e-02,\n",
       "          1.2102e-02,  1.6567e-04, -1.3526e-03,  2.4808e-03, -1.1437e-02,\n",
       "         -1.6096e-02,  2.4100e-02,  9.6970e-03, -7.2729e-03, -1.0728e-02,\n",
       "          8.2592e-03, -6.6930e-03, -5.3400e-03, -4.9358e-03,  9.8373e-04,\n",
       "         -5.3790e-03, -7.8212e-03, -2.0523e-02, -3.1061e-03, -2.3192e-02,\n",
       "          2.2870e-02, -1.3234e-04, -5.3654e-02,  7.4075e-03, -5.7400e-03,\n",
       "          2.2703e-03,  9.0958e-04, -2.5186e-03, -5.2768e-03,  7.3879e-03,\n",
       "         -1.7474e-02, -2.3420e-02, -2.7082e-02,  4.4390e-03, -4.7711e-03,\n",
       "         -1.0617e-02, -3.6429e-02, -2.2357e-02, -1.0678e-04, -7.4757e-03,\n",
       "         -3.8298e-02,  2.0751e-02, -1.0994e-03, -1.2115e-02, -1.2558e-02,\n",
       "         -6.0049e-03,  9.6067e-03, -3.4093e-03,  7.5349e-03, -3.5677e-03,\n",
       "         -2.1317e-02, -6.9488e-03, -1.7231e-02, -2.9676e-03, -3.5509e-02,\n",
       "         -2.6645e-02, -1.0443e-02, -1.5503e-02, -1.9120e-02, -1.2857e-02,\n",
       "          3.8948e-03,  1.6158e-02, -4.6685e-02, -4.6259e-02, -9.6962e-03,\n",
       "         -1.5001e-02, -9.7768e-03, -1.6999e-02,  4.1066e-02,  1.7208e-02,\n",
       "          1.0111e-03, -8.9650e-03, -5.2357e-04,  1.0941e-02, -2.5035e-02,\n",
       "          1.2879e-02, -1.0669e-02, -1.4271e-02, -4.4800e-02, -2.6265e-02,\n",
       "         -1.4543e-02, -4.8399e-02, -1.8789e-02, -1.4584e-02, -6.1484e-03,\n",
       "         -5.9822e-02,  1.8586e-02,  1.0683e-02, -7.0933e-03, -4.8164e-02,\n",
       "         -1.5162e-02,  7.0978e-03, -1.2485e-03, -2.7718e-02, -3.4577e-02,\n",
       "         -2.2659e-02, -1.2923e-02, -8.4565e-03, -8.4343e-02, -2.5245e-02,\n",
       "         -5.1757e-02, -1.4488e-02, -2.8142e-02, -3.4876e-02,  1.1581e-02,\n",
       "         -9.4365e-03, -1.6650e-02, -5.4780e-02, -3.8805e-02, -3.5038e-02,\n",
       "          1.2650e-02, -2.0674e-02, -7.5805e-03, -2.2257e-02, -2.0780e-02,\n",
       "         -2.6710e-02, -1.2507e-02, -2.6399e-02, -7.7296e-03, -1.6713e-02,\n",
       "         -1.7077e-02, -1.2150e-02, -1.9935e-02, -1.3343e-02, -2.7021e-02,\n",
       "         -1.2516e-02, -3.0935e-02, -3.8585e-02, -1.2681e-02,  1.1314e-02,\n",
       "          1.6006e-02,  2.4593e-03,  7.8465e-03,  1.1492e-02, -1.4404e-02,\n",
       "         -4.4452e-03, -2.5865e-02, -1.4426e-03,  6.3945e-04,  3.6290e-04,\n",
       "         -2.1139e-02,  1.4996e-02, -2.2337e-03, -2.1797e-02,  5.7936e-03,\n",
       "         -2.1169e-04, -1.0597e-02,  4.8131e-03,  5.2474e-03, -6.5932e-03,\n",
       "         -4.1882e-02,  1.4937e-02, -4.7842e-02, -1.3475e-02, -2.1830e-02,\n",
       "         -1.7446e-02, -8.8521e-03, -4.3964e-02, -2.5323e-02,  1.3646e-03,\n",
       "         -7.2745e-03, -2.0884e-02,  2.5047e-02, -5.4851e-05, -1.0410e-02,\n",
       "         -1.7453e-03, -1.1151e-02, -1.1672e-02, -9.8326e-03, -1.4585e-02,\n",
       "         -2.7145e-02, -3.8792e-02, -3.4528e-02, -1.9663e-02, -5.8575e-03,\n",
       "         -1.3501e-02, -1.6553e-03, -1.5716e-02, -1.5563e-02, -2.0906e-02,\n",
       "         -2.2624e-02, -2.0963e-02, -5.3912e-03, -1.2410e-02, -4.4098e-02,\n",
       "         -1.7779e-02,  8.9293e-03,  1.3905e-02, -4.8252e-02, -7.9131e-03,\n",
       "         -1.1117e-02, -3.0710e-02, -1.2240e-02, -5.9821e-03, -1.4998e-02,\n",
       "          2.0022e-03, -5.6368e-02, -2.6178e-02, -7.8171e-03, -3.5445e-02,\n",
       "         -2.3954e-02, -1.2082e-02, -1.3584e-02, -1.5059e-03,  1.5348e-02,\n",
       "         -1.5578e-02, -1.6189e-02, -2.3716e-02, -1.2188e-02,  8.2899e-03,\n",
       "         -2.5076e-02,  6.1503e-03, -3.5631e-02, -2.9274e-02, -1.1421e-02,\n",
       "         -1.0979e-02, -3.1396e-02, -6.8167e-03, -4.1847e-02,  3.4890e-03,\n",
       "          1.2740e-04, -7.3092e-03, -4.4243e-02, -1.7707e-02, -5.2031e-03,\n",
       "         -1.0457e-03], device='mps:0'),\n",
       " 'model.7.1.running_mean': tensor([ 0.2718,  0.1581, -0.3237,  0.2780, -0.0102,  0.3151,  0.1381,  0.1135,\n",
       "          0.1002,  0.1524, -0.1537, -0.0922, -0.0784,  0.1683, -0.2817,  0.1705,\n",
       "         -0.2468,  0.1681, -0.5288, -0.1866,  0.1869, -0.0721, -0.0590,  0.3521,\n",
       "         -0.1744, -0.0340, -0.3260,  0.0767,  0.3461,  0.0088,  0.0096,  0.1967,\n",
       "         -0.1281, -0.0453,  0.1045,  0.2189,  0.0472,  0.0321, -0.0786, -0.1187,\n",
       "         -0.0115,  0.2135,  0.0287,  0.0931,  0.0867,  0.1788, -0.3521,  0.0028,\n",
       "         -0.0936, -0.2260,  0.1912, -0.3715,  0.1543, -0.0026, -0.3186, -0.2450,\n",
       "          0.0044,  0.0181,  0.0350,  0.0670,  0.3411,  0.1218,  0.1560,  0.1739,\n",
       "          0.0265, -0.2928, -0.4287, -0.1178, -0.2433, -0.1795, -0.2027, -0.0475,\n",
       "          0.2093, -0.3429,  0.0470, -0.0244, -0.0195,  0.3054,  0.3518, -0.0016,\n",
       "         -0.6231,  0.0231, -0.2500,  0.2135, -0.1581,  0.1017,  0.2284,  0.2533,\n",
       "         -0.4289,  0.0982,  0.1630,  0.2748,  0.0248,  0.2117,  0.1122,  0.1607,\n",
       "          0.1703,  0.0855,  0.1111, -0.0961, -0.0848, -0.4099, -0.1805, -0.0285,\n",
       "         -0.2449, -0.1544,  0.0969,  0.1955,  0.2731, -0.1572, -0.1471,  0.1643,\n",
       "          0.0782, -0.0365,  0.2638, -0.3674, -0.0216,  0.0635, -0.2275, -0.4466,\n",
       "         -0.2748,  0.1613, -0.0692, -0.0493, -0.4887, -0.4669, -0.1094, -0.2561,\n",
       "         -0.9709, -0.1338,  0.1162,  0.3135, -0.0151,  0.1261,  0.4890,  0.1377,\n",
       "         -0.3160, -0.2259, -0.2281,  0.0889,  0.0974, -0.1174, -0.3462,  0.0725,\n",
       "          0.0373, -0.1260, -0.0273,  0.3750,  0.1893,  0.0887,  0.3340, -0.0875,\n",
       "          0.0450,  0.1296, -0.2006,  0.1475,  0.0296, -0.0368,  0.2835, -0.2165,\n",
       "          0.0302, -0.0053,  0.0535,  0.1428, -0.0756, -0.1409,  0.0043,  0.1493,\n",
       "          0.3294,  0.0500, -0.1865,  0.2141, -0.1607, -0.0771, -0.3378, -0.0016,\n",
       "         -0.1169,  0.1694,  0.4550,  0.0151, -0.0355, -0.0167,  0.5583,  0.0572,\n",
       "         -0.3214, -0.1631,  0.2955,  0.0906, -0.1079,  0.0860,  0.0365,  0.2366,\n",
       "         -0.0080,  0.0370, -0.1373,  0.1633, -0.0973,  0.2489, -0.3070, -0.5367,\n",
       "         -0.4408,  0.4085, -0.0115,  0.0513, -0.1147,  0.2835,  0.0332, -0.0512,\n",
       "          0.4284, -0.2071, -0.0138,  0.1785, -0.2478,  0.0817,  0.0220, -0.1607,\n",
       "         -0.0490, -0.2614,  0.3170,  0.3005,  0.0732, -0.0406,  0.0638,  0.2780,\n",
       "         -0.0716,  0.1553, -0.3884, -0.3052, -0.2341,  0.0130,  0.1889, -0.1074,\n",
       "         -0.1575,  0.1472, -0.2482, -0.0114,  0.0364, -0.1000, -0.1188,  0.1798,\n",
       "          0.2482,  0.0366, -0.4872, -0.3485,  0.1895, -0.0546, -0.1699,  0.3657,\n",
       "         -0.2500,  0.1067, -0.0734, -0.0493, -0.2434, -0.1538,  0.2196,  0.5841],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.running_var': tensor([ 0.2574,  0.0614,  0.4043,  0.2533,  0.1080,  0.1408,  0.2766,  0.1957,\n",
       "          0.3629,  0.1799,  0.2918,  0.5094,  0.4509,  0.3320,  0.1999,  0.2967,\n",
       "          0.4684,  0.3689,  0.7104,  0.3208,  0.3193,  0.2464,  0.2872,  0.5029,\n",
       "          0.2035,  0.3481,  0.6388,  0.3980,  0.3612,  0.3934,  0.4333,  0.2842,\n",
       "          0.2360,  0.4681,  0.2606,  0.2470,  0.2640,  0.3394,  0.4118,  0.4354,\n",
       "          0.1280,  0.3546,  0.1973,  0.2355,  0.2879,  0.3686,  0.4395,  0.6321,\n",
       "          0.4369,  0.2905,  0.2427,  0.3242,  0.5285,  0.2236,  0.5959,  0.3002,\n",
       "          0.2056,  0.1808,  0.4870,  0.3750,  0.3583,  0.3160,  0.3919,  0.3997,\n",
       "          0.3468,  0.6002,  0.5152,  0.6243,  0.5087,  0.3633,  0.5856,  0.4417,\n",
       "          0.4427,  0.4586,  0.3466,  0.2185,  0.3173,  0.2358,  0.3678,  0.4246,\n",
       "          0.2614,  0.2175,  0.3577,  0.2401,  0.4050,  0.4637,  0.3447,  0.6980,\n",
       "          0.4151,  0.0913,  0.2911,  0.2116,  0.4520,  0.3256,  0.2759,  0.5910,\n",
       "          0.2348,  0.3255,  0.4213,  0.3710,  0.1407,  0.2940,  0.3368,  0.1340,\n",
       "          0.6954,  0.3386,  0.6381,  0.3280,  0.6238,  0.3268,  0.5956,  0.4187,\n",
       "          0.6877,  0.6431,  0.4207,  0.3325,  0.4078,  0.1272,  0.2861,  0.6372,\n",
       "          0.2824,  0.2682,  0.4058,  0.4521,  0.6983,  0.5730,  0.3420,  0.4912,\n",
       "          2.4029,  0.6120,  0.4072,  0.3042,  0.4671,  0.4530,  0.2165,  0.3080,\n",
       "          0.5139,  0.6580,  0.6216,  0.9233,  0.4171,  0.6094,  0.1146,  0.7965,\n",
       "          0.4844,  0.5315,  0.6212,  0.8996,  0.1685,  0.5714,  0.2853,  0.7048,\n",
       "          0.4837,  0.4716,  0.9212,  0.2994,  0.4970,  0.3378,  0.5828,  0.4382,\n",
       "          1.1653,  0.2762,  0.4992,  0.1370,  0.5345,  0.5401,  0.3717,  0.2648,\n",
       "         -0.0455,  0.6917,  0.4505,  0.1487,  0.6113,  0.2591,  0.3837,  0.2121,\n",
       "          0.4034,  0.3951,  0.7129,  0.3656,  0.6221,  0.2570,  0.3869,  0.3572,\n",
       "          0.5514,  0.3779,  0.3536,  0.3461,  0.2445,  0.2442,  0.1258,  0.4785,\n",
       "          0.1400,  0.3179,  0.4052,  0.4948,  0.4189,  0.5516,  0.5964,  0.5748,\n",
       "          0.3922,  0.7083,  0.2988,  0.4391,  0.2560,  0.2244,  0.2878,  0.6710,\n",
       "          0.2008,  0.3875,  0.3139,  0.2230,  0.4801,  0.3143,  0.2347,  0.7958,\n",
       "          0.3587,  0.7228,  0.2714,  0.4545,  0.3237,  0.2769,  0.3301,  0.9876,\n",
       "          0.3500,  0.2225,  0.7207,  0.3582,  0.2677,  0.5252,  0.6645,  0.2807,\n",
       "          0.2958,  0.4483,  0.4354,  0.4256,  0.4756,  0.4312,  0.4048,  0.4792,\n",
       "          0.3626,  0.3209,  0.3701,  0.4442,  0.7073,  0.3776,  0.5714,  0.4598,\n",
       "          0.7253,  0.6593,  0.4055,  0.3596,  0.3830,  0.2924,  0.2581,  0.4847],\n",
       "        device='mps:0'),\n",
       " 'model.7.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'model.8.0.weight': tensor([[[[-4.5930e-03, -3.9078e-03, -2.9929e-03],\n",
       "           [-2.7862e-03, -1.5205e-03, -2.1411e-03],\n",
       "           [ 2.3959e-03,  2.9514e-03,  6.4945e-04]],\n",
       " \n",
       "          [[ 2.4060e-03,  2.7351e-03,  2.3728e-04],\n",
       "           [ 9.7199e-04, -9.1654e-04, -2.5099e-03],\n",
       "           [-1.6862e-03, -2.3833e-03, -2.5159e-03]],\n",
       " \n",
       "          [[ 9.1970e-04, -1.7771e-03, -3.4165e-03],\n",
       "           [ 1.3298e-03,  1.5308e-03,  7.5021e-04],\n",
       "           [ 3.5485e-03,  5.6936e-03,  5.4456e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3769e-03, -2.3081e-03, -4.4919e-03],\n",
       "           [-1.1050e-03, -1.9452e-03, -5.2796e-03],\n",
       "           [ 8.6457e-04, -5.7039e-04, -3.3144e-03]],\n",
       " \n",
       "          [[-1.7867e-03, -1.2892e-04, -1.7005e-03],\n",
       "           [-1.3155e-03, -2.8976e-03, -5.1221e-03],\n",
       "           [-1.0938e-03, -2.4542e-03, -3.8776e-03]],\n",
       " \n",
       "          [[-8.5859e-04, -1.0130e-03, -7.4782e-04],\n",
       "           [-5.8327e-03, -5.3743e-03, -4.1180e-03],\n",
       "           [-5.3798e-03, -5.4840e-03, -3.9783e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.6666e-03,  1.7670e-03,  9.8199e-04],\n",
       "           [ 1.2922e-03, -1.7087e-03, -3.0966e-03],\n",
       "           [-1.0994e-04, -2.8053e-03, -5.0385e-03]],\n",
       " \n",
       "          [[-6.7132e-03, -7.8323e-03, -4.9455e-03],\n",
       "           [-5.8369e-03, -7.1820e-03, -5.0215e-03],\n",
       "           [-4.1542e-03, -4.4416e-03, -3.6953e-03]],\n",
       " \n",
       "          [[-1.6782e-03, -2.0442e-03, -1.7332e-03],\n",
       "           [-3.1646e-04, -2.8947e-04, -5.9500e-04],\n",
       "           [-1.4433e-03, -3.2265e-03, -4.3160e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.7089e-03, -1.9377e-03, -1.1995e-03],\n",
       "           [-2.7184e-03, -4.2742e-03, -4.2210e-03],\n",
       "           [ 1.9272e-03,  6.2993e-04, -5.1161e-04]],\n",
       " \n",
       "          [[-8.5888e-04,  1.5664e-04,  1.6861e-03],\n",
       "           [-2.1489e-04, -1.4139e-03, -1.9841e-03],\n",
       "           [ 3.2856e-03,  4.2517e-03,  2.6599e-03]],\n",
       " \n",
       "          [[-2.9749e-03, -1.1487e-03,  4.6584e-04],\n",
       "           [-3.0478e-03, -7.1817e-04,  7.0122e-04],\n",
       "           [-3.9393e-03, -7.0525e-04,  9.1498e-04]]],\n",
       " \n",
       " \n",
       "         [[[ 4.1875e-04,  4.6587e-03,  7.9722e-03],\n",
       "           [-2.4836e-03, -1.8018e-03, -1.0688e-03],\n",
       "           [ 1.1031e-03,  2.9347e-04,  1.4948e-04]],\n",
       " \n",
       "          [[ 6.2129e-03,  5.6845e-03,  2.5300e-03],\n",
       "           [ 2.5398e-03,  1.4520e-03,  6.2156e-04],\n",
       "           [ 1.9000e-03,  1.8668e-03,  2.1823e-03]],\n",
       " \n",
       "          [[ 2.9043e-03,  5.7798e-03,  1.0516e-02],\n",
       "           [-3.8871e-03, -1.1219e-03,  1.0537e-03],\n",
       "           [-5.8940e-03, -3.6592e-03, -2.3651e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.0434e-03, -4.8648e-03, -7.2413e-04],\n",
       "           [-4.4176e-03, -2.7310e-03,  1.2648e-03],\n",
       "           [-2.2127e-03,  4.5474e-04,  3.0387e-03]],\n",
       " \n",
       "          [[ 1.9088e-03,  2.3792e-03,  5.2470e-03],\n",
       "           [ 1.3699e-03,  2.0635e-03,  3.0311e-03],\n",
       "           [-2.4932e-03,  1.9990e-04,  8.7470e-04]],\n",
       " \n",
       "          [[-5.0978e-03, -5.8660e-03, -2.6030e-03],\n",
       "           [-9.1596e-03, -9.8489e-03, -7.1544e-03],\n",
       "           [-1.2824e-02, -1.5261e-02, -1.3811e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-3.3574e-03, -2.3890e-03, -2.4422e-03],\n",
       "           [-5.2327e-03, -4.3142e-03, -4.2065e-03],\n",
       "           [-3.4061e-03, -3.9219e-03, -4.9851e-03]],\n",
       " \n",
       "          [[-2.4109e-04,  1.5934e-03,  2.5247e-03],\n",
       "           [-7.2489e-04,  3.5491e-03,  4.6558e-03],\n",
       "           [ 1.5034e-03,  3.1078e-03,  2.1654e-03]],\n",
       " \n",
       "          [[ 5.4719e-03,  2.8007e-03,  1.1872e-03],\n",
       "           [ 3.7568e-03,  2.1556e-03,  1.6507e-03],\n",
       "           [ 2.8882e-03,  3.1821e-03,  3.9395e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.3428e-02,  1.3172e-02,  1.3482e-02],\n",
       "           [ 1.3085e-02,  1.3704e-02,  1.4657e-02],\n",
       "           [ 1.3262e-02,  1.4951e-02,  1.6728e-02]],\n",
       " \n",
       "          [[ 2.4085e-03,  1.4575e-03,  1.6527e-03],\n",
       "           [-2.4267e-03, -2.8273e-03, -2.9826e-04],\n",
       "           [-3.1556e-03, -1.2065e-03, -2.7708e-04]],\n",
       " \n",
       "          [[-2.9748e-03,  3.7474e-04, -1.9346e-04],\n",
       "           [-8.6409e-04,  1.8425e-03,  1.4652e-03],\n",
       "           [-9.2148e-04,  2.8656e-03,  3.0896e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.9869e-03, -2.1406e-03, -2.9248e-04],\n",
       "           [-9.1624e-04, -2.9102e-05,  3.0710e-04],\n",
       "           [-1.2042e-03, -1.6009e-03, -2.0565e-03]],\n",
       " \n",
       "          [[ 3.8344e-03,  1.0808e-02,  5.8258e-03],\n",
       "           [ 4.0588e-03,  9.4780e-03,  5.4906e-03],\n",
       "           [ 5.8976e-04,  6.0696e-03,  4.7465e-03]],\n",
       " \n",
       "          [[-3.4678e-03,  2.2145e-03,  5.1969e-03],\n",
       "           [-5.9787e-03, -4.2050e-03, -3.8084e-03],\n",
       "           [-1.0468e-02, -9.2645e-03, -6.5859e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.5136e-03, -4.9185e-03, -5.2794e-03],\n",
       "           [ 5.8234e-05,  2.5791e-04, -1.7936e-03],\n",
       "           [ 2.9140e-03,  4.6679e-03,  3.1247e-03]],\n",
       " \n",
       "          [[-4.0671e-03, -3.0134e-03, -8.8769e-04],\n",
       "           [-2.6816e-03,  1.2890e-03,  8.1855e-04],\n",
       "           [ 4.1614e-04,  4.4472e-03,  2.4024e-03]],\n",
       " \n",
       "          [[ 4.0953e-03,  4.7724e-03,  5.2199e-03],\n",
       "           [-1.8175e-03, -4.2554e-04,  1.4267e-03],\n",
       "           [-1.5194e-03, -6.8182e-04,  5.1392e-04]]],\n",
       " \n",
       " \n",
       "         [[[-1.3211e-03, -1.1992e-03, -3.2907e-04],\n",
       "           [ 6.7088e-03,  5.7542e-03,  5.5669e-03],\n",
       "           [ 1.1630e-02,  1.0080e-02,  8.6965e-03]],\n",
       " \n",
       "          [[-1.8861e-03, -3.5474e-03, -4.0239e-03],\n",
       "           [-1.3117e-03, -3.6955e-03, -4.0426e-03],\n",
       "           [-1.4019e-03, -3.5960e-03, -3.5572e-03]],\n",
       " \n",
       "          [[-2.0809e-03, -7.1235e-03, -8.0606e-03],\n",
       "           [-3.5613e-03, -7.7694e-03, -8.1347e-03],\n",
       "           [ 1.0567e-03, -1.8006e-03, -1.3766e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.5583e-03,  2.3407e-03,  1.4464e-03],\n",
       "           [-6.2457e-03, -6.7346e-03, -6.2206e-03],\n",
       "           [-8.9762e-03, -1.2090e-02, -1.1820e-02]],\n",
       " \n",
       "          [[ 2.5564e-03,  1.2131e-03,  2.3042e-03],\n",
       "           [-5.3463e-03, -7.2985e-03, -3.6588e-03],\n",
       "           [-1.0256e-02, -1.2155e-02, -8.4913e-03]],\n",
       " \n",
       "          [[-2.6219e-03, -3.6228e-03, -5.5490e-03],\n",
       "           [-1.3287e-03, -4.5134e-03, -7.0389e-03],\n",
       "           [ 1.7242e-03, -1.5478e-03, -3.4227e-03]]]], device='mps:0'),\n",
       " 'model.8.1.weight': tensor([-0.0245, -0.0547, -0.0840, -0.1103, -0.0586, -0.0276, -0.0475, -0.0432,\n",
       "         -0.0885, -0.0187, -0.0423, -0.0189, -0.0492, -0.0335, -0.0650, -0.0440,\n",
       "         -0.0842, -0.0263, -0.0968, -0.0460, -0.0289, -0.0514, -0.0142, -0.0281,\n",
       "         -0.0255, -0.0688, -0.0234, -0.0991, -0.0585, -0.0318, -0.0510, -0.0587,\n",
       "         -0.0478, -0.0604, -0.0872, -0.0639, -0.0750, -0.1056, -0.0748, -0.0678,\n",
       "         -0.0583, -0.0532, -0.0809, -0.0336, -0.0357, -0.0680, -0.0482, -0.0659,\n",
       "         -0.0719, -0.0609, -0.0216, -0.0907, -0.0231, -0.0653, -0.1117, -0.0539,\n",
       "         -0.0286, -0.0904, -0.0205, -0.0796, -0.0522, -0.1033, -0.0465, -0.0678,\n",
       "         -0.0777, -0.1644, -0.1119, -0.0776, -0.0031, -0.0789, -0.0957, -0.0263,\n",
       "         -0.0342, -0.0652, -0.0976, -0.0844, -0.0984, -0.1137, -0.0942, -0.0419,\n",
       "         -0.0758, -0.0365, -0.0461, -0.0890, -0.0845, -0.0365, -0.0838, -0.0201,\n",
       "         -0.0204, -0.0174, -0.0525, -0.0935, -0.0238, -0.0717, -0.0267, -0.0773,\n",
       "         -0.0495, -0.0310, -0.0147, -0.0378, -0.0422, -0.0896, -0.0552, -0.0302,\n",
       "         -0.0986, -0.0535, -0.1077, -0.0237, -0.0975, -0.0519, -0.0339, -0.0695,\n",
       "         -0.0692, -0.0411, -0.0716, -0.0415, -0.0046, -0.0667, -0.0530, -0.0372,\n",
       "         -0.0199, -0.1429, -0.0454, -0.0897, -0.0648, -0.0388, -0.0675, -0.0100,\n",
       "         -0.0438, -0.0379, -0.0420, -0.0529, -0.0632, -0.0117, -0.0956, -0.0410,\n",
       "         -0.0525, -0.0465, -0.0310, -0.0598, -0.0601, -0.0973, -0.0645, -0.0376,\n",
       "         -0.0146, -0.0558, -0.0665, -0.0374, -0.0356, -0.0373, -0.0677, -0.0194,\n",
       "         -0.1331, -0.0410, -0.0286, -0.0237, -0.0426, -0.0258, -0.0502, -0.0748,\n",
       "         -0.0912, -0.0889, -0.0304, -0.0984, -0.0720, -0.0920, -0.0510, -0.0701,\n",
       "         -0.0576, -0.0400, -0.0594, -0.0530, -0.0660, -0.0801, -0.0335, -0.0263,\n",
       "         -0.0527, -0.0279, -0.0576, -0.0713, -0.0547, -0.0478, -0.0547, -0.0711,\n",
       "         -0.0880, -0.0344, -0.0301, -0.0327, -0.0571, -0.0544, -0.0224, -0.0637,\n",
       "         -0.0760, -0.1235, -0.0892, -0.0783, -0.0491, -0.0434, -0.0913, -0.0378,\n",
       "         -0.1431, -0.0269, -0.0439, -0.0337, -0.0576, -0.0400, -0.0525, -0.0458,\n",
       "         -0.0340, -0.0314, -0.0653, -0.0339, -0.0424, -0.0320, -0.0624, -0.0584,\n",
       "         -0.0546, -0.0939, -0.1763, -0.0454, -0.0417, -0.0362, -0.0575, -0.0138,\n",
       "         -0.0562, -0.0404, -0.1215, -0.0394, -0.0963, -0.0653, -0.0998, -0.0677,\n",
       "         -0.0201, -0.0509, -0.0571, -0.1249, -0.0563, -0.0934, -0.0465, -0.0091,\n",
       "         -0.0214, -0.0838, -0.0971, -0.0625, -0.0934, -0.0424, -0.0484, -0.0689,\n",
       "         -0.0852, -0.0415, -0.0380, -0.0642, -0.0334, -0.0619, -0.0681, -0.0703],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.bias': tensor([-0.0201, -0.0312, -0.0455, -0.0589, -0.0424, -0.0226, -0.0224, -0.0185,\n",
       "         -0.0594, -0.0136, -0.0395, -0.0069, -0.0446, -0.0317, -0.0505, -0.0376,\n",
       "         -0.0593, -0.0311, -0.0645, -0.0124, -0.0223, -0.0310, -0.0106, -0.0196,\n",
       "         -0.0279, -0.0445, -0.0170, -0.0768, -0.0480, -0.0320, -0.0406, -0.0372,\n",
       "         -0.0225, -0.0342, -0.0590, -0.0530, -0.0289, -0.0436, -0.0445, -0.0410,\n",
       "         -0.0244, -0.0303, -0.0513, -0.0246, -0.0316, -0.0428, -0.0424, -0.0556,\n",
       "         -0.0529, -0.0373, -0.0186, -0.0690, -0.0219, -0.0357, -0.0959, -0.0360,\n",
       "         -0.0164, -0.0881, -0.0220, -0.0503, -0.0261, -0.0589, -0.0170, -0.0432,\n",
       "         -0.0891, -0.1299, -0.0781, -0.0681, -0.0097, -0.0648, -0.0738, -0.0201,\n",
       "         -0.0206, -0.0537, -0.0725, -0.0661, -0.0670, -0.0596, -0.0555, -0.0346,\n",
       "         -0.0546, -0.0265, -0.0434, -0.0731, -0.0575, -0.0173, -0.0603, -0.0228,\n",
       "         -0.0189, -0.0155, -0.0365, -0.0609, -0.0231, -0.0453, -0.0118, -0.0472,\n",
       "         -0.0473, -0.0238, -0.0274, -0.0346, -0.0299, -0.0617, -0.0186, -0.0160,\n",
       "         -0.0586, -0.0351, -0.0948, -0.0079, -0.0496, -0.0187, -0.0324, -0.0416,\n",
       "         -0.0421, -0.0240, -0.0428, -0.0311, -0.0104, -0.0349, -0.0403, -0.0466,\n",
       "         -0.0189, -0.0842, -0.0305, -0.0673, -0.0443, -0.0284, -0.0518, -0.0063,\n",
       "         -0.0451, -0.0099, -0.0349, -0.0293, -0.0474, -0.0073, -0.0712, -0.0405,\n",
       "         -0.0336, -0.0352, -0.0226, -0.0401, -0.0515, -0.0838, -0.0396, -0.0313,\n",
       "         -0.0068, -0.0339, -0.0615, -0.0269, -0.0412, -0.0291, -0.0417, -0.0263,\n",
       "         -0.0933, -0.0219, -0.0330, -0.0247, -0.0282, -0.0193, -0.0311, -0.0411,\n",
       "         -0.0737, -0.0904, -0.0137, -0.0668, -0.0598, -0.0650, -0.0462, -0.0601,\n",
       "         -0.0457, -0.0372, -0.0345, -0.0416, -0.0492, -0.0623, -0.0214, -0.0240,\n",
       "         -0.0429, -0.0177, -0.0517, -0.0290, -0.0259, -0.0334, -0.0401, -0.0532,\n",
       "         -0.0449, -0.0435, -0.0183, -0.0283, -0.0327, -0.0606, -0.0043, -0.0408,\n",
       "         -0.0552, -0.0759, -0.0848, -0.0521, -0.0372, -0.0469, -0.0332, -0.0304,\n",
       "         -0.0719, -0.0367, -0.0380, -0.0460, -0.0392, -0.0409, -0.0411, -0.0355,\n",
       "         -0.0249, -0.0315, -0.0462, -0.0486, -0.0238, -0.0284, -0.0552, -0.0556,\n",
       "         -0.0394, -0.0648, -0.0898, -0.0329, -0.0264, -0.0353, -0.0321, -0.0090,\n",
       "         -0.0370, -0.0486, -0.0879, -0.0285, -0.0722, -0.0369, -0.0612, -0.0548,\n",
       "         -0.0207, -0.0535, -0.0430, -0.0724, -0.0390, -0.0488, -0.0399, -0.0152,\n",
       "         -0.0199, -0.0548, -0.0585, -0.0232, -0.0807, -0.0179, -0.0420, -0.0479,\n",
       "         -0.0441, -0.0320, -0.0437, -0.0663, -0.0197, -0.0463, -0.0468, -0.0371],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.running_mean': tensor([-0.1252,  0.0506, -0.1088,  0.2308, -0.4179, -0.1306,  0.1226, -0.1670,\n",
       "         -0.1049,  0.5751,  0.2726, -0.7034, -0.0406, -0.7510, -0.1223, -0.1473,\n",
       "          0.3744,  0.0201,  0.6268, -0.6729,  0.1921, -0.5120, -1.0380,  0.2092,\n",
       "         -0.0159, -0.6033,  0.0994,  0.3472, -0.4379, -0.0376,  0.4506,  0.1362,\n",
       "         -0.3980,  0.2227, -0.0065, -0.0741,  0.3219, -0.3822,  0.0342,  0.2823,\n",
       "         -0.1677, -0.2733,  0.5714, -0.0040,  0.2768,  0.1605,  0.1071, -0.5319,\n",
       "         -0.6537,  0.1538,  0.0306,  0.1978, -0.1158, -0.2173, -0.8428,  0.2250,\n",
       "         -0.3490,  0.2695, -0.3334, -0.7463, -0.0681, -0.2825,  0.4115,  0.3283,\n",
       "         -0.3888,  0.0359,  0.0539,  0.3455, -0.5880, -0.0789,  0.3853,  0.1496,\n",
       "         -0.2860,  0.2891, -0.6109, -0.0710, -0.1474, -0.0759,  0.2638, -0.1721,\n",
       "         -0.0892,  0.1353, -0.0971, -0.1685,  0.7687,  0.2826,  0.3814,  0.0575,\n",
       "         -0.0393, -0.1516,  0.3628,  0.3806, -0.1689, -0.1528, -0.2804, -0.1969,\n",
       "         -0.1600, -0.0428,  0.1587, -0.2194, -0.5917,  0.1832,  0.1685,  0.1417,\n",
       "         -0.3158,  0.2057, -0.3119,  0.1167,  0.6966, -0.2999, -0.1128, -0.8003,\n",
       "          0.0621,  0.3510,  0.0184, -0.0354, -0.4455,  0.2661,  0.2558, -0.3068,\n",
       "         -0.6144, -0.1815,  0.2526,  0.0286, -0.1981, -0.3156, -0.1738, -0.0427,\n",
       "          0.0551, -0.5733, -0.1579, -0.2568, -0.0167, -0.3109,  0.0359,  0.1384,\n",
       "         -0.4028, -0.8781, -0.2792, -0.3544,  0.4187, -0.0122,  0.3169, -0.0096,\n",
       "         -0.6737, -0.3805,  0.0340,  0.0176,  0.0335, -0.0357,  0.3053, -0.4240,\n",
       "          0.5187, -0.4078, -0.2286, -0.0123,  0.1032, -0.2594,  0.4079, -0.0781,\n",
       "          0.2781,  0.0587, -0.4823, -0.2277,  0.1571, -0.0481, -0.1308, -0.1334,\n",
       "          0.0893,  0.0795,  0.0770,  0.2589,  0.2305,  0.0437, -0.6060, -0.0992,\n",
       "         -0.5221,  0.7549,  0.4426, -0.0412, -0.0730,  0.1048,  0.3608,  0.0423,\n",
       "          0.0562, -0.1387,  0.1220, -0.2185, -0.0469,  0.2103, -0.3392, -0.0504,\n",
       "         -0.4536,  0.3891, -0.4999, -0.1050,  0.0609, -0.1238,  0.0187, -0.1148,\n",
       "          0.3215, -0.3831, -0.3049, -0.4993, -0.2614, -0.1596, -0.1152, -0.0332,\n",
       "         -0.0338, -0.2333, -0.5051, -0.1188,  0.0494,  0.1521,  0.3051, -0.2388,\n",
       "         -0.2170,  0.2215,  0.4750, -0.2283, -0.1905,  0.1082,  0.1945, -0.1976,\n",
       "         -0.2269,  0.1879, -0.1543, -0.2442, -0.2091, -0.2903,  0.5566,  0.3737,\n",
       "          0.0396,  0.1105, -0.2697, -0.0165,  0.1827,  0.0840, -0.0029, -0.2209,\n",
       "          0.0627, -0.4415,  0.0190, -0.0724, -0.6133, -0.1980,  0.2933,  0.2726,\n",
       "         -0.1896, -0.0147, -0.2562, -1.2198, -0.1496, -0.4299, -0.2511,  0.0521],\n",
       "        device='mps:0'),\n",
       " 'model.8.1.running_var': tensor([1.5952, 0.8295, 2.4603, 2.0422, 0.8168, 0.8784, 3.0134, 2.2488, 1.5984,\n",
       "         1.0118, 0.7624, 1.5134, 1.5409, 0.6142, 1.3115, 0.7979, 2.5213, 0.7117,\n",
       "         3.8892, 1.0905, 0.4805, 1.1435, 1.2235, 1.0345, 1.0153, 0.8399, 1.3404,\n",
       "         2.7213, 0.9888, 0.8204, 2.7179, 1.0727, 1.4741, 1.8743, 1.4167, 2.2106,\n",
       "         1.8630, 2.7821, 1.4137, 1.8242, 2.0402, 1.7079, 4.2974, 0.6787, 1.7698,\n",
       "         1.0450, 1.4718, 1.2011, 1.7020, 1.6421, 0.9105, 2.5421, 1.0380, 1.0201,\n",
       "         2.4595, 0.9567, 1.3215, 2.4462, 0.4427, 2.4007, 1.3685, 2.3048, 1.2601,\n",
       "         1.5788, 1.5675, 2.4034, 1.5589, 1.4325, 0.5215, 1.5312, 2.3802, 0.8865,\n",
       "         1.0826, 1.4091, 1.1849, 1.2671, 1.3790, 3.3122, 1.7613, 1.5512, 1.2098,\n",
       "         1.5155, 1.9455, 2.3636, 3.8072, 0.9975, 1.1141, 1.2947, 0.7715, 1.8700,\n",
       "         3.1515, 2.7267, 1.0528, 1.4240, 1.5087, 1.2608, 1.2439, 0.8927, 1.7640,\n",
       "         0.6748, 1.4146, 1.7132, 2.6174, 1.3871, 2.3367, 2.4102, 2.2161, 1.0149,\n",
       "         3.4312, 1.8166, 2.7350, 2.0188, 2.0844, 1.2658, 1.2377, 1.3196, 0.6962,\n",
       "         0.9158, 2.1209, 2.2060, 1.3784, 2.3968, 1.7967, 3.3054, 1.7498, 1.6199,\n",
       "         1.3017, 0.4149, 2.1772, 1.6571, 1.2467, 1.3718, 1.0923, 0.5943, 1.4338,\n",
       "         2.2430, 2.3299, 0.9584, 0.7803, 1.1256, 1.8680, 1.5086, 1.1167, 0.9409,\n",
       "         0.7742, 2.4839, 2.0087, 2.1505, 0.9465, 0.6515, 3.3316, 0.5697, 2.2174,\n",
       "         0.7409, 1.6349, 2.1568, 0.8117, 1.1640, 1.3008, 1.2166, 2.5821, 3.5606,\n",
       "         1.5475, 1.7960, 3.9851, 2.5428, 1.4467, 2.0088, 1.1457, 1.8536, 1.6521,\n",
       "         1.7179, 2.1691, 2.2921, 1.5180, 0.5815, 1.7328, 1.0188, 2.2462, 1.6770,\n",
       "         2.0470, 1.4299, 3.0160, 0.9231, 2.4533, 1.4340, 0.6642, 1.4328, 1.3376,\n",
       "         0.9094, 2.2473, 2.1994, 2.4515, 2.6983, 1.8356, 1.3243, 1.0329, 3.0299,\n",
       "         3.2013, 0.7972, 3.6890, 0.6845, 1.7532, 0.9278, 1.1344, 1.0055, 1.9799,\n",
       "         0.6583, 1.3077, 1.1091, 1.0259, 1.1749, 0.9742, 0.6886, 1.3927, 0.8253,\n",
       "         0.8935, 1.9756, 3.3906, 0.9077, 1.2418, 0.7476, 1.3676, 1.0683, 0.9996,\n",
       "         1.6535, 1.9716, 0.9033, 2.0230, 0.6980, 2.0303, 3.2753, 1.1687, 2.8776,\n",
       "         0.7829, 3.1346, 1.3601, 1.7652, 2.2859, 0.4740, 1.0127, 2.1568, 2.0970,\n",
       "         1.8607, 1.4967, 2.1924, 2.4713, 0.8952, 1.9678, 1.1589, 4.4128, 1.4187,\n",
       "         0.9181, 2.1259, 1.3361, 1.7741], device='mps:0'),\n",
       " 'model.8.1.num_batches_tracked': tensor(160., device='mps:0'),\n",
       " 'classifier.weight': tensor([[ 2.0220e-02,  7.1526e-03,  2.3164e-02,  ...,  1.2577e-02,\n",
       "           1.3312e-02, -4.4750e-02],\n",
       "         [ 6.6996e-05,  2.3141e-03,  1.1865e-03,  ...,  2.0393e-02,\n",
       "          -1.0786e-02, -1.5953e-02],\n",
       "         [ 9.5859e-03,  7.1229e-03, -4.1012e-02,  ...,  8.9407e-03,\n",
       "          -2.4036e-02,  5.2024e-02],\n",
       "         ...,\n",
       "         [-3.9487e-04,  1.2539e-02, -1.7285e-02,  ..., -3.6987e-02,\n",
       "           1.0924e-02,  1.4537e-02],\n",
       "         [-1.5352e-02, -2.3624e-03, -2.4454e-03,  ..., -9.3511e-03,\n",
       "           6.5175e-03, -5.8754e-03],\n",
       "         [ 1.2526e-02, -3.1110e-02,  6.2351e-03,  ..., -1.7173e-02,\n",
       "           4.5042e-03,  2.1878e-02]], device='mps:0'),\n",
       " 'classifier.bias': tensor([ 0.0696, -0.0326,  0.0060, -0.0018,  0.0210, -0.0618,  0.0351,  0.0198,\n",
       "         -0.0588,  0.0036], device='mps:0')}"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "44334d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_history = [weight_history_to_layer_max_magnitude_and_means(watcher, include_batch_norm = False) for t in range(1)]\n",
    "max_history = [(x[1]) for x in max_history]\n",
    "# by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "# [plt.plot([x for x in range(1)],by_layer[l],  '-k', color=['blue','red','green','blue', 'red', 'green', 'blue', 'red', 'green'][l]) for l in range(5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "928e2d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor(0.1671, device='mps:0'),\n",
       "  tensor(0.1652, device='mps:0'),\n",
       "  tensor(0.1651, device='mps:0'),\n",
       "  tensor(0.1396, device='mps:0'),\n",
       "  tensor(0.1566, device='mps:0'),\n",
       "  tensor(0.1296, device='mps:0'),\n",
       "  tensor(0.1197, device='mps:0'),\n",
       "  tensor(0.0867, device='mps:0'),\n",
       "  tensor(0.0305, device='mps:0')]]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dea98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
