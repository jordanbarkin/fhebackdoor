{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6dca87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6fcba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure GPU (change if not M1 mac)\n",
    "mps = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "827a7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "# Using CIFAR-10 again as in the programming assignments\n",
    "# Load training data\n",
    "transform_train = transforms.Compose([                                   \n",
    "    transforms.RandomCrop(32, padding=4),                                       \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "# Load testing data\n",
    "transform_test = transforms.Compose([                                           \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab5f2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving And helpers\n",
    "\n",
    "def save_tracker(tracker, path):\n",
    "  np.savetxt(path, tracker, delimiter=',') \n",
    "\n",
    "def save_trackers(device, filename):\n",
    "  \"\"\"Save all trackers and current total_time to a file.\"\"\"\n",
    "  torch.save((device['train_loss_tracker'], device['train_acc_tracker'], device['test_loss_tracker'], device['test_acc_tracker'], total_time), filename)\n",
    "  print(\"Saved trackers to \" + filename)\n",
    "\n",
    "def moving_average(a, n=100):\n",
    "  '''Helper function used for visualization'''\n",
    "  ret = torch.cumsum(torch.Tensor(a), 0)\n",
    "  ret[n:] = ret[n:] - ret[:-n]\n",
    "  return ret[n - 1:] / n\n",
    "\n",
    "# Plotting helpers! \n",
    "def make_plot(trackers, num_epochs, title, y_axis_lab, should_average=False, legend=True, fix_ax=True):\n",
    "  avg_fn = moving_average if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  if fix_ax:\n",
    "    ax.set_ylim([0, 100])\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "\n",
    "  if legend:\n",
    "    _ = plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def make_plot_better(trackers, num_epochs, title, y_axis_lab, should_average=False, n = 100):\n",
    "  avg_fn = (lambda x : moving_average(x, n)) if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "  _ = plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7ed703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "def iid_sampler(dataset, num_devices, data_pct):\n",
    "    '''\n",
    "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
    "    num_devices: integer number of devices to create subsets for\n",
    "    data_pct: percentalge of training samples to give each device\n",
    "              e.g., 0.1 represents 10%\n",
    "\n",
    "    return: a dictionary of the following format:\n",
    "      {\n",
    "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
    "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
    "        ...\n",
    "      }\n",
    "\n",
    "    iid (independent and identically distributed) means that the indexes\n",
    "    should be drawn independently in a uniformly random fashion.\n",
    "    '''\n",
    "    total_samples = len(dataset)\n",
    "    sampled = {}\n",
    "    number_samples = int((data_pct)*(total_samples)) \n",
    "\n",
    "    for i in range(num_devices):\n",
    "      sampled[i] = random.sample(range(total_samples), number_samples)\n",
    "        \n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea60c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a718639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net definitions\n",
    "\n",
    "# Same ConvNet as in Assignment 2 and 3\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
    "               padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
    "                  bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(3, 32),\n",
    "            conv_block(32, 32),\n",
    "            conv_block(32, 64, stride=2),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 128, stride=2),\n",
    "            conv_block(128, 128),\n",
    "            conv_block(128, 256),\n",
    "            conv_block(256, 256),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        B, C, _, _ = h.shape\n",
    "        h = h.view(B, C)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e2df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning helpers\n",
    "\n",
    "# The baseline `average' function. \n",
    "def average_weights(devices,*args, **kwargs):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "#     max_magnitude = 0\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "      w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "#             max_magnitude = max(max_magnitude, abs(torch.max(state_dicts[i][k].type(torch.float32))))\n",
    "            w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "def get_devices_for_round(devices, device_pct):  \n",
    "    return random.sample(devices, int(device_pct * len(devices)))\n",
    "\n",
    "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
    "                  milestones=None, batch_size=128):\n",
    "    if milestones == None:\n",
    "        milestones = [25, 50, 75]\n",
    "\n",
    "    device_net = copy.deepcopy(net)\n",
    "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                     milestones=milestones,\n",
    "                                                     gamma=0.1)\n",
    "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
    "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True)\n",
    "    return {\n",
    "        'net': device_net,\n",
    "        'id': device_id,\n",
    "        'dataloader': device_trainloader, \n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'train_loss_tracker': [],\n",
    "        'train_acc_tracker': [],\n",
    "        'test_loss_tracker': [],\n",
    "        'test_acc_tracker': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "584da899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local device training and testing\n",
    "def train(epoch, device, criterion):\n",
    "    device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "        inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "        device['optimizer'].zero_grad()\n",
    "        outputs = device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        device['optimizer'].step()\n",
    "        train_loss += loss.item()\n",
    "        device['train_loss_tracker'].append(loss.item())\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        dev_id = device['id']\n",
    "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' + \n",
    "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "        sys.stdout.flush()\n",
    "    device['train_acc_tracker'].append(acc)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def test(epoch, device, criterion, testloader = testloader):\n",
    "    device['net'].eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "            outputs = device['net'](inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            device['test_loss_tracker'].append(loss.item())\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            loss = test_loss / (batch_idx + 1)\n",
    "            acc = 100.* correct / total\n",
    "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
    "    sys.stdout.flush()  \n",
    "    acc = 100.*correct/total\n",
    "    device['test_acc_tracker'].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce49187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function tests (the main experiment routine)\n",
    "\n",
    "# Given two different sets of aggregated weights, \n",
    "# gives a value representing the difference between them,\n",
    "# as a way to measure the direct cost of using our aggregated function\n",
    "def diff_aggregated_weights(strat, baseline):\n",
    "    result = 0 \n",
    "    for k in strat.keys():\n",
    "        result += torch.linalg.norm(strat[k] - baseline[k])\n",
    "    return result\n",
    "\n",
    "# A data type for experiment results\n",
    "BackdoorResult = namedtuple(\"BackdoorResult\", [\"scheme_loss\", \"test_accuracy\", \"backdoor_success\", \"devices\", \"avg_weight_history\"])\n",
    "\n",
    "# The main routine! \n",
    "def run_federated_test(agg_fn = average_weights,  # Pass in aggregation function, \n",
    "                                                  # Device list -> aggregated weights \n",
    "                       rounds = 10,               # Rounds of FL\n",
    "                       local_epochs = 4,          # Epochs per device                      \n",
    "                       num_devices = 50,          # Total # devices\n",
    "                       device_pct = 0.1,          # % of devices per round\n",
    "                       data_pct = 0.1,            # % of data each device gets\n",
    "                       net = ConvNet().to(mps),   # Net design; make sure on mps\n",
    "                       evil_round = None,         # If None, no attack; else attacker will mount attack on this round\n",
    "                       attacker_strategy = None,  # device --> void --- set up the local weights on the attacker\n",
    "                       evil_device_id = None,     # Which device attacks? \n",
    "                       evaluate_attack = None,    # Function devices --> <any> measuring how well the attack worked at the end\n",
    "                       output_filename = None, \n",
    "                       snapshot = True, \n",
    "                       resume_from_snap = None,\n",
    "                       multiple_attack_rounds = []):   \n",
    "    def lighten_device(d):\n",
    "        return {\n",
    "            k: d[k] for k in ( 'id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker')\n",
    "        }                                   \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "    devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "    \n",
    "    scheme_loss = []\n",
    "#     max_magnitudes = []\n",
    "    avg_weight_history = []\n",
    "    _starting_round_num = 0\n",
    "    \n",
    "    if resume_from_snap: \n",
    "        print(\"Resuming from snapshot!\\n\")\n",
    "        # Load what we can\n",
    "        result = resume_from_snap\n",
    "        scheme_loss = result.scheme_loss\n",
    "        avg_weight_history = result.avg_weight_history\n",
    "        partial_devices = result.devices\n",
    "\n",
    "        # Fresh data and devices\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "        devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "\n",
    "        # Restore the devices with the info from the trackers\n",
    "        def restore_device(old_device, new_device):\n",
    "            for k in ('id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker'):\n",
    "                new_device[k] = old_device[k]\n",
    "            return new_device\n",
    "        \n",
    "        print(\"Restoring devices\\n\")\n",
    "        devices = [restore_device(partial_devices[i], devices[i]) for i in range(len(devices))]\n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(avg_weight_history[-1])\n",
    "        \n",
    "        _starting_round_num = len(result.test_accuracy)\n",
    "        print(\"Finished restoring\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "    ## IID Federated Learning\n",
    "    start_time = time.time()\n",
    "    for round_num in range(_starting_round_num, rounds):\n",
    "        round_start_time = time.time()\n",
    "        # Part 1.3: Implement getting devices for each round here\n",
    "        round_devices = get_devices_for_round(devices, device_pct)\n",
    "\n",
    "        print('Round: ', round_num)\n",
    "        # Train locally \n",
    "        for device in round_devices:\n",
    "            for local_epoch in range(local_epochs):\n",
    "                train(local_epoch, device, criterion)\n",
    "        \n",
    "        # One device becomes evil if required\n",
    "        if ((evil_round and round_num == evil_round) or round_num in multiple_attack_rounds):\n",
    "            assert (evil_device_id is not None)\n",
    "            assert (attacker_strategy is not None)\n",
    "            print(\"Attacking!\\n\")\n",
    "            \n",
    "            attacker_strategy(devices[evil_device_id])\n",
    "            # Make sure evil guy gets averaged in \n",
    "            if evil_device_id not in round_devices:\n",
    "                round_devices.append(devices[evil_device_id])\n",
    "            print(\"Finished attacking\\n\")\n",
    "            \n",
    "        \n",
    "        # Weight averaging\n",
    "        w_baseline = average_weights(round_devices)\n",
    "        w_avg = agg_fn(round_devices, (avg_weight_history[-1] if avg_weight_history != [] else None))\n",
    "#         max_magnitudes.append(max_magnitude)\n",
    "        \n",
    "        # Track the difference between the two; should be 0 if straight average\n",
    "        scheme_loss.append((float(diff_aggregated_weights(w_avg, w_baseline))))\n",
    "        \n",
    "        avg_weight_history.append(copy.deepcopy(w_avg))\n",
    "        \n",
    "        # Gradients         \n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(w_avg)\n",
    "            device['optimizer'].zero_grad()\n",
    "            device['optimizer'].step()\n",
    "            device['scheduler'].step()\n",
    "\n",
    "        # test accuracy after aggregation\n",
    "        # device 0 is the unique device with all of the \n",
    "        # test accuracies and losses in its tracker\n",
    "        test(round_num, devices[0], criterion)\n",
    "        \n",
    "        print(f\"\\nDiff: {scheme_loss[-1]}\\n\")\n",
    "        print(f\"Round time: {time.time() - start_time} \\n\")\n",
    "        if snapshot:\n",
    "            intermediate_result = BackdoorResult(\n",
    "                scheme_loss = scheme_loss, \n",
    "                test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "                backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "                devices = [lighten_device(d) for d in devices], \n",
    "                avg_weight_history = avg_weight_history\n",
    "            )\n",
    "\n",
    "\n",
    "            if output_filename is not None: \n",
    "                print(\"Writing snapshot\\n\")\n",
    "                with open(f\"snapshot_{output_filename}\", 'wb') as file: \n",
    "                    pickle.dump(intermediate_result, file)\n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    print('Total training time: {} seconds'.format(total_time))\n",
    "    \n",
    "    # Pack up everything we care about and the devices for good measure\n",
    "    result = BackdoorResult(\n",
    "        scheme_loss = scheme_loss, \n",
    "        test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "        backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "        devices = [lighten_device(d) for d in devices], \n",
    "        avg_weight_history = avg_weight_history\n",
    "    )\n",
    "\n",
    "    \n",
    "    if output_filename is not None: \n",
    "        with open(output_filename, 'wb') as file: \n",
    "            print(\"Writing file\\n\")\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Load output files back into memory\n",
    "def load_result(filename):\n",
    "    with open(filename, 'rb') as file: \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20f631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be4169e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# results = run_federated_test(local_epochs=1, num_devices = 10, rounds = 2, output_filename = \"testout.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf2e74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also load it back\n",
    "# results = load_result(\"snapshot_testout.pickle\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ad48138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A silly attack that just sends massive weights all of magnitude 10000\n",
    "def sample_attack(device):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    weights = device[\"net\"].state_dict().copy()\n",
    "    \n",
    "    for w in weights.keys():\n",
    "        weights[w] = torch.full(weights[w].size(), 10000)\n",
    "    \n",
    "    device['net'].load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b08537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function that squashes any weights with magnitude over 1000 (except on the first device but whatever)\n",
    "def super_smart_aggregation(devices):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights, excluding huge updates.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "        w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "            if (torch.max(state_dicts[i][k].type(torch.float32)) <= 1000): \n",
    "                w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4507b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how this works\n",
    "\n",
    "# Here, we carry out the attack but use the ordinary average\n",
    "# results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 3,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 10,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 1,        \n",
    "#                                          attacker_strategy = sample_attack,  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline_trivial_attack.pickle\")  \n",
    "# Observe that it absolutely destroys our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e703e878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we do it again but with the aggregation that rejects huge updates\n",
    "# results_reject_huge = run_federated_test(agg_fn = super_smart_aggregation,                    \n",
    "#                                          rounds = 3,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 10,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 1,        \n",
    "#                                          attacker_strategy = sample_attack,  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None,\n",
    "#                                          output_filename = \"simple_attack_and_defense.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1bcc5580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here, we compute a real baseline over 100 epochs and typical averaging. Good starting point for future \n",
    "# tests; can resume from this snapshot.\n",
    "# baseline = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 100,              \n",
    "#                                          local_epochs = 4,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4835de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_result(\"baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7c03e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, now can get things like\n",
    "# baseline.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94b08e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can resume from a snapshot:\n",
    "# NOTE : keep all the basic params (local epochs, num devices, net, etc) the same\n",
    "# when resuming from a snapshot \n",
    "# baseline2 = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 101,              \n",
    "#                                          local_epochs = 4,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline2.pickle\", \n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d140864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline2_loaded = load_result(\"baseline2.pickle\")\n",
    "# baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7864d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move on to a real defense. \n",
    "\n",
    "# We create factory functions that let us parametrize a double sigmoid using threshholds\n",
    "\n",
    "def torch_scaled_sigmoid_factory(a, c = 0.005, left = False):\n",
    "    \n",
    "    def f(x):\n",
    "        scaled = torch.sub(x, a)\n",
    "\n",
    "        divisor = c if left else -1*c\n",
    "\n",
    "        scaled = torch.div(scaled, divisor)\n",
    "\n",
    "        return torch.sigmoid(scaled)\n",
    "    return f\n",
    "\n",
    "def torch_double_sigmoid_factory(a,b,c = 0.005):\n",
    "    left = torch_scaled_sigmoid_factory(a, left = True)\n",
    "    right = torch_scaled_sigmoid_factory(b, left = False) \n",
    "    def f(x):\n",
    "        return (left(x)*right(x))\n",
    "    return f\n",
    "\n",
    "my_sigmoid = torch_double_sigmoid_factory(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a035df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_double_sigmoid_factory(-1,6)(torch.tensor(list(range(-5,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6fd6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it works\n",
    "# torch_double_sigmoid_factory(-2,2)(torch.Tensor([-5,-4,-3,-2,-1.5,-1.4,1.3,-1,0,1,1.5,1.6,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54a43171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sigmoid defense,\n",
    "#     keys_to_range_mapping maps each layer name in the state dict to the sigmoid bounds for processing it\n",
    "#     All other layers just get identity function-ed\n",
    "# watcher = {}\n",
    "def make_sigmoid_defense(keys_to_range_mapping, stickiness = 0):\n",
    "    \n",
    "    sigmoid_dict = defaultdict(lambda : (lambda x: 1))\n",
    "    \n",
    "    for k,(a,b) in keys_to_range_mapping.items():\n",
    "        sigmoid_dict[k] = torch_double_sigmoid_factory(a,b)\n",
    "    \n",
    "    def f(devices, previous_round_weights):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights preprocessed by sigmoid\n",
    "        '''\n",
    "        state_dicts = [device['net'].state_dict() for device in devices]\n",
    "        # initialize w_avg to tensors from device 0\n",
    "        w_avg = copy.deepcopy(state_dicts[0])\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "#             prev_round_x = previous_round_weights[k].type(torch.float32) if  previous_round_weights is not None else x\n",
    "            w_avg[k] = w_avg[k].type(torch.float32)\n",
    "#             for i in range(stickiness):\n",
    "#                 w_avg[k] += x              \n",
    "\n",
    "        # for each model param\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "            # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "            for i in range(1, len(devices)):\n",
    "                new_weight = (state_dicts[i][k].type(torch.float32))\n",
    "                prev_round_x = previous_round_weights[k].type(torch.float32)  if (previous_round_weights is not None) else new_weight\n",
    "#                 if i == 1:\n",
    "#                     watcher[k] = (new_weight - prev_round_x)\n",
    "#                 print((())))\n",
    "#                 print((len(new_weight)))\n",
    "\n",
    "\n",
    "                w_avg[k] += new_weight*(sig(torch.sub(new_weight, prev_round_x)))\n",
    "            # compute average\n",
    "            w_avg[k] /= float(len(devices) + stickiness)\n",
    "        return w_avg\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2da666cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.0.0.weight',\n",
       " 'model.1.0.weight',\n",
       " 'model.2.0.weight',\n",
       " 'model.3.0.weight',\n",
       " 'model.4.0.weight',\n",
       " 'model.5.0.weight',\n",
       " 'model.6.0.weight',\n",
       " 'model.7.0.weight',\n",
       " 'model.8.0.weight']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the actual layer weights that we care about\n",
    "[x for x in baseline.avg_weight_history[-1].keys() if '.0.weight' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "286d9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up a potential sigmoid defense\n",
    "# empirical_cutoffs = {\n",
    "#     'model.0.0.weight' : (-2,2),\n",
    "#     'model.1.0.weight' : (-2,2),\n",
    "#     'model.2.0.weight' : (-.7,.7),\n",
    "#     'model.3.0.weight' : (-.6,.6),\n",
    "#     'model.4.0.weight' : (-0.7,0.7),\n",
    "#     'model.5.0.weight' : (-0.5,0.5),\n",
    "#     'model.6.0.weight' : (-0.3,0.3),\n",
    "#     'model.7.0.weight' : (-0.2,0.2),\n",
    "#     'model.8.0.weight' : (-0.2,0.2),\n",
    "# }\n",
    "empirical_cutoffs = {\n",
    "    'model.0.0.weight' : (-0.3,0.3),\n",
    "    'model.1.0.weight' : (-0.3,0.3),\n",
    "    'model.2.0.weight' : (-0.3,0.3),\n",
    "    'model.3.0.weight' : (-0.3,0.3),\n",
    "    'model.4.0.weight' : (-0.3,0.3),\n",
    "    'model.5.0.weight' : (-0.3,0.3),\n",
    "    'model.6.0.weight' : (-0.3,0.3),\n",
    "    'model.7.0.weight' : (-0.1,0.1),\n",
    "    'model.8.0.weight' : (-0.1,0.1),\n",
    "}\n",
    "sigmoid_aggregation = make_sigmoid_defense(empirical_cutoffs, stickiness=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d064241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid_resumption = run_federated_test(agg_fn = sigmoid_accuracy,                    \n",
    "#                                          rounds = 110,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = None,\n",
    "#                                          snapshot = False,\n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8ed2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make an attack\n",
    "# Makes an attack that puts noise in all of target layers. \n",
    "# Noise is uniform over a,b\n",
    "def noise_attack_factory(target_layers, a,b):\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        weights = device[\"net\"].state_dict().copy()\n",
    "\n",
    "        for w in weights.keys():\n",
    "            if w in target_layers:\n",
    "                weights[w] = (a - b) * torch.rand(weights[w].size()) + b\n",
    "\n",
    "        device['net'].load_state_dict(weights)\n",
    "    return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a127ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attack these layers with weights ranging from -4,4\n",
    "target_layers = ['model.0.0.weight',\n",
    " 'model.1.0.weight',\n",
    " 'model.2.0.weight',\n",
    " 'model.3.0.weight',\n",
    " 'model.4.0.weight',\n",
    " 'model.5.0.weight',\n",
    " 'model.6.0.weight',\n",
    " 'model.7.0.weight',\n",
    " 'model.8.0.weight']\n",
    "big_noise_attack = noise_attack_factory(target_layers,-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "774e5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll resume from our baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e049559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3188c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      " | Test Loss: 0.387 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4.258912086486816 \n",
      "\n",
      "Total training time: 4.2589240074157715 seconds\n"
     ]
    }
   ],
   "source": [
    "# baseline = load_result(\"baseline.pickle\")\n",
    "# determine_cutoffs = run_federated_test( agg_fn = sigmoid_aggregation,                    \n",
    "#                                          rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "#                                          local_epochs = 0,        # all else the same                     \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = None, # attack after 10 rounds more training with the new acc fn        \n",
    "#                                          attacker_strategy = None, # device 2 will carry out big noise attack  \n",
    "#                                          evil_device_id = None,     \n",
    "#                                          evaluate_attack = None, # we will evaluate manually afterwards \n",
    "#                                          output_filename = None,\n",
    "#                                          resume_from_snap = baseline, #pick up where baseline left off  \n",
    "#                                          snapshot = False ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "439a7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bcfdcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sigmoid_on_cutoff(a,c=0.005, left = False):\n",
    "#     def f(x):\n",
    "#         if(not left and x > (a + 2)):\n",
    "#             return 0\n",
    "#         if(left and x < (a - 2)):\n",
    "#             return 0\n",
    "#         exponent = (-(x-a))/(c if left else -1*c)\n",
    "#         return 1/(1 + (math.e**(exponent)))\n",
    "#     return f \n",
    "\n",
    "# def make_double_sigmoid(a,b):\n",
    "#     left = make_sigmoid_on_cutoff(a, left = True)\n",
    "#     right = make_sigmoid_on_cutoff(b, left = False)\n",
    "#     def f(x):\n",
    "#         return left(x)*right(x)\n",
    "#     return f\n",
    "# baseline2.devices[0]['net']\n",
    "\n",
    "def make_test_device(trainset):\n",
    "    data_idxs = iid_sampler(trainset, 1, .1)\n",
    "    return create_device(ConvNet().to(mps), 0, trainset, data_idxs[0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5be3a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c289183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_noise_attack(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cfc77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device['net'].state_dict()['model.0.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d447ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3cdcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [x[1] for x in trainset if x[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee5f3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d3f0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_classes_dataset(s, a, b):\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if s[i][1] == a:\n",
    "            s[i] = s[i][0],b\n",
    "        if s[i][1] == b:\n",
    "            s[i] = s[i][0],a \n",
    "    \n",
    "    return s\n",
    "\n",
    "# Make switch classes attack\n",
    "def switch_classes_attack(a,b, train_epochs):\n",
    "    transform_train = transforms.Compose([                                   \n",
    "        transforms.RandomCrop(32, padding=4),                                       \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    evil_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "    evil_trainset = swap_classes_dataset(evil_trainset, a,b)\n",
    "    print(\"swapping\\n\")\n",
    "    \n",
    "    # Load testing data\n",
    "    transform_test = transforms.Compose([                                           \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    evil_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transform_test)\n",
    "    \n",
    "    evil_testset = swap_classes_dataset(evil_testset, a,b)\n",
    "    \n",
    "    evil_testloader = torch.utils.data.DataLoader(evil_testset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    attack_idx = iid_sampler(evil_trainset, 1, 1)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    evil_device_trainset = DatasetSplit(evil_trainset, attack_idx)\n",
    "    evil_device_trainloader = torch.utils.data.DataLoader(evil_device_trainset,\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    logged_state_dict = None\n",
    "\n",
    "    class attack_class:\n",
    "        def __init__(self):\n",
    "            self.logged_state_dict = None\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        def __call__(self, device):\n",
    "            device['dataloader'] = evil_device_trainloader\n",
    "\n",
    "            if self.logged_state_dict is not None:\n",
    "                print(\"Using memoized attack\\n\")\n",
    "                device['net'].load_state_dict(self.logged_state_dict)\n",
    "            else:\n",
    "                for local_epoch in range(train_epochs):\n",
    "                    train(local_epoch, device, criterion)\n",
    "\n",
    "            print(\"Confirm the attack worked. (This should be high)\")  \n",
    "            test(0, device, criterion,testloader =  evil_testloader)\n",
    "            self.logged_state_dict = device['net'].state_dict()\n",
    "\n",
    "        \n",
    "\n",
    "    return attack_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b090d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4ed4ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Now let's make an instance of this attack that performs 25 epochs of training on the evil device with the misclassified data.\n",
    "# Specifically, we switch cars and airplanes\n",
    "sca_01 = switch_classes_attack(0,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1c32c53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline = load_result(\"baseline.pickle\")\n",
    "# switch_classes_no_defense = run_federated_test(                    \n",
    "#                                          rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "#                                          local_epochs = 4,        # all else the same                     \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "#                                          attacker_strategy = sca2, # device 2 will carry out big noise attack  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None, # we will evaluate manually afterwards \n",
    "#                                          output_filename = \"switch_classes_no_defense.pickle\",\n",
    "#                                          resume_from_snap = baseline, #pick up where baseline left off  \n",
    "#                                          snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "227a32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch_classes_no_defense = load_result(\"switch_classes_no_defense.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ef19dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch_classes_no_defense.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0c4baa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_device = make_test_device(trainset)\n",
    "test_device['net'].load_state_dict(switch_classes_no_defense.avg_weight_history[112])\n",
    "# def test(epoch, device, criterion, testloader = testloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "cb9c2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.368 | Test Acc: 88.560\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0657ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_test_set(s, labels):\n",
    "    s = list(s)\n",
    "    s = [s for s in s if s[1] in labels]\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def make_testloader_subset(labels):\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "    \n",
    "    restricted_test_set = limit_test_set(testset, labels)\n",
    "    print(len(restricted_test_set))\n",
    "#     restricted_test_set = swap_classes_dataset(restricted_test_set, 0, 1)\n",
    "    \n",
    "    restricted_testloader = torch.utils.data.DataLoader(restricted_test_set, batch_size=128, shuffle=False)\n",
    "    return restricted_testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c69742b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "checker_test_set = make_testloader_subset([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "51054b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.392 | Test Acc: 89.400\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), checker_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3778876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-125-34489808078c>:16: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"-k\" (-> color='k'). The keyword argument will take precedence.\n",
      "  [plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.lines.Line2D at 0x112313580>],\n",
       " [<matplotlib.lines.Line2D at 0x112313430>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77e50>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77c10>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77af0>],\n",
       " [<matplotlib.lines.Line2D at 0x132073b80>],\n",
       " [<matplotlib.lines.Line2D at 0x132073220>],\n",
       " [<matplotlib.lines.Line2D at 0x132073070>],\n",
       " [<matplotlib.lines.Line2D at 0x1101b5730>]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weight_history_to_layer_max_magnitude_and_means(w_avg, include_batch_norm = True):\n",
    "    weight_keys = [x for x in w_avg.keys() if \".0.weight\" in x]\n",
    "    if include_batch_norm:\n",
    "        weight_keys += [x for x in w_avg.keys() if \".1.weight\" in x]\n",
    "    def max_magnitude(t):\n",
    "        return torch.max(torch.abs(t))\n",
    "    def mean_magnitude(t):\n",
    "        return torch.mean(torch.abs(t))\n",
    "    all_means = [mean_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    all_max = [max_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    return all_means, all_max\n",
    "max_history = [weight_history_to_layer_max_magnitude_and_means(baseline.avg_weight_history[t], include_batch_norm = False) for t in range(100)]\n",
    "max_history = [x[1] for x in max_history]\n",
    "by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "[plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d35b2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44334d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_history = [weight_history_to_layer_max_magnitude_and_means(watcher, include_batch_norm = False) for t in range(1)]\n",
    "# max_history = [(x[1]) for x in max_history]\n",
    "# by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "# [plt.plot([x for x in range(1)],by_layer[l],  '-k', color=['blue','red','green','blue', 'red', 'green', 'blue', 'red', 'green'][l]) for l in range(5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "928e2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729dea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_result(\"baseline.pickle\")\n",
    "sigmoid_against_noise_attack = run_federated_test(agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = big_noise_attack, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"sigmoid_against_noise_attack_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc08bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_zero_one = switch_classes_attack(0,1,25)\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_no_defense = run_federated_test(                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca_zero_one, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_no_defense_multiple_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True, \n",
    "                                         multiple_attack_rounds = [100,101,102,103,104,105,106,107,108,109]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0cca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sca_zero_one_2 = switch_classes_attack(0,1,25)\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_sigmoid_defense = run_federated_test(  agg_fn = sigmoid_aggregation, \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca_zero_one_2, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_sigmoid_defense_multiple_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True, \n",
    "                                         multiple_attack_rounds = [100,101,102,103,104,105,106,107,108,109]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac02d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
