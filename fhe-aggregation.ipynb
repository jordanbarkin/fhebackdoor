{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6dca87e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random \n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d6fcba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure GPU (change if not M1 mac)\n",
    "mps = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "827a7479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "\n",
    "# Using CIFAR-10 again as in the programming assignments\n",
    "# Load training data\n",
    "transform_train = transforms.Compose([                                   \n",
    "    transforms.RandomCrop(32, padding=4),                                       \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True,\n",
    "                                        transform=transform_train)\n",
    "\n",
    "# Load testing data\n",
    "transform_test = transforms.Compose([                                           \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ab5f2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving And helpers\n",
    "\n",
    "def save_tracker(tracker, path):\n",
    "  np.savetxt(path, tracker, delimiter=',') \n",
    "\n",
    "def save_trackers(device, filename):\n",
    "  \"\"\"Save all trackers and current total_time to a file.\"\"\"\n",
    "  torch.save((device['train_loss_tracker'], device['train_acc_tracker'], device['test_loss_tracker'], device['test_acc_tracker'], total_time), filename)\n",
    "  print(\"Saved trackers to \" + filename)\n",
    "\n",
    "def moving_average(a, n=100):\n",
    "  '''Helper function used for visualization'''\n",
    "  ret = torch.cumsum(torch.Tensor(a), 0)\n",
    "  ret[n:] = ret[n:] - ret[:-n]\n",
    "  return ret[n - 1:] / n\n",
    "\n",
    "# Plotting helpers! \n",
    "def make_plot(trackers, num_epochs, title, y_axis_lab, should_average=False, legend=True, fix_ax=True):\n",
    "  avg_fn = moving_average if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  if fix_ax:\n",
    "    ax.set_ylim([0, 100])\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "\n",
    "  if legend:\n",
    "    _ = plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "def make_plot_better(trackers, num_epochs, title, y_axis_lab, should_average=False, n = 100):\n",
    "  avg_fn = (lambda x : moving_average(x, n)) if should_average else (lambda x : x) \n",
    "  x = np.arange(1, len(avg_fn(list(trackers.values())[0])) + 1)\n",
    "  x = x / (len(x)/num_epochs)\n",
    "  ax = plt.subplot(1,1,1)\n",
    "  plt.title(title)\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(y_axis_lab)\n",
    "  # plt.xticks(np.arange(min(x), max(x)+1, 1))\n",
    "  ax.xaxis.set_major_formatter(ticker.FormatStrFormatter('%1.0f'))\n",
    "\n",
    "  for lab, t in trackers.items(): \n",
    "    l1, = ax.plot(x, avg_fn(t), label = lab)\n",
    "  _ = plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7ed703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSplit(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, torch.tensor(label)\n",
    "\n",
    "def iid_sampler(dataset, num_devices, data_pct):\n",
    "    '''\n",
    "    dataset: PyTorch Dataset (e.g., CIFAR-10 training set)\n",
    "    num_devices: integer number of devices to create subsets for\n",
    "    data_pct: percentalge of training samples to give each device\n",
    "              e.g., 0.1 represents 10%\n",
    "\n",
    "    return: a dictionary of the following format:\n",
    "      {\n",
    "        0: [3, 65, 2233, ..., 22] // device 0 sample indexes\n",
    "        1: [0, 2, 4, ..., 583] // device 1 sample indexes\n",
    "        ...\n",
    "      }\n",
    "\n",
    "    iid (independent and identically distributed) means that the indexes\n",
    "    should be drawn independently in a uniformly random fashion.\n",
    "    '''\n",
    "    total_samples = len(dataset)\n",
    "    sampled = {}\n",
    "    number_samples = int((data_pct)*(total_samples)) \n",
    "\n",
    "    for i in range(num_devices):\n",
    "      sampled[i] = random.sample(range(total_samples), number_samples)\n",
    "        \n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea60c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a718639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural net definitions\n",
    "\n",
    "# Same ConvNet as in Assignment 2 and 3\n",
    "def conv_block(in_channels, out_channels, kernel_size=3, stride=1,\n",
    "               padding=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding,\n",
    "                  bias=False),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            conv_block(3, 32),\n",
    "            conv_block(32, 32),\n",
    "            conv_block(32, 64, stride=2),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 64),\n",
    "            conv_block(64, 128, stride=2),\n",
    "            conv_block(128, 128),\n",
    "            conv_block(128, 256),\n",
    "            conv_block(256, 256),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.model(x)\n",
    "        B, C, _, _ = h.shape\n",
    "        h = h.view(B, C)\n",
    "        return self.classifier(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e2df5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Federated learning helpers\n",
    "\n",
    "# The baseline `average' function. \n",
    "def average_weights(devices,*args, **kwargs):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "#     max_magnitude = 0\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "      w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "#             max_magnitude = max(max_magnitude, abs(torch.max(state_dicts[i][k].type(torch.float32))))\n",
    "            w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg\n",
    "\n",
    "\n",
    "def get_devices_for_round(devices, device_pct):  \n",
    "    return random.sample(devices, int(device_pct * len(devices)))\n",
    "\n",
    "def create_device(net, device_id, trainset, data_idxs, lr=0.1,\n",
    "                  milestones=None, batch_size=128):\n",
    "    if milestones == None:\n",
    "        milestones = [25, 50, 75]\n",
    "\n",
    "    device_net = copy.deepcopy(net)\n",
    "    optimizer = torch.optim.SGD(device_net.parameters(), lr=lr, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                     milestones=milestones,\n",
    "                                                     gamma=0.1)\n",
    "    device_trainset = DatasetSplit(trainset, data_idxs)\n",
    "    device_trainloader = torch.utils.data.DataLoader(device_trainset,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     shuffle=True)\n",
    "    return {\n",
    "        'net': device_net,\n",
    "        'id': device_id,\n",
    "        'dataloader': device_trainloader, \n",
    "        'optimizer': optimizer,\n",
    "        'scheduler': scheduler,\n",
    "        'train_loss_tracker': [],\n",
    "        'train_acc_tracker': [],\n",
    "        'test_loss_tracker': [],\n",
    "        'test_acc_tracker': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "584da899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local device training and testing\n",
    "def train(epoch, device, criterion):\n",
    "    device['net'].train()\n",
    "    train_loss, correct, total = 0, 0, 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(device['dataloader']):\n",
    "        inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "        device['optimizer'].zero_grad()\n",
    "        outputs = device['net'](inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        device['optimizer'].step()\n",
    "        train_loss += loss.item()\n",
    "        device['train_loss_tracker'].append(loss.item())\n",
    "        loss = train_loss / (batch_idx + 1)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        acc = 100. * correct / total\n",
    "        dev_id = device['id']\n",
    "        sys.stdout.write(f'\\r(Device {dev_id}/Epoch {epoch}) ' + \n",
    "                         f'Train Loss: {loss:.3f} | Train Acc: {acc:.3f}')\n",
    "        sys.stdout.flush()\n",
    "    device['train_acc_tracker'].append(acc)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def test(epoch, device, criterion, testloader = testloader):\n",
    "    device['net'].eval()\n",
    "    test_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(mps), targets.to(mps)\n",
    "            outputs = device['net'](inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            device['test_loss_tracker'].append(loss.item())\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            loss = test_loss / (batch_idx + 1)\n",
    "            acc = 100.* correct / total\n",
    "    sys.stdout.write(f' | Test Loss: {loss:.3f} | Test Acc: {acc:.3f}\\n')\n",
    "    sys.stdout.flush()  \n",
    "    acc = 100.*correct/total\n",
    "    device['test_acc_tracker'].append(acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce49187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function tests (the main experiment routine)\n",
    "\n",
    "# Given two different sets of aggregated weights, \n",
    "# gives a value representing the difference between them,\n",
    "# as a way to measure the direct cost of using our aggregated function\n",
    "def diff_aggregated_weights(strat, baseline):\n",
    "    result = 0 \n",
    "    for k in strat.keys():\n",
    "        result += torch.linalg.norm(strat[k] - baseline[k])\n",
    "    return result\n",
    "\n",
    "# A data type for experiment results\n",
    "BackdoorResult = namedtuple(\"BackdoorResult\", [\"scheme_loss\", \"test_accuracy\", \"backdoor_success\", \"devices\", \"avg_weight_history\"])\n",
    "\n",
    "# The main routine! \n",
    "def run_federated_test(agg_fn = average_weights,  # Pass in aggregation function, \n",
    "                                                  # Device list -> aggregated weights \n",
    "                       rounds = 10,               # Rounds of FL\n",
    "                       local_epochs = 4,          # Epochs per device                      \n",
    "                       num_devices = 50,          # Total # devices\n",
    "                       device_pct = 0.1,          # % of devices per round\n",
    "                       data_pct = 0.1,            # % of data each device gets\n",
    "                       net = ConvNet().to(mps),   # Net design; make sure on mps\n",
    "                       evil_round = None,         # If None, no attack; else attacker will mount attack on this round\n",
    "                       attacker_strategy = None,  # device --> void --- set up the local weights on the attacker\n",
    "                       evil_device_id = None,     # Which device attacks? \n",
    "                       evaluate_attack = None,    # Function devices --> <any> measuring how well the attack worked at the end\n",
    "                       output_filename = None, \n",
    "                       snapshot = True, \n",
    "                       resume_from_snap = None,\n",
    "                       multiple_attack_rounds = []):   \n",
    "    def lighten_device(d):\n",
    "        return {\n",
    "            k: d[k] for k in ( 'id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker')\n",
    "        }                                   \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "    devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "    \n",
    "    scheme_loss = []\n",
    "#     max_magnitudes = []\n",
    "    avg_weight_history = []\n",
    "    _starting_round_num = 0\n",
    "    \n",
    "    if resume_from_snap: \n",
    "        print(\"Resuming from snapshot!\\n\")\n",
    "        # Load what we can\n",
    "        result = resume_from_snap\n",
    "        scheme_loss = result.scheme_loss\n",
    "        avg_weight_history = result.avg_weight_history\n",
    "        partial_devices = result.devices\n",
    "\n",
    "        # Fresh data and devices\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        data_idxs = iid_sampler(trainset, num_devices, data_pct)\n",
    "\n",
    "        devices = [create_device(net, i, trainset, data_idxs[i]) for i in range(num_devices)]\n",
    "\n",
    "        # Restore the devices with the info from the trackers\n",
    "        def restore_device(old_device, new_device):\n",
    "            for k in ('id', 'train_loss_tracker', 'train_acc_tracker', 'test_loss_tracker', 'test_acc_tracker'):\n",
    "                new_device[k] = old_device[k]\n",
    "            return new_device\n",
    "        \n",
    "        print(\"Restoring devices\\n\")\n",
    "        devices = [restore_device(partial_devices[i], devices[i]) for i in range(len(devices))]\n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(avg_weight_history[-1])\n",
    "        \n",
    "        _starting_round_num = len(result.test_accuracy)\n",
    "        print(\"Finished restoring\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "    ## IID Federated Learning\n",
    "    start_time = time.time()\n",
    "    for round_num in range(_starting_round_num, rounds):\n",
    "        round_start_time = time.time()\n",
    "        # Part 1.3: Implement getting devices for each round here\n",
    "        round_devices = get_devices_for_round(devices, device_pct)\n",
    "\n",
    "        print('Round: ', round_num)\n",
    "        # Train locally \n",
    "        for device in round_devices:\n",
    "            for local_epoch in range(local_epochs):\n",
    "                train(local_epoch, device, criterion)\n",
    "        \n",
    "        # One device becomes evil if required\n",
    "        if ((evil_round and round_num == evil_round) or round_num in multiple_attack_rounds):\n",
    "            assert (evil_device_id is not None)\n",
    "            assert (attacker_strategy is not None)\n",
    "            print(\"Attacking!\\n\")\n",
    "            \n",
    "            attacker_strategy(devices[evil_device_id])\n",
    "            # Make sure evil guy gets averaged in \n",
    "            if evil_device_id not in round_devices:\n",
    "                round_devices.append(devices[evil_device_id])\n",
    "            print(\"Finished attacking\\n\")\n",
    "            \n",
    "        \n",
    "        # Weight averaging\n",
    "        w_baseline = average_weights(round_devices)\n",
    "        w_avg = agg_fn(round_devices, (avg_weight_history[-1] if avg_weight_history != [] else None))\n",
    "#         max_magnitudes.append(max_magnitude)\n",
    "        \n",
    "        # Track the difference between the two; should be 0 if straight average\n",
    "        scheme_loss.append((float(diff_aggregated_weights(w_avg, w_baseline))))\n",
    "        \n",
    "        avg_weight_history.append(copy.deepcopy(w_avg))\n",
    "        \n",
    "        # Gradients         \n",
    "        for device in devices:\n",
    "            device['net'].load_state_dict(w_avg)\n",
    "            device['optimizer'].zero_grad()\n",
    "            device['optimizer'].step()\n",
    "            device['scheduler'].step()\n",
    "\n",
    "        # test accuracy after aggregation\n",
    "        # device 0 is the unique device with all of the \n",
    "        # test accuracies and losses in its tracker\n",
    "        test(round_num, devices[0], criterion)\n",
    "        \n",
    "        print(f\"\\nDiff: {scheme_loss[-1]}\\n\")\n",
    "        print(f\"Round time: {time.time() - start_time} \\n\")\n",
    "        if snapshot:\n",
    "            intermediate_result = BackdoorResult(\n",
    "                scheme_loss = scheme_loss, \n",
    "                test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "                backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "                devices = [lighten_device(d) for d in devices], \n",
    "                avg_weight_history = avg_weight_history\n",
    "            )\n",
    "\n",
    "\n",
    "            if output_filename is not None: \n",
    "                print(\"Writing snapshot\\n\")\n",
    "                with open(f\"snapshot_{output_filename}\", 'wb') as file: \n",
    "                    pickle.dump(intermediate_result, file)\n",
    "        \n",
    "    total_time = time.time() - start_time\n",
    "    print('Total training time: {} seconds'.format(total_time))\n",
    "    \n",
    "    # Pack up everything we care about and the devices for good measure\n",
    "    result = BackdoorResult(\n",
    "        scheme_loss = scheme_loss, \n",
    "        test_accuracy = devices[0][\"test_acc_tracker\"], \n",
    "        backdoor_success = evaluate_attack(devices) if evaluate_attack is not None else None, \n",
    "        devices = [lighten_device(d) for d in devices], \n",
    "        avg_weight_history = avg_weight_history\n",
    "    )\n",
    "\n",
    "    \n",
    "    if output_filename is not None: \n",
    "        with open(output_filename, 'wb') as file: \n",
    "            print(\"Writing file\\n\")\n",
    "            pickle.dump(result, file)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Load output files back into memory\n",
    "def load_result(filename):\n",
    "    with open(filename, 'rb') as file: \n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd20f631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be4169e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# results = run_federated_test(local_epochs=1, num_devices = 10, rounds = 2, output_filename = \"testout.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bf2e74d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Can also load it back\n",
    "# results = load_result(\"snapshot_testout.pickle\")\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2ad48138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A silly attack that just sends massive weights all of magnitude 10000\n",
    "def sample_attack(device):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights.\n",
    "    '''\n",
    "    weights = device[\"net\"].state_dict().copy()\n",
    "    \n",
    "    for w in weights.keys():\n",
    "        weights[w] = torch.full(weights[w].size(), 10000)\n",
    "    \n",
    "    device['net'].load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b08537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation function that squashes any weights with magnitude over 1000 (except on the first device but whatever)\n",
    "def super_smart_aggregation(devices):\n",
    "    '''\n",
    "    devices: a list of devices generated by create_devices\n",
    "    Returns an the average of the weights, excluding huge updates.\n",
    "    '''\n",
    "    state_dicts = [device['net'].state_dict() for device in devices]\n",
    "    # initialize w_avg to tensors from device 0\n",
    "    w_avg = copy.deepcopy(state_dicts[0])\n",
    "    for k in w_avg.keys():\n",
    "        w_avg[k] = w_avg[k].type(torch.float32)\n",
    "\n",
    "    # for each model param\n",
    "    for k in w_avg.keys():\n",
    "        # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "        for i in range(1, len(devices)):\n",
    "            if (torch.max(state_dicts[i][k].type(torch.float32)) <= 1000): \n",
    "                w_avg[k] += (state_dicts[i][k].type(torch.float32))\n",
    "        # compute average\n",
    "        w_avg[k] /= float(len(devices))\n",
    "    return w_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a4507b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how this works\n",
    "\n",
    "# Here, we carry out the attack but use the ordinary average\n",
    "# results_straight_avg = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 3,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 10,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 1,        \n",
    "#                                          attacker_strategy = sample_attack,  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline_trivial_attack.pickle\")  \n",
    "# Observe that it absolutely destroys our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e703e878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now we do it again but with the aggregation that rejects huge updates\n",
    "# results_reject_huge = run_federated_test(agg_fn = super_smart_aggregation,                    \n",
    "#                                          rounds = 3,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 10,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 1,        \n",
    "#                                          attacker_strategy = sample_attack,  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None,\n",
    "#                                          output_filename = \"simple_attack_and_defense.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1bcc5580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here, we compute a real baseline over 100 epochs and typical averaging. Good starting point for future \n",
    "# tests; can resume from this snapshot.\n",
    "# baseline = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 100,              \n",
    "#                                          local_epochs = 4,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline.pickle\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4835de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = load_result(\"baseline.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7c03e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, now can get things like\n",
    "# baseline.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94b08e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can resume from a snapshot:\n",
    "# NOTE : keep all the basic params (local epochs, num devices, net, etc) the same\n",
    "# when resuming from a snapshot \n",
    "# baseline2 = run_federated_test(agg_fn = (lambda x : average_weights(x)[0]),                    \n",
    "#                                          rounds = 101,              \n",
    "#                                          local_epochs = 4,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = \"baseline2.pickle\", \n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d140864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline2_loaded = load_result(\"baseline2.pickle\")\n",
    "# baseline2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7864d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can move on to a real defense. \n",
    "\n",
    "# We create factory functions that let us parametrize a double sigmoid using threshholds\n",
    "\n",
    "def torch_scaled_sigmoid_factory(a, c = 0.005, left = False):\n",
    "    \n",
    "    def f(x):\n",
    "        scaled = torch.sub(x, a)\n",
    "\n",
    "        divisor = c if left else -1*c\n",
    "\n",
    "        scaled = torch.div(scaled, divisor)\n",
    "\n",
    "        return torch.sigmoid(scaled)\n",
    "    return f\n",
    "\n",
    "def torch_double_sigmoid_factory(a,b,c = 0.005):\n",
    "    left = torch_scaled_sigmoid_factory(a, left = True)\n",
    "    right = torch_scaled_sigmoid_factory(b, left = False) \n",
    "    def f(x):\n",
    "        return (left(x)*right(x))\n",
    "    return f\n",
    "\n",
    "my_sigmoid = torch_double_sigmoid_factory(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a035df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_double_sigmoid_factory(-1,6)(torch.tensor(list(range(-5,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6fd6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it works\n",
    "# torch_double_sigmoid_factory(-2,2)(torch.Tensor([-5,-4,-3,-2,-1.5,-1.4,1.3,-1,0,1,1.5,1.6,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "54a43171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a sigmoid defense,\n",
    "#     keys_to_range_mapping maps each layer name in the state dict to the sigmoid bounds for processing it\n",
    "#     All other layers just get identity function-ed\n",
    "# watcher = {}\n",
    "def make_sigmoid_defense(keys_to_range_mapping, stickiness = 0):\n",
    "    \n",
    "    sigmoid_dict = defaultdict(lambda : (lambda x: 1))\n",
    "    \n",
    "    for k,(a,b) in keys_to_range_mapping.items():\n",
    "        sigmoid_dict[k] = torch_double_sigmoid_factory(a,b)\n",
    "    \n",
    "    def f(devices, previous_round_weights):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights preprocessed by sigmoid\n",
    "        '''\n",
    "        state_dicts = [device['net'].state_dict() for device in devices]\n",
    "        # initialize w_avg to tensors from device 0\n",
    "        w_avg = copy.deepcopy(state_dicts[0])\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "#             prev_round_x = previous_round_weights[k].type(torch.float32) if  previous_round_weights is not None else x\n",
    "            w_avg[k] = w_avg[k].type(torch.float32)\n",
    "#             for i in range(stickiness):\n",
    "#                 w_avg[k] += x              \n",
    "\n",
    "        # for each model param\n",
    "        for k in w_avg.keys():\n",
    "            sig = sigmoid_dict[k]\n",
    "            # for each remaining device i, add tensor state_dicts[i][k] to w_avg[k]\n",
    "            for i in range(1, len(devices)):\n",
    "                new_weight = (state_dicts[i][k].type(torch.float32))\n",
    "                prev_round_x = previous_round_weights[k].type(torch.float32)  if (previous_round_weights is not None) else new_weight\n",
    "#                 if i == 1:\n",
    "#                     watcher[k] = (new_weight - prev_round_x)\n",
    "#                 print((())))\n",
    "#                 print((len(new_weight)))\n",
    "\n",
    "\n",
    "                w_avg[k] += new_weight*(sig(torch.sub(new_weight, prev_round_x)))\n",
    "            # compute average\n",
    "            w_avg[k] /= float(len(devices) + stickiness)\n",
    "        return w_avg\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2da666cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.0.0.weight',\n",
       " 'model.1.0.weight',\n",
       " 'model.2.0.weight',\n",
       " 'model.3.0.weight',\n",
       " 'model.4.0.weight',\n",
       " 'model.5.0.weight',\n",
       " 'model.6.0.weight',\n",
       " 'model.7.0.weight',\n",
       " 'model.8.0.weight']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the actual layer weights that we care about\n",
    "[x for x in baseline.avg_weight_history[-1].keys() if '.0.weight' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "286d9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets set up a potential sigmoid defense\n",
    "# empirical_cutoffs = {\n",
    "#     'model.0.0.weight' : (-2,2),\n",
    "#     'model.1.0.weight' : (-2,2),\n",
    "#     'model.2.0.weight' : (-.7,.7),\n",
    "#     'model.3.0.weight' : (-.6,.6),\n",
    "#     'model.4.0.weight' : (-0.7,0.7),\n",
    "#     'model.5.0.weight' : (-0.5,0.5),\n",
    "#     'model.6.0.weight' : (-0.3,0.3),\n",
    "#     'model.7.0.weight' : (-0.2,0.2),\n",
    "#     'model.8.0.weight' : (-0.2,0.2),\n",
    "# }\n",
    "empirical_cutoffs = {\n",
    "    'model.0.0.weight' : (-0.3,0.3),\n",
    "    'model.1.0.weight' : (-0.3,0.3),\n",
    "    'model.2.0.weight' : (-0.3,0.3),\n",
    "    'model.3.0.weight' : (-0.3,0.3),\n",
    "    'model.4.0.weight' : (-0.3,0.3),\n",
    "    'model.5.0.weight' : (-0.3,0.3),\n",
    "    'model.6.0.weight' : (-0.3,0.3),\n",
    "    'model.7.0.weight' : (-0.1,0.1),\n",
    "    'model.8.0.weight' : (-0.1,0.1),\n",
    "}\n",
    "sigmoid_aggregation = make_sigmoid_defense(empirical_cutoffs, stickiness=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99f8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d064241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid_resumption = run_federated_test(agg_fn = sigmoid_accuracy,                    \n",
    "#                                          rounds = 110,              \n",
    "#                                          local_epochs = 1,                             \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evaluate_attack = None, \n",
    "#                                          output_filename = None,\n",
    "#                                          snapshot = False,\n",
    "#                                          resume_from_snap = baseline )  # we pass in a results object here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8ed2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make an attack\n",
    "# Makes an attack that puts noise in all of target layers. \n",
    "# Noise is uniform over a,b\n",
    "def noise_attack_factory(target_layers, a,b):\n",
    "    def attack(device):\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        weights = device[\"net\"].state_dict().copy()\n",
    "\n",
    "        for w in weights.keys():\n",
    "            if w in target_layers:\n",
    "                weights[w] = (a - b) * torch.rand(weights[w].size()) + b\n",
    "\n",
    "        device['net'].load_state_dict(weights)\n",
    "    return attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a127ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attack these layers with weights ranging from -4,4\n",
    "target_layers = ['model.0.0.weight',\n",
    " 'model.1.0.weight',\n",
    " 'model.2.0.weight',\n",
    " 'model.3.0.weight',\n",
    " 'model.4.0.weight',\n",
    " 'model.5.0.weight',\n",
    " 'model.6.0.weight',\n",
    " 'model.7.0.weight',\n",
    " 'model.8.0.weight']\n",
    "big_noise_attack = noise_attack_factory(target_layers,-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "774e5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll resume from our baseline model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e049559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3188c313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      " | Test Loss: 0.387 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4.258912086486816 \n",
      "\n",
      "Total training time: 4.2589240074157715 seconds\n"
     ]
    }
   ],
   "source": [
    "# baseline = load_result(\"baseline.pickle\")\n",
    "# determine_cutoffs = run_federated_test( agg_fn = sigmoid_aggregation,                    \n",
    "#                                          rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "#                                          local_epochs = 0,        # all else the same                     \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.05,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = None, # attack after 10 rounds more training with the new acc fn        \n",
    "#                                          attacker_strategy = None, # device 2 will carry out big noise attack  \n",
    "#                                          evil_device_id = None,     \n",
    "#                                          evaluate_attack = None, # we will evaluate manually afterwards \n",
    "#                                          output_filename = None,\n",
    "#                                          resume_from_snap = baseline, #pick up where baseline left off  \n",
    "#                                          snapshot = False ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "439a7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bcfdcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sigmoid_on_cutoff(a,c=0.005, left = False):\n",
    "#     def f(x):\n",
    "#         if(not left and x > (a + 2)):\n",
    "#             return 0\n",
    "#         if(left and x < (a - 2)):\n",
    "#             return 0\n",
    "#         exponent = (-(x-a))/(c if left else -1*c)\n",
    "#         return 1/(1 + (math.e**(exponent)))\n",
    "#     return f \n",
    "\n",
    "# def make_double_sigmoid(a,b):\n",
    "#     left = make_sigmoid_on_cutoff(a, left = True)\n",
    "#     right = make_sigmoid_on_cutoff(b, left = False)\n",
    "#     def f(x):\n",
    "#         return left(x)*right(x)\n",
    "#     return f\n",
    "# baseline2.devices[0]['net']\n",
    "\n",
    "def make_test_device(trainset):\n",
    "    data_idxs = iid_sampler(trainset, 1, .1)\n",
    "    return create_device(ConvNet().to(mps), 0, trainset, data_idxs[0]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5be3a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c289183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_noise_attack(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8cfc77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device['net'].state_dict()['model.0.0.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d447ac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a3cdcded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [x[1] for x in trainset if x[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ee5f3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "5d3f0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_classes_dataset(s, a, b):\n",
    "    s = list(s)\n",
    "    for i in range(len(s)):\n",
    "        if s[i][1] == a:\n",
    "            s[i] = s[i][0],b\n",
    "        elif s[i][1] == b:\n",
    "            s[i] = s[i][0],a \n",
    "    \n",
    "    return s\n",
    "\n",
    "def limit_test_set(s, labels):\n",
    "    s = list(s)\n",
    "    s = [s for s in s if s[1] in labels]\n",
    "    return s\n",
    "\n",
    "\n",
    "# Make switch classes attack\n",
    "def switch_classes_attack(a,b, train_epochs):\n",
    "    transform_train = transforms.Compose([                                   \n",
    "        transforms.RandomCrop(32, padding=4),                                       \n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    evil_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                            download=True,\n",
    "                                            transform=transform_train)\n",
    "    print(len(evil_trainset))\n",
    "\n",
    "\n",
    "#     evil_trainset = limit_test_set(evil_trainset, [a,b])\n",
    "    evil_trainset = swap_classes_dataset(evil_trainset, a,b)\n",
    "    print(len(evil_trainset))\n",
    "\n",
    "\n",
    "    print(\"swapping and limiting\\n\")\n",
    "    \n",
    "    # Load testing data\n",
    "    transform_test = transforms.Compose([                                           \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    evil_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transform_test)\n",
    "    evil_testset = limit_test_set(evil_testset, [a,b])\n",
    "\n",
    "    \n",
    "    evil_testset = swap_classes_dataset(evil_testset, a,b)\n",
    "    \n",
    "    evil_testloader = torch.utils.data.DataLoader(evil_testset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    attack_idx = iid_sampler(evil_trainset, 1, 1)[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    evil_device_trainset = DatasetSplit(evil_trainset, attack_idx)\n",
    "    evil_device_trainloader = torch.utils.data.DataLoader(evil_device_trainset,\n",
    "                                                     batch_size=128,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    logged_state_dict = None\n",
    "\n",
    "    class attack_class:\n",
    "        def __init__(self):\n",
    "            self.logged_state_dict = None\n",
    "        '''\n",
    "        devices: a list of devices generated by create_devices\n",
    "        Returns an the average of the weights.\n",
    "        '''\n",
    "        def __call__(self, device):\n",
    "            device['dataloader'] = evil_device_trainloader\n",
    "\n",
    "            if self.logged_state_dict is not None:\n",
    "                print(\"Using memoized attack\\n\")\n",
    "                device['net'].load_state_dict(self.logged_state_dict)\n",
    "            else:\n",
    "                for local_epoch in range(train_epochs):\n",
    "                    train(local_epoch, device, criterion)\n",
    "                    test(0, device, criterion,testloader =  evil_testloader)\n",
    "\n",
    "\n",
    "            print(\"Confirm the attack worked. (This should be high)\")  \n",
    "            test(0, device, criterion,testloader =  evil_testloader)\n",
    "\n",
    "\n",
    "            self.logged_state_dict = copy.deepcopy(device['net'].state_dict())\n",
    "\n",
    "        \n",
    "\n",
    "    return attack_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b090d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's make an instance of this attack that performs 25 epochs of training on the evil device with the misclassified data.\n",
    "# Specifically, we switch cars and airplanes\n",
    "sca_01 = switch_classes_attack(0,1,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1c32c53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# baseline = load_result(\"baseline.pickle\")\n",
    "# switch_classes_no_defense = run_federated_test(                    \n",
    "#                                          rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "#                                          local_epochs = 4,        # all else the same                     \n",
    "#                                          num_devices = 50,         \n",
    "#                                          device_pct = 0.2,          \n",
    "#                                          data_pct = 0.1,           \n",
    "#                                          net = ConvNet().to(mps),  \n",
    "#                                          evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "#                                          attacker_strategy = sca2, # device 2 will carry out big noise attack  \n",
    "#                                          evil_device_id = 2,     \n",
    "#                                          evaluate_attack = None, # we will evaluate manually afterwards \n",
    "#                                          output_filename = \"switch_classes_no_defense.pickle\",\n",
    "#                                          resume_from_snap = baseline, #pick up where baseline left off  \n",
    "#                                          snapshot = True ) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "227a32c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch_classes_no_defense = load_result(\"switch_classes_no_defense.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "ef19dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch_classes_no_defense.test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0c4baa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# def test(epoch, device, criterion, testloader = testloader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cb9c2a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.352 | Test Acc: 89.210\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "0657ad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_test_set(s, labels):\n",
    "    s = list(s)\n",
    "    s = [s for s in s if s[1] in labels]\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def make_testloader_subset(labels, a, b):\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transform_test)\n",
    "    \n",
    "    restricted_test_set = limit_test_set(testset, labels)\n",
    "#     print(len(restricted_test_set))\n",
    "    restricted_test_set = swap_classes_dataset(restricted_test_set, a, b)\n",
    "    \n",
    "    restricted_testloader = torch.utils.data.DataLoader(restricted_test_set, batch_size=128, shuffle=False)\n",
    "    \n",
    "    return restricted_testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c69742b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d0ca080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [x[1] for x in checker_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "51054b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 13.767 | Test Acc: 0.600\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), checker_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a3778876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-125-34489808078c>:16: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"-k\" (-> color='k'). The keyword argument will take precedence.\n",
      "  [plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[<matplotlib.lines.Line2D at 0x112313580>],\n",
       " [<matplotlib.lines.Line2D at 0x112313430>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77e50>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77c10>],\n",
       " [<matplotlib.lines.Line2D at 0x127e77af0>],\n",
       " [<matplotlib.lines.Line2D at 0x132073b80>],\n",
       " [<matplotlib.lines.Line2D at 0x132073220>],\n",
       " [<matplotlib.lines.Line2D at 0x132073070>],\n",
       " [<matplotlib.lines.Line2D at 0x1101b5730>]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weight_history_to_layer_max_magnitude_and_means(w_avg, include_batch_norm = True):\n",
    "    weight_keys = [x for x in w_avg.keys() if \".0.weight\" in x]\n",
    "    if include_batch_norm:\n",
    "        weight_keys += [x for x in w_avg.keys() if \".1.weight\" in x]\n",
    "    def max_magnitude(t):\n",
    "        return torch.max(torch.abs(t))\n",
    "    def mean_magnitude(t):\n",
    "        return torch.mean(torch.abs(t))\n",
    "    all_means = [mean_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    all_max = [max_magnitude(w_avg[w]) for w in weight_keys]\n",
    "    return all_means, all_max\n",
    "max_history = [weight_history_to_layer_max_magnitude_and_means(baseline.avg_weight_history[t], include_batch_norm = False) for t in range(100)]\n",
    "max_history = [x[1] for x in max_history]\n",
    "by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "[plt.plot([x for x in range(100)],by_layer[l],  '-k', color='blue') for l in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d35b2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "44334d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_history = [weight_history_to_layer_max_magnitude_and_means(watcher, include_batch_norm = False) for t in range(1)]\n",
    "# max_history = [(x[1]) for x in max_history]\n",
    "# by_layer = [[max_history[k][l].cpu() for k in range(len(max_history))] for l in range(len(max_history[0]))]\n",
    "\n",
    "# [plt.plot([x for x in range(1)],by_layer[l],  '-k', color=['blue','red','green','blue', 'red', 'green', 'blue', 'red', 'green'][l]) for l in range(5,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "928e2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "729dea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 34/Epoch 3) Train Loss: 0.353 | Train Acc: 88.640 | Test Loss: 0.403 | Test Acc: 86.770\n",
      "\n",
      "Diff: 0.21199172735214233\n",
      "\n",
      "Round time: 338.0134241580963 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 49/Epoch 3) Train Loss: 0.347 | Train Acc: 88.020 | Test Loss: 0.381 | Test Acc: 87.730\n",
      "\n",
      "Diff: 2.324102933926042e-05\n",
      "\n",
      "Round time: 662.2266662120819 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 2/Epoch 3) Train Loss: 0.240 | Train Acc: 91.2600 | Test Loss: 0.387 | Test Acc: 87.700\n",
      "\n",
      "Diff: 7.141364767448977e-05\n",
      "\n",
      "Round time: 984.8954751491547 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 3/Epoch 3) Train Loss: 0.303 | Train Acc: 89.3000 | Test Loss: 0.378 | Test Acc: 87.960\n",
      "\n",
      "Diff: 2.7878273613168858e-05\n",
      "\n",
      "Round time: 1270.7090492248535 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 16/Epoch 3) Train Loss: 0.387 | Train Acc: 87.040 | Test Loss: 0.386 | Test Acc: 87.480\n",
      "\n",
      "Diff: 0.00034004563349299133\n",
      "\n",
      "Round time: 1559.5193321704865 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 33/Epoch 3) Train Loss: 0.210 | Train Acc: 92.800 | Test Loss: 0.379 | Test Acc: 88.100\n",
      "\n",
      "Diff: 2.031960138992872e-05\n",
      "\n",
      "Round time: 1745.902722120285 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 49/Epoch 3) Train Loss: 0.208 | Train Acc: 93.200 | Test Loss: 0.363 | Test Acc: 88.450\n",
      "\n",
      "Diff: 0.0014024514239281416\n",
      "\n",
      "Round time: 1924.789852142334 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 32/Epoch 3) Train Loss: 0.274 | Train Acc: 89.960 | Test Loss: 0.358 | Test Acc: 88.570\n",
      "\n",
      "Diff: 0.0001915216853376478\n",
      "\n",
      "Round time: 2103.1979172229767 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 12/Epoch 3) Train Loss: 0.261 | Train Acc: 90.920 | Test Loss: 0.376 | Test Acc: 88.280\n",
      "\n",
      "Diff: 9.961040632333606e-05\n",
      "\n",
      "Round time: 2283.013152360916 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 2/Epoch 3) Train Loss: 0.190 | Train Acc: 93.7200 | Test Loss: 0.378 | Test Acc: 88.440\n",
      "\n",
      "Diff: 6.921531894477084e-05\n",
      "\n",
      "Round time: 2461.277685403824 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 42/Epoch 3) Train Loss: 0.404 | Train Acc: 86.580Attacking!\n",
      "\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.569 | Test Acc: 81.700\n",
      "\n",
      "Diff: 411.1285705566406\n",
      "\n",
      "Round time: 2639.307859182358 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 23/Epoch 3) Train Loss: 0.143 | Train Acc: 95.000 | Test Loss: 0.364 | Test Acc: 88.570\n",
      "\n",
      "Diff: 0.01019325852394104\n",
      "\n",
      "Round time: 2817.9722332954407 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 49/Epoch 3) Train Loss: 0.424 | Train Acc: 85.380 | Test Loss: 0.394 | Test Acc: 87.780\n",
      "\n",
      "Diff: 0.012016956694424152\n",
      "\n",
      "Round time: 3001.2249562740326 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 35/Epoch 3) Train Loss: 0.216 | Train Acc: 92.740 | Test Loss: 0.361 | Test Acc: 88.720\n",
      "\n",
      "Diff: 4.299101419746876e-05\n",
      "\n",
      "Round time: 3183.949806213379 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 13/Epoch 3) Train Loss: 0.281 | Train Acc: 90.020 | Test Loss: 0.354 | Test Acc: 89.130\n",
      "\n",
      "Diff: 0.0002179448347305879\n",
      "\n",
      "Round time: 3370.5046911239624 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 5/Epoch 3) Train Loss: 0.131 | Train Acc: 95.3400 | Test Loss: 0.348 | Test Acc: 89.280\n",
      "\n",
      "Diff: 0.00028175555053167045\n",
      "\n",
      "Round time: 3557.6465661525726 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 24/Epoch 3) Train Loss: 0.255 | Train Acc: 90.940 | Test Loss: 0.361 | Test Acc: 88.830\n",
      "\n",
      "Diff: 0.00160264503210783\n",
      "\n",
      "Round time: 3740.7970910072327 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 19/Epoch 3) Train Loss: 0.239 | Train Acc: 91.840 | Test Loss: 0.349 | Test Acc: 89.140\n",
      "\n",
      "Diff: 0.007501357700675726\n",
      "\n",
      "Round time: 3922.2070519924164 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 19/Epoch 3) Train Loss: 0.177 | Train Acc: 94.700 | Test Loss: 0.386 | Test Acc: 88.380\n",
      "\n",
      "Diff: 0.035732515156269073\n",
      "\n",
      "Round time: 4109.553030252457 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 39/Epoch 3) Train Loss: 0.226 | Train Acc: 92.220 | Test Loss: 0.398 | Test Acc: 88.050\n",
      "\n",
      "Diff: 0.003836588002741337\n",
      "\n",
      "Round time: 4295.968320131302 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 6/Epoch 3) Train Loss: 0.132 | Train Acc: 95.38000 | Test Loss: 0.378 | Test Acc: 88.970\n",
      "\n",
      "Diff: 0.06036344915628433\n",
      "\n",
      "Round time: 4487.158486127853 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 36/Epoch 3) Train Loss: 0.176 | Train Acc: 94.740 | Test Loss: 0.347 | Test Acc: 89.510\n",
      "\n",
      "Diff: 0.0031616499181836843\n",
      "\n",
      "Round time: 4674.330126047134 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 47/Epoch 3) Train Loss: 0.143 | Train Acc: 94.820 | Test Loss: 0.391 | Test Acc: 88.670\n",
      "\n",
      "Diff: 0.0014756062300875783\n",
      "\n",
      "Round time: 4860.598829030991 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 28/Epoch 3) Train Loss: 0.127 | Train Acc: 96.260 | Test Loss: 0.345 | Test Acc: 89.610\n",
      "\n",
      "Diff: 0.0018236682517454028\n",
      "\n",
      "Round time: 5046.52060008049 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 24/Epoch 3) Train Loss: 0.255 | Train Acc: 91.920 | Test Loss: 0.354 | Test Acc: 89.580\n",
      "\n",
      "Diff: 0.0036055194213986397\n",
      "\n",
      "Round time: 5232.379231214523 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 15/Epoch 3) Train Loss: 0.094 | Train Acc: 96.7800 | Test Loss: 0.340 | Test Acc: 90.020\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5418.352782011032 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 0/Epoch 3) Train Loss: 0.074 | Train Acc: 97.7200 | Test Loss: 0.338 | Test Acc: 90.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5604.615499019623 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 46/Epoch 3) Train Loss: 0.089 | Train Acc: 97.0200 | Test Loss: 0.336 | Test Acc: 90.310\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5792.045459270477 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 23/Epoch 3) Train Loss: 0.077 | Train Acc: 97.780 | Test Loss: 0.340 | Test Acc: 90.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5982.049333333969 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 39/Epoch 3) Train Loss: 0.062 | Train Acc: 98.2800 | Test Loss: 0.342 | Test Acc: 90.150\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6169.599514245987 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 6172.737816095352 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline = load_result(\"baseline.pickle\")\n",
    "sigmoid_against_noise_attack = run_federated_test(agg_fn = sigmoid_aggregation,                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = big_noise_attack, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"sigmoid_against_noise_attack_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c767d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n",
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 44/Epoch 3) Train Loss: 0.285 | Train Acc: 90.480Attacking!\n",
      "\n",
      "(Device 2/Epoch 24) Train Loss: 0.014 | Train Acc: 99.5660Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.963 | Test Acc: 85.330\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.411 | Test Acc: 86.850\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1250.4205939769745 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 15/Epoch 3) Train Loss: 0.311 | Train Acc: 89.640Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.255 | Test Acc: 78.250\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.404 | Test Acc: 86.880\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1435.8249740600586 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 39/Epoch 3) Train Loss: 0.269 | Train Acc: 90.700Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.810 | Test Acc: 78.590\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.395 | Test Acc: 87.440\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1619.1456139087677 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 26/Epoch 3) Train Loss: 0.269 | Train Acc: 90.600Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.669 | Test Acc: 82.810\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.433 | Test Acc: 86.750\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 1956.4879717826843 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 28/Epoch 3) Train Loss: 0.262 | Train Acc: 90.780Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.872 | Test Acc: 79.930\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.454 | Test Acc: 86.090\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2142.7575058937073 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 49/Epoch 3) Train Loss: 0.208 | Train Acc: 92.940Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.681 | Test Acc: 84.050\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.457 | Test Acc: 86.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2479.3429250717163 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 33/Epoch 3) Train Loss: 0.357 | Train Acc: 88.180Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.893 | Test Acc: 79.500\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.391 | Test Acc: 87.650\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2666.9391298294067 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 43/Epoch 3) Train Loss: 0.242 | Train Acc: 91.540Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.757 | Test Acc: 78.930\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.380 | Test Acc: 88.490\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 2851.377774000168 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 7/Epoch 3) Train Loss: 0.245 | Train Acc: 91.6000Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.944 | Test Acc: 79.410\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.366 | Test Acc: 88.960\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3037.1944308280945 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 39/Epoch 3) Train Loss: 0.277 | Train Acc: 90.760Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 2.009 | Test Acc: 79.570\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.359 | Test Acc: 88.940\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3224.3572149276733 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 29/Epoch 3) Train Loss: 0.188 | Train Acc: 93.160Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.961 | Test Acc: 79.520\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.374 | Test Acc: 88.880\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3419.0711059570312 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 36/Epoch 3) Train Loss: 0.257 | Train Acc: 91.040 | Test Loss: 0.355 | Test Acc: 89.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3606.8760719299316 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 4/Epoch 3) Train Loss: 0.280 | Train Acc: 90.54000 | Test Loss: 0.361 | Test Acc: 89.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3792.78076171875 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 29/Epoch 3) Train Loss: 0.178 | Train Acc: 93.660 | Test Loss: 0.357 | Test Acc: 89.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 3987.803965806961 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 44/Epoch 3) Train Loss: 0.172 | Train Acc: 94.860 | Test Loss: 0.370 | Test Acc: 89.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4351.923414945602 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 39/Epoch 3) Train Loss: 0.117 | Train Acc: 96.060 | Test Loss: 0.359 | Test Acc: 89.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4539.46182179451 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 9/Epoch 3) Train Loss: 0.147 | Train Acc: 95.0600 | Test Loss: 0.351 | Test Acc: 89.390\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4729.595947980881 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 31/Epoch 3) Train Loss: 0.133 | Train Acc: 96.1200 | Test Loss: 0.356 | Test Acc: 89.680\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 4929.9669868946075 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 10/Epoch 3) Train Loss: 0.194 | Train Acc: 93.400 | Test Loss: 0.366 | Test Acc: 89.050\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5118.179821968079 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 25/Epoch 3) Train Loss: 0.228 | Train Acc: 92.120 | Test Loss: 0.351 | Test Acc: 89.900\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5306.937247037888 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 17/Epoch 3) Train Loss: 0.160 | Train Acc: 95.120 | Test Loss: 0.366 | Test Acc: 89.460\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5502.8072509765625 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 7/Epoch 3) Train Loss: 0.115 | Train Acc: 95.8200 | Test Loss: 0.345 | Test Acc: 89.970\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 5692.020018815994 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 9/Epoch 3) Train Loss: 0.223 | Train Acc: 92.6000 | Test Loss: 0.361 | Test Acc: 89.340\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6040.297296762466 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 42/Epoch 3) Train Loss: 0.085 | Train Acc: 97.3400 | Test Loss: 0.382 | Test Acc: 89.360\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6230.666080951691 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 18/Epoch 3) Train Loss: 0.162 | Train Acc: 94.6400 | Test Loss: 0.349 | Test Acc: 89.790\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6418.991494894028 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 1/Epoch 3) Train Loss: 0.096 | Train Acc: 96.9400 | Test Loss: 0.347 | Test Acc: 90.320\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6606.251834869385 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 17/Epoch 3) Train Loss: 0.065 | Train Acc: 97.9600 | Test Loss: 0.349 | Test Acc: 90.280\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 6948.046301841736 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 19/Epoch 3) Train Loss: 0.073 | Train Acc: 97.740 | Test Loss: 0.353 | Test Acc: 90.230\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7138.234809875488 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 34/Epoch 3) Train Loss: 0.074 | Train Acc: 97.8000 | Test Loss: 0.355 | Test Acc: 90.170\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7327.037197113037 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 18/Epoch 3) Train Loss: 0.058 | Train Acc: 98.4400 | Test Loss: 0.357 | Test Acc: 90.190\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7516.31902384758 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 7520.757854938507 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sca_zero_one = switch_classes_attack(0,1,25)\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_no_defense = run_federated_test(                    \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca_zero_one, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_no_defense_multiple_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True, \n",
    "                                         multiple_attack_rounds = [100,101,102,103,104,105,106,107,108,109]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4e10c9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "swapping\n",
      "\n",
      "Files already downloaded and verified\n",
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "(Device 7/Epoch 3) Train Loss: 0.354 | Train Acc: 88.2400Attacking!\n",
      "\n",
      "(Device 2/Epoch 24) Train Loss: 0.019 | Train Acc: 99.3360Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.802 | Test Acc: 86.410\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.539 | Test Acc: 82.430\n",
      "\n",
      "Diff: 10.120282173156738\n",
      "\n",
      "Round time: 1260.700845003128 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  101\n",
      "(Device 10/Epoch 3) Train Loss: 0.304 | Train Acc: 90.080Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.646 | Test Acc: 84.470\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.394 | Test Acc: 88.150\n",
      "\n",
      "Diff: 1.0120688676834106\n",
      "\n",
      "Round time: 1605.5601961612701 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  102\n",
      "(Device 9/Epoch 3) Train Loss: 0.250 | Train Acc: 91.8800Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.160 | Test Acc: 79.510\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.369 | Test Acc: 88.710\n",
      "\n",
      "Diff: 0.000545351707842201\n",
      "\n",
      "Round time: 1804.8574283123016 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  103\n",
      "(Device 33/Epoch 3) Train Loss: 0.320 | Train Acc: 89.140Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.775 | Test Acc: 79.150\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.371 | Test Acc: 88.350\n",
      "\n",
      "Diff: 0.2273254096508026\n",
      "\n",
      "Round time: 1994.2636981010437 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  104\n",
      "(Device 34/Epoch 3) Train Loss: 0.249 | Train Acc: 91.060Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 2.010 | Test Acc: 78.710\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.361 | Test Acc: 88.480\n",
      "\n",
      "Diff: 0.0004312241217121482\n",
      "\n",
      "Round time: 2182.455514192581 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  105\n",
      "(Device 20/Epoch 3) Train Loss: 0.362 | Train Acc: 88.500Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.828 | Test Acc: 79.160\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.365 | Test Acc: 88.620\n",
      "\n",
      "Diff: 0.0171380452811718\n",
      "\n",
      "Round time: 2383.003970146179 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  106\n",
      "(Device 42/Epoch 3) Train Loss: 0.172 | Train Acc: 94.240Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.648 | Test Acc: 84.760\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.482 | Test Acc: 85.970\n",
      "\n",
      "Diff: 0.1966441571712494\n",
      "\n",
      "Round time: 2731.1573972702026 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  107\n",
      "(Device 32/Epoch 3) Train Loss: 0.162 | Train Acc: 94.440Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.760 | Test Acc: 80.810\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.394 | Test Acc: 88.290\n",
      "\n",
      "Diff: 0.011711034923791885\n",
      "\n",
      "Round time: 2932.9708671569824 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  108\n",
      "(Device 35/Epoch 3) Train Loss: 0.233 | Train Acc: 91.920Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.720 | Test Acc: 79.780\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.390 | Test Acc: 88.160\n",
      "\n",
      "Diff: 0.00041811345727182925\n",
      "\n",
      "Round time: 3125.602886199951 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  109\n",
      "(Device 20/Epoch 3) Train Loss: 0.157 | Train Acc: 94.680Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.893 | Test Acc: 79.880\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.377 | Test Acc: 88.420\n",
      "\n",
      "Diff: 0.09476998448371887\n",
      "\n",
      "Round time: 3326.7698023319244 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  110\n",
      "(Device 40/Epoch 3) Train Loss: 0.179 | Train Acc: 94.260Attacking!\n",
      "\n",
      "Using memoized attack\n",
      "\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 1.971 | Test Acc: 79.760\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.361 | Test Acc: 88.740\n",
      "\n",
      "Diff: 0.00030925663304515183\n",
      "\n",
      "Round time: 3524.3542079925537 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  111\n",
      "(Device 31/Epoch 3) Train Loss: 0.210 | Train Acc: 92.840 | Test Loss: 0.363 | Test Acc: 89.040\n",
      "\n",
      "Diff: 0.009649098850786686\n",
      "\n",
      "Round time: 3734.484055995941 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  112\n",
      "(Device 19/Epoch 3) Train Loss: 0.179 | Train Acc: 94.4800 | Test Loss: 0.354 | Test Acc: 89.220\n",
      "\n",
      "Diff: 0.015375320799648762\n",
      "\n",
      "Round time: 3962.994415998459 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  113\n",
      "(Device 10/Epoch 3) Train Loss: 0.140 | Train Acc: 95.120 | Test Loss: 0.355 | Test Acc: 89.300\n",
      "\n",
      "Diff: 0.0003145982918795198\n",
      "\n",
      "Round time: 4179.241348981857 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  114\n",
      "(Device 35/Epoch 3) Train Loss: 0.299 | Train Acc: 89.4000 | Test Loss: 0.371 | Test Acc: 89.040\n",
      "\n",
      "Diff: 0.03675477206707001\n",
      "\n",
      "Round time: 4586.433605194092 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  115\n",
      "(Device 8/Epoch 3) Train Loss: 0.184 | Train Acc: 93.54000 | Test Loss: 0.352 | Test Acc: 89.510\n",
      "\n",
      "Diff: 0.005422140937298536\n",
      "\n",
      "Round time: 4800.521832227707 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  116\n",
      "(Device 49/Epoch 3) Train Loss: 0.261 | Train Acc: 91.340 | Test Loss: 0.371 | Test Acc: 89.130\n",
      "\n",
      "Diff: 0.005069469567388296\n",
      "\n",
      "Round time: 5021.807204008102 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  117\n",
      "(Device 23/Epoch 3) Train Loss: 0.229 | Train Acc: 92.220 | Test Loss: 0.348 | Test Acc: 89.850\n",
      "\n",
      "Diff: 0.0009505321504548192\n",
      "\n",
      "Round time: 5247.358416080475 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  118\n",
      "(Device 14/Epoch 3) Train Loss: 0.201 | Train Acc: 93.520 | Test Loss: 0.350 | Test Acc: 89.540\n",
      "\n",
      "Diff: 0.008713014423847198\n",
      "\n",
      "Round time: 5470.169590950012 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  119\n",
      "(Device 11/Epoch 3) Train Loss: 0.199 | Train Acc: 92.940 | Test Loss: 0.350 | Test Acc: 89.640\n",
      "\n",
      "Diff: 0.036510057747364044\n",
      "\n",
      "Round time: 5865.939716100693 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  120\n",
      "(Device 29/Epoch 3) Train Loss: 0.274 | Train Acc: 90.9800 | Test Loss: 0.355 | Test Acc: 89.910\n",
      "\n",
      "Diff: 0.2861802577972412\n",
      "\n",
      "Round time: 6092.064857006073 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  121\n",
      "(Device 38/Epoch 3) Train Loss: 0.092 | Train Acc: 97.2200 | Test Loss: 0.352 | Test Acc: 90.010\n",
      "\n",
      "Diff: 0.0017421803204342723\n",
      "\n",
      "Round time: 6312.076562166214 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  122\n",
      "(Device 13/Epoch 3) Train Loss: 0.093 | Train Acc: 97.3600 | Test Loss: 0.363 | Test Acc: 89.570\n",
      "\n",
      "Diff: 0.03876407817006111\n",
      "\n",
      "Round time: 6530.912013053894 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  123\n",
      "(Device 23/Epoch 3) Train Loss: 0.179 | Train Acc: 94.280 | Test Loss: 0.350 | Test Acc: 90.160\n",
      "\n",
      "Diff: 0.03298230469226837\n",
      "\n",
      "Round time: 6758.608757972717 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  124\n",
      "(Device 29/Epoch 3) Train Loss: 0.077 | Train Acc: 97.380 | Test Loss: 0.363 | Test Acc: 89.800\n",
      "\n",
      "Diff: 0.05205897241830826\n",
      "\n",
      "Round time: 6983.1133069992065 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  125\n",
      "(Device 43/Epoch 3) Train Loss: 0.066 | Train Acc: 98.120 | Test Loss: 0.343 | Test Acc: 90.330\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7208.319562196732 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  126\n",
      "(Device 42/Epoch 3) Train Loss: 0.066 | Train Acc: 97.8400 | Test Loss: 0.342 | Test Acc: 90.470\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7426.290471076965 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  127\n",
      "(Device 20/Epoch 3) Train Loss: 0.060 | Train Acc: 98.3000 | Test Loss: 0.343 | Test Acc: 90.310\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 7622.184158086777 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  128\n",
      "(Device 13/Epoch 3) Train Loss: 0.066 | Train Acc: 98.120 | Test Loss: 0.346 | Test Acc: 90.440\n",
      "\n",
      "Diff: 1.1847208014614807e-07\n",
      "\n",
      "Round time: 7976.075016260147 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Round:  129\n",
      "(Device 38/Epoch 3) Train Loss: 0.096 | Train Acc: 97.8200 | Test Loss: 0.349 | Test Acc: 90.470\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 8180.8768701553345 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 8186.628128051758 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sca_zero_one_2 = switch_classes_attack(0,1,25)\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_sigmoid_defense = run_federated_test(  agg_fn = sigmoid_aggregation, \n",
    "                                         rounds = 130, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 4,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca_zero_one_2, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_sigmoid_defense_multiple_final.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True, \n",
    "                                         multiple_attack_rounds = [100,101,102,103,104,105,106,107,108,109]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6bd63178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('model.0.0.weight',\n",
       "              tensor([[[[ 7.4600e-01,  8.4820e-01,  4.7823e-01],\n",
       "                        [ 5.1573e-01,  1.0049e+00,  1.2566e+00],\n",
       "                        [-5.9251e-01, -3.1604e-01, -1.8427e-01]],\n",
       "              \n",
       "                       [[-5.3358e-01, -8.8284e-01, -5.9071e-01],\n",
       "                        [-1.0610e+00, -8.9894e-01,  4.1919e-01],\n",
       "                        [-1.0492e+00, -1.1256e+00, -3.9162e-01]],\n",
       "              \n",
       "                       [[ 1.2420e-01, -1.3487e-01,  8.3084e-04],\n",
       "                        [-1.8890e-01,  3.6324e-01,  1.1430e+00],\n",
       "                        [ 1.9642e-01,  6.0267e-01,  1.1399e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.9969e-01,  3.3645e-01,  3.9868e-01],\n",
       "                        [-1.1443e+00, -3.7165e-01,  1.0054e+00],\n",
       "                        [-9.7183e-02, -2.2539e-02,  3.8900e-01]],\n",
       "              \n",
       "                       [[-4.9338e-01, -3.5729e-01,  2.5315e-01],\n",
       "                        [-1.0529e+00, -6.9401e-01,  9.6998e-01],\n",
       "                        [-1.2148e-01,  2.0725e-01,  6.5304e-01]],\n",
       "              \n",
       "                       [[-2.0915e-01, -1.8893e-01,  2.2833e-01],\n",
       "                        [-9.4088e-01, -3.4339e-01,  8.9907e-01],\n",
       "                        [-2.1204e-03,  3.0896e-01,  4.9953e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1321e-01,  5.4262e-02,  1.8721e-01],\n",
       "                        [ 7.7245e-01, -4.2362e-01, -9.7571e-01],\n",
       "                        [ 5.8087e-01,  2.3426e-01, -4.4087e-01]],\n",
       "              \n",
       "                       [[ 4.8934e-01, -5.9026e-02,  1.6839e-03],\n",
       "                        [ 6.8533e-01, -4.8358e-01, -1.3530e+00],\n",
       "                        [ 5.4588e-01,  3.4553e-01, -5.9782e-01]],\n",
       "              \n",
       "                       [[ 8.5630e-02,  2.2176e-01,  5.3444e-01],\n",
       "                        [ 3.4456e-01, -4.1069e-01, -6.1995e-01],\n",
       "                        [ 2.2876e-01,  1.3409e-01, -5.0664e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.2215e-01, -6.2452e-01, -4.0303e-01],\n",
       "                        [-6.1050e-01, -7.5069e-01, -7.8922e-01],\n",
       "                        [-5.7783e-01, -9.8292e-01, -8.4384e-01]],\n",
       "              \n",
       "                       [[-1.5789e-01,  1.2242e-01, -2.9747e-01],\n",
       "                        [ 3.8840e-01,  6.6292e-01,  3.0778e-01],\n",
       "                        [ 6.8307e-02,  1.0262e-01,  2.9979e-02]],\n",
       "              \n",
       "                       [[ 1.3978e-01,  5.4648e-01,  5.9003e-02],\n",
       "                        [ 5.8368e-01,  1.4628e+00,  8.6412e-01],\n",
       "                        [ 3.7575e-01,  8.5173e-01,  4.0163e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3140e-01,  6.5279e-01, -4.1369e-01],\n",
       "                        [-6.2593e-01, -1.2069e+00,  7.2996e-02],\n",
       "                        [ 3.0293e-01,  3.2063e-01,  8.2402e-01]],\n",
       "              \n",
       "                       [[ 8.4682e-01,  1.0004e+00,  1.0241e-01],\n",
       "                        [-8.5225e-01, -1.4023e+00,  4.8998e-02],\n",
       "                        [ 4.3616e-02, -3.0539e-01,  7.6269e-01]],\n",
       "              \n",
       "                       [[ 6.5153e-01,  6.1098e-01,  3.9530e-02],\n",
       "                        [-3.9860e-01, -1.0256e+00, -1.0201e-01],\n",
       "                        [-3.6981e-02, -5.1075e-01,  3.8620e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.8512e-01,  5.6056e-01,  1.9931e-01],\n",
       "                        [-7.1396e-01, -7.4205e-01,  7.5849e-02],\n",
       "                        [ 3.0334e-01,  8.7610e-02,  1.6386e-01]],\n",
       "              \n",
       "                       [[ 3.0663e-01,  8.5636e-01,  5.9673e-01],\n",
       "                        [-8.3291e-01, -7.5372e-01, -3.6590e-01],\n",
       "                        [ 5.2356e-03, -2.3271e-02, -1.1739e-01]],\n",
       "              \n",
       "                       [[ 7.4793e-01,  8.3830e-01,  2.3682e-01],\n",
       "                        [-4.7219e-01, -4.7703e-01, -1.9997e-01],\n",
       "                        [ 9.9404e-02, -3.7972e-01, -4.1654e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4389e-01, -1.6766e-01, -1.9358e-01],\n",
       "                        [-6.5485e-01, -5.7184e-01, -7.9434e-01],\n",
       "                        [-6.7295e-01, -5.9633e-01, -5.9251e-01]],\n",
       "              \n",
       "                       [[-1.0399e-01,  4.6378e-01,  1.6142e-02],\n",
       "                        [-1.9374e-01, -8.2373e-02, -1.3812e-01],\n",
       "                        [-2.2333e-01, -2.1542e-01, -2.5140e-01]],\n",
       "              \n",
       "                       [[ 5.3864e-01,  1.1065e+00,  7.2999e-01],\n",
       "                        [ 5.7934e-01,  1.0594e+00,  6.2575e-01],\n",
       "                        [-3.3914e-02,  4.3139e-01,  3.0039e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.5557e-01,  7.7835e-01, -1.7814e-01],\n",
       "                        [ 1.9155e-01,  4.1013e-01,  3.6364e-01],\n",
       "                        [ 2.6347e-02, -2.8235e-02,  2.2341e-01]],\n",
       "              \n",
       "                       [[-5.0296e-01, -3.9266e-01, -1.8949e-01],\n",
       "                        [-8.2804e-01, -6.1499e-01,  1.1121e-02],\n",
       "                        [-3.1366e-01, -1.7471e-01,  5.4434e-01]],\n",
       "              \n",
       "                       [[-4.5348e-01, -2.3656e-01, -4.0574e-01],\n",
       "                        [-6.1831e-01, -4.2694e-01, -3.8332e-02],\n",
       "                        [-2.6471e-01,  1.9310e-01,  3.0584e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8455e-01,  1.2126e+00,  8.0503e-01],\n",
       "                        [ 1.4647e+00, -1.2733e+00,  1.1694e-01],\n",
       "                        [-1.1123e+00, -1.0796e+00,  9.6822e-01]],\n",
       "              \n",
       "                       [[-8.3310e-01, -1.0898e-01,  6.5875e-02],\n",
       "                        [ 1.4889e+00, -2.1803e+00, -2.3472e-01],\n",
       "                        [-5.5331e-02, -3.7314e-01,  1.6295e+00]],\n",
       "              \n",
       "                       [[-3.3531e-01,  5.5317e-01, -4.9394e-01],\n",
       "                        [ 1.5348e+00, -1.1421e+00, -8.6518e-01],\n",
       "                        [ 6.2617e-01, -5.4433e-02,  4.6411e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.4604e-01,  1.2608e+00,  1.0239e+00],\n",
       "                        [ 6.0905e-02,  2.5489e-01,  1.5757e-01],\n",
       "                        [-7.9464e-01, -9.7786e-01, -9.5878e-01]],\n",
       "              \n",
       "                       [[ 5.0220e-01,  4.0124e-01,  4.4711e-01],\n",
       "                        [ 4.7901e-03, -1.1536e-01, -5.1425e-02],\n",
       "                        [-2.7524e-01, -7.8621e-01, -5.0263e-01]],\n",
       "              \n",
       "                       [[ 3.3087e-01,  1.4517e-01, -7.0901e-02],\n",
       "                        [-4.0793e-02,  2.4547e-01,  1.8638e-02],\n",
       "                        [-1.9316e-01, -1.1762e-01, -4.6944e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.1189e-01, -1.3706e-01,  1.5707e-01],\n",
       "                        [-2.3585e-03, -1.0508e+00, -5.0788e-01],\n",
       "                        [ 3.5409e-01,  8.6983e-02, -7.2599e-02]],\n",
       "              \n",
       "                       [[ 3.8382e-01, -9.1621e-02,  1.8528e-01],\n",
       "                        [ 1.1166e-01, -6.7314e-01, -2.4659e-01],\n",
       "                        [ 1.8720e-01,  2.8836e-01,  2.8809e-01]],\n",
       "              \n",
       "                       [[ 1.1892e-01, -1.9946e-01,  2.2136e-01],\n",
       "                        [-5.0872e-01, -8.2646e-01, -4.7349e-01],\n",
       "                        [-2.0345e-01, -3.7981e-01, -4.1044e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.0992e+00, -3.6817e-03,  1.0181e+00],\n",
       "                        [-3.5721e-01,  3.9177e-02,  1.1431e-01],\n",
       "                        [ 1.0578e+00,  6.4090e-02, -8.5409e-01]],\n",
       "              \n",
       "                       [[-1.0481e+00, -1.6901e-01,  1.0465e+00],\n",
       "                        [-1.7580e-01,  2.1051e-01,  1.4377e-01],\n",
       "                        [ 9.2165e-01, -3.2907e-01, -8.3878e-01]],\n",
       "              \n",
       "                       [[-7.5452e-01,  3.0559e-01,  6.2661e-01],\n",
       "                        [-2.5981e-01,  3.1321e-01,  2.6233e-01],\n",
       "                        [ 7.7262e-01, -2.7381e-01, -8.9623e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2306e-01, -9.2307e-01,  4.5236e-01],\n",
       "                        [-3.3498e-01, -1.0396e+00, -2.1117e-01],\n",
       "                        [ 8.3307e-01,  8.2997e-01,  9.0825e-01]],\n",
       "              \n",
       "                       [[-4.3742e-01, -6.6041e-01,  1.1552e-01],\n",
       "                        [-1.5698e-01, -8.8968e-01, -1.3198e-01],\n",
       "                        [ 9.4637e-01,  7.2481e-01,  7.0995e-01]],\n",
       "              \n",
       "                       [[ 1.1793e-02, -5.7150e-01,  3.5219e-01],\n",
       "                        [ 2.2607e-02, -9.5980e-01, -2.1904e-01],\n",
       "                        [ 6.5610e-01,  3.8355e-01,  2.2455e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.2842e-01, -1.3555e-01, -2.0949e-01],\n",
       "                        [-1.2356e-01,  4.2564e-01,  4.5131e-01],\n",
       "                        [ 7.0156e-01,  1.1215e+00,  7.0723e-01]],\n",
       "              \n",
       "                       [[-4.6227e-01, -2.9525e-01, -6.7845e-01],\n",
       "                        [-9.5757e-01, -8.7562e-01, -1.0047e+00],\n",
       "                        [-4.4320e-01, -5.2527e-01, -7.1877e-01]],\n",
       "              \n",
       "                       [[ 8.4654e-01,  8.8862e-01,  7.5659e-01],\n",
       "                        [ 1.1400e-01,  2.7547e-01,  2.3232e-01],\n",
       "                        [-1.9108e-01,  5.0945e-02, -1.6371e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5764e-01,  7.8496e-02,  7.0316e-02],\n",
       "                        [-9.8618e-03,  3.5874e-01,  1.4442e-01],\n",
       "                        [ 9.6966e-02,  1.8458e-01,  9.3510e-03]],\n",
       "              \n",
       "                       [[-1.9471e-01,  2.5681e-01, -1.8786e-01],\n",
       "                        [ 1.4716e-01,  9.6748e-02, -8.6126e-02],\n",
       "                        [ 3.5148e-02,  3.1066e-01, -6.5107e-02]],\n",
       "              \n",
       "                       [[ 2.5573e-01,  4.7144e-01,  1.9082e-01],\n",
       "                        [ 3.6060e-01,  5.8935e-01,  8.1626e-02],\n",
       "                        [-1.7770e-02,  1.2095e-01, -9.5245e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.0492e-01, -7.9451e-01, -2.0177e-01],\n",
       "                        [ 2.9974e-01,  9.3592e-01,  5.7752e-01],\n",
       "                        [ 4.5517e-01,  5.7255e-01,  1.0055e-01]],\n",
       "              \n",
       "                       [[-3.9410e-01, -9.5116e-01, -4.0499e-01],\n",
       "                        [-7.1705e-02,  4.2422e-01,  2.7775e-01],\n",
       "                        [-1.3216e-01, -2.8865e-01, -3.6781e-01]],\n",
       "              \n",
       "                       [[-9.0501e-02, -2.5837e-01,  1.6859e-01],\n",
       "                        [ 2.0695e-01,  7.0540e-01,  3.1135e-01],\n",
       "                        [-3.1081e-02,  5.2900e-02, -1.8616e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.1950e-01, -4.1508e-01, -2.8218e-01],\n",
       "                        [-1.4278e-02, -1.2342e-01, -7.2811e-02],\n",
       "                        [-2.5550e-01,  2.3747e-02,  4.0854e-02]],\n",
       "              \n",
       "                       [[-2.0806e-01,  1.3843e-02, -3.3811e-01],\n",
       "                        [ 2.6848e-03,  2.5554e-01, -8.4292e-02],\n",
       "                        [-5.0058e-01, -4.9409e-01, -4.0431e-01]],\n",
       "              \n",
       "                       [[ 2.5918e-01,  5.0689e-01,  2.3340e-01],\n",
       "                        [ 2.8925e-01,  6.9060e-01,  2.6207e-01],\n",
       "                        [-1.8518e-01, -7.2043e-02, -2.1737e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.2315e-01, -9.4369e-01, -7.2165e-01],\n",
       "                        [-5.0508e-02,  9.0636e-02, -1.1688e-01],\n",
       "                        [ 4.9442e-01,  6.7985e-01,  6.4325e-01]],\n",
       "              \n",
       "                       [[-3.7517e-01, -5.2720e-01, -4.6969e-01],\n",
       "                        [ 4.9999e-01,  3.3864e-01,  3.6457e-01],\n",
       "                        [ 1.5075e-01,  8.9029e-01,  7.5332e-01]],\n",
       "              \n",
       "                       [[-1.0619e-01, -9.4547e-01, -5.8482e-01],\n",
       "                        [ 7.8396e-02,  3.2259e-03,  1.5844e-02],\n",
       "                        [ 2.9331e-01,  1.3868e-01,  3.6770e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.6490e-01, -2.8646e-01,  3.7080e-02],\n",
       "                        [-4.6360e-01, -8.8054e-01, -2.2498e-01],\n",
       "                        [ 1.1127e-01, -6.8173e-02,  3.6203e-01]],\n",
       "              \n",
       "                       [[ 2.8686e-01, -1.3965e-02,  2.5676e-01],\n",
       "                        [-2.0552e-01, -4.3999e-01, -2.6020e-01],\n",
       "                        [ 1.2199e-01,  5.1533e-02,  2.1905e-01]],\n",
       "              \n",
       "                       [[ 2.5427e-01, -2.5339e-01,  1.3233e-01],\n",
       "                        [-4.4425e-01, -7.9445e-01, -2.3966e-01],\n",
       "                        [ 5.9852e-02, -1.1686e-01, -8.3175e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1581e+00,  1.5876e+00,  1.2343e+00],\n",
       "                        [ 1.4999e-01,  2.3932e-02,  9.7031e-02],\n",
       "                        [-1.0668e+00, -1.6777e+00, -1.2232e+00]],\n",
       "              \n",
       "                       [[-2.6281e-01, -3.1214e-01, -4.1979e-01],\n",
       "                        [-6.6602e-02, -2.8669e-01, -2.1713e-02],\n",
       "                        [ 4.5412e-01,  1.3624e-01,  5.0685e-01]],\n",
       "              \n",
       "                       [[-1.0695e+00, -1.3316e+00, -1.2191e+00],\n",
       "                        [-3.3425e-01,  2.9614e-01,  2.0976e-02],\n",
       "                        [ 1.0264e+00,  1.4344e+00,  9.6358e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1699e-01, -8.9804e-02, -4.8738e-01],\n",
       "                        [-1.0412e+00,  2.2035e-01, -2.7585e-02],\n",
       "                        [-1.8318e-01,  4.6138e-02,  1.6011e-01]],\n",
       "              \n",
       "                       [[ 4.5050e-02,  8.1832e-01,  4.8944e-01],\n",
       "                        [-6.2886e-01,  1.2733e+00,  1.1358e+00],\n",
       "                        [-9.8908e-02,  3.2021e-01,  3.9740e-01]],\n",
       "              \n",
       "                       [[-3.2753e-01,  2.7570e-01, -3.1633e-01],\n",
       "                        [-8.7083e-01,  3.8136e-01, -1.0155e-01],\n",
       "                        [-4.9953e-01, -1.0893e-01,  2.0734e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8644e-02, -3.2624e-01, -2.2315e-01],\n",
       "                        [ 3.7384e-01,  3.1365e-01,  2.7697e-01],\n",
       "                        [ 2.1826e-01,  2.5302e-01,  2.2848e-01]],\n",
       "              \n",
       "                       [[-2.3903e-01, -2.9286e-01, -3.7492e-01],\n",
       "                        [ 2.2696e-01,  3.0064e-01,  4.3780e-02],\n",
       "                        [ 1.6319e-01,  9.1570e-02, -4.1368e-02]],\n",
       "              \n",
       "                       [[-5.3434e-02, -5.6940e-02, -3.6186e-01],\n",
       "                        [ 4.6369e-01,  3.0135e-01, -1.4473e-01],\n",
       "                        [ 3.5113e-01,  1.4846e-01, -1.3136e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0714e-01, -7.0433e-01, -5.0340e-01],\n",
       "                        [ 7.2643e-02,  5.7143e-02,  3.3262e-02],\n",
       "                        [ 5.6978e-01,  7.9702e-01,  6.5755e-01]],\n",
       "              \n",
       "                       [[ 5.5029e-03, -2.8522e-01, -2.0949e-01],\n",
       "                        [-1.4425e-01,  2.7532e-01,  2.0440e-01],\n",
       "                        [ 1.8113e-01,  3.5645e-01,  1.7561e-01]],\n",
       "              \n",
       "                       [[ 9.9449e-01,  1.0417e+00,  5.4901e-01],\n",
       "                        [ 3.8781e-02, -1.3406e-01, -2.5410e-01],\n",
       "                        [-5.8594e-01, -1.1834e+00, -1.1219e+00]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.7754e-02, -2.0948e-01,  1.2229e-01],\n",
       "                        [ 3.5918e-01,  2.3606e-01,  8.2641e-01],\n",
       "                        [ 1.8891e-01, -3.9553e-01,  2.4130e-01]],\n",
       "              \n",
       "                       [[ 3.8047e-01, -3.5316e-02,  4.0284e-02],\n",
       "                        [ 2.7422e-01, -4.9840e-01, -7.2813e-02],\n",
       "                        [-4.5077e-01, -1.0116e+00, -5.7418e-01]],\n",
       "              \n",
       "                       [[ 4.2405e-01,  4.4689e-01,  5.1046e-01],\n",
       "                        [ 6.5073e-01,  1.3184e-01,  2.2423e-01],\n",
       "                        [-2.9629e-01, -9.2983e-01, -3.9708e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7836e-02, -7.5087e-01,  1.3452e+00],\n",
       "                        [-6.2575e-01,  2.6040e+00, -1.3689e+00],\n",
       "                        [-1.2604e+00,  5.9851e-02,  1.0685e-01]],\n",
       "              \n",
       "                       [[ 4.4690e-02, -5.2580e-01,  1.4804e-01],\n",
       "                        [-2.8576e-01,  2.5846e+00, -2.2666e+00],\n",
       "                        [-4.4783e-01,  5.1641e-01, -3.2163e-02]],\n",
       "              \n",
       "                       [[ 3.0412e-01, -8.0242e-01,  4.2518e-01],\n",
       "                        [-4.9551e-01,  1.5338e+00, -1.7846e+00],\n",
       "                        [ 1.7764e-01,  4.2812e-01,  3.4481e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.6875e-02,  5.1701e-01, -4.1698e-01],\n",
       "                        [-1.0267e+00,  7.3840e-01,  8.0301e-01],\n",
       "                        [-6.2991e-01,  7.0737e-02, -2.1441e-01]],\n",
       "              \n",
       "                       [[-5.2782e-01, -7.1171e-03,  1.7121e-02],\n",
       "                        [-1.5023e+00,  5.9908e-01,  1.2550e+00],\n",
       "                        [-6.6325e-01,  3.4872e-01,  3.2508e-01]],\n",
       "              \n",
       "                       [[-3.8546e-01,  8.9735e-02, -4.4784e-02],\n",
       "                        [-1.3276e+00,  7.2525e-01,  9.7362e-01],\n",
       "                        [-6.6382e-01,  5.0661e-01,  2.8737e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.0297e-01, -4.4385e-01, -3.7963e-01],\n",
       "                        [ 5.0906e-02, -2.2639e-01, -5.6638e-02],\n",
       "                        [-8.5377e-01, -1.6898e+00, -6.8952e-01]],\n",
       "              \n",
       "                       [[ 7.9777e-01,  1.0436e+00,  5.7461e-01],\n",
       "                        [ 1.6498e+00,  1.7265e+00,  1.4330e+00],\n",
       "                        [ 7.9440e-01,  8.3967e-02,  5.4361e-01]],\n",
       "              \n",
       "                       [[-7.7544e-01, -1.0937e+00, -8.4160e-01],\n",
       "                        [ 5.5908e-02, -6.1526e-01, -1.2425e-01],\n",
       "                        [-1.9594e-01, -8.8816e-01,  6.3752e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5261e-01,  2.7538e-01, -2.0202e-01],\n",
       "                        [ 1.0844e+00,  2.6398e-01, -1.1756e+00],\n",
       "                        [ 1.3704e-01, -1.7433e-01, -2.9942e-01]],\n",
       "              \n",
       "                       [[ 7.7017e-01, -1.3015e-01, -1.2435e+00],\n",
       "                        [ 1.4542e+00, -1.1615e-01, -1.6577e+00],\n",
       "                        [ 4.1894e-01,  3.4633e-03, -5.3822e-01]],\n",
       "              \n",
       "                       [[ 4.9902e-01, -1.3109e-01, -8.7425e-01],\n",
       "                        [ 1.4743e+00,  3.6337e-01, -1.2042e+00],\n",
       "                        [ 8.6177e-01,  1.4009e-02, -4.8786e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.1483e+00,  1.4821e+00,  7.9972e-01],\n",
       "                        [ 8.8295e-01, -1.0935e+00,  8.8492e-01],\n",
       "                        [-3.6108e-01, -1.7023e+00, -1.5850e+00]],\n",
       "              \n",
       "                       [[-4.0459e-01, -2.9197e-01, -4.1407e-01],\n",
       "                        [-3.1370e-03, -1.6041e+00,  1.1043e+00],\n",
       "                        [ 5.1098e-01, -1.2983e-01,  5.8607e-01]],\n",
       "              \n",
       "                       [[-7.6655e-01, -5.9248e-01, -1.0845e+00],\n",
       "                        [ 4.7828e-02, -8.3389e-01,  6.7056e-01],\n",
       "                        [ 1.0259e+00,  9.6670e-01,  7.5338e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.7627e-02, -9.3956e-01, -6.5185e-01],\n",
       "                        [ 4.4882e-01,  9.8119e-01,  5.2181e-01],\n",
       "                        [-4.9687e-02,  2.4900e-01,  9.4613e-02]],\n",
       "              \n",
       "                       [[-3.7113e-01, -7.7517e-01, -6.7337e-01],\n",
       "                        [ 2.0036e-01,  9.5474e-01,  3.9141e-01],\n",
       "                        [-3.6652e-01,  4.6237e-02, -3.3025e-01]],\n",
       "              \n",
       "                       [[-2.4663e-02, -5.6934e-01, -3.3191e-01],\n",
       "                        [ 1.7403e-01,  9.3419e-01,  5.2080e-01],\n",
       "                        [-1.9306e-01,  7.5581e-02, -1.6303e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.4526e-01, -4.7319e-01, -5.8144e-02],\n",
       "                        [ 5.2575e-01,  2.0558e-01, -7.9737e-01],\n",
       "                        [ 6.0704e-01,  3.6191e-01, -3.0978e-01]],\n",
       "              \n",
       "                       [[-1.0660e-01, -1.8084e-01,  1.4867e-01],\n",
       "                        [ 8.7418e-01,  4.1051e-01, -5.4904e-01],\n",
       "                        [ 3.5131e-01,  4.0586e-02, -5.6816e-01]],\n",
       "              \n",
       "                       [[ 5.2015e-03, -1.3211e-03, -1.5475e-01],\n",
       "                        [ 9.4173e-01,  2.8285e-01, -6.4030e-01],\n",
       "                        [ 4.9779e-01, -2.2143e-01, -7.4964e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.3121e-01, -7.5906e-01, -4.7272e-01],\n",
       "                        [-3.3155e-01, -5.1259e-01, -1.3841e-01],\n",
       "                        [-2.5138e-01, -9.3561e-02,  8.6543e-02]],\n",
       "              \n",
       "                       [[-6.1921e-01, -7.8019e-01, -4.7794e-01],\n",
       "                        [ 1.3205e-01, -1.3983e-01,  7.7905e-02],\n",
       "                        [ 3.3254e-01,  1.7180e-01,  1.6117e-01]],\n",
       "              \n",
       "                       [[-3.0669e-01, -5.3661e-01, -4.6193e-01],\n",
       "                        [ 4.1804e-01,  5.2455e-01,  4.3928e-01],\n",
       "                        [ 6.3286e-01,  5.7358e-01,  4.0605e-01]]]], device='mps:0')),\n",
       "             ('model.0.1.weight',\n",
       "              tensor([1.0030, 1.2417, 1.1108, 0.7086, 1.4484, 1.0021, 0.7617, 0.9483, 2.0205,\n",
       "                      1.0026, 1.6280, 1.0919, 1.1475, 0.7983, 1.0918, 0.7695, 0.9342, 0.9284,\n",
       "                      1.6964, 1.3543, 0.8664, 0.4545, 1.1657, 0.8296, 2.8554, 1.4328, 1.1043,\n",
       "                      1.4243, 1.5086, 1.2256, 0.8222, 1.2479], device='mps:0')),\n",
       "             ('model.0.1.bias',\n",
       "              tensor([ 0.4378,  0.3951,  0.3621,  0.4648,  0.6802,  0.6909, -0.0453, -0.1896,\n",
       "                       1.9524,  0.5220, -0.6369,  0.4615,  0.5035,  0.1235, -0.6217,  0.3958,\n",
       "                      -0.6410,  0.4458, -1.2411, -0.4490,  0.5662,  0.2558, -0.6704,  0.0869,\n",
       "                       2.5992,  0.5860,  0.2017,  0.6434,  1.4005,  0.5692,  0.4218, -0.2638],\n",
       "                     device='mps:0')),\n",
       "             ('model.0.1.running_mean',\n",
       "              tensor([-0.1925,  0.1269,  0.1261, -0.1591,  0.2431,  0.1259,  0.0644,  0.5090,\n",
       "                       0.1148, -0.1223,  0.9110,  0.0363,  0.1858,  0.3026, -0.8746, -0.2723,\n",
       "                       0.3888, -0.1681,  0.8223,  0.0382, -0.1881, -0.4679, -0.0647, -0.0038,\n",
       "                      -0.1742, -0.1371, -0.0841, -0.0358,  0.1297, -0.2176, -0.0398,  0.6656],\n",
       "                     device='mps:0')),\n",
       "             ('model.0.1.running_var',\n",
       "              tensor([12.2908, 21.1225, 15.0946, 18.5407, 10.2946, 11.1816, 16.6319, 10.5193,\n",
       "                       6.9239, 24.3742, 17.8641,  4.8731, 22.7847,  4.5885, 14.5112,  7.1435,\n",
       "                       4.8605, 22.8186, 13.8453,  2.8103, 10.1067,  7.4839,  1.3455,  9.2337,\n",
       "                       9.1040, 23.1241, 11.0842, 46.6388,  5.3780, 10.1471, 11.1330, 20.9485],\n",
       "                     device='mps:0')),\n",
       "             ('model.0.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.1.0.weight',\n",
       "              tensor([[[[-2.0450e-01, -2.3559e-01, -1.6379e-01],\n",
       "                        [-2.3276e-01, -2.4086e-01, -2.4306e-01],\n",
       "                        [-9.4205e-02, -8.1977e-02, -2.6264e-02]],\n",
       "              \n",
       "                       [[-8.4158e-02,  4.9218e-02,  1.4698e-01],\n",
       "                        [-1.6226e-01, -3.4957e-02,  5.6308e-02],\n",
       "                        [-3.4209e-01, -2.1271e-01, -7.5631e-02]],\n",
       "              \n",
       "                       [[ 5.9199e-02, -1.3700e-02, -3.3085e-02],\n",
       "                        [ 2.5260e-02, -6.1533e-02, -4.0967e-02],\n",
       "                        [-5.4628e-02, -2.2659e-01, -1.9803e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3319e-01, -8.3192e-02, -1.4808e-01],\n",
       "                        [-2.0992e-02, -1.0417e-01, -8.4455e-02],\n",
       "                        [-2.8770e-02, -1.0738e-01, -9.2791e-02]],\n",
       "              \n",
       "                       [[-5.6517e-02, -8.5416e-02, -9.4544e-02],\n",
       "                        [ 5.2510e-02, -8.7249e-04,  2.9981e-02],\n",
       "                        [ 7.4321e-02,  3.7569e-02, -8.6443e-02]],\n",
       "              \n",
       "                       [[ 1.2159e-01,  9.9381e-02,  6.2586e-02],\n",
       "                        [ 2.9087e-01,  4.0082e-01,  3.3885e-01],\n",
       "                        [ 2.1024e-01,  3.1226e-01,  2.0942e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.7163e-02,  8.4086e-02,  9.8936e-03],\n",
       "                        [-2.8634e-01, -6.9121e-02,  3.9750e-02],\n",
       "                        [ 1.8067e-01,  6.6750e-02, -1.2808e-01]],\n",
       "              \n",
       "                       [[-7.3003e-02, -4.6267e-02, -7.5809e-02],\n",
       "                        [-2.8704e-01, -2.5646e-03,  1.8111e-01],\n",
       "                        [-1.3710e-01, -3.4417e-03,  2.3700e-02]],\n",
       "              \n",
       "                       [[ 7.2436e-03, -5.5749e-02, -5.1142e-02],\n",
       "                        [ 1.6388e-01, -9.9758e-03, -2.7778e-01],\n",
       "                        [-5.1662e-03,  1.9875e-01,  6.9679e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-6.4422e-03,  1.1803e-01, -1.5709e-01],\n",
       "                        [-3.0361e-01, -3.8535e-01, -2.0324e-01],\n",
       "                        [ 3.2971e-01,  5.8092e-01,  1.0326e-01]],\n",
       "              \n",
       "                       [[-9.8443e-02,  1.5720e-01,  7.9685e-02],\n",
       "                        [ 9.2909e-02, -1.2188e-01, -2.8326e-01],\n",
       "                        [-1.5366e-01,  1.3486e-01,  2.7730e-01]],\n",
       "              \n",
       "                       [[ 2.7207e-02,  1.5755e-01,  1.4364e-02],\n",
       "                        [-1.9243e-01, -8.5793e-02, -1.1409e-01],\n",
       "                        [-1.6731e-01,  3.4023e-02, -1.7437e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.7813e-01, -6.9504e-01, -4.2501e-01],\n",
       "                        [-1.2750e-01, -4.3643e-02,  1.0075e-01],\n",
       "                        [ 5.6347e-02,  4.3477e-01,  5.2736e-01]],\n",
       "              \n",
       "                       [[-1.6504e-01, -1.2353e-01, -1.2828e-02],\n",
       "                        [-1.8011e-01, -3.3459e-01, -3.7747e-02],\n",
       "                        [ 8.0111e-02,  9.7101e-02,  1.8796e-01]],\n",
       "              \n",
       "                       [[-4.7334e-02, -9.8294e-03,  1.4581e-03],\n",
       "                        [-1.5802e-01, -2.2482e-01,  1.4797e-01],\n",
       "                        [ 9.8968e-02, -7.6019e-02,  9.6128e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.8537e-02,  3.4886e-02, -9.0443e-02],\n",
       "                        [-1.4379e-03,  1.2311e-01,  4.8882e-02],\n",
       "                        [-2.1723e-01, -1.4267e-01,  1.2544e-01]],\n",
       "              \n",
       "                       [[ 1.5352e-01,  9.9329e-02,  1.5618e-01],\n",
       "                        [ 1.1465e-04, -6.1684e-03,  1.0449e-01],\n",
       "                        [-5.4194e-02, -2.0709e-01, -1.6001e-01]],\n",
       "              \n",
       "                       [[-3.0162e-02,  1.1974e-01, -2.4478e-02],\n",
       "                        [-1.7273e-01, -9.5262e-02, -1.8966e-01],\n",
       "                        [-1.8664e-01, -1.7581e-01, -1.9986e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.9211e-01, -6.6578e-02,  5.4359e-01],\n",
       "                        [-3.9380e-01, -3.5574e-01,  4.5573e-01],\n",
       "                        [-3.0933e-01, -3.1804e-01,  1.7506e-01]],\n",
       "              \n",
       "                       [[-4.7914e-01, -1.8475e-02,  1.8818e-01],\n",
       "                        [-3.6681e-01, -1.6110e-01,  4.8769e-01],\n",
       "                        [-2.2666e-01, -3.7882e-01,  1.4193e-01]],\n",
       "              \n",
       "                       [[ 1.1715e-01,  2.2990e-01, -2.9764e-01],\n",
       "                        [ 5.6628e-03,  4.7946e-01, -4.0796e-01],\n",
       "                        [-2.8893e-01,  3.0915e-01, -1.7982e-01]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.4583e-01, -2.9147e-02,  1.8430e-01],\n",
       "                        [ 1.6447e-01, -2.2349e-01, -3.5572e-02],\n",
       "                        [ 2.0772e-01, -2.0713e-02, -1.7547e-01]],\n",
       "              \n",
       "                       [[ 1.9872e-01,  1.5174e-01, -3.9253e-01],\n",
       "                        [ 1.6320e-02,  2.8003e-01, -3.9971e-01],\n",
       "                        [-1.0956e-01,  3.0948e-01, -3.2189e-02]],\n",
       "              \n",
       "                       [[ 5.8455e-02, -3.5647e-02,  5.8517e-02],\n",
       "                        [ 7.2825e-02, -7.1414e-02, -3.7585e-02],\n",
       "                        [ 1.2763e-01,  2.1051e-02,  2.1819e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5174e-02,  1.3353e-01,  6.8893e-02],\n",
       "                        [-3.3124e-02,  9.8053e-02, -1.6580e-02],\n",
       "                        [-1.2421e-01, -1.5969e-01, -1.9190e-01]],\n",
       "              \n",
       "                       [[-8.6922e-02,  1.1312e-01,  1.5660e-01],\n",
       "                        [ 6.0805e-02,  1.3355e-01, -9.8768e-03],\n",
       "                        [-2.7388e-02, -7.5958e-03,  1.0256e-02]],\n",
       "              \n",
       "                       [[-5.9784e-04,  7.7569e-02, -1.4120e-01],\n",
       "                        [ 4.2412e-02,  1.3326e-02, -3.5752e-02],\n",
       "                        [ 1.8106e-01,  1.4062e-01,  4.2871e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.0071e-02, -5.2341e-02, -3.7222e-03],\n",
       "                        [ 1.9100e-01,  3.3520e-01,  2.1077e-01],\n",
       "                        [-1.1907e-02, -1.8068e-04,  1.8417e-02]],\n",
       "              \n",
       "                       [[-8.2724e-02, -1.5755e-02, -9.2832e-02],\n",
       "                        [ 1.5520e-02,  1.2935e-01,  8.7191e-02],\n",
       "                        [ 8.9260e-02,  3.1560e-02,  8.9415e-02]],\n",
       "              \n",
       "                       [[-8.5277e-02,  1.3269e-01,  6.2698e-02],\n",
       "                        [-3.3066e-03,  1.2319e-01,  6.2084e-02],\n",
       "                        [-1.1390e-01, -1.2787e-01, -1.2984e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3697e-02, -1.0072e-01, -6.1971e-03],\n",
       "                        [-1.5723e-01, -3.0556e-01, -1.1410e-01],\n",
       "                        [-2.4133e-01, -2.7589e-01, -1.9675e-01]],\n",
       "              \n",
       "                       [[-1.3003e-01, -1.4654e-04,  1.6108e-01],\n",
       "                        [-1.9634e-01, -7.3402e-02,  8.6209e-02],\n",
       "                        [-1.5153e-01, -8.3117e-02,  2.6136e-01]],\n",
       "              \n",
       "                       [[-6.2059e-02, -1.6364e-01, -2.6964e-01],\n",
       "                        [ 9.4567e-03, -6.1158e-02, -1.3125e-01],\n",
       "                        [ 2.9274e-01,  1.2319e-01, -5.1836e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3252e-02,  4.9279e-02,  1.3983e-02],\n",
       "                        [-2.2418e-01, -2.0307e-01, -1.7296e-01],\n",
       "                        [ 1.5339e-01,  1.2269e-01,  9.4176e-02]],\n",
       "              \n",
       "                       [[-7.9548e-02, -1.2242e-01, -1.1164e-01],\n",
       "                        [-2.3198e-02, -7.0765e-02, -1.0083e-01],\n",
       "                        [ 1.8194e-01,  9.9496e-02, -1.4201e-02]],\n",
       "              \n",
       "                       [[-1.0527e-01, -2.1383e-02, -9.0091e-02],\n",
       "                        [-3.6708e-01, -3.3485e-01, -3.5718e-01],\n",
       "                        [-2.2739e-01, -2.0871e-01, -2.3488e-01]]]], device='mps:0')),\n",
       "             ('model.1.1.weight',\n",
       "              tensor([1.2075, 1.6137, 1.5039, 1.1208, 1.3842, 1.8038, 1.8866, 1.1497, 2.3041,\n",
       "                      1.7560, 1.3912, 1.3800, 1.8007, 1.0066, 1.3157, 1.4913, 1.0902, 2.0610,\n",
       "                      1.0382, 2.1025, 1.1388, 1.5548, 1.8249, 1.8082, 1.3678, 2.6456, 2.4558,\n",
       "                      1.4036, 1.2387, 1.8133, 1.1103, 1.3620], device='mps:0')),\n",
       "             ('model.1.1.bias',\n",
       "              tensor([ 0.1179,  0.1031, -0.2335, -0.2701, -0.3128, -0.5125,  0.5676, -0.1560,\n",
       "                      -0.2460, -0.5754, -0.2256,  0.6038, -0.1898, -0.4951, -0.6099, -0.7462,\n",
       "                      -0.3689, -0.5736, -0.3172, -0.4241, -0.2158, -0.0523, -0.1862, -0.9262,\n",
       "                      -0.1928, -0.1471,  0.9170, -0.4284, -0.3327, -0.1152, -0.3112, -0.0748],\n",
       "                     device='mps:0')),\n",
       "             ('model.1.1.running_mean',\n",
       "              tensor([ -9.4253,  -2.8421,  -7.0705,  -4.4638,  -4.1854,  -7.7021,  -9.6240,\n",
       "                       -8.3632,  -4.1775,  -4.0232, -11.2920,  -4.9486,  -8.0370,   6.3452,\n",
       "                       -5.7452,   3.9910,  -1.4648,  -6.1724,  -3.3224,  -8.0714,  -7.5331,\n",
       "                       -4.3516,  -1.3795,  10.8637,  -9.4199,  -3.7977,  -5.9999,  -6.1545,\n",
       "                        7.2919,  -2.9348,   3.2052,  -7.9581], device='mps:0')),\n",
       "             ('model.1.1.running_var',\n",
       "              tensor([ 29.1162,  34.1855,  20.8430,  18.1495,  40.8200,  38.2013,  42.4680,\n",
       "                       34.3650, 242.1780,  51.0480,  40.0988,  44.0444, 105.4031,  13.3313,\n",
       "                       23.3735,  26.5661,  17.5198,  56.2843,  28.1791, 126.2668,  29.5352,\n",
       "                       65.6716,  92.5008,  48.2277,  25.6542, 410.7781,  56.3970,  38.1616,\n",
       "                       33.2006, 148.6181,  21.2483,  29.4248], device='mps:0')),\n",
       "             ('model.1.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.2.0.weight',\n",
       "              tensor([[[[-0.2047, -0.1127, -0.2001],\n",
       "                        [ 0.1811,  0.1478,  0.1489],\n",
       "                        [ 0.0889,  0.0572,  0.1019]],\n",
       "              \n",
       "                       [[ 0.1447, -0.0318, -0.1641],\n",
       "                        [-0.2170,  0.0112,  0.1703],\n",
       "                        [-0.2715, -0.5288, -0.3099]],\n",
       "              \n",
       "                       [[ 0.1018,  0.2345,  0.3516],\n",
       "                        [-0.0803, -0.2030, -0.1575],\n",
       "                        [-0.0365,  0.0885, -0.0690]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1357, -0.1432,  0.0248],\n",
       "                        [-0.1570, -0.0315, -0.0737],\n",
       "                        [ 0.0488,  0.0523,  0.0546]],\n",
       "              \n",
       "                       [[-0.1076, -0.0442,  0.0269],\n",
       "                        [-0.0019, -0.0290,  0.0323],\n",
       "                        [ 0.1646,  0.1136,  0.1026]],\n",
       "              \n",
       "                       [[-0.0303, -0.0221, -0.0988],\n",
       "                        [-0.1768, -0.0711, -0.0264],\n",
       "                        [-0.0498, -0.0046,  0.0040]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0866, -0.1529, -0.0138],\n",
       "                        [ 0.0116, -0.1068, -0.0356],\n",
       "                        [ 0.0731,  0.0089, -0.0824]],\n",
       "              \n",
       "                       [[ 0.0918, -0.0516, -0.1196],\n",
       "                        [ 0.0061,  0.1402, -0.0640],\n",
       "                        [-0.1016, -0.0927,  0.0177]],\n",
       "              \n",
       "                       [[-0.1282,  0.0934,  0.1125],\n",
       "                        [-0.0618, -0.0905,  0.1292],\n",
       "                        [ 0.0087, -0.0483, -0.0514]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0770, -0.2613, -0.1909],\n",
       "                        [ 0.0834,  0.0418,  0.0565],\n",
       "                        [ 0.1051,  0.2371,  0.2921]],\n",
       "              \n",
       "                       [[ 0.0201,  0.0307,  0.1518],\n",
       "                        [-0.0197, -0.0188,  0.0354],\n",
       "                        [-0.1265,  0.0069,  0.0107]],\n",
       "              \n",
       "                       [[ 0.0052, -0.0188,  0.0846],\n",
       "                        [-0.0449, -0.1434, -0.1113],\n",
       "                        [ 0.0011, -0.0100, -0.1220]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1060,  0.0847,  0.0848],\n",
       "                        [ 0.1148,  0.1475,  0.1645],\n",
       "                        [-0.0387,  0.0526,  0.0013]],\n",
       "              \n",
       "                       [[ 0.0229,  0.0112,  0.0490],\n",
       "                        [ 0.1034,  0.0858, -0.0886],\n",
       "                        [ 0.0517,  0.0633,  0.1276]],\n",
       "              \n",
       "                       [[ 0.0126, -0.0448, -0.0514],\n",
       "                        [ 0.1116,  0.0011, -0.0918],\n",
       "                        [ 0.2544,  0.1428,  0.0274]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0638, -0.0745,  0.0011],\n",
       "                        [-0.2179, -0.2851, -0.1804],\n",
       "                        [-0.0477, -0.3101, -0.1535]],\n",
       "              \n",
       "                       [[-0.0757, -0.1224, -0.1786],\n",
       "                        [-0.0625,  0.0166,  0.0569],\n",
       "                        [-0.0148,  0.0368, -0.0032]],\n",
       "              \n",
       "                       [[-0.1264, -0.0981, -0.0872],\n",
       "                        [ 0.0349, -0.0211,  0.0758],\n",
       "                        [-0.0213,  0.0303,  0.1087]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1678,  0.1229, -0.0932],\n",
       "                        [ 0.1106,  0.0357, -0.1184],\n",
       "                        [ 0.3243,  0.1664, -0.0230]],\n",
       "              \n",
       "                       [[ 0.2427, -0.0276, -0.3133],\n",
       "                        [ 0.5886,  0.1057, -0.4671],\n",
       "                        [ 0.1340, -0.1473, -0.5652]],\n",
       "              \n",
       "                       [[ 0.0940,  0.0701, -0.3001],\n",
       "                        [ 0.4073,  0.2877, -0.0375],\n",
       "                        [ 0.2765,  0.3032, -0.0733]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0824, -0.0833,  0.1645],\n",
       "                        [-0.0165,  0.1692,  0.3578],\n",
       "                        [ 0.0216,  0.2752,  0.2568]],\n",
       "              \n",
       "                       [[ 0.2045, -0.0729, -0.1481],\n",
       "                        [ 0.2564, -0.0909, -0.2747],\n",
       "                        [ 0.1700, -0.1715, -0.2892]],\n",
       "              \n",
       "                       [[ 0.1707,  0.0988, -0.1609],\n",
       "                        [ 0.1244, -0.0649, -0.2620],\n",
       "                        [ 0.2649,  0.0546, -0.1681]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0117, -0.0740, -0.0565],\n",
       "                        [-0.0262, -0.0954, -0.0321],\n",
       "                        [-0.1090,  0.0018,  0.0836]],\n",
       "              \n",
       "                       [[ 0.2174, -0.0588, -0.2400],\n",
       "                        [ 0.2047, -0.1886, -0.0908],\n",
       "                        [-0.0807, -0.0451, -0.0545]],\n",
       "              \n",
       "                       [[ 0.0508, -0.1656, -0.0206],\n",
       "                        [ 0.0406, -0.0241, -0.0577],\n",
       "                        [ 0.1356, -0.1414, -0.0403]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1350,  0.0061, -0.0161],\n",
       "                        [ 0.0854, -0.0183, -0.1447],\n",
       "                        [ 0.0770, -0.1295, -0.0736]],\n",
       "              \n",
       "                       [[-0.1838,  0.0188,  0.0858],\n",
       "                        [-0.0660,  0.0651,  0.0555],\n",
       "                        [-0.1312, -0.0774, -0.1413]],\n",
       "              \n",
       "                       [[-0.0256, -0.0832,  0.0044],\n",
       "                        [-0.0884, -0.1029,  0.0329],\n",
       "                        [ 0.0342, -0.0391,  0.0804]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0467, -0.0580,  0.1572],\n",
       "                        [ 0.0072, -0.0206,  0.1267],\n",
       "                        [ 0.0245,  0.0372,  0.2685]],\n",
       "              \n",
       "                       [[-0.0505, -0.2868, -0.1865],\n",
       "                        [ 0.1293, -0.1056, -0.2029],\n",
       "                        [ 0.2643,  0.0313, -0.0833]],\n",
       "              \n",
       "                       [[-0.0836, -0.2319, -0.2564],\n",
       "                        [ 0.0273, -0.2309, -0.1155],\n",
       "                        [-0.0040, -0.1378, -0.1510]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2878, -0.0362, -0.2228],\n",
       "                        [ 0.1939, -0.0413, -0.2647],\n",
       "                        [ 0.2101, -0.0301, -0.1748]],\n",
       "              \n",
       "                       [[-0.0894, -0.2128, -0.1667],\n",
       "                        [ 0.0366, -0.0243, -0.1481],\n",
       "                        [ 0.1919, -0.0343, -0.0528]],\n",
       "              \n",
       "                       [[ 0.0331,  0.0574,  0.0927],\n",
       "                        [ 0.0194,  0.0018,  0.0250],\n",
       "                        [ 0.0826, -0.0610, -0.0608]]]], device='mps:0')),\n",
       "             ('model.2.1.weight',\n",
       "              tensor([1.9256, 1.1403, 1.7446, 1.2133, 1.1309, 1.2049, 1.3980, 1.0988, 1.2684,\n",
       "                      1.2076, 1.0705, 1.2139, 1.4536, 1.6127, 1.3342, 1.1467, 1.1203, 1.3695,\n",
       "                      1.2475, 1.1073, 1.3371, 1.0271, 1.1530, 1.3951, 1.4328, 1.1859, 1.2219,\n",
       "                      1.0953, 1.0390, 1.0514, 1.7910, 0.9668, 1.2804, 1.6110, 1.2575, 0.9457,\n",
       "                      1.8649, 1.2512, 1.2944, 1.4385, 1.2408, 1.1781, 1.2670, 1.5709, 1.2379,\n",
       "                      1.6553, 1.2537, 1.6272, 1.2396, 1.4157, 1.3694, 1.4025, 1.1961, 1.3674,\n",
       "                      1.3943, 1.2592, 1.3740, 1.2671, 1.4051, 0.8829, 1.2363, 1.2853, 1.2570,\n",
       "                      1.3252], device='mps:0')),\n",
       "             ('model.2.1.bias',\n",
       "              tensor([-0.4465, -0.3081, -0.0381,  0.0147, -0.1504, -0.1281, -0.3135, -0.2718,\n",
       "                      -0.4213, -0.1064, -0.1362,  0.0986, -0.2400, -0.3684, -0.7908, -0.2050,\n",
       "                      -0.3550, -0.6338, -0.2392, -0.0587, -0.4594, -0.1533, -0.3746, -0.3429,\n",
       "                      -0.1735, -0.2453, -0.2189, -0.6403,  0.1461, -0.3892, -0.3638,  0.1967,\n",
       "                      -0.3444, -0.3732, -0.2118, -0.1732, -0.7756, -0.7076, -0.0654, -0.3057,\n",
       "                      -0.2316, -0.2749, -0.0192, -0.5112, -0.3534, -0.3142, -0.4422, -0.6408,\n",
       "                      -0.1298, -0.2533, -0.3032, -0.4673, -0.2066, -0.2858, -0.4452, -0.5167,\n",
       "                      -0.5261,  0.3231, -0.3390, -0.1759, -0.2902, -0.2319, -0.4067, -0.2068],\n",
       "                     device='mps:0')),\n",
       "             ('model.2.1.running_mean',\n",
       "              tensor([-1.9928,  3.0382, -6.5124, -2.5793, -2.6497, -2.0214, -1.1960, -0.7739,\n",
       "                      -3.1130, -2.6572, -2.8864, -3.6639, -2.5891, -1.7849, -0.1971, -1.2064,\n",
       "                      -4.4809, -3.9984, -4.9632, -0.7046, -2.1570,  0.9328, -0.2520, -2.5753,\n",
       "                      -3.9227,  2.5348, -1.7117,  3.9908, -1.9985,  0.1702, -4.8052, -4.0665,\n",
       "                      -2.4480, -1.6426, -3.2465,  3.1451, -7.5892,  0.2519, -1.9659,  5.7323,\n",
       "                      -0.5691, -1.1463, -3.8796, -2.2772,  0.0522, -3.3473, -3.8480, -6.5169,\n",
       "                      -0.8059, -1.1953, -1.6095, -4.3841, -1.7210, -5.1408, -4.3451, -3.5907,\n",
       "                      -2.9697, -2.5128, -2.1638, -0.7995, -1.1497, -1.0447, -0.7016, -2.9561],\n",
       "                     device='mps:0')),\n",
       "             ('model.2.1.running_var',\n",
       "              tensor([55.7063, 14.0940, 65.2682, 22.1385, 20.2429, 17.2499, 24.1205, 12.7838,\n",
       "                      15.0807, 19.4452, 17.7245, 19.9584, 29.9409, 28.9750, 13.0230, 15.5467,\n",
       "                      14.6561, 27.8253, 15.9239, 13.6248, 16.4803,  8.8682, 21.2981, 31.1923,\n",
       "                      32.0190, 18.9847, 21.8575, 12.7613, 24.6558, 10.7394, 49.6963, 22.5372,\n",
       "                      15.1605, 30.8096, 22.0495, 10.7526, 42.3788, 12.0234, 16.2590, 33.4382,\n",
       "                      23.1852, 22.7367, 26.1346, 32.4730, 22.2370, 30.9052, 25.3398, 21.3355,\n",
       "                      19.1165, 30.5844, 31.7406, 18.4297, 16.4332, 16.6414, 22.3340, 18.9612,\n",
       "                      22.1248, 31.1446, 25.2996, 15.0442, 16.4801,  8.6418, 24.4000, 20.9368],\n",
       "                     device='mps:0')),\n",
       "             ('model.2.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.3.0.weight',\n",
       "              tensor([[[[-0.0083,  0.1500, -0.0054],\n",
       "                        [-0.0723,  0.0230, -0.2313],\n",
       "                        [-0.0227, -0.0838, -0.0619]],\n",
       "              \n",
       "                       [[ 0.1004,  0.0312, -0.1434],\n",
       "                        [-0.0500, -0.0283, -0.2366],\n",
       "                        [-0.0978, -0.1703, -0.0821]],\n",
       "              \n",
       "                       [[-0.0550, -0.0554, -0.0895],\n",
       "                        [-0.0345,  0.0335,  0.0371],\n",
       "                        [ 0.0686,  0.1515,  0.0998]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1164,  0.1141,  0.1143],\n",
       "                        [-0.1796, -0.0766, -0.1126],\n",
       "                        [-0.0150, -0.0876,  0.0009]],\n",
       "              \n",
       "                       [[ 0.1904, -0.0516,  0.1672],\n",
       "                        [ 0.1991,  0.2198,  0.1382],\n",
       "                        [-0.0008,  0.0580, -0.1694]],\n",
       "              \n",
       "                       [[ 0.1730,  0.3803,  0.1922],\n",
       "                        [-0.2188,  0.0720, -0.0495],\n",
       "                        [-0.0767, -0.1826, -0.2539]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0702,  0.1338,  0.0045],\n",
       "                        [ 0.1851,  0.1291,  0.0475],\n",
       "                        [ 0.1103,  0.1706,  0.0817]],\n",
       "              \n",
       "                       [[-0.0374, -0.0801, -0.0948],\n",
       "                        [-0.0886, -0.1439, -0.1945],\n",
       "                        [-0.0125, -0.0558, -0.0249]],\n",
       "              \n",
       "                       [[ 0.0395,  0.0319, -0.1479],\n",
       "                        [ 0.0409,  0.0687, -0.1958],\n",
       "                        [ 0.1202,  0.1357, -0.1844]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0822,  0.0975, -0.0858],\n",
       "                        [-0.0877,  0.1262, -0.0104],\n",
       "                        [-0.1335,  0.1006,  0.1042]],\n",
       "              \n",
       "                       [[ 0.0050, -0.0523, -0.0383],\n",
       "                        [-0.0202, -0.1341, -0.1067],\n",
       "                        [-0.0758, -0.2085, -0.1334]],\n",
       "              \n",
       "                       [[ 0.0784,  0.0547, -0.0939],\n",
       "                        [-0.0526, -0.1416, -0.1999],\n",
       "                        [ 0.1080, -0.1683, -0.1837]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1442,  0.1356, -0.0660],\n",
       "                        [ 0.1100,  0.0578, -0.1165],\n",
       "                        [ 0.0167, -0.1166, -0.1031]],\n",
       "              \n",
       "                       [[-0.0341,  0.0712,  0.0497],\n",
       "                        [-0.0460, -0.0800, -0.0388],\n",
       "                        [ 0.0139, -0.0669, -0.0230]],\n",
       "              \n",
       "                       [[ 0.0204, -0.0644, -0.1453],\n",
       "                        [ 0.2527,  0.1273,  0.0850],\n",
       "                        [ 0.0836,  0.0221,  0.0422]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0093,  0.0234,  0.0585],\n",
       "                        [ 0.0175, -0.0381, -0.0210],\n",
       "                        [ 0.0135, -0.0540, -0.0571]],\n",
       "              \n",
       "                       [[ 0.0590,  0.0646,  0.0917],\n",
       "                        [-0.0856,  0.0141,  0.1569],\n",
       "                        [-0.0221, -0.0038,  0.1658]],\n",
       "              \n",
       "                       [[-0.1884, -0.0609,  0.1747],\n",
       "                        [-0.0564, -0.0908,  0.1538],\n",
       "                        [ 0.1046,  0.0723,  0.1130]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0940,  0.1750, -0.0022],\n",
       "                        [-0.1133,  0.0053,  0.0422],\n",
       "                        [-0.0602,  0.1732,  0.0832]],\n",
       "              \n",
       "                       [[ 0.0394,  0.1203,  0.0671],\n",
       "                        [-0.1050, -0.0093, -0.0752],\n",
       "                        [-0.1130,  0.1176, -0.0034]],\n",
       "              \n",
       "                       [[-0.3203, -0.0097,  0.1765],\n",
       "                        [-0.4532,  0.0232,  0.3331],\n",
       "                        [-0.2294, -0.1019,  0.1312]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0563,  0.0013,  0.0709],\n",
       "                        [ 0.2010, -0.1721,  0.0615],\n",
       "                        [ 0.1396, -0.0913,  0.2144]],\n",
       "              \n",
       "                       [[ 0.0123, -0.1960, -0.1536],\n",
       "                        [ 0.3914,  0.0433, -0.2460],\n",
       "                        [ 0.1856,  0.0222, -0.2020]],\n",
       "              \n",
       "                       [[-0.1993, -0.1158, -0.1832],\n",
       "                        [-0.0041,  0.2234, -0.0272],\n",
       "                        [-0.2288, -0.1128, -0.0563]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0531,  0.0115,  0.0063],\n",
       "                        [ 0.1512,  0.0624,  0.1500],\n",
       "                        [-0.0294,  0.0015,  0.0682]],\n",
       "              \n",
       "                       [[-0.1657, -0.2169, -0.0378],\n",
       "                        [-0.1453, -0.1703, -0.0532],\n",
       "                        [-0.1080, -0.1303, -0.0451]],\n",
       "              \n",
       "                       [[-0.0166,  0.0583,  0.0124],\n",
       "                        [-0.1330, -0.0136, -0.1286],\n",
       "                        [-0.1505, -0.0036, -0.0315]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0193, -0.0110,  0.0438],\n",
       "                        [ 0.1742,  0.0646,  0.1578],\n",
       "                        [-0.0017, -0.0186,  0.1116]],\n",
       "              \n",
       "                       [[ 0.0292, -0.0349, -0.0704],\n",
       "                        [-0.0202,  0.0031, -0.2036],\n",
       "                        [-0.0212, -0.1400, -0.1568]],\n",
       "              \n",
       "                       [[-0.0624, -0.0781, -0.1796],\n",
       "                        [-0.0022, -0.1193, -0.1671],\n",
       "                        [-0.0821, -0.2195, -0.1771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1056,  0.0142, -0.2399],\n",
       "                        [-0.0049,  0.0453,  0.1754],\n",
       "                        [ 0.0466, -0.0077, -0.1130]],\n",
       "              \n",
       "                       [[ 0.0567,  0.1212,  0.1499],\n",
       "                        [-0.0321, -0.1286,  0.2002],\n",
       "                        [-0.0457,  0.0176, -0.0976]],\n",
       "              \n",
       "                       [[-0.0215,  0.0314,  0.0674],\n",
       "                        [-0.1464, -0.1990, -0.0037],\n",
       "                        [ 0.0149, -0.1820, -0.0784]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0761, -0.0619, -0.1314],\n",
       "                        [ 0.0161,  0.0051,  0.0543],\n",
       "                        [-0.1800, -0.0262, -0.0177]],\n",
       "              \n",
       "                       [[ 0.0266,  0.0476,  0.0704],\n",
       "                        [ 0.0892,  0.0362, -0.0326],\n",
       "                        [-0.1064,  0.0497, -0.0992]],\n",
       "              \n",
       "                       [[ 0.0980, -0.1993, -0.1468],\n",
       "                        [ 0.1409,  0.0760, -0.3261],\n",
       "                        [-0.1185, -0.0214,  0.0533]]]], device='mps:0')),\n",
       "             ('model.3.1.weight',\n",
       "              tensor([1.3190, 1.1180, 1.2382, 1.2546, 1.1259, 1.0365, 1.1074, 1.0645, 1.2794,\n",
       "                      1.2908, 1.2159, 1.2696, 1.2822, 1.3349, 1.3393, 1.2548, 1.4102, 1.4814,\n",
       "                      1.6202, 1.6525, 1.2932, 1.3967, 1.2795, 1.6835, 1.1727, 1.1932, 1.0921,\n",
       "                      1.0750, 1.2434, 1.5235, 1.0360, 1.1725, 1.4504, 1.3967, 1.0869, 1.2597,\n",
       "                      1.4732, 1.3651, 1.3401, 1.2821, 1.2864, 1.1884, 1.7954, 1.4907, 1.5965,\n",
       "                      1.6143, 1.4476, 1.3842, 1.2697, 0.9808, 1.0397, 1.4917, 1.4099, 1.2984,\n",
       "                      1.5375, 1.3735, 1.5544, 1.1962, 1.4156, 1.4147, 1.1754, 1.5876, 1.1456,\n",
       "                      1.1748], device='mps:0')),\n",
       "             ('model.3.1.bias',\n",
       "              tensor([-0.4854, -0.2668, -0.5873, -0.4109, -0.4938, -0.6440, -0.5770, -0.0908,\n",
       "                      -0.1735, -0.3019, -0.5167, -0.7163, -0.3336, -0.7762, -0.7664, -0.5621,\n",
       "                      -0.6404, -0.4426, -0.2865, -0.3600, -0.6672, -0.3504, -0.5030, -0.5217,\n",
       "                      -0.3071, -0.5105, -0.2730, -0.3122, -0.5838, -0.5779, -0.3074, -0.5794,\n",
       "                      -0.9491, -0.5583, -0.4573, -0.4525, -0.7482, -0.3548, -0.7252, -0.6638,\n",
       "                      -0.3966, -0.4201, -0.6708, -0.5003, -0.4045, -0.7621, -0.5259, -0.4067,\n",
       "                      -0.2220, -0.3420, -0.3101, -0.3821, -0.3612, -0.5837, -0.6755, -0.5457,\n",
       "                      -0.5992, -0.2263, -0.3358, -0.2267, -0.1568, -0.6493, -0.3560, -0.6185],\n",
       "                     device='mps:0')),\n",
       "             ('model.3.1.running_mean',\n",
       "              tensor([ -0.4888,  -5.6021,  -0.8027,  -4.3722,   3.8333,  -2.1104,  -4.5647,\n",
       "                        0.1274,  -5.2746,  -4.1091,  -0.5473,  -3.4791,  -2.7392,  -7.1562,\n",
       "                       -3.0521,  -2.5922,  -2.7966,  -5.7435,  -0.7540,  -3.5287,  -1.3683,\n",
       "                       -2.3207,  -1.3927,  -4.2081,  -3.2862,  -2.8587,  -4.6630,  -2.5314,\n",
       "                       -2.9189,  -2.7521,  -3.3458,   1.2015,  -4.6294,  -2.7083,   0.5240,\n",
       "                       -4.2818,  -6.4446,  -3.2725,  -6.1555,  -3.1081,  -5.0032,   0.0339,\n",
       "                       -1.4064,  -6.2180,  -5.2362,  -1.5057,  -6.0688,  -1.3179,  -2.7370,\n",
       "                       -3.2648,  -1.4364,  -3.8325,  -4.3731,  -4.9827,  -5.5363,  -2.1743,\n",
       "                       -3.5827,  -3.9385,  -4.7900, -10.1379,  -5.0204,  -2.8411,  -7.1180,\n",
       "                       -1.6577], device='mps:0')),\n",
       "             ('model.3.1.running_var',\n",
       "              tensor([16.8949, 12.5606,  9.8843, 16.4332, 16.1254, 10.8427, 10.5227, 11.8037,\n",
       "                      13.3581, 12.0905, 13.1394, 12.7650, 15.4342, 13.9630, 10.2298,  9.4212,\n",
       "                      11.5822, 16.5965, 25.2216, 19.5119, 13.0804, 15.1732, 16.8932, 20.7458,\n",
       "                      12.7237,  6.6458, 10.7897, 10.4430, 11.8725, 13.3705,  9.0570, 11.9949,\n",
       "                      11.5323, 12.3209, 14.3645, 11.6610, 12.7421, 15.6724, 12.5693, 10.1125,\n",
       "                       9.3820,  9.3522, 14.4353, 11.6209, 27.1242, 15.4302, 12.3543, 15.8935,\n",
       "                      11.2553,  7.3714,  9.8187, 20.9656, 12.3698, 13.3801, 16.7866, 16.1229,\n",
       "                      12.5393, 12.8755,  9.3663, 27.3126, 14.5344, 14.2208, 12.8565, 15.5489],\n",
       "                     device='mps:0')),\n",
       "             ('model.3.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.4.0.weight',\n",
       "              tensor([[[[-0.1176,  0.0107, -0.0429],\n",
       "                        [ 0.1977,  0.2009,  0.1522],\n",
       "                        [ 0.1119,  0.0461, -0.1063]],\n",
       "              \n",
       "                       [[-0.0538, -0.0435, -0.2097],\n",
       "                        [ 0.0731,  0.0501,  0.0081],\n",
       "                        [-0.0064,  0.0285,  0.0931]],\n",
       "              \n",
       "                       [[ 0.0086,  0.0426,  0.0070],\n",
       "                        [ 0.0221, -0.0206,  0.0221],\n",
       "                        [-0.0106, -0.0497, -0.0731]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0125, -0.0387],\n",
       "                        [-0.0222, -0.0578,  0.1192],\n",
       "                        [-0.0322,  0.0282,  0.1220]],\n",
       "              \n",
       "                       [[-0.0295, -0.1214, -0.1559],\n",
       "                        [-0.0158, -0.0017,  0.0271],\n",
       "                        [ 0.1386,  0.2121,  0.1496]],\n",
       "              \n",
       "                       [[ 0.2929,  0.3589,  0.1960],\n",
       "                        [ 0.2914,  0.4306,  0.2696],\n",
       "                        [ 0.0058,  0.0098, -0.0213]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0259, -0.0383, -0.1965],\n",
       "                        [ 0.0822,  0.0561,  0.1431],\n",
       "                        [-0.1519, -0.0313,  0.2850]],\n",
       "              \n",
       "                       [[ 0.2061,  0.1306, -0.1561],\n",
       "                        [ 0.0655, -0.0775, -0.2238],\n",
       "                        [-0.0571, -0.2417, -0.2259]],\n",
       "              \n",
       "                       [[-0.1108,  0.0578,  0.2150],\n",
       "                        [-0.1000,  0.1666,  0.2679],\n",
       "                        [-0.0473,  0.1298,  0.1487]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.2559, -0.1803,  0.0141],\n",
       "                        [-0.2492, -0.0955,  0.0846],\n",
       "                        [-0.1614, -0.0608, -0.0487]],\n",
       "              \n",
       "                       [[-0.1505,  0.0650,  0.0168],\n",
       "                        [-0.1898, -0.0146,  0.1504],\n",
       "                        [-0.0555,  0.1159,  0.1735]],\n",
       "              \n",
       "                       [[ 0.1641,  0.2030,  0.0422],\n",
       "                        [ 0.1504, -0.1502, -0.0497],\n",
       "                        [ 0.1450, -0.1265, -0.2116]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2430, -0.1891, -0.1834],\n",
       "                        [-0.0622, -0.1214, -0.2139],\n",
       "                        [ 0.5142,  0.2361,  0.1361]],\n",
       "              \n",
       "                       [[-0.1484, -0.1370, -0.1995],\n",
       "                        [-0.1627, -0.1367, -0.2503],\n",
       "                        [-0.0077,  0.0106, -0.0370]],\n",
       "              \n",
       "                       [[ 0.0856,  0.0673,  0.0646],\n",
       "                        [-0.0218, -0.0816, -0.1267],\n",
       "                        [ 0.0535, -0.0434, -0.1558]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0121, -0.0453, -0.0152],\n",
       "                        [-0.0701, -0.0980, -0.0884],\n",
       "                        [-0.1358,  0.0586,  0.1427]],\n",
       "              \n",
       "                       [[ 0.0969,  0.0974,  0.0183],\n",
       "                        [ 0.0044,  0.0136, -0.0318],\n",
       "                        [-0.0781, -0.0261, -0.0914]],\n",
       "              \n",
       "                       [[-0.0347, -0.0168,  0.0208],\n",
       "                        [-0.0017,  0.0636,  0.0129],\n",
       "                        [-0.0184,  0.0770,  0.1377]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0739, -0.2572, -0.0998],\n",
       "                        [ 0.0658, -0.1494, -0.1830],\n",
       "                        [-0.0858, -0.2126, -0.2987]],\n",
       "              \n",
       "                       [[ 0.0018,  0.1105, -0.1209],\n",
       "                        [ 0.1622,  0.3122,  0.0259],\n",
       "                        [ 0.0030,  0.1779,  0.0544]],\n",
       "              \n",
       "                       [[-0.1063, -0.1610, -0.1484],\n",
       "                        [-0.0393, -0.1491, -0.1667],\n",
       "                        [ 0.1375,  0.0430,  0.0804]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1852, -0.1992, -0.2095],\n",
       "                        [-0.1139, -0.1705, -0.1691],\n",
       "                        [-0.0067, -0.0662, -0.1142]],\n",
       "              \n",
       "                       [[ 0.0605, -0.0094,  0.0999],\n",
       "                        [ 0.0206, -0.0034,  0.0122],\n",
       "                        [-0.0587, -0.0027, -0.0717]],\n",
       "              \n",
       "                       [[ 0.0370,  0.1835,  0.1163],\n",
       "                        [ 0.0177,  0.2201,  0.2675],\n",
       "                        [ 0.0089,  0.1282,  0.1708]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2747,  0.0768, -0.0370],\n",
       "                        [ 0.0990, -0.0089, -0.0917],\n",
       "                        [-0.1302, -0.0299, -0.0374]],\n",
       "              \n",
       "                       [[ 0.0270,  0.0469,  0.1108],\n",
       "                        [-0.0093,  0.1143,  0.1700],\n",
       "                        [-0.1847, -0.1940, -0.1680]],\n",
       "              \n",
       "                       [[-0.0548, -0.1692, -0.2138],\n",
       "                        [-0.0183, -0.2422, -0.1510],\n",
       "                        [-0.0006, -0.2289, -0.1065]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2382,  0.0461, -0.1419],\n",
       "                        [ 0.1135,  0.0208,  0.0111],\n",
       "                        [-0.1012, -0.0770,  0.0903]],\n",
       "              \n",
       "                       [[-0.1574, -0.0317, -0.1266],\n",
       "                        [ 0.0207,  0.1278,  0.0411],\n",
       "                        [-0.0558,  0.1040,  0.0760]],\n",
       "              \n",
       "                       [[-0.1348,  0.0779,  0.1519],\n",
       "                        [ 0.0086,  0.1342,  0.2490],\n",
       "                        [ 0.1279,  0.2465,  0.1962]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0512,  0.0185,  0.1555],\n",
       "                        [-0.1807, -0.0139,  0.2570],\n",
       "                        [-0.1918, -0.0514,  0.0820]],\n",
       "              \n",
       "                       [[ 0.1704,  0.0982, -0.0390],\n",
       "                        [ 0.0485,  0.0422, -0.0185],\n",
       "                        [-0.0411, -0.1185, -0.2182]],\n",
       "              \n",
       "                       [[-0.2099, -0.1831, -0.0087],\n",
       "                        [-0.1119,  0.0168,  0.1992],\n",
       "                        [-0.0338,  0.0972,  0.1409]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1506, -0.0294,  0.0917],\n",
       "                        [ 0.1225,  0.0391,  0.0012],\n",
       "                        [-0.0934, -0.2671, -0.1637]],\n",
       "              \n",
       "                       [[-0.0131, -0.0187, -0.0307],\n",
       "                        [ 0.0254, -0.0020, -0.0125],\n",
       "                        [ 0.0163, -0.0057, -0.0451]],\n",
       "              \n",
       "                       [[ 0.0298, -0.0842, -0.2562],\n",
       "                        [-0.0779, -0.1239, -0.2586],\n",
       "                        [ 0.0265, -0.0361, -0.2389]]]], device='mps:0')),\n",
       "             ('model.4.1.weight',\n",
       "              tensor([1.2667, 1.4633, 1.4652, 1.2473, 1.2678, 1.3275, 1.2704, 1.3103, 1.3267,\n",
       "                      1.3089, 1.1075, 1.1774, 1.2050, 1.2696, 1.1714, 1.5410, 1.3020, 1.1395,\n",
       "                      1.1654, 1.1934, 1.3384, 1.2071, 1.4387, 1.2159, 1.2397, 1.2435, 1.4120,\n",
       "                      1.3159, 1.2508, 1.4048, 1.6459, 1.2926, 1.4018, 1.0484, 1.1737, 1.2419,\n",
       "                      1.3507, 1.0782, 1.3316, 1.2210, 1.3727, 1.2936, 1.3843, 1.1571, 1.3361,\n",
       "                      1.4103, 1.6268, 1.4152, 1.2670, 1.2594, 1.3058, 1.2780, 1.2616, 1.3644,\n",
       "                      1.2317, 1.5056, 1.6880, 1.2385, 1.4461, 1.5951, 1.2388, 1.2257, 1.4276,\n",
       "                      1.2208], device='mps:0')),\n",
       "             ('model.4.1.bias',\n",
       "              tensor([-0.6408, -0.6198, -0.7592, -0.4416, -0.4156, -0.2914, -0.3514, -0.3897,\n",
       "                      -0.4619, -0.5087, -0.6733, -0.3757, -0.6500, -0.3709, -0.2966, -0.4767,\n",
       "                      -0.6845, -0.3249, -0.6998, -0.6008, -0.7427, -0.5350, -0.5317, -0.0403,\n",
       "                      -0.4801, -0.3535, -0.4311, -0.2167, -0.5179, -0.7103, -1.2621, -0.2590,\n",
       "                      -0.7217, -0.4630, -0.3937, -0.1279, -0.7425, -0.3795, -0.5655, -0.3992,\n",
       "                      -0.6073, -0.5747, -0.5160, -0.2287, -0.4712, -0.4138, -0.4513, -0.4475,\n",
       "                      -0.1692, -0.8053, -0.4273, -0.3812, -0.3055, -0.4501, -0.6182, -0.6035,\n",
       "                      -0.6540, -1.2893, -0.2947, -1.0344, -0.5830, -0.1799, -0.5099, -0.4666],\n",
       "                     device='mps:0')),\n",
       "             ('model.4.1.running_mean',\n",
       "              tensor([-0.1712, -2.9924, -3.9894, -3.7864, -0.4492, -0.5111, -1.9707,  0.2430,\n",
       "                      -3.3982, -2.9897, -2.7136, -3.6269, -1.5591, -0.5647,  1.7384, -5.5602,\n",
       "                      -0.7546, -1.8628, -0.7234, -2.7783, -4.3481, -0.9485, -5.6084, -5.9963,\n",
       "                      -4.2262, -2.9135, -0.9096, -2.3539, -2.8570, -1.7209, -5.6677, -4.7934,\n",
       "                      -0.3744, -2.1989, -3.3858, -1.3962, -4.3127, -3.4048,  0.4998, -1.2620,\n",
       "                      -6.0606,  0.2153, -6.9155, -0.7795, -3.5615, -1.5350, -4.2344,  0.6406,\n",
       "                      -1.8597, -3.0793, -0.6737, -7.0803, -5.9711, -3.1867, -1.6543, -2.5406,\n",
       "                      -2.3667,  2.4432, -2.5341, -1.2085, -5.0150, -3.8083, -4.3958, -3.2634],\n",
       "                     device='mps:0')),\n",
       "             ('model.4.1.running_var',\n",
       "              tensor([ 9.2968, 14.5978, 12.4169, 15.6569, 10.9786, 11.1443, 12.0076, 11.0371,\n",
       "                      13.0240, 16.7714, 15.1350, 14.0162, 13.4145, 15.1080,  7.8095, 12.5433,\n",
       "                      14.3805, 11.1915,  8.3504,  9.7478,  8.9307, 11.0929, 12.6689, 17.2849,\n",
       "                      13.1578,  9.0983, 11.1299, 11.2598,  8.2720, 11.4439, 15.6425, 18.8047,\n",
       "                      16.7939, 12.8289,  9.0320, 14.2778,  9.3551,  7.4770,  8.5497, 18.9538,\n",
       "                      12.2480, 12.8766, 13.4617, 13.5801, 20.2872, 13.4006, 34.3165, 14.4026,\n",
       "                      19.9387,  8.7656, 13.6607, 14.7772, 24.2815, 11.3039, 12.5187, 17.9699,\n",
       "                      23.4652,  7.1584, 17.3399,  9.9262, 12.7152, 14.1361, 14.4367, 10.9589],\n",
       "                     device='mps:0')),\n",
       "             ('model.4.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.5.0.weight',\n",
       "              tensor([[[[-0.0205,  0.0247,  0.0467],\n",
       "                        [ 0.0772,  0.1259,  0.0626],\n",
       "                        [ 0.1496,  0.1431,  0.1448]],\n",
       "              \n",
       "                       [[ 0.1279,  0.0364,  0.0453],\n",
       "                        [ 0.0520, -0.0388, -0.0640],\n",
       "                        [-0.0325, -0.0919, -0.0671]],\n",
       "              \n",
       "                       [[-0.0360, -0.0230, -0.0184],\n",
       "                        [ 0.0748,  0.1162,  0.0832],\n",
       "                        [ 0.0859,  0.0921,  0.0654]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0460, -0.0099, -0.0158],\n",
       "                        [ 0.0531,  0.1059,  0.0305],\n",
       "                        [ 0.1434,  0.2077,  0.1595]],\n",
       "              \n",
       "                       [[-0.0768,  0.0232,  0.0048],\n",
       "                        [-0.0434,  0.0096, -0.0145],\n",
       "                        [-0.0662, -0.0897, -0.0662]],\n",
       "              \n",
       "                       [[ 0.0391,  0.0036, -0.0158],\n",
       "                        [-0.0323, -0.0143,  0.0606],\n",
       "                        [-0.0804, -0.0757, -0.0080]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0415, -0.0392, -0.1055],\n",
       "                        [ 0.0267,  0.0222,  0.1402],\n",
       "                        [ 0.1352,  0.1365,  0.1584]],\n",
       "              \n",
       "                       [[-0.0452, -0.0955, -0.0099],\n",
       "                        [ 0.0216, -0.0048, -0.0030],\n",
       "                        [ 0.1167,  0.0180,  0.0296]],\n",
       "              \n",
       "                       [[ 0.0756,  0.0569,  0.0418],\n",
       "                        [ 0.0625,  0.0471,  0.0101],\n",
       "                        [-0.0270, -0.0600, -0.0563]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0248, -0.0065, -0.1094],\n",
       "                        [ 0.1249,  0.0277, -0.0280],\n",
       "                        [ 0.0777,  0.0496,  0.0189]],\n",
       "              \n",
       "                       [[ 0.0467,  0.0615, -0.0585],\n",
       "                        [-0.0526, -0.0643, -0.0714],\n",
       "                        [-0.0739, -0.0950, -0.1224]],\n",
       "              \n",
       "                       [[-0.0545, -0.0589, -0.0288],\n",
       "                        [-0.0756, -0.0372, -0.0241],\n",
       "                        [-0.0644, -0.0760, -0.0891]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0256, -0.0905,  0.0598],\n",
       "                        [-0.0650, -0.0473,  0.0266],\n",
       "                        [-0.1142, -0.1023, -0.0545]],\n",
       "              \n",
       "                       [[-0.0794, -0.1641, -0.2534],\n",
       "                        [-0.1043, -0.1951, -0.2406],\n",
       "                        [-0.0295, -0.0298, -0.1966]],\n",
       "              \n",
       "                       [[-0.1387,  0.0119, -0.0139],\n",
       "                        [-0.0163,  0.0771,  0.0741],\n",
       "                        [ 0.0339, -0.0287, -0.0170]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0377, -0.0585, -0.0464],\n",
       "                        [ 0.0158, -0.0892, -0.0256],\n",
       "                        [-0.0705, -0.0818, -0.0254]],\n",
       "              \n",
       "                       [[ 0.0407, -0.0483, -0.0504],\n",
       "                        [ 0.0868,  0.0413, -0.0414],\n",
       "                        [ 0.0294,  0.0045,  0.0348]],\n",
       "              \n",
       "                       [[-0.0209, -0.0362, -0.0505],\n",
       "                        [-0.1339, -0.1714, -0.1521],\n",
       "                        [-0.1785, -0.1308, -0.0697]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0389, -0.0631, -0.0263],\n",
       "                        [-0.0772, -0.1617, -0.0986],\n",
       "                        [ 0.0463, -0.0223, -0.0764]],\n",
       "              \n",
       "                       [[ 0.0483, -0.0113,  0.0040],\n",
       "                        [ 0.0447, -0.0682,  0.0025],\n",
       "                        [-0.0331,  0.0082,  0.0393]],\n",
       "              \n",
       "                       [[-0.0326, -0.0277, -0.0194],\n",
       "                        [-0.0448, -0.0107, -0.0672],\n",
       "                        [ 0.0269,  0.0913,  0.1017]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1041,  0.1090,  0.1676],\n",
       "                        [ 0.0436, -0.0584,  0.0537],\n",
       "                        [ 0.0176, -0.1275, -0.1277]],\n",
       "              \n",
       "                       [[-0.1125, -0.0690, -0.1392],\n",
       "                        [-0.0446, -0.0037, -0.0108],\n",
       "                        [-0.0512,  0.0039,  0.1312]],\n",
       "              \n",
       "                       [[-0.0469, -0.0614, -0.1127],\n",
       "                        [-0.0237, -0.0179, -0.0512],\n",
       "                        [-0.0174,  0.0101,  0.0169]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0629,  0.0406,  0.0430],\n",
       "                        [ 0.0305,  0.0280,  0.0607],\n",
       "                        [-0.0104,  0.0841,  0.0612]],\n",
       "              \n",
       "                       [[ 0.0005, -0.0212, -0.0243],\n",
       "                        [-0.0570, -0.1607, -0.0841],\n",
       "                        [-0.0319, -0.1210, -0.1309]],\n",
       "              \n",
       "                       [[-0.0665, -0.0370, -0.0666],\n",
       "                        [-0.0038, -0.0154,  0.0040],\n",
       "                        [-0.0663, -0.0978,  0.0248]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1144,  0.1104,  0.0134],\n",
       "                        [ 0.0984,  0.0386, -0.0228],\n",
       "                        [-0.0412, -0.0298,  0.0089]],\n",
       "              \n",
       "                       [[-0.0660, -0.1089, -0.1419],\n",
       "                        [ 0.0575,  0.0316,  0.0074],\n",
       "                        [ 0.0342, -0.0590, -0.0515]],\n",
       "              \n",
       "                       [[-0.0121,  0.0391,  0.0767],\n",
       "                        [-0.0518, -0.0084,  0.0083],\n",
       "                        [-0.0430, -0.0959, -0.0616]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1468,  0.2227,  0.1510],\n",
       "                        [ 0.0730,  0.1294,  0.1378],\n",
       "                        [-0.0169, -0.0746, -0.0816]],\n",
       "              \n",
       "                       [[ 0.0389,  0.0496, -0.0165],\n",
       "                        [ 0.1249,  0.0191,  0.0284],\n",
       "                        [ 0.1653,  0.0833,  0.0912]],\n",
       "              \n",
       "                       [[-0.0023,  0.1798,  0.1027],\n",
       "                        [-0.0187,  0.0257,  0.0559],\n",
       "                        [ 0.0389,  0.0220, -0.0217]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0811,  0.0605,  0.0709],\n",
       "                        [-0.0063, -0.0554, -0.0178],\n",
       "                        [-0.0323, -0.0548, -0.0778]],\n",
       "              \n",
       "                       [[ 0.0766,  0.0812,  0.1239],\n",
       "                        [ 0.0490,  0.0838,  0.0445],\n",
       "                        [-0.0417,  0.0430, -0.0313]],\n",
       "              \n",
       "                       [[ 0.0398,  0.0680,  0.1484],\n",
       "                        [ 0.0247,  0.0051,  0.0182],\n",
       "                        [-0.0787, -0.0992, -0.0988]]]], device='mps:0')),\n",
       "             ('model.5.1.weight',\n",
       "              tensor([1.0140, 0.9736, 1.2556, 1.2318, 0.9264, 1.0344, 1.0676, 1.1272, 1.1088,\n",
       "                      1.0506, 1.2019, 1.1125, 1.0218, 1.0692, 1.1038, 1.3065, 0.9893, 1.0874,\n",
       "                      1.0050, 1.0805, 0.9795, 0.9976, 1.1720, 1.1852, 0.9186, 1.0760, 1.0798,\n",
       "                      1.0449, 0.9614, 0.9175, 1.2760, 1.0854, 1.2161, 1.1676, 1.0621, 1.0518,\n",
       "                      0.9884, 0.8626, 1.1106, 1.1950, 1.1592, 1.0935, 1.1499, 1.0638, 0.9965,\n",
       "                      0.9562, 1.0989, 1.3429, 0.9100, 1.0978, 1.0770, 0.9810, 1.0555, 1.1279,\n",
       "                      1.2253, 0.9577, 1.0505, 0.9827, 1.0881, 0.9525, 0.7627, 1.1386, 1.1727,\n",
       "                      0.9317, 1.0694, 1.1305, 1.1657, 1.1649, 1.0793, 0.9340, 1.0519, 1.2099,\n",
       "                      1.0100, 0.8113, 1.1334, 0.8933, 1.2030, 1.1499, 1.0374, 1.0672, 0.8542,\n",
       "                      1.1928, 1.1136, 1.2677, 1.2306, 1.0328, 1.0910, 1.1113, 1.1547, 1.1631,\n",
       "                      1.0613, 1.0297, 0.9618, 0.9999, 1.2014, 1.0486, 1.1726, 1.0459, 1.0579,\n",
       "                      1.1641, 1.1641, 1.0820, 1.1023, 1.1828, 1.0458, 1.2258, 0.9245, 0.9279,\n",
       "                      1.0948, 1.1835, 1.1201, 0.8823, 0.9543, 1.0699, 1.1234, 1.1590, 0.7684,\n",
       "                      1.1993, 1.0217, 1.1087, 1.0649, 1.2777, 1.1501, 1.1071, 0.9283, 1.1411,\n",
       "                      0.8879, 0.9850], device='mps:0')),\n",
       "             ('model.5.1.bias',\n",
       "              tensor([-0.5263, -0.5478, -0.4994, -0.5335, -0.5097, -0.5218, -0.4032, -0.6312,\n",
       "                      -0.5050, -0.5273, -0.6893, -0.5927, -0.6077, -0.4639, -0.5039, -0.6330,\n",
       "                      -0.7610, -0.4761, -0.3610, -0.3871, -0.4580, -0.5331, -0.5201, -0.6251,\n",
       "                      -0.6084, -0.5871, -0.5085, -0.4806, -0.5408, -0.4773, -0.3139, -0.5220,\n",
       "                      -0.2583, -0.5592, -0.5345, -0.4714, -0.5243, -0.4496, -0.5270, -0.4659,\n",
       "                      -0.2209, -0.2945, -0.5870, -0.4366, -0.4439, -0.4272, -0.7581, -0.2973,\n",
       "                      -0.3479, -0.3981, -0.6374, -0.1865, -0.4967, -0.4857, -0.5466, -0.3689,\n",
       "                      -0.7173, -0.6589, -0.3944, -0.4567, -0.3389, -0.4487, -0.3903, -0.5621,\n",
       "                      -0.4034, -0.4803, -0.3478, -1.0259, -0.4243, -0.5426, -0.5957, -0.3485,\n",
       "                      -0.4469, -0.3792, -0.5411, -0.5224, -0.6441, -0.4373, -0.4811, -0.4358,\n",
       "                      -0.5821, -0.4319, -0.5532, -0.4229, -0.4360, -0.4681, -0.3269, -0.3979,\n",
       "                      -0.4030, -0.6962, -0.2599, -0.7554, -0.4021, -0.6306, -0.5172, -0.6080,\n",
       "                      -0.4151, -0.4502, -0.8285, -0.3271, -0.6280, -0.4987, -0.6136, -0.4464,\n",
       "                      -0.6666, -0.4909, -0.5058, -0.5042, -0.6150, -0.2558, -0.1543, -0.5681,\n",
       "                      -0.6638, -0.6351, -0.4955, -0.1856, -0.5583, -0.4768, -0.4187, -0.4695,\n",
       "                      -0.4704, -0.2672, -0.3975, -0.3925, -0.6803, -0.3118, -0.5160, -0.5535],\n",
       "                     device='mps:0')),\n",
       "             ('model.5.1.running_mean',\n",
       "              tensor([-0.9107, -1.7900, -2.0575, -2.7286, -0.1095, -4.3137, -0.7282, -0.0096,\n",
       "                      -2.2766, -3.7708, -3.2161,  0.1168, -1.8256,  0.5896, -1.2735, -2.5248,\n",
       "                       1.2874, -2.0714, -2.6182, -2.3522, -3.3696, -2.6149, -0.5353, -3.3668,\n",
       "                      -2.8591, -3.8399, -1.3838, -2.3339, -1.2429, -1.3038, -3.5862, -1.1368,\n",
       "                      -4.6798, -2.1754, -4.7398, -1.4704, -2.6670, -2.0895, -2.3351, -1.3321,\n",
       "                      -4.8913, -0.7241, -3.9685, -0.8153, -2.1489, -2.9554,  2.5546,  0.2889,\n",
       "                      -2.7581, -1.6367, -0.7957, -0.5689, -0.1830, -3.8407, -2.0927, -2.3386,\n",
       "                      -0.4910,  0.0958, -0.3657, -3.8049, -2.1003, -1.2631, -1.6398, -0.2197,\n",
       "                      -2.9286, -2.4470, -1.7715, -3.3434, -2.2361, -2.5269, -2.1939, -0.5478,\n",
       "                       0.4924, -2.8499, -2.9747, -2.8869, -2.6982,  1.1808,  1.0057, -1.9344,\n",
       "                       1.7154, -2.2927, -1.4055, -0.2220,  1.8079, -0.3228, -4.7191, -1.6164,\n",
       "                      -2.1280, -1.7292, -3.2136, -0.7913, -1.8100,  0.6174,  2.6839,  0.7837,\n",
       "                      -1.4608, -3.4953, -2.9808, -2.2763,  2.4667, -0.5746, -1.2432, -3.7246,\n",
       "                      -0.3427, -1.8846, -2.3365, -1.9829, -2.5499, -3.8720, -2.2094,  2.4115,\n",
       "                      -3.4715,  0.6986, -3.7998, -3.9402,  0.0683, -2.3245,  0.7748, -1.5087,\n",
       "                      -4.3211,  2.0422, -1.6110, -3.2429, -0.1015, -3.0634, -0.6176, -0.7073],\n",
       "                     device='mps:0')),\n",
       "             ('model.5.1.running_var',\n",
       "              tensor([ 7.3390,  5.8133, 10.4117,  6.9549,  5.5715,  9.2830,  7.1265,  8.9383,\n",
       "                       5.9799,  6.3383,  6.8513,  5.4686,  5.5909,  6.5746,  7.4847,  9.3103,\n",
       "                      10.4039,  6.8292,  9.1206,  8.1145,  5.5759,  8.7575,  8.0304,  7.1336,\n",
       "                       7.1955,  5.9291,  9.2876,  5.9773,  5.9917,  4.2327,  8.1502,  6.2169,\n",
       "                       9.4943,  8.1296,  7.5176,  6.9142,  7.2648,  8.0803,  5.7002,  7.5392,\n",
       "                       8.6073,  7.4584,  9.5716,  7.0691,  5.0327,  7.2253,  8.3937,  6.9662,\n",
       "                       7.4576,  6.9791,  5.7069,  6.6470,  8.0972,  7.9759,  7.3617,  4.6515,\n",
       "                       9.9394,  6.9997,  6.1799,  9.2857,  4.8129,  5.0629,  7.7315,  5.4794,\n",
       "                       7.8451,  6.2684,  6.5667,  8.8231, 12.3260,  5.6659,  7.8807,  7.3687,\n",
       "                       5.3254,  7.4585, 10.1799,  6.1135,  6.1652,  7.4181,  5.9595,  7.1828,\n",
       "                      10.6328,  9.4817,  6.8109,  7.7314,  8.8330,  7.3143,  7.2334,  5.0406,\n",
       "                       9.6885,  9.8645,  8.6359,  8.4416,  6.2059, 10.1041,  7.0868,  9.3789,\n",
       "                       8.1381, 10.0535,  7.0274,  5.5471,  5.2143,  6.0760,  8.7418,  9.1028,\n",
       "                       8.5876,  7.3243, 10.3937,  5.7336,  7.0564,  5.9117,  7.3540,  6.6826,\n",
       "                       8.1686,  6.7226,  6.6651,  7.4824,  5.7141,  8.1723,  5.5397,  7.0979,\n",
       "                       7.3226,  9.0407,  8.2133,  6.5011,  6.7883,  6.3399,  8.1782,  5.9610],\n",
       "                     device='mps:0')),\n",
       "             ('model.5.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.6.0.weight',\n",
       "              tensor([[[[-1.5354e-02,  1.6217e-02,  1.7414e-02],\n",
       "                        [ 1.6167e-02,  1.3051e-02,  1.5055e-02],\n",
       "                        [ 2.0788e-01,  1.7980e-01,  7.1811e-02]],\n",
       "              \n",
       "                       [[-1.3643e-01, -1.5158e-01, -1.0574e-01],\n",
       "                        [-1.3999e-01, -1.2414e-01, -8.7790e-02],\n",
       "                        [ 2.7520e-02,  4.3926e-02, -3.7491e-02]],\n",
       "              \n",
       "                       [[ 1.2896e-02,  3.6678e-02,  6.1837e-02],\n",
       "                        [-4.8332e-02, -1.4126e-02,  2.9848e-02],\n",
       "                        [-1.3820e-01, -1.3733e-01, -9.9609e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9680e-02,  4.9325e-02,  3.0791e-02],\n",
       "                        [-1.2682e-02, -1.9302e-02, -1.4824e-03],\n",
       "                        [ 1.1458e-02,  4.3487e-02, -8.9041e-03]],\n",
       "              \n",
       "                       [[-1.6942e-01, -3.8658e-02, -3.2368e-02],\n",
       "                        [-5.1043e-02, -1.5225e-02, -7.8275e-02],\n",
       "                        [ 3.4903e-02, -2.3936e-02, -7.7602e-02]],\n",
       "              \n",
       "                       [[-2.6266e-02, -1.7725e-02,  7.9433e-02],\n",
       "                        [ 3.0650e-02, -7.7182e-05,  3.9189e-02],\n",
       "                        [ 8.2557e-02, -1.2076e-02,  2.5773e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 5.9670e-02,  1.3784e-01,  1.2194e-01],\n",
       "                        [ 2.8056e-03, -4.7721e-02, -2.3364e-02],\n",
       "                        [-1.3856e-01, -8.9754e-02, -1.1520e-01]],\n",
       "              \n",
       "                       [[-6.2918e-02, -1.9526e-02, -3.8300e-02],\n",
       "                        [-7.4681e-02, -7.5941e-02, -1.0325e-02],\n",
       "                        [-1.0021e-01,  8.1888e-03,  5.9245e-03]],\n",
       "              \n",
       "                       [[ 2.4499e-01,  1.9405e-01, -4.6967e-02],\n",
       "                        [ 5.3671e-02, -1.4612e-02, -5.6238e-02],\n",
       "                        [ 1.7039e-02, -6.5469e-02,  2.0335e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.3782e-01, -5.5361e-02, -5.8022e-02],\n",
       "                        [-2.7038e-02, -1.2664e-01, -9.8652e-02],\n",
       "                        [-6.0174e-02, -2.7194e-02,  8.4918e-03]],\n",
       "              \n",
       "                       [[ 4.5778e-02,  3.2863e-02, -8.2634e-03],\n",
       "                        [-1.1836e-01, -1.0031e-02,  1.4164e-01],\n",
       "                        [-1.2959e-01, -5.9157e-02,  5.2683e-02]],\n",
       "              \n",
       "                       [[-1.0234e-01, -7.7967e-02, -8.1150e-02],\n",
       "                        [-7.8564e-02, -9.0317e-02, -7.2680e-02],\n",
       "                        [ 3.7609e-02,  3.1480e-02, -2.8134e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.7578e-03, -3.5649e-02, -4.9075e-02],\n",
       "                        [-5.6350e-02, -6.6085e-02, -7.1923e-02],\n",
       "                        [-5.3546e-02,  1.1262e-01, -2.7459e-02]],\n",
       "              \n",
       "                       [[-4.5255e-03, -1.8942e-02, -8.3203e-02],\n",
       "                        [ 2.4911e-02, -1.0033e-01, -1.1002e-01],\n",
       "                        [-3.1624e-03,  5.0052e-02,  5.3223e-02]],\n",
       "              \n",
       "                       [[-3.2017e-02,  1.0766e-01, -3.9899e-03],\n",
       "                        [-7.0967e-02,  8.7982e-02, -3.3040e-02],\n",
       "                        [-1.0673e-01, -5.3850e-02, -7.4965e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.9319e-02, -6.7305e-02, -3.0483e-02],\n",
       "                        [ 1.2687e-02, -1.5986e-01, -2.8070e-02],\n",
       "                        [ 1.0238e-01,  5.7692e-02,  5.8612e-02]],\n",
       "              \n",
       "                       [[-3.9243e-02, -5.6864e-02, -3.9086e-02],\n",
       "                        [ 5.4323e-03, -5.7328e-02, -8.1355e-02],\n",
       "                        [ 1.2421e-01, -7.4687e-02, -7.1855e-02]],\n",
       "              \n",
       "                       [[ 5.9919e-02,  1.8137e-02,  1.9677e-02],\n",
       "                        [ 8.8455e-02,  1.2633e-01,  1.1621e-01],\n",
       "                        [ 7.9000e-02,  8.2516e-02,  5.1222e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0566e-02, -3.5078e-02, -2.1313e-02],\n",
       "                        [ 4.2362e-02,  7.4342e-02, -1.2727e-02],\n",
       "                        [ 6.6565e-02,  7.7948e-03, -2.2316e-02]],\n",
       "              \n",
       "                       [[ 2.3791e-02, -2.3853e-02,  3.1778e-02],\n",
       "                        [ 8.4099e-02, -1.8164e-02,  6.9623e-02],\n",
       "                        [ 5.9658e-02, -1.9268e-02,  3.2313e-02]],\n",
       "              \n",
       "                       [[-7.3192e-02, -1.8820e-02,  4.4859e-02],\n",
       "                        [-1.1540e-01, -1.8180e-01, -4.8628e-02],\n",
       "                        [-2.4636e-01, -1.1763e-01,  5.9367e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 7.5585e-03,  1.8020e-03,  1.1613e-01],\n",
       "                        [-4.1104e-02, -3.0720e-02, -1.4741e-01],\n",
       "                        [ 4.5172e-02, -2.4631e-02, -6.5192e-02]],\n",
       "              \n",
       "                       [[-3.2372e-02, -7.7876e-02,  6.7020e-02],\n",
       "                        [-3.5187e-02, -1.1203e-01,  2.6171e-03],\n",
       "                        [-1.4505e-01, -2.3333e-01, -7.9461e-02]],\n",
       "              \n",
       "                       [[-8.0288e-02, -9.9464e-02, -7.6488e-02],\n",
       "                        [-7.1549e-02, -1.6537e-01, -1.3707e-01],\n",
       "                        [-7.4038e-02, -1.8226e-01, -1.5557e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.0025e-02, -3.4925e-02, -4.1067e-03],\n",
       "                        [ 6.1060e-02, -2.3774e-02,  5.7831e-03],\n",
       "                        [ 1.0447e-02, -3.6296e-02, -5.6996e-02]],\n",
       "              \n",
       "                       [[-5.4087e-02, -6.1758e-02, -7.7486e-02],\n",
       "                        [-1.3123e-01, -7.0396e-02, -1.5892e-01],\n",
       "                        [ 6.0707e-02,  5.0854e-02,  1.7449e-02]],\n",
       "              \n",
       "                       [[ 6.3034e-03, -1.1662e-01, -1.0970e-01],\n",
       "                        [ 1.1141e-02, -1.1890e-01, -4.3812e-02],\n",
       "                        [-9.6343e-02,  5.3895e-03, -2.7611e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.3115e-02,  4.9802e-02,  2.5395e-02],\n",
       "                        [-1.0413e-01, -6.8861e-02, -8.5125e-02],\n",
       "                        [ 8.5972e-02,  2.2125e-02, -6.6227e-02]],\n",
       "              \n",
       "                       [[-1.3475e-01, -7.7926e-02, -4.3808e-02],\n",
       "                        [-1.0636e-01, -1.7218e-01, -1.7948e-01],\n",
       "                        [ 2.7263e-05,  4.1266e-02,  1.5567e-03]],\n",
       "              \n",
       "                       [[ 5.4045e-02,  8.2080e-02,  4.9001e-02],\n",
       "                        [ 3.8261e-02,  4.8881e-02,  6.1113e-02],\n",
       "                        [-1.2305e-02, -4.0608e-02,  3.3018e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.3554e-02,  9.0679e-02, -5.5785e-02],\n",
       "                        [-1.0929e-02,  9.2945e-02, -2.4075e-02],\n",
       "                        [-1.9748e-02,  1.9609e-02, -2.2558e-02]],\n",
       "              \n",
       "                       [[-3.1773e-02, -4.9519e-02, -3.5621e-02],\n",
       "                        [ 1.4005e-02,  1.8999e-02,  5.4526e-02],\n",
       "                        [-3.9120e-02, -7.5056e-03,  6.6775e-03]],\n",
       "              \n",
       "                       [[-9.3685e-02,  5.9152e-02,  1.0313e-01],\n",
       "                        [-1.4960e-01, -1.9510e-02,  2.0944e-01],\n",
       "                        [-2.1063e-01, -8.7310e-02,  1.8700e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.8574e-02,  9.2517e-03,  1.8408e-02],\n",
       "                        [ 6.4905e-02, -2.0691e-02,  2.5479e-02],\n",
       "                        [-1.2619e-01, -1.2009e-01, -1.3951e-01]],\n",
       "              \n",
       "                       [[ 3.8722e-02,  8.0839e-02,  4.4349e-02],\n",
       "                        [ 5.8926e-02,  1.0239e-01,  1.5708e-01],\n",
       "                        [-6.2716e-02, -6.4815e-02,  1.6227e-02]],\n",
       "              \n",
       "                       [[-7.1990e-02, -1.5712e-02, -4.2307e-02],\n",
       "                        [-4.4866e-02, -7.8299e-03, -9.6548e-03],\n",
       "                        [-2.9060e-02, -4.8894e-02, -1.8387e-02]]]], device='mps:0')),\n",
       "             ('model.6.1.weight',\n",
       "              tensor([1.1526, 1.1482, 0.9900, 1.1343, 1.1138, 1.2443, 1.1020, 1.0665, 0.8731,\n",
       "                      0.8043, 0.7415, 0.7914, 0.5157, 1.1658, 1.1919, 1.0789, 1.1050, 1.0320,\n",
       "                      1.0102, 0.9659, 1.1503, 1.0771, 1.1378, 0.9645, 1.2206, 0.8819, 1.2276,\n",
       "                      1.0232, 0.9599, 1.0652, 1.0426, 0.8801, 0.9001, 1.0520, 1.2384, 1.0371,\n",
       "                      1.1459, 0.7239, 1.0081, 1.0407, 0.9410, 1.0131, 1.0289, 1.2335, 1.1129,\n",
       "                      1.1447, 0.8910, 0.9432, 1.1408, 1.4637, 1.1949, 0.9326, 1.2022, 0.9732,\n",
       "                      1.0157, 1.0846, 0.8173, 1.0330, 1.1555, 0.9685, 1.0584, 0.9141, 1.1383,\n",
       "                      0.8645, 1.0814, 1.0079, 1.1124, 1.1677, 0.9491, 1.0846, 1.1392, 1.0338,\n",
       "                      1.2344, 1.1792, 0.9903, 0.9972, 0.9688, 0.9192, 0.7430, 1.1353, 0.8268,\n",
       "                      0.9240, 1.1942, 0.9969, 0.8375, 1.0839, 1.2274, 0.9947, 1.0217, 1.0462,\n",
       "                      1.0816, 1.1179, 0.8991, 1.0624, 0.8386, 0.9563, 1.2655, 1.0359, 1.1616,\n",
       "                      0.9273, 1.1063, 1.2023, 1.1115, 0.8698, 0.9787, 1.3083, 0.9990, 1.0867,\n",
       "                      0.9825, 1.0406, 1.1095, 0.8490, 1.0567, 1.1508, 1.1538, 0.9430, 1.0294,\n",
       "                      0.9534, 1.1051, 0.9429, 1.1147, 1.2227, 1.2274, 1.2263, 1.0179, 1.2231,\n",
       "                      1.0968, 1.1759], device='mps:0')),\n",
       "             ('model.6.1.bias',\n",
       "              tensor([-0.9318, -0.8034, -0.7789, -0.7513, -0.5571, -0.6597, -0.5878, -0.4918,\n",
       "                      -0.6506, -0.6969, -0.6652, -0.7630, -0.5041, -0.5478, -0.9574, -0.9306,\n",
       "                      -0.6893, -0.6976, -0.7303, -0.4917, -0.6462, -0.8852, -0.5242, -0.6753,\n",
       "                      -0.7111, -0.5506, -0.6987, -0.6386, -0.6250, -0.7620, -0.8163, -0.5814,\n",
       "                      -0.7545, -0.8194, -0.8086, -0.9323, -0.7641, -0.8011, -0.6057, -0.7011,\n",
       "                      -0.5599, -0.3462, -0.8906, -0.9003, -0.9468, -0.9139, -0.6954, -0.8006,\n",
       "                      -0.6122, -0.5867, -0.7812, -0.7346, -0.8918, -0.9232, -1.0643, -0.7710,\n",
       "                      -0.7530, -0.3898, -1.1535, -0.7662, -0.9408, -0.5669, -0.7147, -0.7523,\n",
       "                      -0.7713, -0.6036, -0.9161, -0.8026, -0.6351, -0.5427, -0.6794, -0.8186,\n",
       "                      -0.6333, -0.6090, -0.8912, -0.7917, -0.7036, -1.0113, -0.6024, -0.7377,\n",
       "                      -0.4211, -0.9564, -0.6686, -0.4839, -0.8220, -0.8057, -0.6200, -0.6759,\n",
       "                      -0.7390, -0.6504, -0.6110, -0.7558, -0.8080, -0.8608, -0.6657, -0.5955,\n",
       "                      -0.7639, -0.7052, -0.8412, -0.8861, -0.7786, -0.8541, -0.7427, -0.9499,\n",
       "                      -0.7204, -0.4734, -0.8762, -0.6549, -0.3505, -0.6037, -0.7420, -0.5641,\n",
       "                      -0.7070, -0.4766, -0.5968, -0.8190, -0.6498, -0.8889, -0.7401, -0.7742,\n",
       "                      -0.5113, -1.0216, -0.6875, -0.8230, -0.7808, -0.5557, -0.7319, -0.4652],\n",
       "                     device='mps:0')),\n",
       "             ('model.6.1.running_mean',\n",
       "              tensor([-1.1957, -1.7162, -0.8805, -2.1526, -2.9462, -2.3159, -0.8520, -4.8048,\n",
       "                      -2.0099, -0.0535, -3.0584, -1.4745, -0.1293, -2.8202, -1.1799,  0.0596,\n",
       "                      -1.3392, -1.3800, -1.9197, -3.5598, -0.6140, -1.9829,  0.0196, -2.6455,\n",
       "                      -3.1544, -3.4206, -2.1984, -3.1482, -0.8784, -4.3819, -3.8112, -2.6930,\n",
       "                      -2.9225, -1.1028, -2.7071, -1.7872, -2.1325,  0.3216, -1.0077, -1.4445,\n",
       "                      -2.3025, -2.0434, -1.6410, -2.1695, -2.3755, -1.3966, -3.0577, -2.2409,\n",
       "                      -3.1820, -3.1014, -1.6404, -3.3476, -2.2201, -2.6425,  1.0515, -2.0435,\n",
       "                       0.0334, -1.6489, -2.9894, -1.1960, -1.9713, -2.0550, -2.0630, -0.3144,\n",
       "                      -1.0672, -2.1179, -2.4707, -2.9483, -1.2084, -2.1797, -2.5332, -1.1906,\n",
       "                      -3.4954, -1.5278, -1.6549, -2.7654, -1.4122, -0.8728, -1.4721, -3.4363,\n",
       "                      -1.8930, -1.9702, -2.5747, -2.6061, -2.1635, -2.2426, -1.8597, -2.9178,\n",
       "                      -0.4660, -2.7665, -2.6516, -0.7597, -0.1164, -1.0808,  0.3845, -2.0383,\n",
       "                      -2.1645, -1.3188, -1.8660, -0.5465, -2.2045, -0.8688, -1.1150, -0.5432,\n",
       "                      -0.4113, -1.6053, -1.5969, -2.0374, -1.9859,  1.2539, -1.9291, -0.4869,\n",
       "                      -1.6793, -4.4315, -1.9309, -1.2451, -3.1039, -2.3003, -1.8690, -2.2327,\n",
       "                      -2.8768, -1.5186, -1.6882, -2.8017, -2.7879, -2.2827, -1.1081, -3.1748],\n",
       "                     device='mps:0')),\n",
       "             ('model.6.1.running_var',\n",
       "              tensor([ 6.6900,  5.4153,  6.0425,  5.4622,  8.0007,  7.7510,  6.1009,  7.2614,\n",
       "                       6.6004,  4.3530,  4.5596,  6.4508,  4.9979,  6.1042,  6.9753,  5.7561,\n",
       "                       5.7045,  7.0969,  5.4256,  7.1702,  6.3720,  5.3390,  7.6964,  5.7568,\n",
       "                       6.3745,  5.8920,  6.8791,  6.0229,  4.6042,  7.5006,  4.8315,  4.6364,\n",
       "                       5.0875,  5.8688,  7.4879,  5.7091,  6.5328,  6.9680,  5.1269,  5.3722,\n",
       "                       4.9809,  5.9907,  6.4453,  7.4565,  7.1081,  6.4177,  5.9539,  5.9835,\n",
       "                       6.6002, 13.4296,  6.9831,  6.0318,  6.9048,  4.7802,  5.3641,  5.6029,\n",
       "                       5.6991,  7.9826,  7.0423,  4.4167,  5.2923,  5.5239,  4.8785,  4.5030,\n",
       "                       5.9117,  4.6106,  5.5053,  7.4638,  5.5717,  5.2481,  5.4679,  5.8507,\n",
       "                       9.4832,  8.5251,  6.4527,  5.7425,  5.9205,  4.2573,  3.8259,  5.9157,\n",
       "                       5.6662,  4.6673,  6.3395,  4.7957,  5.6240,  5.6875,  7.4769,  5.2389,\n",
       "                       5.7160,  4.2078,  5.1445,  4.5642,  4.6558,  5.3440,  3.0982,  4.9475,\n",
       "                       6.9748,  6.1372,  5.4026,  5.8553,  6.7545,  6.3827,  6.2735,  5.0943,\n",
       "                       6.2072,  8.3780,  5.7689,  5.5307,  6.3222,  5.5570,  4.8683,  4.8156,\n",
       "                       4.9667,  6.9944,  5.3638,  5.2753,  6.8807,  5.2042,  5.1856,  3.9278,\n",
       "                       6.9632,  6.9907,  8.6224,  7.0119,  6.3654,  8.0286,  5.5482,  7.5286],\n",
       "                     device='mps:0')),\n",
       "             ('model.6.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.7.0.weight',\n",
       "              tensor([[[[ 7.5910e-02,  5.4683e-02,  3.0322e-02],\n",
       "                        [-1.7837e-03,  8.4180e-03, -5.0583e-02],\n",
       "                        [-1.0774e-01, -1.1413e-01, -1.1907e-01]],\n",
       "              \n",
       "                       [[-9.7641e-02, -7.5787e-02, -8.8121e-02],\n",
       "                        [-8.6561e-02, -6.3873e-02, -4.0782e-02],\n",
       "                        [-2.1441e-02,  2.4564e-02,  3.9275e-02]],\n",
       "              \n",
       "                       [[-3.1951e-02, -6.4867e-02, -7.3506e-04],\n",
       "                        [-2.8872e-03, -5.3425e-02,  1.2965e-02],\n",
       "                        [-1.4857e-02, -3.1940e-02, -1.0621e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.3396e-03, -2.2119e-02,  3.3186e-02],\n",
       "                        [-1.3899e-02,  2.1387e-02,  5.2410e-02],\n",
       "                        [-4.3119e-02, -4.9171e-02, -3.2710e-02]],\n",
       "              \n",
       "                       [[-3.6841e-02, -2.6411e-02, -5.1245e-02],\n",
       "                        [ 2.5460e-02,  7.3194e-02,  5.7084e-02],\n",
       "                        [-1.8237e-02, -8.0592e-03, -1.5945e-02]],\n",
       "              \n",
       "                       [[ 6.8811e-02,  4.7476e-02,  5.9196e-02],\n",
       "                        [-1.5873e-02, -4.8520e-02, -6.2704e-02],\n",
       "                        [-7.4144e-02, -6.6195e-02, -8.0565e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.3267e-03,  2.6044e-02,  1.8906e-02],\n",
       "                        [ 2.1960e-02,  3.1476e-02,  2.7443e-02],\n",
       "                        [-6.0798e-02, -6.3141e-02, -4.1343e-02]],\n",
       "              \n",
       "                       [[-1.6539e-02,  2.1315e-02, -2.2696e-03],\n",
       "                        [ 1.2876e-02, -4.2154e-02, -3.8450e-02],\n",
       "                        [-4.3300e-02,  1.2805e-02,  7.3587e-03]],\n",
       "              \n",
       "                       [[-6.3485e-02, -5.3899e-02, -3.0412e-02],\n",
       "                        [ 1.5611e-02, -1.7121e-02,  8.8125e-04],\n",
       "                        [-2.2552e-02, -3.4309e-02, -2.8597e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.6796e-02,  3.2238e-02,  4.4980e-02],\n",
       "                        [ 1.9905e-02, -2.8269e-02,  8.0557e-03],\n",
       "                        [-8.8761e-02, -7.1015e-02, -1.0170e-01]],\n",
       "              \n",
       "                       [[-1.1105e-02, -5.7393e-02, -6.4641e-03],\n",
       "                        [-4.0826e-02, -6.1926e-02, -3.6526e-02],\n",
       "                        [-5.1630e-02, -8.0944e-02, -4.5080e-02]],\n",
       "              \n",
       "                       [[-6.4609e-02, -8.5225e-03, -5.9021e-02],\n",
       "                        [ 4.4836e-02,  7.5375e-02,  4.8544e-02],\n",
       "                        [ 4.1624e-02,  9.3464e-02,  6.7039e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.9389e-02,  4.8539e-02,  8.5840e-02],\n",
       "                        [ 2.9569e-02,  4.1249e-02,  1.7625e-02],\n",
       "                        [-4.5169e-02, -1.0071e-01, -6.0172e-02]],\n",
       "              \n",
       "                       [[-2.9260e-02, -5.4970e-02, -4.9870e-02],\n",
       "                        [-4.9780e-02, -6.6647e-03,  6.6983e-03],\n",
       "                        [-5.5037e-02, -6.4092e-03, -3.4609e-02]],\n",
       "              \n",
       "                       [[ 8.7412e-02,  5.5105e-02,  5.9010e-02],\n",
       "                        [-1.0163e-02, -1.3180e-02, -2.2225e-02],\n",
       "                        [-2.5894e-02, -6.8413e-02, -5.6265e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0336e-02, -5.8663e-03,  2.5627e-02],\n",
       "                        [ 3.6439e-02,  1.4832e-02,  2.3641e-02],\n",
       "                        [ 7.8313e-03, -1.9043e-02, -1.9285e-02]],\n",
       "              \n",
       "                       [[ 1.5435e-01,  1.0475e-01,  1.3456e-01],\n",
       "                        [ 1.0886e-01,  4.9376e-02,  4.2451e-02],\n",
       "                        [-9.2743e-03, -7.0502e-02, -7.6000e-02]],\n",
       "              \n",
       "                       [[-7.6290e-03,  6.3104e-02, -3.5033e-03],\n",
       "                        [-3.8742e-02,  3.5503e-02, -4.9684e-02],\n",
       "                        [-1.0177e-01, -6.4619e-02, -1.5883e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3049e-02,  6.1279e-02,  5.0074e-02],\n",
       "                        [-3.8527e-02, -2.3193e-02, -2.8086e-02],\n",
       "                        [-5.4679e-02, -2.0224e-02, -1.4098e-02]],\n",
       "              \n",
       "                       [[-3.7530e-02, -6.9741e-02, -2.3459e-02],\n",
       "                        [-1.9276e-02, -5.6814e-02, -1.2904e-02],\n",
       "                        [ 5.2592e-02,  3.3004e-02,  3.5216e-02]],\n",
       "              \n",
       "                       [[-5.8410e-02, -2.2886e-02, -3.2053e-02],\n",
       "                        [-7.3035e-03, -3.8817e-02, -8.1954e-03],\n",
       "                        [ 1.6932e-03,  1.3742e-02, -7.6392e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-4.0695e-03, -1.4148e-02, -1.2213e-04],\n",
       "                        [-5.4539e-02, -6.0491e-02, -2.1562e-02],\n",
       "                        [-5.4261e-02, -6.0061e-02, -6.2087e-02]],\n",
       "              \n",
       "                       [[-7.2051e-02, -3.3394e-02, -2.6836e-02],\n",
       "                        [-5.4487e-02, -1.2019e-02, -1.0087e-02],\n",
       "                        [ 7.0735e-04,  7.0171e-03,  3.7843e-02]],\n",
       "              \n",
       "                       [[ 1.0297e-01,  9.1523e-02,  6.1391e-02],\n",
       "                        [-3.2094e-02,  2.9106e-03, -8.3848e-03],\n",
       "                        [-5.2674e-02, -8.6778e-02, -6.8391e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.9346e-02,  6.1875e-02,  4.6642e-02],\n",
       "                        [-1.7912e-03,  1.3161e-03, -4.8518e-03],\n",
       "                        [-4.5249e-02,  2.4303e-03,  1.2281e-02]],\n",
       "              \n",
       "                       [[-2.4536e-02, -4.9064e-02, -3.0009e-02],\n",
       "                        [ 4.7805e-02,  3.2606e-02, -7.6464e-03],\n",
       "                        [ 4.1986e-02,  3.3052e-02,  2.1605e-02]],\n",
       "              \n",
       "                       [[-6.8668e-02, -8.0491e-02, -8.2970e-02],\n",
       "                        [-3.8623e-02, -6.5300e-02, -7.1152e-02],\n",
       "                        [-3.0703e-02, -8.3503e-04, -3.8969e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1149e-03,  3.9709e-02,  2.9492e-02],\n",
       "                        [-6.8064e-02, -7.1409e-02, -2.5037e-02],\n",
       "                        [-7.0903e-02, -8.9650e-02, -7.3290e-02]],\n",
       "              \n",
       "                       [[ 4.8375e-02, -1.3903e-02,  1.7467e-02],\n",
       "                        [ 3.8539e-02,  2.4640e-02,  3.2465e-02],\n",
       "                        [-3.8135e-02, -6.6060e-02, -3.0767e-02]],\n",
       "              \n",
       "                       [[-1.6285e-02,  2.4335e-02, -2.4263e-02],\n",
       "                        [-2.4966e-02,  2.6745e-02, -2.3130e-02],\n",
       "                        [-8.0837e-02, -7.0704e-02, -7.7369e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.3759e-02, -4.1179e-02, -4.3488e-02],\n",
       "                        [-3.0179e-02, -7.1476e-03, -2.5191e-02],\n",
       "                        [ 1.7340e-02, -3.1599e-02, -6.2961e-04]],\n",
       "              \n",
       "                       [[ 2.7178e-02,  2.3510e-02,  3.8324e-02],\n",
       "                        [ 2.5877e-02,  5.8817e-02,  9.2815e-02],\n",
       "                        [ 7.8795e-02,  1.0072e-01,  1.3112e-01]],\n",
       "              \n",
       "                       [[-2.8865e-02, -3.7765e-02,  2.8971e-02],\n",
       "                        [ 1.3437e-02,  3.8527e-02,  4.4278e-02],\n",
       "                        [-1.6616e-02, -4.3777e-03,  3.8411e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.4029e-03,  7.6663e-03,  1.8545e-02],\n",
       "                        [ 6.8405e-02,  1.0965e-01,  7.6022e-02],\n",
       "                        [ 7.9486e-02,  1.2414e-01,  7.4817e-02]],\n",
       "              \n",
       "                       [[-3.5782e-03,  1.2330e-02, -2.8389e-03],\n",
       "                        [ 3.3706e-03,  1.5497e-02,  1.7250e-02],\n",
       "                        [-2.3481e-02, -2.1112e-02, -8.3011e-03]],\n",
       "              \n",
       "                       [[ 6.6304e-02,  1.8096e-02,  6.3936e-02],\n",
       "                        [ 6.8328e-02,  5.8837e-02,  7.6811e-02],\n",
       "                        [-1.9997e-02, -1.7378e-02, -1.3286e-02]]]], device='mps:0')),\n",
       "             ('model.7.1.weight',\n",
       "              tensor([0.9675, 1.1227, 0.9505, 0.9792, 0.8670, 1.0075, 1.0217, 0.9969, 0.9976,\n",
       "                      0.8107, 0.9353, 0.9790, 1.0015, 0.9258, 1.0368, 0.8956, 0.9118, 0.9010,\n",
       "                      1.0990, 0.9334, 0.8525, 0.8062, 0.8805, 0.9170, 1.0043, 0.8684, 1.0201,\n",
       "                      1.0005, 1.0232, 0.9896, 0.8027, 0.8861, 0.9150, 0.9570, 0.8736, 0.7612,\n",
       "                      0.5939, 0.6253, 0.9191, 1.0288, 0.7436, 0.9745, 0.9506, 1.0051, 0.8694,\n",
       "                      0.9926, 0.8788, 0.9170, 0.8358, 0.9738, 0.8432, 1.0165, 0.9400, 0.7918,\n",
       "                      0.9296, 0.7039, 0.9315, 0.9786, 0.5991, 0.6464, 0.7739, 0.8393, 0.8832,\n",
       "                      0.9610, 0.8336, 1.0620, 0.9754, 1.1158, 0.9440, 0.8312, 0.8923, 0.7150,\n",
       "                      1.0553, 0.7510, 1.0099, 1.0093, 0.7670, 1.1920, 0.7898, 1.0881, 0.8562,\n",
       "                      0.9329, 1.0688, 0.9703, 0.6822, 0.8515, 0.9583, 0.6701, 0.7661, 0.7491,\n",
       "                      0.6676, 0.7705, 0.9715, 0.8901, 0.9341, 0.8181, 0.9634, 0.9325, 0.8489,\n",
       "                      0.9321, 0.9530, 0.9211, 1.0159, 0.6856, 0.9134, 0.6189, 1.1494, 0.9075,\n",
       "                      0.9497, 0.8040, 0.9941, 1.0023, 0.6952, 0.6142, 0.7752, 0.8037, 1.0146,\n",
       "                      0.6795, 0.8229, 0.8837, 0.7624, 1.0425, 1.1014, 0.9375, 1.0194, 1.0619,\n",
       "                      0.8820, 1.0318, 0.9902, 0.8797, 1.0018, 0.8912, 0.7288, 0.7511, 1.0302,\n",
       "                      1.0637, 0.8714, 0.9398, 0.7332, 0.7498, 0.7444, 0.9964, 1.0121, 1.0214,\n",
       "                      1.0661, 1.1010, 0.9395, 0.8545, 0.6963, 0.9288, 0.8703, 0.7366, 0.8033,\n",
       "                      1.0432, 0.9577, 1.0301, 1.0357, 1.1212, 0.9146, 0.8835, 0.7933, 0.7355,\n",
       "                      0.6121, 0.8581, 0.9033, 0.6410, 0.9294, 0.7579, 0.9763, 0.6196, 0.8305,\n",
       "                      0.9989, 0.7367, 0.7182, 0.8106, 1.0546, 0.9253, 0.8100, 0.9875, 0.7990,\n",
       "                      0.9309, 0.7698, 0.9340, 1.1791, 0.9321, 1.0301, 0.8304, 0.8540, 1.0163,\n",
       "                      0.8360, 0.7153, 1.0644, 0.7483, 0.8535, 1.0328, 0.8178, 0.6414, 0.8936,\n",
       "                      0.9257, 1.0292, 1.1175, 0.9245, 0.9438, 1.1169, 1.0007, 1.0611, 0.8198,\n",
       "                      0.6578, 1.1177, 0.9248, 0.8831, 0.9267, 0.8492, 0.9321, 0.9184, 0.6631,\n",
       "                      1.0676, 0.8431, 0.9155, 0.9293, 1.0957, 0.8003, 0.9349, 0.9939, 0.8517,\n",
       "                      0.7088, 1.0490, 0.8172, 0.8282, 0.9732, 0.9923, 1.0389, 0.9256, 1.0332,\n",
       "                      1.0361, 0.9681, 0.9311, 1.0209, 0.8738, 0.9698, 0.9123, 0.9389, 0.8953,\n",
       "                      0.9298, 1.1734, 0.9290, 0.9590, 0.6831, 0.8074, 0.5237, 0.8675, 0.8996,\n",
       "                      1.0215, 1.1326, 0.9885, 0.9673], device='mps:0')),\n",
       "             ('model.7.1.bias',\n",
       "              tensor([-0.3631, -0.2535, -0.4933, -0.2911, -0.5154, -0.3594, -0.3964, -0.5251,\n",
       "                      -0.5125, -0.4565, -0.4301, -0.4195, -0.3274, -0.4769, -0.4231, -0.2692,\n",
       "                      -0.6417, -0.5386, -0.7778, -0.4097, -0.5882, -0.3741, -0.4079, -0.4366,\n",
       "                      -0.3672, -0.6616, -0.4605, -0.5837, -0.4053, -0.5818, -0.6013, -0.4677,\n",
       "                      -0.6780, -0.4626, -0.3418, -0.4844, -0.3988, -0.2979, -0.7535, -0.4268,\n",
       "                      -0.4917, -0.3264, -0.4143, -0.4697, -0.5850, -0.3086, -0.3711, -0.6802,\n",
       "                      -0.4121, -0.6085, -0.2482, -0.4463, -0.8062, -0.4348, -0.5698, -0.5209,\n",
       "                      -0.3616, -0.4922, -0.2932, -0.3203, -0.6081, -0.7090, -0.5163, -0.5407,\n",
       "                      -0.5896, -0.5831, -0.6676, -0.5157, -0.7168, -0.3995, -0.6961, -0.4851,\n",
       "                      -0.4681, -0.3496, -0.2774, -0.2923, -0.4847, -0.2635, -0.4703, -0.4654,\n",
       "                      -0.5551, -0.5421, -0.5531, -0.2778, -0.4615, -0.4270, -0.5681, -0.4005,\n",
       "                      -0.5452, -0.5952, -0.5463, -0.3357, -0.6981, -0.6524, -0.4547, -0.5307,\n",
       "                      -0.3002, -0.8021, -0.4798, -0.6531, -0.3885, -0.4805, -0.3084, -0.3684,\n",
       "                      -0.6540, -0.4146, -0.4140, -0.4019, -0.7932, -0.5788, -0.3240, -0.7795,\n",
       "                      -0.5478, -0.3913, -0.6161, -0.4759, -0.1447, -0.5430, -0.5702, -0.4835,\n",
       "                      -0.5187, -0.4749, -0.2456, -0.3872, -0.6612, -0.4473, -0.5705, -0.5146,\n",
       "                      -0.6018, -0.4247, -0.6101, -0.6984, -0.5798, -0.4584, -0.4559, -0.5827,\n",
       "                      -0.4955, -0.5527, -0.6057, -0.5652, -0.4539, -0.6581, -0.4583, -0.6554,\n",
       "                      -0.3348, -0.3056, -0.6021, -0.5355, -0.4436, -0.4183, -0.4224, -0.4843,\n",
       "                      -0.4990, -0.4588, -0.5205, -0.3869, -0.8551, -0.5169, -0.5031, -0.4082,\n",
       "                      -0.5333, -0.4860, -0.5533, -0.4498, -0.5693, -0.4342, -0.4153, -0.3920,\n",
       "                      -0.4110, -0.3813, -0.6381, -0.3633, -0.4350, -0.5351, -0.6140, -0.5995,\n",
       "                      -0.6324, -0.5977, -0.6879, -0.4875, -0.6665, -0.4264, -0.6529, -0.7651,\n",
       "                      -0.5679, -0.4144, -0.6439, -0.5457, -0.3782, -0.4351, -0.5073, -0.5471,\n",
       "                      -0.3623, -0.3947, -0.2191, -0.6344, -0.4285, -0.5190, -0.6481, -0.4989,\n",
       "                      -0.7070, -0.5802, -0.4934, -0.2108, -0.6921, -0.5497, -0.3981, -0.4961,\n",
       "                      -0.2869, -0.4953, -0.3909, -0.7479, -0.7506, -0.5584, -0.7428, -0.5841,\n",
       "                      -0.1845, -0.6970, -0.5349, -0.5148, -0.5365, -0.6355, -0.5170, -0.5247,\n",
       "                      -0.5758, -0.4382, -0.7726, -0.6694, -0.5079, -0.5408, -0.6548, -0.6612,\n",
       "                      -0.3504, -0.2096, -0.3456, -0.2435, -0.5484, -0.5911, -0.5124, -0.4016,\n",
       "                      -0.5403, -0.2215, -0.4316, -0.4712, -0.5997, -0.5339, -0.5466, -0.5285,\n",
       "                      -0.4417, -0.3767, -0.4852, -0.3781, -0.5914, -0.3974, -0.3611, -0.4404],\n",
       "                     device='mps:0')),\n",
       "             ('model.7.1.running_mean',\n",
       "              tensor([-0.6555, -1.6841, -0.8074, -1.8573, -1.3348, -1.2559, -1.0963, -0.7839,\n",
       "                      -0.7733, -0.3453, -1.9863, -1.3936, -2.0823, -0.3456, -1.2113, -1.0551,\n",
       "                      -1.2143, -1.3734, -0.4885, -1.4554, -1.1317, -0.8874, -2.0634, -0.9569,\n",
       "                      -2.2711, -1.9078, -0.8468, -0.6898, -2.6416, -0.7960, -0.6104, -1.2734,\n",
       "                      -0.6714, -1.8492, -1.5798, -1.1345, -0.3184, -0.9569, -0.3854, -0.5022,\n",
       "                      -0.4822, -1.2595, -0.3874, -1.8064, -0.9220, -1.4273, -1.9071, -1.5201,\n",
       "                      -1.4767, -1.8050, -1.8924, -0.5506, -1.1172, -1.4393,  0.0544, -0.9915,\n",
       "                      -1.0812, -1.6903, -1.3242, -1.1250, -0.9423, -0.7232, -0.8183, -0.4369,\n",
       "                      -0.4872, -1.5214, -0.8619, -1.0103, -0.5936, -1.5708, -1.5443, -1.3813,\n",
       "                      -1.2713, -1.5322, -1.2358, -2.0794, -1.1028, -0.6411, -0.6882, -0.7965,\n",
       "                      -0.8932, -1.0523, -1.8078, -1.5494, -0.2682, -1.0592, -2.3417, -1.0728,\n",
       "                      -1.2573, -0.6237, -0.8770, -1.2095, -1.5869, -0.5884, -1.2690, -0.8940,\n",
       "                      -1.0300, -1.4574,  0.9158, -1.8267, -0.4450, -1.2022, -2.2810, -0.1987,\n",
       "                      -0.5187, -0.5227, -0.3335, -1.5320, -0.4255,  0.0416, -0.1532, -1.2937,\n",
       "                      -0.9074, -0.7648, -1.1885, -0.4124, -1.3946, -1.1673, -0.5521, -1.0891,\n",
       "                      -0.6600, -1.2950, -1.2913, -2.2490, -0.4895, -1.1671, -1.6298, -0.8405,\n",
       "                      -0.5882, -2.2902, -0.7467, -1.2419, -0.7930, -1.0105, -1.5396, -1.3559,\n",
       "                       0.2114, -0.8757, -0.5745, -0.8246, -0.7537, -1.7519, -0.8622, -1.8593,\n",
       "                      -0.6234, -1.4580, -1.2905, -1.5350, -1.2270, -1.4816, -1.1138, -1.2412,\n",
       "                      -1.4718, -1.5491, -1.7276, -1.2614, -0.8606,  0.2111, -0.8306, -0.2578,\n",
       "                      -1.1774, -0.1454,  0.0453, -0.8885, -1.2955, -1.4122, -1.5175, -1.3313,\n",
       "                      -0.4546, -0.7996, -1.3150, -1.2654, -1.2870, -0.6461, -1.0462, -0.8878,\n",
       "                      -0.8947, -0.8530, -1.0887, -0.6492, -0.3391, -0.4926, -1.0511, -0.8236,\n",
       "                      -0.6541, -1.5487, -1.4966, -0.1163,  0.2459, -1.2538, -1.1806, -0.6739,\n",
       "                      -2.0794, -1.0592, -1.8548, -0.7669, -1.0098, -0.9189, -1.9149, -0.5218,\n",
       "                      -1.2524,  0.3932, -0.0250, -1.2860, -1.1513, -1.0084, -0.7118, -0.8175,\n",
       "                      -1.7773, -0.7762, -1.2448, -1.2721, -0.7212, -1.0295,  0.2190, -0.5115,\n",
       "                      -1.6553, -0.2365, -1.6499, -1.6393, -1.5411, -0.4533, -1.7174, -1.1422,\n",
       "                      -1.2922, -0.0932, -0.8124, -0.8142, -0.1430, -1.6784, -1.5711, -3.0365,\n",
       "                      -2.3976, -2.0246, -0.4032, -0.7458, -1.4214, -0.6815, -0.7927, -0.8775,\n",
       "                      -1.5740, -1.6397, -1.3682, -0.4840, -1.1867, -1.9936, -1.9949, -1.4031,\n",
       "                      -1.0557, -0.6072, -1.0122, -1.2556, -1.7868, -1.3698, -0.8597,  0.1704],\n",
       "                     device='mps:0')),\n",
       "             ('model.7.1.running_var',\n",
       "              tensor([0.9829, 1.4027, 1.0510, 1.7831, 1.1523, 1.5572, 1.0334, 1.2622, 1.6725,\n",
       "                      0.8937, 1.4009, 1.2957, 1.1115, 1.3498, 1.1917, 1.1282, 1.3961, 1.3674,\n",
       "                      1.9431, 1.0785, 1.2682, 1.1357, 1.3984, 1.6072, 1.3146, 1.5860, 1.3781,\n",
       "                      1.1044, 2.1857, 1.2687, 1.4049, 1.2430, 1.1573, 1.2344, 1.0413, 1.0435,\n",
       "                      1.2424, 1.3175, 1.3974, 1.1450, 1.2048, 1.1545, 1.1807, 1.5916, 1.2088,\n",
       "                      1.3017, 1.2250, 1.4039, 1.0721, 1.2330, 1.6546, 1.1391, 1.5601, 1.0400,\n",
       "                      1.4962, 0.9934, 0.8599, 1.1104, 1.1557, 1.1937, 0.8430, 1.4038, 1.0378,\n",
       "                      1.2170, 1.3056, 1.6450, 1.2347, 1.4771, 1.4288, 1.2105, 1.7176, 1.2423,\n",
       "                      1.7317, 1.1736, 1.0647, 1.4809, 1.0097, 1.3838, 1.6264, 1.2863, 1.1015,\n",
       "                      0.9013, 1.8438, 1.2961, 1.0801, 1.3217, 1.4647, 1.3246, 1.2514, 0.9844,\n",
       "                      1.1939, 1.2877, 1.2311, 1.5338, 1.1197, 1.4086, 1.1582, 1.6622, 1.0676,\n",
       "                      1.3275, 0.9435, 1.0982, 1.4205, 0.8226, 1.5027, 1.7053, 2.0806, 1.2883,\n",
       "                      1.4541, 0.9824, 0.9909, 1.6238, 1.8280, 1.6758, 1.5779, 1.0293, 1.2719,\n",
       "                      1.0734, 1.1838, 0.8859, 1.6214, 1.4890, 1.0071, 1.4748, 1.8360, 1.1294,\n",
       "                      1.6289, 1.4353, 1.3130, 1.7049, 1.5616, 1.2752, 1.2518, 0.8671, 1.3156,\n",
       "                      1.5499, 1.0464, 1.4211, 1.7135, 1.9433, 0.9475, 1.4147, 1.0183, 1.5593,\n",
       "                      1.3289, 1.3351, 1.1505, 1.6158, 1.4333, 1.3074, 1.3580, 1.4599, 1.2217,\n",
       "                      1.3432, 1.5867, 1.3102, 1.4224, 1.4816, 1.7894, 1.0682, 1.6374, 0.8694,\n",
       "                      1.5599, 0.8973, 1.6104, 1.1903, 0.9622, 0.9628, 1.0339, 1.2180, 1.4436,\n",
       "                      1.5732, 1.3914, 1.2750, 1.2889, 1.5073, 1.5404, 1.2277, 1.8020, 1.1398,\n",
       "                      1.4426, 0.9158, 1.8035, 2.1949, 1.1733, 1.3180, 1.5100, 1.2248, 1.2223,\n",
       "                      1.0844, 0.8742, 1.5064, 1.5284, 1.8062, 1.6403, 1.2048, 1.2073, 1.3405,\n",
       "                      1.2085, 1.1214, 1.9673, 1.7692, 1.0907, 1.2806, 1.1829, 1.4972, 0.9866,\n",
       "                      1.2293, 1.7453, 1.0302, 1.0799, 1.2489, 1.2640, 1.3757, 1.3127, 1.2886,\n",
       "                      1.6026, 1.7580, 1.1661, 1.2047, 1.4451, 1.2550, 1.4218, 1.6187, 1.5248,\n",
       "                      1.1563, 1.9787, 1.4328, 0.9431, 1.2193, 1.4249, 2.3322, 1.3269, 1.5257,\n",
       "                      1.3408, 0.8798, 1.1422, 1.1257, 1.1731, 1.2861, 1.4049, 0.8277, 1.3222,\n",
       "                      1.3853, 2.1064, 1.3436, 1.5919, 0.9468, 1.4868, 1.2504, 0.9047, 1.0434,\n",
       "                      1.3671, 1.2401, 1.1654, 1.9629], device='mps:0')),\n",
       "             ('model.7.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('model.8.0.weight',\n",
       "              tensor([[[[-3.0168e-02, -7.6708e-03, -1.5573e-02],\n",
       "                        [-9.8868e-03, -3.2023e-02, -1.9806e-02],\n",
       "                        [ 5.8903e-03, -1.3656e-03, -1.0718e-02]],\n",
       "              \n",
       "                       [[ 3.0271e-02,  6.4691e-03,  1.2573e-02],\n",
       "                        [-2.1954e-02, -2.4908e-02, -2.5616e-03],\n",
       "                        [-4.2953e-02, -3.9630e-02, -2.5609e-02]],\n",
       "              \n",
       "                       [[-2.7080e-02,  1.0444e-02,  1.6147e-02],\n",
       "                        [-4.1309e-02, -2.4608e-02, -3.2125e-02],\n",
       "                        [-4.9239e-02, -4.2255e-02, -5.4569e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1926e-02, -2.0021e-02, -4.7760e-02],\n",
       "                        [-4.8920e-03, -2.8714e-02, -2.6230e-02],\n",
       "                        [-2.8033e-02,  7.1174e-04, -2.9601e-02]],\n",
       "              \n",
       "                       [[-3.2270e-02, -1.6481e-02, -1.1581e-02],\n",
       "                        [ 1.0719e-02, -9.6610e-03, -3.9159e-02],\n",
       "                        [ 2.8188e-02, -4.7967e-03, -7.2376e-03]],\n",
       "              \n",
       "                       [[ 6.9307e-03,  1.4343e-02,  1.5391e-03],\n",
       "                        [ 1.8817e-02,  7.5693e-03,  2.3330e-02],\n",
       "                        [ 4.7858e-03,  1.6419e-02,  7.0070e-06]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.9061e-03, -1.2735e-02, -1.6869e-03],\n",
       "                        [ 5.6892e-03, -2.4985e-02, -6.2826e-03],\n",
       "                        [ 6.2254e-03, -3.5305e-02, -1.7403e-02]],\n",
       "              \n",
       "                       [[ 4.8222e-03,  3.6315e-04,  4.4588e-03],\n",
       "                        [-3.1164e-02, -4.4497e-02, -1.5847e-02],\n",
       "                        [-2.0965e-02, -3.9476e-03, -1.7445e-02]],\n",
       "              \n",
       "                       [[ 5.3467e-03,  2.4315e-02,  7.4126e-03],\n",
       "                        [-8.2150e-03, -1.5851e-02, -6.2708e-03],\n",
       "                        [-3.6171e-02, -1.2939e-03, -1.4976e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.3617e-03,  7.1514e-04,  1.7155e-02],\n",
       "                        [-1.0853e-02, -1.2416e-02, -1.8132e-02],\n",
       "                        [-1.4768e-02, -1.0473e-02, -2.8021e-02]],\n",
       "              \n",
       "                       [[-3.8187e-03,  2.2462e-02,  2.8636e-02],\n",
       "                        [-6.9663e-03,  3.5659e-03,  3.9363e-02],\n",
       "                        [ 1.3404e-02, -1.6896e-02,  1.1430e-02]],\n",
       "              \n",
       "                       [[-1.0430e-03,  9.1268e-03,  1.0148e-02],\n",
       "                        [-2.6466e-02, -2.3425e-02, -1.0852e-02],\n",
       "                        [-5.3916e-02, -3.9715e-02, -3.4506e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.7843e-02, -5.0821e-02, -4.5108e-02],\n",
       "                        [-6.2374e-02, -5.5430e-02, -4.0633e-02],\n",
       "                        [-2.5661e-02, -4.3405e-02, -1.7859e-02]],\n",
       "              \n",
       "                       [[ 1.0539e-02, -3.7343e-02, -2.6692e-02],\n",
       "                        [-1.8067e-02, -7.1004e-02, -3.6903e-02],\n",
       "                        [-4.1934e-02, -6.0858e-02, -4.8291e-02]],\n",
       "              \n",
       "                       [[ 1.8932e-03, -7.6767e-03, -2.2510e-03],\n",
       "                        [-4.7701e-02, -3.8065e-02, -6.0919e-03],\n",
       "                        [-3.3916e-03,  6.6357e-04, -3.6400e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-5.7771e-02, -6.7366e-02, -4.5924e-02],\n",
       "                        [-6.4883e-02, -7.1817e-02, -8.3660e-02],\n",
       "                        [-6.4472e-02, -7.8665e-02, -4.9041e-02]],\n",
       "              \n",
       "                       [[ 2.2448e-02, -7.9445e-03, -2.5902e-02],\n",
       "                        [-3.0015e-02, -5.3157e-02, -4.2718e-02],\n",
       "                        [-8.5998e-03, -2.3035e-02, -1.2705e-02]],\n",
       "              \n",
       "                       [[-1.9064e-02, -3.4704e-02, -1.7819e-02],\n",
       "                        [-3.0182e-02, -4.5836e-02, -5.9080e-02],\n",
       "                        [-3.8873e-02, -3.4770e-02, -1.6886e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 5.8702e-03,  6.8515e-03, -2.0388e-03],\n",
       "                        [-1.0833e-02, -1.8401e-02, -2.4071e-02],\n",
       "                        [-4.0374e-03, -8.0181e-03, -2.3214e-02]],\n",
       "              \n",
       "                       [[-2.1485e-02, -1.1634e-02, -6.1990e-03],\n",
       "                        [-1.2291e-02, -6.3019e-02, -1.5111e-02],\n",
       "                        [-1.7218e-02, -3.4021e-02,  4.8477e-03]],\n",
       "              \n",
       "                       [[-8.4766e-03, -3.5826e-02, -3.5586e-03],\n",
       "                        [-5.2973e-02, -3.0279e-02, -9.8959e-03],\n",
       "                        [-2.1247e-02, -1.1753e-02, -9.0205e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 3.2522e-02,  3.6628e-03,  3.7974e-02],\n",
       "                        [ 2.3555e-02, -2.8655e-02,  1.1324e-02],\n",
       "                        [ 3.2601e-02,  2.9777e-04,  3.1403e-03]],\n",
       "              \n",
       "                       [[ 1.8980e-02,  3.3130e-02,  2.6358e-02],\n",
       "                        [ 1.5671e-02, -1.7249e-02,  2.9767e-02],\n",
       "                        [-1.8166e-02, -1.2555e-02, -1.0856e-02]],\n",
       "              \n",
       "                       [[-7.3598e-03,  1.9659e-02,  1.4315e-02],\n",
       "                        [ 2.0768e-03, -3.3350e-02, -9.2786e-03],\n",
       "                        [-5.8694e-02, -3.0899e-02, -4.6824e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.4034e-02, -3.7698e-02, -1.3985e-03],\n",
       "                        [-2.5831e-02, -2.5119e-02, -1.2089e-02],\n",
       "                        [-2.5191e-02,  4.1643e-03, -2.2906e-02]],\n",
       "              \n",
       "                       [[ 3.6644e-02,  3.1997e-04,  1.7653e-02],\n",
       "                        [ 2.1408e-02, -1.2411e-02, -2.5772e-02],\n",
       "                        [ 2.5596e-02, -2.2725e-02,  1.8071e-02]],\n",
       "              \n",
       "                       [[-2.2227e-02,  4.5408e-03, -1.2287e-02],\n",
       "                        [-1.3711e-02, -3.8088e-02, -2.4859e-02],\n",
       "                        [-2.9436e-02, -2.8553e-02, -3.6893e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.7718e-02, -2.7182e-02, -3.0649e-02],\n",
       "                        [-5.9171e-02, -5.2970e-02, -4.7795e-02],\n",
       "                        [-1.3224e-02, -2.2334e-02, -4.1423e-02]],\n",
       "              \n",
       "                       [[-1.6268e-02, -1.4023e-02, -1.3823e-02],\n",
       "                        [-2.4447e-02, -4.9765e-03, -4.2601e-02],\n",
       "                        [-2.1630e-02, -1.7375e-02, -4.9212e-03]],\n",
       "              \n",
       "                       [[-5.0970e-02, -4.8046e-02, -5.9222e-02],\n",
       "                        [-8.3811e-02, -7.6556e-02, -7.2725e-02],\n",
       "                        [-1.5504e-02, -3.9333e-02, -3.6030e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.8928e-02, -4.8646e-03,  7.5118e-03],\n",
       "                        [-4.7823e-02, -4.2544e-02, -3.0703e-02],\n",
       "                        [-7.9526e-04, -1.1317e-02, -1.5849e-02]],\n",
       "              \n",
       "                       [[-4.1966e-03, -1.8554e-02, -1.9337e-02],\n",
       "                        [-4.7693e-02, -3.2356e-02, -2.8931e-02],\n",
       "                        [-1.7698e-02, -1.1199e-02, -1.9506e-05]],\n",
       "              \n",
       "                       [[-5.5008e-02, -5.6039e-02, -5.7755e-03],\n",
       "                        [-5.0614e-02, -5.8016e-02, -2.5962e-02],\n",
       "                        [ 4.0553e-06, -4.3726e-02, -7.4586e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.9035e-02,  3.1074e-02,  1.5538e-02],\n",
       "                        [-1.2119e-02,  1.9834e-02,  1.1956e-02],\n",
       "                        [ 7.8825e-03, -1.5554e-02,  2.5736e-02]],\n",
       "              \n",
       "                       [[ 7.0239e-03, -1.1370e-02, -2.9957e-02],\n",
       "                        [ 6.5035e-03,  5.1479e-03, -4.3408e-03],\n",
       "                        [ 8.9171e-03,  1.4371e-03, -1.5489e-02]],\n",
       "              \n",
       "                       [[ 2.2683e-02,  1.8384e-02,  1.2628e-02],\n",
       "                        [ 4.6655e-03, -2.0947e-03,  8.1952e-03],\n",
       "                        [-4.0643e-03, -1.3595e-02, -1.0407e-02]]]], device='mps:0')),\n",
       "             ('model.8.1.weight',\n",
       "              tensor([1.0308, 0.8874, 1.1690, 1.0939, 0.9597, 1.0182, 1.0422, 1.0519, 1.0254,\n",
       "                      0.9102, 0.8797, 1.0252, 0.9971, 0.9420, 1.0300, 0.8791, 1.0207, 0.8250,\n",
       "                      1.0679, 1.0767, 1.0078, 0.9794, 1.0096, 0.9176, 0.8638, 1.0283, 0.9737,\n",
       "                      1.2252, 1.0279, 0.9214, 0.9660, 0.8590, 0.9516, 1.0178, 1.0257, 1.0721,\n",
       "                      0.9995, 1.1100, 0.9444, 1.0553, 1.0520, 1.0258, 1.1414, 0.9887, 0.9818,\n",
       "                      0.9086, 1.1466, 1.0036, 1.1037, 1.0161, 0.8205, 1.2591, 0.8926, 0.8514,\n",
       "                      1.0578, 0.8890, 0.9357, 1.3010, 0.8723, 0.8431, 0.8837, 1.2148, 0.8862,\n",
       "                      0.9405, 0.9404, 1.1990, 1.0773, 1.0639, 0.8848, 0.9433, 1.0363, 1.0046,\n",
       "                      1.0270, 0.9579, 1.1859, 0.9207, 1.1511, 1.3795, 1.2800, 1.0925, 1.0532,\n",
       "                      0.9058, 1.1037, 1.1546, 1.4678, 0.8637, 1.0895, 0.9946, 0.8525, 1.0097,\n",
       "                      1.0130, 1.0805, 0.9000, 0.9938, 0.9160, 0.9015, 0.9371, 0.8111, 1.3362,\n",
       "                      0.9495, 1.1069, 0.9501, 0.9961, 0.9890, 1.1570, 0.9527, 1.0031, 1.0758,\n",
       "                      1.1379, 0.9681, 1.0346, 1.2044, 1.0579, 0.8749, 0.9119, 0.9735, 0.8443,\n",
       "                      1.0533, 1.0377, 1.1058, 1.0459, 1.1998, 1.0271, 1.1396, 1.0182, 0.9188,\n",
       "                      0.9236, 0.8104, 1.0594, 1.0661, 1.0839, 0.9170, 1.0707, 0.8988, 1.1952,\n",
       "                      0.9974, 1.0785, 0.8823, 0.9564, 1.0571, 0.9317, 1.0122, 0.8481, 0.9531,\n",
       "                      0.8810, 1.2565, 1.1384, 1.1721, 1.0015, 0.8507, 1.0699, 1.0163, 1.2615,\n",
       "                      0.8918, 1.0795, 0.9757, 0.8327, 0.9575, 0.8884, 0.8958, 1.2742, 1.0658,\n",
       "                      1.2866, 1.0630, 1.1079, 1.2583, 0.9767, 0.9718, 0.9714, 1.0285, 0.8815,\n",
       "                      0.9229, 0.9334, 1.0596, 0.8340, 0.8687, 1.1986, 0.8790, 1.0460, 1.0660,\n",
       "                      1.1495, 1.0142, 1.0247, 0.9169, 1.1923, 1.1508, 0.9166, 1.0844, 1.0570,\n",
       "                      1.0437, 0.9492, 1.0880, 1.1078, 1.1288, 1.1991, 1.0240, 0.9840, 1.1613,\n",
       "                      1.1755, 0.9921, 1.2538, 0.8211, 1.0968, 1.0313, 0.9014, 0.8620, 1.0041,\n",
       "                      0.8604, 0.8378, 0.9413, 0.9620, 1.0918, 0.9267, 0.8885, 1.0364, 0.9624,\n",
       "                      0.8983, 1.0512, 1.4554, 0.9081, 0.9179, 0.8989, 1.1124, 0.7234, 0.8016,\n",
       "                      0.9833, 1.1875, 0.9908, 0.9968, 0.9409, 1.0454, 1.1355, 0.9838, 1.0515,\n",
       "                      1.0068, 1.2345, 0.9344, 1.0950, 0.9760, 0.8508, 0.8350, 1.2071, 1.0936,\n",
       "                      1.1375, 0.9939, 0.9701, 1.0758, 0.9567, 1.1311, 0.8718, 1.2685, 1.0941,\n",
       "                      0.7996, 1.0430, 0.9925, 1.0784], device='mps:0')),\n",
       "             ('model.8.1.bias',\n",
       "              tensor([-0.4297, -0.5306, -0.6522, -0.9460, -0.5909, -0.6346, -0.3648, -0.4678,\n",
       "                      -0.6528, -0.5129, -0.4458, -0.5373, -0.6273, -0.6467, -0.6617, -0.4957,\n",
       "                      -0.5592, -0.4778, -0.4642, -0.5432, -0.5031, -0.5746, -0.5194, -0.4136,\n",
       "                      -0.4350, -0.5166, -0.4099, -0.8586, -0.5386, -0.4165, -0.3852, -0.6161,\n",
       "                      -0.4731, -0.4703, -0.5774, -0.6953, -0.5967, -0.5666, -0.4505, -0.5691,\n",
       "                      -0.6166, -0.4949, -0.5010, -0.4893, -0.2954, -0.5817, -0.7623, -0.5835,\n",
       "                      -0.6048, -0.4831, -0.4075, -0.8801, -0.5465, -0.5924, -0.5974, -0.4542,\n",
       "                      -0.5365, -0.7509, -0.5065, -0.5472, -0.5536, -0.9623, -0.4126, -0.6254,\n",
       "                      -0.5301, -0.6219, -0.6780, -0.5267, -0.5273, -0.3749, -0.4525, -0.5350,\n",
       "                      -0.7062, -0.5382, -0.5854, -0.4124, -0.7003, -0.7501, -0.6699, -0.5676,\n",
       "                      -0.4915, -0.5154, -0.5079, -0.6253, -1.0708, -0.3795, -0.5496, -0.4179,\n",
       "                      -0.4856, -0.5466, -0.3663, -0.7055, -0.6357, -0.6861, -0.5295, -0.6710,\n",
       "                      -0.5037, -0.5149, -0.6724, -0.4119, -0.7595, -0.4505, -0.6070, -0.4635,\n",
       "                      -0.6386, -0.5070, -0.4414, -0.4363, -0.8381, -0.5448, -0.4918, -0.3434,\n",
       "                      -0.5887, -0.4095, -0.7194, -0.5968, -0.4249, -0.5259, -0.3846, -0.7521,\n",
       "                      -0.5495, -0.7547, -0.4687, -0.4553, -0.5425, -0.4854, -0.4703, -0.4409,\n",
       "                      -0.4465, -0.6088, -0.4162, -0.5630, -0.5933, -0.5668, -0.7198, -0.3739,\n",
       "                      -0.4954, -0.4415, -0.5833, -0.5773, -0.4115, -0.5750, -0.6064, -0.4999,\n",
       "                      -0.5046, -0.7538, -0.5424, -0.2867, -0.4727, -0.6023, -0.4670, -0.5892,\n",
       "                      -0.8211, -0.4967, -0.6999, -0.5581, -0.4762, -0.4887, -0.3881, -0.6685,\n",
       "                      -0.5463, -0.4625, -0.6814, -0.6130, -0.5760, -0.5286, -0.5229, -0.5419,\n",
       "                      -0.4914, -0.5513, -0.5305, -0.6109, -0.3773, -0.6094, -0.4505, -0.4551,\n",
       "                      -0.6951, -0.5618, -0.5203, -0.4814, -0.6877, -0.6259, -0.4978, -0.6259,\n",
       "                      -0.5890, -0.6354, -0.4739, -0.4595, -0.6090, -0.5328, -0.4235, -0.6749,\n",
       "                      -0.7384, -0.7435, -0.6458, -0.7893, -0.4314, -0.4818, -0.3246, -0.6784,\n",
       "                      -0.7593, -0.4083, -0.5982, -0.5051, -0.5719, -0.5169, -0.5252, -0.4735,\n",
       "                      -0.4891, -0.5337, -0.4350, -0.6003, -0.6640, -0.4913, -0.5520, -0.6375,\n",
       "                      -0.5353, -0.6208, -1.2581, -0.5395, -0.4945, -0.5444, -0.4623, -0.4866,\n",
       "                      -0.4639, -0.3255, -0.6739, -0.5035, -0.6120, -0.6378, -0.4831, -0.4154,\n",
       "                      -0.5791, -0.4852, -0.5985, -0.9302, -0.5191, -0.6362, -0.5885, -0.4418,\n",
       "                      -0.4797, -0.6341, -0.6760, -0.6201, -0.7298, -0.5507, -0.3566, -0.6133,\n",
       "                      -0.6768, -0.4960, -0.5479, -0.6586, -0.4764, -0.5067, -0.6405, -0.6827],\n",
       "                     device='mps:0')),\n",
       "             ('model.8.1.running_mean',\n",
       "              tensor([-0.4941, -1.0094, -1.7038, -1.0933, -0.2052, -0.6391, -0.4792, -0.4224,\n",
       "                      -1.0133, -0.7561, -0.9313, -0.7992, -1.1958, -0.2733, -0.6834, -1.1708,\n",
       "                      -1.4565, -0.9840, -0.5442, -1.2844, -0.8634, -0.7614, -0.8149, -0.7377,\n",
       "                      -0.8901, -1.0905, -0.1318, -1.6965, -1.2550, -0.1603, -0.4412, -0.4027,\n",
       "                      -1.1215, -0.1332, -1.5407, -0.7312, -0.6987, -1.3687, -1.6190, -1.6145,\n",
       "                      -0.6750, -1.2861, -0.0686, -0.8464, -0.4286, -0.3853, -0.8645, -0.3802,\n",
       "                      -0.6891, -0.1906, -0.8926, -0.7729, -1.2678, -0.7436, -1.3636, -0.7532,\n",
       "                      -0.6793, -0.8838, -0.7856, -1.1342,  0.3065, -0.7740, -0.8689, -0.7690,\n",
       "                      -1.4846, -1.8971, -1.2731, -1.5975, -1.0179, -1.6392, -0.7223, -0.6726,\n",
       "                      -1.6052, -1.1385, -1.1608, -1.5979, -1.0783, -0.0740, -1.6524, -1.3062,\n",
       "                      -0.9039, -1.0959, -1.3106, -1.6887, -0.1421, -0.8588, -1.4282, -1.2323,\n",
       "                      -0.6870, -0.9969, -0.3731, -0.4749, -1.0172, -0.2783, -0.7414, -0.6548,\n",
       "                      -1.0883, -0.9434, -0.9272, -0.8400, -1.3631, -1.2235,  0.0030, -0.6526,\n",
       "                      -1.2325, -0.9278, -1.6742, -0.7637, -0.6251, -1.1302, -0.8258, -1.3936,\n",
       "                      -1.0333, -1.0198, -0.6443, -1.2059, -1.0648, -0.6850, -0.2598, -1.3440,\n",
       "                      -1.1077, -1.2384, -1.3569, -1.2979, -0.8110, -1.4729, -1.2413, -0.5510,\n",
       "                      -0.4350, -0.5714, -0.4959, -0.3828, -1.4676, -1.1333, -1.9143, -0.8810,\n",
       "                      -1.0257, -1.2960, -0.6164, -0.6843, -0.7134, -1.1263, -0.8478, -0.6832,\n",
       "                      -1.1148, -1.0303, -1.0954, -0.5106, -0.7351, -0.6655, -0.7223, -0.8696,\n",
       "                      -1.2527, -0.9287, -1.1434, -1.2369, -1.0862, -0.7628, -1.1860, -0.3517,\n",
       "                      -0.4351, -0.4609, -2.0867, -1.2452, -0.9814, -1.5421, -0.4826, -0.6479,\n",
       "                      -1.3353, -0.6166, -1.2609, -1.1498, -0.3941, -0.9518, -1.3849, -0.8849,\n",
       "                      -1.5015, -0.3610, -0.2098, -0.2693, -0.9152, -0.2270, -1.0735, -1.4492,\n",
       "                      -0.1947, -0.6456, -0.4786, -0.1632, -1.2389, -1.1187, -0.5968, -0.2930,\n",
       "                      -1.0498, -1.4973, -1.6538, -1.1066, -0.8791, -0.8750, -0.8764, -0.9775,\n",
       "                      -1.2535, -1.1121, -1.3016, -0.8005, -0.7101, -0.9187, -0.2567, -1.1557,\n",
       "                      -0.8811, -0.6118, -1.4393, -1.8863, -0.4922, -0.8364, -1.1875, -0.3090,\n",
       "                      -1.5371, -0.9290, -0.8305, -0.9168, -0.9670, -0.9073, -0.3790, -0.5844,\n",
       "                      -1.5206, -0.9008, -1.2376, -0.1514, -1.7173, -1.0512, -1.9179, -0.4761,\n",
       "                      -1.2766, -0.4609, -0.8908, -1.1010, -1.2556, -0.4665, -0.5917, -0.7208,\n",
       "                      -0.7762, -1.4240, -1.3414, -1.0601, -1.0455, -0.5723, -0.2770, -0.9137,\n",
       "                      -1.0671, -1.4327, -0.7263, -1.3254, -1.1180, -2.0386, -1.1148, -0.1366],\n",
       "                     device='mps:0')),\n",
       "             ('model.8.1.running_var',\n",
       "              tensor([1.4486, 0.9410, 1.9336, 1.8464, 0.7545, 1.1844, 2.0913, 1.9786, 1.4301,\n",
       "                      0.7836, 0.7025, 1.4848, 1.2630, 0.7371, 1.1402, 0.7764, 1.3917, 0.9301,\n",
       "                      2.0012, 1.0894, 1.8083, 1.1755, 0.6608, 1.4172, 0.8511, 1.1616, 1.9248,\n",
       "                      1.7294, 1.2275, 1.0325, 1.3673, 0.6833, 1.3174, 1.0913, 1.1091, 1.5753,\n",
       "                      1.5667, 2.0198, 1.2408, 1.3926, 1.6969, 1.0224, 2.6325, 1.6065, 1.3534,\n",
       "                      0.7884, 1.4172, 1.1191, 1.8695, 1.9037, 0.7170, 2.5935, 0.8115, 0.6250,\n",
       "                      1.3450, 0.9900, 1.0555, 1.9741, 0.4291, 1.0998, 1.3793, 2.3187, 1.0527,\n",
       "                      0.9273, 1.0971, 2.0150, 1.4723, 1.3347, 0.5419, 1.2895, 1.2344, 0.9124,\n",
       "                      1.3229, 1.4740, 1.7842, 1.0743, 1.8532, 4.2239, 3.1490, 1.5755, 1.2016,\n",
       "                      1.1128, 2.0294, 2.3130, 2.3699, 0.7994, 1.9352, 1.3770, 0.6520, 1.1812,\n",
       "                      2.0382, 1.5768, 0.9825, 0.9533, 0.8271, 1.1481, 0.8781, 0.7549, 1.9215,\n",
       "                      1.1129, 1.6512, 1.4645, 2.0936, 1.7363, 2.0574, 1.4335, 1.6929, 2.4693,\n",
       "                      1.6423, 1.5502, 1.9099, 2.5104, 1.4948, 0.8968, 0.9023, 1.0435, 0.6639,\n",
       "                      2.0681, 1.8700, 2.4401, 1.0850, 2.3445, 1.3905, 2.7239, 1.3116, 1.0093,\n",
       "                      1.1597, 0.4427, 1.9121, 1.2763, 1.8084, 0.8658, 1.2189, 0.7377, 1.8883,\n",
       "                      1.4138, 1.6949, 0.5872, 0.6841, 0.9259, 1.2526, 0.8595, 0.9855, 0.8502,\n",
       "                      0.5589, 2.9702, 1.8585, 2.5343, 1.5037, 0.6117, 2.3511, 1.0088, 1.8796,\n",
       "                      0.7482, 1.6115, 1.5352, 0.8302, 1.2797, 0.9398, 0.9961, 2.4591, 1.8624,\n",
       "                      2.2100, 1.7028, 2.4314, 2.3245, 1.3403, 0.9439, 0.8248, 1.3867, 1.1654,\n",
       "                      0.8723, 1.3498, 2.1462, 0.7504, 0.6136, 2.6036, 0.7964, 1.4090, 1.6043,\n",
       "                      1.3164, 1.2661, 2.0636, 0.8865, 2.5826, 1.9045, 1.5928, 1.2491, 1.3145,\n",
       "                      0.9583, 1.3678, 1.4880, 1.8180, 1.4515, 1.9290, 1.2365, 0.9649, 2.0984,\n",
       "                      2.5091, 0.8113, 2.4730, 0.4708, 1.8647, 1.6986, 0.8772, 0.8933, 1.3446,\n",
       "                      0.7136, 0.8453, 0.9925, 0.8827, 1.6811, 0.9046, 0.7479, 1.3585, 0.8767,\n",
       "                      0.9858, 1.6682, 2.7497, 1.0419, 0.9196, 0.9028, 2.4798, 0.6961, 0.7325,\n",
       "                      1.2366, 2.3166, 1.2347, 1.5441, 0.7337, 1.6086, 2.1972, 0.9934, 2.5463,\n",
       "                      0.9574, 1.9913, 1.3071, 1.9962, 1.0894, 0.7424, 0.8064, 2.2150, 1.6131,\n",
       "                      2.0072, 1.4788, 1.4969, 2.3147, 0.8446, 1.9977, 0.8550, 3.4108, 1.3492,\n",
       "                      0.5936, 1.6755, 1.4523, 1.3157], device='mps:0')),\n",
       "             ('model.8.1.num_batches_tracked', tensor(22484., device='mps:0')),\n",
       "             ('classifier.weight',\n",
       "              tensor([[ 0.2539, -0.4129, -0.4710,  ..., -0.4428,  0.2303,  0.4016],\n",
       "                      [ 0.1029,  0.1596, -0.3664,  ..., -0.2843, -0.4157,  0.2217],\n",
       "                      [-0.5143, -0.1243,  0.5136,  ..., -0.0231,  0.6600, -0.4438],\n",
       "                      ...,\n",
       "                      [-0.2359, -0.4257, -0.5459,  ...,  0.6352, -0.4225, -0.0575],\n",
       "                      [ 0.6336, -0.2844, -0.2890,  ..., -0.3333, -0.1888, -0.2694],\n",
       "                      [ 0.2781,  0.1640,  0.0090,  ...,  0.6026, -0.0594, -0.3741]],\n",
       "                     device='mps:0')),\n",
       "             ('classifier.bias',\n",
       "              tensor([ 0.3287, -0.6605,  0.4113,  0.5110,  0.0181, -0.2609,  0.0303,  0.1200,\n",
       "                      -0.0530, -0.3119], device='mps:0'))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_classes_no_defense.avg_weight_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4902aef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n",
      "swapping and limiting\n",
      "\n",
      "Files already downloaded and verified\n",
      "Resuming from snapshot!\n",
      "\n",
      "Restoring devices\n",
      "\n",
      "Finished restoring\n",
      "\n",
      "Round:  100\n",
      "Attacking!\n",
      "\n",
      "(Device 2/Epoch 0) Train Loss: 0.455 | Train Acc: 91.550 | Test Loss: 0.072 | Test Acc: 97.850\n",
      "(Device 2/Epoch 1) Train Loss: 0.041 | Train Acc: 98.600 | Test Loss: 0.082 | Test Acc: 97.500\n",
      "Confirm the attack worked. (This should be high)\n",
      " | Test Loss: 0.082 | Test Acc: 97.500\n",
      "Finished attacking\n",
      "\n",
      " | Test Loss: 0.513 | Test Acc: 81.870\n",
      "\n",
      "Diff: 0.0\n",
      "\n",
      "Round time: 41.35078501701355 \n",
      "\n",
      "Writing snapshot\n",
      "\n",
      "Total training time: 51.71305704116821 seconds\n",
      "Writing file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sca_zero_one = switch_classes_attack(0,1,2)\n",
    "baseline = load_result(\"baseline.pickle\")\n",
    "switch_classes_no_defense_fixed = run_federated_test(                    \n",
    "                                         rounds = 101, # go 30 pounds past where the baseline left off              \n",
    "                                         local_epochs = 0,        # all else the same                     \n",
    "                                         num_devices = 50,         \n",
    "                                         device_pct = 0.2,          \n",
    "                                         data_pct = 0.1,           \n",
    "                                         net = ConvNet().to(mps),  \n",
    "                                         evil_round = 110, # attack after 10 rounds more training with the new acc fn        \n",
    "                                         attacker_strategy = sca_zero_one, # device 2 will carry out big noise attack  \n",
    "                                         evil_device_id = 2,     \n",
    "                                         evaluate_attack = None, # we will evaluate manually afterwards \n",
    "                                         output_filename = \"switch_classes_no_defense_multiple_final_fixed.pickle\",\n",
    "                                         resume_from_snap = baseline, #pick up where baseline left off  \n",
    "                                         snapshot = True, \n",
    "                                         multiple_attack_rounds = [100,101,102,103,104,105,106,107,108,109]) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4e9a4a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_classes_no_defense_fixed = load_result(\"snapshot_switch_classes_no_defense_multiple_final_fixed.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c30ae876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_device = make_test_device(trainset)\n",
    "test_device['net'].load_state_dict(switch_classes_no_defense_fixed.avg_weight_history[100])\n",
    "checker_test_set = make_testloader_subset(list(range(0,2)), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8b9fdeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | Test Loss: 0.678 | Test Acc: 73.050\n"
     ]
    }
   ],
   "source": [
    "test(0, test_device, nn.CrossEntropyLoss(), checker_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc740e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
